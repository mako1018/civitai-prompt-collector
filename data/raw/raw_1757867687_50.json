[
  {
    "id": "257749",
    "prompt": "Pony Diffusion V6 XL\n<p><a target=\"_blank\" rel=\"ugc\" href=\"https://fictional.ai/?ref=v6-card\"><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0061ed7a-2afa-4513-b855-e0e82d78b3cb/width=525/0061ed7a-2afa-4513-b855-e0e82d78b3cb.jpeg\" /></a>(and don't worry, coming to your computer very soon - Astra)</p><p></p><h2 id=\"pony-diffusion-v6-is-a-versatile-sdxl-finetune-capable-of-producing-stunning-sfw-and-nsfw-visuals-of-various-anthro-feral-or-humanoids-species-and-their-interactions-based-on-simple-natural-language-prompts.-9rf16zav8\">Pony Diffusion V6 is a versatile SDXL finetune capable of producing stunning SFW and NSFW visuals of various anthro, feral, or humanoids species and their interactions based on simple natural language prompts.</h2><p>CHECK \"ABOUT THIS VERSION\" ON THE RIGHT IF YOU ARE NOT ON \"V6\" FOR IMPORTANT INFORMATION.</p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/pYsdjMfu3q\">Please join our Discord Server to support development of new versions of this model and get access to free SD bot </a>and <a target=\"_blank\" rel=\"ugc\" href=\"https://purplesmart.ai/collection/top?nsfw=0&amp;page=1&amp;model=11&amp;order=created_desc\">check out more examples of this model capabilities on our prompt sharing website </a>or <a target=\"_blank\" rel=\"ugc\" href=\"https://twitter.com/AstraliteHeart\">follow the author on Twitter</a>.</p><h2 id=\"important-information-rzlb1z46m\">Important information</h2><p></p><p><strong>Make sure you load this model with clip skip 2 (or -2 in some software), otherwise you will be getting low quality blobs.</strong></p><p></p><p><span style=\"color:rgb(219, 222, 225)\">This model supports a wide array of styles and aesthetics but provides an opinionated default prompt template that allows generation of high quality samples with no negative prompt and otherwise default settings</span></p><pre><code>score_9, score_8_up, score_7_up, score_6_up, score_5_up, score_4_up, just describe what you want, tag1, tag2</code></pre><p>(previous Pony Diffusion models used a simpler <code>score_9</code> quality modifier, the longer version of V6 XL version is a training issue that was too late to correct during training, you can still use <code>score_9</code> but it has a much weaker effect compared to full string. You can learn more about these tags <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/4248\">here</a>).</p><p></p><p>The model is designed to not need negative prompts in most cases and does not need other quality modifiers like \"hd\", \"masterpiece\", etc...</p><p></p><p>Other special data selection tags include, 'source_pony', 'source_furry', 'source_cartoon' and 'source_anime' and ratings of 'rating_safe', 'rating_questionable' and 'rating_explicit'.</p><p></p><p><strong>This model is capable of recognizing many popular and obscure characters and series.</strong></p><p></p><p>If you are looking specifically for pony style, I recommend using one of the two following templates `anthro/feral pony, rest of the prompt` or `source_pony, rest of the prompt`.</p><p></p><p>This model is trained on combination of natural language prompts and tags and is capable of understanding both, so describing intended result using normal language works in most cases, although you can add some tags after the main prompt to boost them.</p><p></p><p>Using Euler a with 25 steps and resolution of 1024px is recommended although model generally can do most supported SDXL resolution.</p><p></p><p>This model will sometimes generate pseudo signatures that are hard to remove even with negative prompts, this is unfortunately a training issue that would be corrected in future models. If that's an issue for you I suggest trying V5.5 or inpainting.</p><p></p><h2 id=\"special-thanks-a8immpgql\">Special thanks</h2><ul><li><p><strong>Iceman</strong> for helping to procure necessary training resources</p></li><li><p><strong>Haru</strong> for assistance with captioning efforts</p></li><li><p><strong>Cookie</strong> for technical expertise in training</p></li><li><p><strong>PSAI Server Subscribers</strong> for supporting the project costs</p></li><li><p><strong>PSAI Server Moderators</strong> for being vigilant and managing the community</p></li></ul><h2 id=\"technical-details-jb1ydvwaq\">Technical details</h2><p>The model has been trained on ~2.6M images aesthetically ranked based on authors personal preferences, with roughly 1:1 ratio between anime/cartoon/furry/pony datasets and 1:1 ratio between safe/questionable/explicit ratings. About 50% of all images has been captioned with high quality detailed captions, which results in very strong natural language capabilities.</p><p></p><p>All images has been trained with both captions (when available) and tags, artists' names have been removed and source data has been filtered based on our Opt-in/Opt-out <a target=\"_blank\" rel=\"ugc\" href=\"https://purplesmart.ai/artist\">program</a>. Any explicit content involving underage characters has been filtered out.</p><h2 id=\"license-ubky7ouqn\">License</h2><p>This model is licensed under a modified <span style=\"color:rgb(193, 194, 197)\">Fair AI Public License 1.0-SD</span><a target=\"_blank\" rel=\"ugc\" href=\"https://freedevproject.org/faipl-1.0-sd/\"> </a><span style=\"color:rgb(193, 194, 197)\">(</span><a target=\"_blank\" rel=\"ugc\" href=\"https://freedevproject.org/faipl-1.0-sd/\">https://freedevproject.org/faipl-1.0-sd/</a><span style=\"color:rgb(193, 194, 197)\">) license</span>.</p><p></p><p><strong>The following modifications have been added to <span style=\"color:rgb(193, 194, 197)\">Fair AI Public License</span>:</strong></p><p>You are not permitted to run inference of this model on websites or applications allowing any form of monetization (paid inference, faster tiers, etc.). This applies to any derivative models or model merges.</p><p>If you want to use this model commercially, please reach us at <a target=\"_blank\" rel=\"ugc\" href=\"mailto:contact@purplesmart.ai\">contact@purplesmart.ai</a>.</p><p>Explicit permission for commercial inference has been granted to <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/\">CivitAi </a>and <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/\"><u>Hugging Face</u></a>.</p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.580971+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "43331",
    "prompt": "majicMIX realistic éº¦æ©˜å†™å®\n<p>V7 is here. So far so good for me.</p><h3 id=\"asian-alert!-n3n8dvt66\"><strong><span style=\"color:rgb(250, 82, 82)\">ASIAN ALERT!</span></strong></h3><h2 id=\"recommended-parameters-for-v7:-2wbt1xre9\"><span style=\"color:rgb(253, 126, 20)\">æ¨èå‚æ•° Recommended Parameters for V7:</span></h2><p>Sampler: <strong>Euler a, Euler, restart</strong></p><p>Steps: 20~40</p><p>Hires upscaler: <strong>ESRGAN 4x or 4x-UltraSharp or 8x_NMKD-Superscale_150000_G</strong></p><p>Hires upscale: 2+</p><p>Hires steps: 15+</p><p>Hires denoising strength: 0.05~0.5</p><p><strong>clip skip 2</strong></p><p></p><h3 id=\"after-detailer.-sy61gp8o5\"><strong>å¦‚æœè¦ä¿®å¤è„¸éƒ¨ï¼Œè¯·ä½¿ç”¨after detailer.</strong></h3><h3 id=\"if-your-face-comes-out-badly-use-after-detailer-instead-of-face-restoration.-032yvj7g2\"><strong>If your face comes out badly, use after detailer instead of face restoration.</strong></h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\"><strong>https://github.com/Bing-su/adetailer</strong></a></p><p></p><h3 id=\"dynamic-thresholdingcfg1~20-jn2df8b47\"><strong>æˆ‘ä¹ æƒ¯å¼€å¯Dynamic Thresholdingæ¥æ›´å¥½æ§åˆ¶cfgå€¼ï¼Œ1~20éƒ½å¯ä»¥å°è¯•ä¸€ä¸‹ã€‚</strong></h3><h3 id=\"use-dynmaic-thresholding-to-control-cfg.-you-can-try-from-1~20.-2tq8t65mn\"><strong>Use Dynmaic Thresholding to control CFG. You can try from 1~20.</strong></h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/mcmonkeyprojects/sd-dynamic-thresholding\">https://github.com/mcmonkeyprojects/sd-dynamic-thresholding</a></p><p></p><h3 id=\"bmab.-xwemseufr\"><strong>å¦‚æœè¦æ·»åŠ æ»¤é•œæ•ˆæœã€å™ªç‚¹ï¼Œè¯·ä½¿ç”¨BMAB.</strong></h3><h3 id=\"if-you-want-to-add-noise-like-me-use-bmab.-bozbavi5z\"><strong>If you want to add noise like me, use BMAB.</strong></h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/portu-sim/sd-webui-bmab\">GitHub - portu-sim/sd-webui-bmab: Auto masking and inpainting for person, face, hand. Resizing image using detection model.</a></p><p></p><hr /><p><strong>v2.5 is here</strong>. Note that this is not v7, but an upgrade for v2. V7 may need to address more issues, which I am still trying to do. In the process, I have created a model worth sharing.</p><p>This model can restore the light and shadow of the original majicmix v2, but with increased realism while still keeping the basic aesthetic of the face. I have tested other face loras and they work fine. Please use adetailer and put the face lora in it.</p><p>è¯·æ³¨æ„ï¼Œè¿™ä¸æ˜¯v7ï¼Œè€Œæ˜¯å¯¹v2çš„ä¿®ç¼®ã€‚v7å¯èƒ½éœ€è¦çªç ´æ›´å¤šé—®é¢˜ï¼Œè¿™ä¸ªç›®å‰æˆ‘è¿˜åœ¨å°è¯•ã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­æˆ‘èåˆå‡ºä¸€ä¸ªæ¨¡å‹ï¼Œæˆ‘è®¤ä¸ºä¹Ÿå€¼å¾—åˆ†äº«ã€‚</p><p>æœ¬æ¨¡å‹å¯ä»¥è¿˜åŸåˆä»£majicmixçš„å…‰å½±ï¼Œä½†æ˜¯å¢åŠ å†™å®åº¦ï¼Œè„¸éƒ¨è¿˜æ˜¯ä¿æŒåŸºæœ¬è°ƒæ€§çš„å®¡ç¾ï¼Œæˆ‘æµ‹è¯•äº†å…¶ä»–è„¸éƒ¨loraéƒ½æ²¡é—®é¢˜ã€‚è¯·ä½¿ç”¨adetailerç„¶åæŠŠè„¸éƒ¨loraæ”¾åœ¨é‡Œé¢ä½¿ç”¨ã€‚</p><p></p><hr /><p>v5å¯¹æˆ‘æ¥è¯´ä¸å¤Ÿå¥½ï¼Œå¯¹ä½ ä»¬æ¥è¯´ä¹Ÿæ˜¯çš„ï¼Œè€Œä¸”ä¸å¤Ÿå†™å®ã€‚æ‰€ä»¥v6å¾ˆè¿«åˆ‡éœ€è¦ã€‚ç”¨Eulerç”»ç‰¹å†™ï¼Œç”¨euler a ç”»å…¶ä»–çš„ã€‚ä¸è¦ï¼ä¸è¦ï¼ä¸è¦å¼€è„¸éƒ¨ä¿®å¤ï¼ç”¨adetaileræ¥ä¿®è„¸ã€‚æˆ‘çš„ä¾‹å›¾éƒ½ç”¨äº†ã€‚</p><p><strong>v6 is here</strong>. v5 is not good as I played for a while and see the results from yours. Therefore a v6 is urgent.</p><p>Use Euler for close up, and Euler a for others. Again, don't use facial restoration, use After detailer instead! All my samples used adetailer without lora.</p><p></p><hr /><p>ç¬¬äº”ç‰ˆå…ˆè¡Œç‰ˆæ¥äº†ï¼Œå…ˆæŠŠèµ›åšæ°¸ç”Ÿå°å§å§å¨œä¹Œæ–¯å˜‰èè¿›æ¥åšä¸ªä¾‹å­ï¼Œä¹Ÿç®—æ˜¯å…¬æµ‹å§ã€‚</p><p>5th edtion is coming soon. I've posted a preview version with the face of nwsj.</p><p>æ¨èä½¿ç”¨Eulerä½œä¸ºé‡‡æ ·å™¨ã€‚</p><p>Use Euler as sampler.</p><p></p><hr /><h2 id=\"-ak6ows6o8\"><span style=\"color:rgb(250, 82, 82)\">å¬æˆ‘ä¸€å¥åŠï¼Œä¸è¦å¼€è„¸éƒ¨ä¿®å¤ï¼</span></h2><h2 id=\"please-don't-use-face-restoration!-a55utx8rw\"><strong><span style=\"color:rgb(250, 82, 82)\">Please don't use Face Restoration!</span></strong></h2><p><strong>å¦‚æœè¦ä¿®å¤è„¸éƒ¨ï¼Œè¯·ä½¿ç”¨after detailer.</strong></p><p><strong>If your face comes out badly, use after detailer instead.</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\"><strong>https://github.com/Bing-su/adetailer</strong></a></p><p></p><p><strong>æˆ‘ä¹ æƒ¯å¼€å¯Dynamic Thresholdingæ¥æ›´å¥½æ§åˆ¶cfgå€¼ï¼Œ1~20éƒ½å¯ä»¥å°è¯•ä¸€ä¸‹ã€‚</strong></p><p><strong>Use Dynmaic Thresholding to control CFG. You can try from 1~20.</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/mcmonkeyprojects/sd-dynamic-thresholding\">https://github.com/mcmonkeyprojects/sd-dynamic-thresholding</a></p><p>å¾ˆæŠ±æ­‰åœ¨ä¹‹å‰çš„ä¾‹å›¾ä¸­æˆ‘ä½¿ç”¨äº†åˆ†å±‚çš„loraè®©å¤§å®¶å›°æƒ‘ï¼Œä¹Ÿè®©å¤§å®¶å¤åˆ»æˆ‘çš„ä¾‹å›¾å˜å¾—å›°éš¾ã€‚æ‰€ä»¥æ–°ä¸€ç‰ˆçš„ä¾‹å›¾æˆ‘æ²¡æœ‰ä½¿ç”¨ä»»ä½•loraã€‚æƒ³äº†è§£loraåˆ†å±‚çš„å¯ä»¥å‚è€ƒï¼š<a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/hako-mikan/sd-webui-lora-block-weight\">GitHub - hako-mikan/sd-webui-lora-block-weight</a></p><p>I apologize for using lora block weight in the example images of the previous edition, which confused most of you and made it difficult for you to replicate my examples. Therefore, in the newer editions, I did not use any lora in my showcase. If you would like to learn about lora block weight, please refer to: <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/hako-mikan/sd-webui-lora-block-weight\">https://github.com/hako-mikan/sd-webui-lora-block-weight</a></p><p></p><p></p><hr /><p><br />èåˆäº†å¤šç§æ¨¡å‹ï¼Œå¯ä»¥ç”Ÿæˆå¥½çœ‹çš„è„¸éƒ¨ï¼Œä¹Ÿèƒ½æœ‰æ•ˆåº”å¯¹æš—éƒ¨å¤„ç†ã€‚è¿œè·ç¦»è„¸éƒ¨éœ€è¦inpaintä»¥è¾¾æˆæœ€å¥½æ•ˆæœã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨after detailer.</p><p>A good looking model, suitable for NSFW and dark scene (because I added noiseoffset). long-range facial detail require inpainting to achieve the best results. You can also use after detailer.<br /><br />æ¨èå…³é”®è¯ recommended positive prompts: <em>Best quality, masterpiece, ultra high res, (photorealistic:1.4), 1girl</em><br /><br />å¦‚æœæƒ³è¦æ›´æš—çš„å›¾åƒ if you want darker picture, add: <em>in the dark, deep shadow, low key</em>, etc.<br /><br />è´Ÿé¢å…³é”®è¯ use <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4629/deep-negative-v1x\"><em>ng_deepnegative_v1_75t</em> </a>and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16993/badhandv4-animeillustdiffusion\"><em>badhandv4</em> </a>in negative prompt</p><p><br /><strong>I've used a bug-fixed version of DPM++ 2M Karras, you can check this out: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/35966/dpm-2m-alt-karras-sampler\">https://civitai.com/models/35966/dpm-2m-alt-karras-sampler</a></p><p>æ¨èå‚æ•°Recommended Parameters:</p><p>Sampler: Euler a, Euler, DPM++ 2M Karras (bug-fixed) or DPM++ SDE Karras</p><p>Steps: 20~40</p><p>Hires upscaler: R-ESRGAN 4x+ or 4x-UltraSharp</p><p>Hires upscale: 2</p><p>Hires steps: 15</p><p>Denoising strength: 0.2~0.5</p><p>CFG scale: 6-8</p><p>clip skip 2<br /><br />basic formula:<br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/24591/kanpiromix\"><strong>KanPiroMix</strong></a> + <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/31473/xsmix\"><strong>XSMix</strong></a> + <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9871/chikmix\"><strong>ChikMix</strong></a></p><p><strong>å…³æ³¨æˆ‘çš„TGé¢‘é“çœ‹æ›´å¤šä¾‹å›¾ï¼š</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://t.me/majic_NSFW\"><strong>https://t.me/majic_NSFW</strong></a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.580999+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "827184",
    "prompt": "WAI-NSFW-illustrious-SDXL\n<p>If you want to use more my checkpoint online generation, please visit here.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/u/762555264535746522\">https://tensor.art/u/762555264535746522</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.seaart.ai/models/detail/d8300cd33eb1ab8018baa6685ec4a7e9\">WAI-NSFW-illustrious-SDXL - SeaArt AI Model</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.shakker.ai/modelinfo/0f204323a06f40e18f8ffc5b1813df5a/WAI-NSFW-illustrious-SDXL-NSFW-illustrious-SDXL-NSFW-illustrious-SDXL-NSFW-illustrious-SDXL?from=personal_page\">WAI_NSFW-illustrious-SDXL_NSFW-illustrious-SDXL_NSFW-illustrious-SDXL_NSFW-illustrious-SDXL-Checkpoint-WAI-Shakker</a></p><hr /><h3 id=\"if-you-are-using-webui-please-be-sure-to-use-this-plugin-as-it-can-conveniently-generate-combinations-of-characters-and-actions.\"><span style=\"color:rgb(250, 82, 82)\"><strong>If you are using WEBUI, please be sure to use this plugin as it can conveniently generate combinations of characters and actions.</strong></span></h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/10754/wai-nsfw-illustrious-sdxl-v80-built-in-character-prompt-generator-v8\">WAI-NSFW-illustrious-SDXL V8.0 æ¨¡å‹äººç‰©æç¤ºå™¨ / Built-in Character Prompt Generator (å°æ‡‰V8ä»¥ä¸Šç‰ˆæœ¬) | Civitai</a></p><p><span style=\"color:rgb(250, 176, 5)\"><strong>This plugin can directly suggest thousands of existing character models, along with a feature for randomly selecting characters.</strong></span></p><p><span style=\"color:rgb(250, 176, 5)\"><strong>V8-V12 are all well compatible.</strong></span></p><h3 id=\"character-select-saa\"><span style=\"color:rgb(250, 82, 82)\"><strong>Character Select SAA</strong></span></h3><p><span style=\"color:rgb(250, 82, 82)\"><strong>This is a Stand Alone App with AI prompt, Semi-auto Tag Complete and ComfyUI/WebUI API support.</strong></span></p><p><span style=\"color:rgb(250, 82, 82)\"><strong>Now supports 5058 (includes multiple costumes) Character list.</strong></span></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/mirabarukaso/character_select_stand_alone_app\">https://github.com/mirabarukaso/character_select_stand_alone_app</a></p><p><span style=\"color:rgb(250, 176, 5)\">One-ClickÂ embeddedÂ package<br />InÂ caseÂ youÂ don'tÂ knowÂ howÂ toÂ buildÂ yourÂ ownÂ PythonÂ enverment,Â tryÂ theÂ embeded_env_for_SAA<br />DownÂ andÂ unzipÂ toÂ yourÂ computer<br />Db-clickÂ #run_XX.bat</span></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/datasets/flagrantia/character_select_stand_alone_app/resolve/main/embeded_env_for_SAA.zip\">https://huggingface.co/datasets/flagrantia/character_select_stand_alone_app/resolve/main/embeded_env_for_SAA.zip</a><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/datasets/flagrantia/character_select_stand_alone_app/resolve/main/embeded_env_for_SAA.zipï¿¼ï¿¼ã€ç¾¤ä¸»ã€‘oOkÌ¥Í£Í«Í¥ami(4955241)\"><br /></a>ä¸‹è½½è§£å‹åˆ°ä»»æ„ç›®å½•ï¼Œè¿è¡ŒÂ #run_CNÂ Â <br />DownloadÂ andÂ extractÂ toÂ anyÂ directory.Â RunÂ #run_CNÂ orÂ #run_EN</p><hr /><h2 id=\"online-quick-search-character\"><strong>Online Quick search character</strong></h2><h2 id=\"character-select-saa-a-hugging-face-space-by-flagrantia\"><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/spaces/flagrantia/character_select_saa\"><strong>Character Select Saa - a Hugging Face Space by flagrantia</strong></a></h2><p></p><h3 id=\"please-do-not-add-too-many-quality-and-aesthetic-related-tags-nor-overly-long-negative-prompts-as-this-will-actually-reduce-image-quality-and-make-it-more-blurry.\"><span style=\"color:rgb(250, 176, 5)\"><strong>Please do not add too many quality and aesthetic-related tags, nor overly long negative prompts, as this will actually reduce image quality and make it more blurry.</strong></span></h3><p></p><h1 id=\"v15\"><span style=\"color:rgb(250, 82, 82)\"><strong>v15</strong></span></h1><p></p><ol><li><p><span style=\"color:rgb(190, 75, 219)\"><strong>Base ill 1.0</strong></span></p></li><li><p><span style=\"color:rgb(190, 75, 219)\"><strong>added data (roughly up to May 2025, mainly popular social games and some anime).</strong></span><span style=\"color:rgb(250, 82, 82)\"><strong><u>PS:</u></strong></span><span style=\"color:rgb(250, 82, 82)\"><strong><u>The new character data hasnâ€™t been fully fixed yet. Iâ€™ll continue to improve it in the upcoming versions.</u></strong></span></p></li><li><p><span style=\"color:rgb(190, 75, 219)\"><strong>Data adjustment, trying to reduce the chance of watermarks appearing.</strong></span></p></li></ol><h3 id=\"recommended-settings:\"><span style=\"color:rgb(230, 73, 128)\">Recommended settings:</span></h3><p><span style=\"color:rgb(250, 82, 82)\">Steps: </span><span style=\"color:rgb(250, 176, 5)\">15-30</span></p><p><span style=\"color:rgb(250, 82, 82)\">CFG scale: </span><span style=\"color:rgb(250, 176, 5)\">5-7</span></p><p><span style=\"color:rgb(250, 82, 82)\">Sampler: </span><span style=\"color:rgb(250, 176, 5)\">Euler a</span></p><p></p><p><span style=\"color:rgb(250, 82, 82)\">The VAE is already integrated, please do not ask such questions anymore.</span></p><p></p><p><span style=\"color:rgb(250, 176, 5)\">use size larger than1024x1024 for the original dimensions.</span></p><p></p><p><span style=\"color:rgb(190, 75, 219)\">Hires upscale: 1.5, Hires steps: 20, Hires upscaler: R-ESRGAN 4x+ Anime6B,Denoising strength: 0.35~0.5</span></p><p></p><p><span style=\"color:rgb(130, 201, 30)\">There are four safety rating tags: </span><span style=\"color:rgb(250, 176, 5)\"><strong>general, sensitive, nsfw,explicit</strong></span><span style=\"color:rgb(130, 201, 30)\">.<br />Users are expected to consciously add \"nsfw\" to negative prompts to filter inappropriate content.</span></p><p></p><p>Positive Prompt</p><pre><code>masterpiece,best quality,</code></pre><p></p><p>Negative Prompt</p><pre><code>bad quality,worst quality,worst detail,</code></pre><h3></h3><p></p><hr /><h1 id=\"v5-v14-user-manual\">V5-V14 User Manual</h1><h3 id=\"v1-v4-are-outdatedplease-do-not-download-them-anymore.\"><span style=\"color:rgb(255, 255, 255)\">V1-V4 are outdated,please do not download them anymore.</span></h3><p></p><p><span style=\"color:rgb(190, 75, 219)\"><br /></span></p><p></p><p><span style=\"color:rgb(255, 255, 255)\">This is a list of characters that have been tested and are implementable on V11.</span></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/datasets/sieecc/WAI-NSFW-illustrious-SDXL/tree/main\">sieecc/WAI-NSFW-illustrious-SDXL at main</a></p><p><span style=\"color:rgb(255, 255, 255)\">These are just temporary and not all tests have been completed yet; more will be added subsequently.</span></p><p></p><p></p><h3 id=\"recommended-settings:\"><span style=\"color:rgb(230, 73, 128)\">Recommended settings:</span></h3><p><span style=\"color:rgb(250, 82, 82)\">Steps: </span><span style=\"color:rgb(250, 176, 5)\">25-40</span></p><p><span style=\"color:rgb(250, 82, 82)\">CFG scale: </span><span style=\"color:rgb(250, 176, 5)\">5-7</span></p><p><span style=\"color:rgb(250, 82, 82)\">Sampler: </span><span style=\"color:rgb(250, 176, 5)\">Euler a</span></p><p></p><p><span style=\"color:rgb(250, 82, 82)\">The VAE is already integrated, please do not ask such questions anymore.</span></p><p></p><p><span style=\"color:rgb(250, 176, 5)\">use size larger than1024x1024 for the original dimensions.</span></p><p></p><p><span style=\"color:rgb(190, 75, 219)\">Hires upscale: 1.5, Hires steps: 20, Hires upscaler: R-ESRGAN 4x+ Anime6B,Denoising strength: 0.35~0.5</span></p><p></p><p><span style=\"color:rgb(130, 201, 30)\">There are four safety rating tags: </span><span style=\"color:rgb(250, 176, 5)\"><strong>general, sensitive, nsfw,explicit</strong></span><span style=\"color:rgb(130, 201, 30)\">.<br />Users are expected to consciously add \"nsfw\" to negative prompts to filter inappropriate content.</span></p><p></p><p>Positive Prompt</p><pre><code>masterpiece,best quality,amazing quality,</code></pre><p></p><p>Negative Prompt</p><pre><code>bad quality,worst quality,worst detail,sketch,censor,</code></pre><h3></h3><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581010+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "4384",
    "prompt": "DreamShaper\n<h1 id=\"heading-133\">DreamShaper - Vâˆ!</h1><h3 id=\"heading-134\">Please check out my other <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Lykon/models?tag=base+model\">base models</a>, including <u>SDXL</u> ones!</h3><p><strong>Check the version description below (bottom right) for more info and add a â¤ï¸ to receive future updates.</strong><br /><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> ğŸ…¿ï¸ to get exclusive tips and tutorials, or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> â˜•</strong><br />ğŸŸï¸ <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/lykon/commissions\"><strong>Commissions on Ko-Fi</strong></a></p><p></p><h3 id=\"heading-135\">Join my <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/uAhsmDq7GC\">Discord Server</a></h3><p><strong><span style=\"color:rgb(253, 126, 20)\">For LCM read the version description.</span></strong></p><p></p><p><strong>Available on the following websites with GPU acceleration:</strong></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/\"><strong>Mage.space</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/4zdwGOB\"><strong>Sinkin.ai</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://randomseed.co/model/20?via=lykon\"><strong>RandomSeed</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"http://AnimeMaker.ai\"><strong>AnimeMaker.ai</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://rendernet.ai/creator/Lykon\"><strong>Rendernet.ai</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/u/600303455797521413\">https://tensor.art/u/600303455797521413</a></p></li></ul><p><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/spaces/Lykon/DreamShaper-webui\"><strong>Live demo available on HuggingFace</strong></a><strong> (CPU is slow but free).</strong></p><p><strong>New Negative Embedding for this: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/72437?modelVersionId=77169\"><strong>Bad Dream</strong></a><strong>.</strong><br /></p><h2 id=\"heading-210\"><strong>Message from the author</strong></h2><p>Hello hello, my fellow <strong>AI Art</strong> lovers. Version 8 just released. Did you like the cover with the âˆ symbol? This version holds a special meaning for me.<br /><br />DreamShaper started as a model to have an alternative to MidJourney in the open source world. I didn't like how MJ was handled back when I started and how closed it was and still is, as well as the lack of freedom it gives to users compared to SD. Look at all the tools we have now from TIs to LoRA, from ControlNet to Latent Couple. We can do anything. The purpose of DreamShaper has always been to make \"a better Stable Diffusion\", a model capable of doing everything on its own, to <em>weave dreams</em>. <br />With SDXL (and, of course, <strong>DreamShaper XL</strong> ğŸ˜‰) just released, I think the \"<em>swiss knife</em>\" type of model is closer then ever. That model architecture is big and heavy enough to accomplish that the pretty easily. But what about all the resources built on top of SD1.5? Or all the users that don't have 10GB of vram? It might just be a bit too early to let go of DreamShaper. <br /><br />Not before one. Last. Push. <br /><br />And here it is, I hope you enjoy. And thank you for all the support you've given me in the recent months.</p><p><strong>PS: </strong>the primary goal is still towards art and illustrations. Being good at everything comes second.</p><p><br /><strong>Suggested settings:</strong><br />- I had CLIP skip 2 on some pics, the model works with that too. <br />- I have <em>ENSD</em> set to 31337, in case you need to reproduce some results, but it doesn't guarantee it. <br />- All of them had <strong>highres.fix</strong> or img2img at higher resolution. Some even have ADetailer. Careful with that tho, as <strong><span style=\"color:rgb(250, 82, 82)\">it tends to make all faces look the same</span>.</strong><br />- I <strong>don't use \"restore faces\"</strong>.</p><p><strong>For old versions:</strong><br />- Versions &gt;4 require no LoRA for anime style. For version 3 I suggest to use one of these LoRA networks at 0.35 weight: <br />-- <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4219\">https://civitai.com/models/4219</a> (the girls with glasses or if it says <code>wanostyle</code>)<br />-- <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/closertodeath/dpepmkmp/blob/main/last.pt\">https://huggingface.co/closertodeath/dpepmkmp/blob/main/last.pt</a> (if it says <code>mksk style</code>)<br />-- <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4982/anime-screencap-style-lora\">https://civitai.com/models/4982/anime-screencap-style-lora</a> (not used for any example but works great).</p><h3 id=\"heading-252\"><strong>LCM</strong></h3><p>Being a distilled model it has lower quality compared to the base one. However it's MUCH faster and perfect for video and real time applications.</p><p>Use it with 5-15 steps, ~2 cfg. <strong><u><span style=\"color:rgb(253, 126, 20)\">IT WORKS ONLY WITH LCM SAMPLER</span></u></strong> (as of December 2023, Auto1111 requires an external plugin for it).</p><p>Comparison with V7 LCM <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/951513\">https://civitai.com/posts/951513</a><br /><br /><strong>NOTES</strong></p><ul><li><p>Version 8 focuses on improving what V7 started. Might be harder to do photorealism compared to realism focused models, as it might be hard to do anime compared to anime focused models, but it can do both pretty well if you're skilled enough. <u>Check the examples!</u></p></li><li><p>Version 7 improves lora support, NSFW and realism. If you're interested in \"absolute\" realism, try <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/81458\">AbsoluteReality</a>.</p></li><li><p>Version 6 adds more lora support and more style in general. It should also be better at generating directly at 1024 height (but be careful with it). 6.x are all improvements.</p></li><li><p>Version 5 is the best at photorealism and has noise offset.</p></li><li><p>Version 4 is much better with anime (can do them with no LoRA) and booru tags. IT might be harder to control if you're used to caption style, so you might still want to use version 3.31.</p></li><li><p>V4 is also better with eyes at lower resolutions. Overall is like a \"fix\" of V3 and shouldn't be too much different.</p></li><li><p>Results of version 3.32 \"clip fix\" will vary from the examples (produced on 3.31, which I personally prefer).</p></li><li><p>I get no money from any generative service, but you can buy me a coffee.</p></li><li><p>You should use 3.32 for mixing, so the clip error doesn't spread.</p></li><li><p><strong>Inpainting models are only for inpaint and outpaint, not txt2img or mixing. </strong><br /></p></li></ul><p><strong>Original v1 description:</strong> <br />After a lot of tests I'm finally releasing my <s>mix</s> model. This started as a model to make good portraits that do not look like cg or photos with heavy filters, but more like actual paintings. The result is a model capable of doing portraits like I wanted, but also great backgrounds and anime-style characters. Below you can find some suggestions, including LoRA networks to make anime style images. <br /><br />I hope you'll enjoy it as much as I do.<br /></p><p>Official HF repository: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Lykon/DreamShaper\">https://huggingface.co/Lykon/DreamShaper</a><br /></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581017+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "4201",
    "prompt": "Realistic Vision V6.0 B1\n<p><strong><span style=\"color:rgb(21, 170, 191)\">Check my exclusive models on Mage: </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/4371756b27bf52e7a1146dc6fe2d969c\"><strong><span style=\"color:rgb(230, 73, 128)\">ParagonXL</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/df67a9f27f19629a98cb0fb619d1949a\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/d8db06ae964310acb4e090eec03984df\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL Lightning</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/541da1e10976ab82976a5cacc770a413\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL V2</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/a56d2680c464ef25b8c66df126b3f706\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL Pony</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/b0ab6733c3be2408c93523d57a605371\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL Pony Lightning</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/e3b01cd493ed86ed8e4708751b1c9165\"><strong><span style=\"color:rgb(230, 73, 128)\">RealDreamXL</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/ef062fc389c3f8723002428290c1158c\"><strong><span style=\"color:rgb(230, 73, 128)\">RealDreamXL Lightning</span></strong></a></p><p><strong><span style=\"color:rgb(130, 201, 30)\">Recommendations for using the Hyper model:</span><br /><span style=\"color:rgb(130, 201, 30)\">Sampler = </span><u><span style=\"color:rgb(130, 201, 30)\">DPM SDE++ Karras</span></u><span style=\"color:rgb(130, 201, 30)\"> or </span><u><span style=\"color:rgb(130, 201, 30)\">another</span></u><span style=\"color:rgb(130, 201, 30)\"> / 4-6+ steps<br />CFG Scale = 1.5-2.0 (</span><u><span style=\"color:rgb(130, 201, 30)\">the lower the value, the more mutations, but the less contrast</span></u><span style=\"color:rgb(130, 201, 30)\">)</span></strong></p><p><strong><span style=\"color:rgb(130, 201, 30)\">I also recommend using </span><u><span style=\"color:rgb(130, 201, 30)\">ADetailer</span></u><span style=\"color:rgb(130, 201, 30)\"> for generation (some examples were generated with ADetailer, this will be noted in the image comments).</span></strong></p><p>This model is available on <a target=\"_blank\" rel=\"ugc\" href=\"http://Mage.Space\"><strong>Mage.Space</strong></a><strong> (main sponsor)</strong>.<br />You can also support me directly on <a target=\"_blank\" rel=\"ugc\" href=\"https://boosty.to/sg_161222\"><strong><u><span style=\"color:rgb(250, 176, 5)\">Boosty</span></u></strong></a>.</p><pre><code>Realistic Vision V6.0 (B2 - Full Re-train) Status (Updated: Apr. 4, 2024):\n- Training Images: +3400 (B1: 3000)\n- Training Steps: +724k (B1: 664k)\n- Approximate percentage of completion: ~30%</code></pre><p>All models, including <strong>Realistic Vision (VAE / noVAE)</strong> are also on <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/SG161222\"><strong>Hugging Face</strong></a></p><p><span style=\"color:rgb(44, 45, 46)\">á… </span></p><p><strong>Please read this! How to remove strong contrast.</strong></p><p>To make the image less contrasty you can use LoRA <strong>[</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/58390/detail-tweaker-lora-lora\"><strong>Detail Tweaker LoRA</strong></a><strong>]</strong> in a negative value.</p><p><span style=\"color:rgb(44, 45, 46)\">á… </span></p><p><strong><span style=\"color:rgb(253, 126, 20)\">Orange Color</span></strong> <strong>= Optional</strong></p><p><span style=\"color:rgb(44, 45, 46)\">á… </span></p><p><strong>I use this template to get good generation results:</strong></p><p><span style=\"color:rgb(44, 45, 46)\">á… </span></p><p><strong>Prompt:</strong></p><p>RAW photo, <em>subject</em>, 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3</p><p><span style=\"color:rgb(44, 45, 46)\">á… </span></p><p><strong>Negative Prompt:</strong></p><p></p><ul><li><p>(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime), text, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/72437/baddream-unrealisticdream-negative-embeddings\"><strong><span style=\"color:rgb(253, 126, 20)\">UnrealisticDream</span></strong></a></p><p></p></li><li><p>(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime, mutated hands and fingers:1.4), (deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs, mutation, mutated, ugly, disgusting, amputation, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/72437/baddream-unrealisticdream-negative-embeddings\"><strong><span style=\"color:rgb(253, 126, 20)\">UnrealisticDream</span></strong></a></p></li></ul><p><span style=\"color:rgb(44, 45, 46)\">á… </span></p><p><strong>Euler A or DPM++ SDE Karras</strong></p><p><strong>CFG Scale 3,5 - 7</strong></p><p><strong><span style=\"color:rgb(253, 126, 20)\">Hires. fix</span> with </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/lokCX/4x-Ultrasharp/tree/main\"><strong><span style=\"color:rgb(253, 126, 20)\">4x-UltraSharp upscaler</span></strong></a></p><p><strong>Denoising strength <span style=\"color:rgb(253, 126, 20)\">0.25-0.45</span></strong></p><p><strong>Upscale by 1.1-2.0</strong></p><p><strong>Clip Skip 1-2</strong></p><p><strong><span style=\"color:rgb(253, 126, 20)\">ENSD 31337</span></strong></p><p><span style=\"color:rgb(44, 45, 46)\">á… </span></p><p><strong>Thanks to the creators of these models for their work. Without them it would not have been possible to create this model.</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1173?modelVersionId=4635\"><strong>HassanBlend 1.5.1.2</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/sdhassan\"><strong>sdhassan</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2661?modelVersionId=15640\"><strong>Uber Realistic Porn Merge (URPM)</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/saftle\"><strong>saftle</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3666?modelVersionId=4048\"><strong>Protogen x3.4 (Photorealism)</strong></a><strong> + </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3816?modelVersionId=4229\"><strong>Protogen x5.3 (Photorealism)</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/darkstorm2150\"><strong>darkstorm2150</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3950?modelVersionId=5180\"><strong>Art &amp; Eros (aEros)</strong></a><strong> + </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1654?modelVersionId=1798\"><strong>RealEldenApocalypse</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/aine_captain\"><strong>aine_captain</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3811?modelVersionId=4224\"><strong>Dreamlike Photoreal 2.0</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/sviasem\"><strong>sviasem</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3758?modelVersionId=4167\"><strong>HASDX</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/bestjammer\"><strong>bestjammer</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1265/analog-diffusion\"><strong>Analog Diffusion</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/wavymulder\"><strong>wavymulder</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4041/woopwoop-photo\"><strong>WoopWoop-Photo</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/zoidbb\"><strong>zoidbb</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16804?modelVersionId=29682\"><strong>Life Like Diffusion</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/lutherjonna409\"><strong>lutherjonna409</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/81458?modelVersionId=86437\"><strong>AbsoluteReality</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Lykon\"><strong>Lykon</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/15003?modelVersionId=89680\"><strong>CyberRealistic</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Cyberdelia\"><strong>Cyberdelia</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8030?modelVersionId=101080\"><strong>Analog Madness</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/CornmeisterNL\"><strong>CornmeisterNL</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/57319/a-zovya-photoreal\"><strong>A-Zovya Photoreal</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Zovya\"><strong>Zovya</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/28059?modelVersionId=109115\"><strong>ICBINP - \"I Can't Believe It's Not Photography\"</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/residentchiefnz\"><strong>residentchiefnz</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/25694?modelVersionId=105035\"><strong>epiCRealism</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/epinikion\"><strong>epinikion</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/46422?modelVersionId=106157\"><strong>Juggernaut</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/KandooAI\"><strong>KandooAI</strong></a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581023+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "7808",
    "prompt": "EasyNegative\n<p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/datasets/gsdf/EasyNegative\"><strong>Original Hugging Face Repository</strong></a><br /><strong>Counterfeit-V3 (which has 2.5 and 2.5 as well) on Civitai - </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4468/counterfeit-v25\"><strong>https://civitai.com/models/4468/counterfeit-v25</strong></a><br /><strong>If you like this embedding, please consider taking the time to give the repository a like and browsing their other work on HuggingFace.</strong><br /></p><p><strong>This embedding should be used in your NEGATIVE prompt. Adjust the strength as desired (seems to scale well without any distortions), the strength required may vary based on positive and negative prompts. Use the EasyNegative_pt (PickleTensors) version if you are unable to use SafeTensors embeddings.</strong><br /><br /><strong>Samples are, in order:</strong></p><ol><li><p><strong>sample01 - Counterfeit-V2.0.safetensors</strong></p></li><li><p><strong>sample02 - AbyssOrangeMix2_sfw.safetensors</strong></p></li><li><p><strong>sample03 - anything-v4.0-pruned.safetensors</strong></p></li><li><p><strong>Strength comparison using AbyssOrangeMix2_sfw.</strong></p></li></ol><p><br /><strong>From Author</strong><br />\"This is a Negative Embedding trained with Counterfeit. Please use it in the \"\\stable-diffusion-webui\\embeddings\" folder. It can be used with other models, but the effectiveness is not certain.\"</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581027+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "4468",
    "prompt": "Counterfeit-V3.0\n<p>high quality anime style model.</p><p>Supportâ˜• <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/sfa837348\">https://ko-fi.com/sfa837348</a></p><p>more info. <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/gsdf/Counterfeit-V2.0\">https://huggingface.co/gsdf/Counterfeit-V2.0</a></p><p>Verson2.5 <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/gsdf/Counterfeit-V2.5\">https://huggingface.co/gsdf/Counterfeit-V2.5</a></p><p>Verson3.0 <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/gsdf/Counterfeit-V3.0\">https://huggingface.co/gsdf/Counterfeit-V3.0</a></p><p>EasyNegative <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/datasets/gsdf/EasyNegative\">https://huggingface.co/datasets/gsdf/EasyNegative</a></p><p>(Use clip: openai/clip-vit-large-patch14-336)<br />EasyNegative(Negative Embedding) <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/datasets/gsdf/EasyNegative\">https://huggingface.co/datasets/gsdf/EasyNegative</a></p><p></p><p><span style=\"color:rgb(209, 213, 219)\">Official hosting for online AI image generator. </span></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://rendernet.ai/\">https://rendernet.ai/</a></p></li></ul>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581032+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "7240",
    "prompt": "MeinaMix\n<p><strong>MeinaMix objective </strong>is to be<strong> </strong>able to do good art with little prompting.<br /><span style=\"color:rgb(193, 194, 197)\">I have a </span><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/F6yeQtEQ98\">discord</a><span style=\"color:rgb(193, 194, 197)\"> where you can </span><strong>share images</strong><span style=\"color:rgb(193, 194, 197)\">, </span><strong>discuss prompt</strong><span style=\"color:rgb(193, 194, 197)\"> and </span><strong>ask for help</strong><span style=\"color:rgb(193, 194, 197)\">. </span><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/F6yeQtEQ98\">https://discord.gg/meinaverse</a><br /><span style=\"color:rgb(193, 194, 197)\">æˆ‘æœ‰ä¸ªå¯ä»¥è®©ä½ åˆ†äº«å›¾ç‰‡å’Œå‚ä¸è®¨è®ºä¸è¯¢é—®é—®é¢˜çš„discordç¾¤ã€‚</span><br /><br />I also have a <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/meina\"><strong>ko-fi</strong></a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/MeinaMix\"><strong>Patreon</strong></a> page where you can support me or buy me a coffee &lt;3 , <strong>it will be very much appreciated:</strong><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/meina\"><strong>https://ko-fi.com/meina</strong></a><strong> and </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/MeinaMix\"><strong>https://www.patreon.com/MeinaMix</strong></a><br /><br /><strong>MeinaMix is officially hosted for online generation in:</strong></p><p>-<strong> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.seaart.ai/models/detail/3fae6b919ed209006e0a56248183fdff\">SeaArt</a><br />- <a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/e151cb844760205954e7f7b130fcc525\">Mage.space</a> ( with animate feature )<br /><br /><strong>MeinaMix and the other of Meinas will ALWAYS be FREE.</strong><br /><strong>Cover image lora made by: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/FallenIncursio\">FallenIncursio | Civitai</a><br /><br /><strong>Recommendations of use:</strong><br />--------------------------------------------------------------------------------<br /><strong>Enable Quantization in K samplers.</strong><br /><br /><strong>Hires.fix is needed for prompts where the character is far away</strong> in order to make decent images, it drastically improve the quality of face and eyes!<br />---------------------------------------------<br /><strong>Recommended parameters:</strong><br /><strong>Sampler:</strong> DPM++ SDE Karras: 20 to 30 steps.<br /><strong>Sampler:</strong> DPM++ 2M Karras: 20 to 60 steps.<br /><strong>Sampler:</strong> Euler a: 40 to 60 steps.<br /><strong>CFG Scale:</strong> 4 to 9.<br /><strong>Resolutions:</strong> 512x768, 512x1024 for Portrait!<br /><strong>Resolutions: </strong>768x512, 1024x512, 1536x512 for Landscape!<br /><strong>Hires.fix:</strong> R-ESRGAN 4x+Anime6b, with 10 steps at 0.3 up to 0.6 denoising.<br /><strong>Clip Skip:</strong> 2.<br /><strong>Negatives:</strong> ' (worst quality, low quality), (zombie, interlocked fingers) '<br /><strong>Negatives if you can't use Hires.fix:</strong><br />'(worst quality:1.6, low quality:1.6), (zombie, sketch, interlocked fingers, comic)'<br />--------------------------------------------------------------------------------<br /><br /><strong>In the merged models list: MeinaMix V1~11, MeinaPastel V3~6, MeinaHentai V2~5, Night Sky YOZORA Style Model, PastelMix, Facebomb, MeinaAlterV3 </strong>i do not have the exact recipe because i did multiple mixings using block weighted merges with multiple settings and kept the better version of each merge.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581036+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "7371",
    "prompt": "ReV Animated\n<p><em>April 28, 2024: added V2 Rebirth pruned</em></p><h1 id=\"heading-46\"><span style=\"color:rgb(64, 192, 87)\">v2:REBIRTH</span></h1><p><span style=\"color:rgb(230, 73, 128)\">Thanks to </span><span style=\"color:rgb(250, 82, 82)\">S6yx</span><span style=\"color:rgb(230, 73, 128)\"> for the creation of this beautiful model. Enjoyed by millions. With their permission, I, </span><span style=\"color:rgb(250, 82, 82)\">Zovya</span><span style=\"color:rgb(230, 73, 128)\">, will be maintaining it moving forward.</span></p><p></p><p><em>April 4, 2024: fp16 and +VAE added</em></p><p><em>April 2, 2024: Rebirth</em></p><p><em>Update 3: Disclaimer/Permissions updated</em></p><p><em>Update 2: I am no longer maintaining/updating this model</em></p><p><em>Update 1: I've been a bit burnt out on SD model development (SD in general tbh) and that is the reason there have not been an update. Looking to come back around and develop again by next month or so.Thank you everyone who sends reviews and enjoy my model</em><br /></p><p><strong>Pay attention to the <em><u>About this version</u></em></strong> <strong>section </strong>of model page<strong> for specific version information. â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸</strong></p><h3 id=\"heading-416\"><br /><u>Model Overview:</u></h3><ul><li><p><u>rev</u> or <u>revision</u>: The concept of how the model generates images is likely to change as I see fit.</p></li><li><p><u>Animated</u>: The model has the ability to create 2.5D like image generations. This model is a checkpoint merge, meaning it is a product of other models to create a product that derives from the originals.</p></li><li><p>Kind of generations:</p><ul><li><p>Fantasy</p></li><li><p>Anime</p></li><li><p>semi-realistic</p></li><li><p><em>decent Landscape</em></p></li></ul></li><li><p>LoRA friendly</p></li><li><p>It works <strong><em><u>best on these resolution dimensions:</u></em></strong></p><ul><li><p>512x512</p></li><li><p>512x768</p></li><li><p>768x512</p></li></ul></li></ul><p></p><h3 id=\"heading-417\"><u>VAE</u>:</h3><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs/blob/main/VAEs/orangemix.vae.pt\"><u>orangemix.vae.pt</u></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/tree/main/vae\">kl-f8-anime2.ckpt</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/NoCrypt/blessed_vae/blob/main/blessed2.vae.pt\">Blessed2.vae.pt</a></p><p><br /></p></li></ul><h3 id=\"heading-418\"><u>Prompting</u>:</h3><ul><li><p><strong>Order matters</strong> - words near the front of your prompt are weighted more heavily than the things in the back of your prompt.</p></li><li><p><strong>Prompt order</strong> - content type &gt; description &gt; style &gt; composition</p></li><li><p><strong>This model likes</strong>: ((best quality)), ((masterpiece)), (detailed) in beginning of prompt if you want anime-2.5D type</p></li><li><p>This model does great on<strong> <u>PORTRAITS</u></strong></p></li></ul><p></p><p><strong><u>Negative Prompt Embeddings:</u></strong></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/embed/EasyNegative/tree/main\">EasyNegative</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4629/deep-negative-v1x\">Deep Negative</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/embed/bad_prompt/blob/main/bad_prompt_version2.pt\">bad_prompt_version2</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nick-x-hacker/bad-artist/blob/main/bad-artist.pt\">bad-artist</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nick-x-hacker/bad-artist/blob/main/bad-artist-anime.pt\">bad-artist-anime</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/p1atdev/badquality/tree/main\">bad-quality</a></p></li><li><p>Make use of weights in negative prompts (i.e (worst quality, low quality:1.4))</p><p></p></li></ul><p></p><h3 id=\"heading-419\"><u>Video Features</u></h3><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://youtu.be/Nl43zR5dVuM?t=192\">Olivio Sarikas - Why Is EVERYONE Using This Model?! - Rev Animated for Stable Diffusion / A1111</a></p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/watch?v=A6dQPMy_tHY\">Olivio Sarikas - ULTRA SHARP Upscale! - Don't miss this Method!!! / A1111 - NEW Model</a><br /><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/watch?v=ezNDCWhv4pQ\">AMAZING SD Models - And how to get the MOST out of them!</a></p><p></p><p></p><h2 id=\"heading-420\"><strong><u>Disclaimer (Updated 10/31/2023):</u></strong><br /></h2><p>The license type is <a target=\"_blank\" rel=\"ugc\" href=\"https://creativecommons.org/licenses/by-nc-nd/4.0\">CC BY-NC-ND 4.0</a> <br /><strong>Do not sell</strong> this model on any website without permissions from creator (me)</p><p><strong>Credit</strong> me if you use my model in your own merges</p><p><strong><u>You can use derivative models which uses ReV Animated for Buzz points and site-based currency that does not convert over to real world currency.</u></strong></p><p>Do not use this model to <strong><u>monetize</u></strong> on other platforms without expressed written consent. <br /><br /></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581040+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "122359",
    "prompt": "Detail Tweaker XL\n<p>Detail tweaker for SDXL.</p><p>Works with weights [-3, 3]</p><p>Use positive weight to increase details and negative weight to reduce details.</p><p>Good weight depends on your prompt and number of sampling steps, I recommend starting at 1.5 and then adjusting it.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581043+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "288584",
    "prompt": "AutismMix SDXL\n<p>Mix of pony with some stuff. It's an attempt at making pony more predictable and less dependent on schizo negatives without removing its comprehension and artist knowledge. Personally I'm using AutismMix_confetti for general use and AutismMix_pony for certain loras. If you want to train a lora on top of autism I recommend doing so in the AutismMix_pony version for better compatibility. The Lightning versions require specific settings to work, read the \"about model\" information under download.</p><p></p><p>What is the difference between the models:</p><p>AutismMix_confetti is a small amount of AnimeConfettiTune and AutismMix_pony. Has less style swing than pony and better hands. I prefer this one.</p><p>AutismMix_pony is a merge of ponyv6 with loras, its more compatible with certain styles made for the base ponydiffusion model.</p><p>AutismMix_DPO is AutismMix_confetti+DPO lora, made by request. Very similar to confetti version.</p><p></p><p>Add 3d to negs if you want a more traditional anime style. Quality tags should be same as ponyv6, but feel free to experiment: \"score_9, score_8_up, score_7_up, score_6_up, score_5_up, score_4_up, source_anime, BREAK\"</p><p>From my testing schizo negatives and those negative embeds made for SDXL/pony make it worse, but do whatever you want.</p><p>If you have any issues running this model I suggest using this webui: <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/lllyasviel/stable-diffusion-webui-forge\">https://github.com/lllyasviel/stable-diffusion-webui-forge</a></p><p>As well as this extension if you get noise outputs:<br /><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/hako-mikan/sd-webui-prevent-artifact\">https://github.com/hako-mikan/sd-webui-prevent-artifact</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581046+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "58390",
    "prompt": "Detail Tweaker LoRA (ç»†èŠ‚è°ƒæ•´LoRA)\n<p>HF: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/OedoSoldier/detail-tweaker-lora\">https://huggingface.co/OedoSoldier/detail-tweaker-lora</a></p><p>This is a LoRA for enhancing/diminishing detail while keeping the overall style/character; it works well with all kinds of base models (incl anime &amp; realistic models)/style LoRA/character LoRA, etc.</p><p>Apply your own weight; this LoRA can be utilized for any weight up/down to 2/-2!</p><p><strong>Note: use a negative weight to reduce details!</strong></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581049+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "133005",
    "prompt": "Juggernaut XL\n<p><strong><u>Updated the Prompting Guide</u></strong></p><p><span style=\"color:rgb(219, 222, 225)\">For business inquires, commercial licensing, custom models, and consultation contact me under </span><a target=\"_blank\" rel=\"ugc\" href=\"mailto:juggernaut@rundiffusion.com\"><span style=\"color:rgb(219, 222, 225)\">juggernaut@rundiffusion.com</span></a></p><p><span style=\"color:rgb(219, 222, 225)\">Join Juggernaut now on </span><a target=\"_blank\" rel=\"ugc\" href=\"https://twitter.com/Juggernaut_AI\"><span style=\"color:rgb(76, 110, 245)\">X/Twitter</span></a><br /><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://learn.rundiffusion.com/prompt-guide-for-juggernaut-xiii-ragnarok-by-rundiffusion/\"><span style=\"color:rgb(76, 110, 245)\">Prompting Guide for Juggernaut Ragnarok by Adam</span></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://learn.rundiffusion.com/prompt-guide-for-juggernaut-xi-and-xii/\"><span style=\"color:rgb(76, 110, 245)\">Prompting Guide by Adam for XI &amp; XII</span></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/RunDiffusion/Juggernaut-XI-v11\">Juggernaut on HuggingFace</a></p><p>A big thanks goes to <a target=\"_blank\" rel=\"ugc\" href=\"http://rundiffusion.com/?utm_source=Civitai&amp;utm_medium=referral&amp;utm_campaign=Kandoo\">RunDiffusion</a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://twitter.com/Colorblind_Adam\">Adam</a>, who diligently helped me make it work :) (Leave some love for them ;) )</p><p></p><p><strong>Hey everyone,</strong></p><p>Itâ€™s been 8 months since the last version was released here on CivitAI.<br />Of course, I havenâ€™t been idle during that time . I completed several projects to ensure Iâ€™d have the financial means to keep exploring new architectures and possibly do full finetunes on them in the future.</p><p>Juggernaut Flux (and its many sub-variants) was a ton of work, but ultimately, Iâ€™ve wrapped that chapter up. The training process gave me way too many headaches. To keep my sanity, I spent my spare time working on Juggernaut SDXL with the hope of maybe releasing one final version for you all.<br />And that day has finally come. :)</p><p>I wonâ€™t waste too much time on technical details.<br />I started by training a photographic dataset using <strong>Jug XII</strong> as the base to shift the focus back toward photorealism (Jug XII was leaning more into an artistic direction).<br />Then I re-captioned my set with <strong>Booru tags</strong> and trained it using <strong>SDXL</strong> as the base.<br />I merged these two sets (at a 0.15 ratio), but ultimately I wasnâ€™t satisfied.</p><p>So I ran the same Set again, this time using <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/573152/lustify-sdxl-nsfw-checkpoint\"><strong>Lustify</strong></a> by <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/coyotte\">Coyotte</a> as the base model.<br />That version was then added to the earlier one (at a 0.1 ratio) as a stabilizer for the output.<br />Since the Dataset was captioned using Booru tags, both Booru tagging and the captioning style from versions Xâ€“XII work extremely well with <strong>Ragnarok</strong>.</p><p></p><p><strong>Juggernaut Ragnarok</strong> has improved in many areas: <strong>photorealism, digital painting, poses, hands, feet</strong>, and much more.<br />That said, itâ€™s still an <strong>SDXL model</strong>, and I donâ€™t recommend comparing it to models like Flux, Reve, or Sora. For example, it still has limitations when it comes to text rendering or faces at a distance.</p><p>I recommend using it <strong>as part of a pipeline</strong> for your projects. Example setup:<br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/618692/flux\"><strong>FluxDev</strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/141592/pixelwave\"><strong>Pixelwave</strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.rundiffusion.com/juggernaut-flux\"><strong>Jug Flux Pro</strong></a> â†’ <strong>Juggernaut Ragnarok</strong></p><p>A quick personal note about Juggernaut:<br />Honestly, I donâ€™t know what comes next.<br />After the release of Sora and similar tools, the open-source image generation space feels a bit dull in comparison.<br />Nothing has really excited me enough to dive back into training (yes, Iâ€™m talking about HiDream too).<br />So Iâ€™m seeing <strong>Juggernaut Ragnarok</strong> as a kind of <strong>farewell</strong>, especially since itâ€™s unclear where things are headed with CivitAI in general.<br />(You can download <strong>all Juggernaut versions</strong> from HuggingFace, by the way.)</p><p><strong>Last but not least:</strong><br />Have fun with the model, share your creations, and good luck with your projects!<br />And in case youâ€™re wondering: <strong>Yes, you can do anything you want with Juggernaut</strong> : merge it, train it, sell the image outputs, etc.<br />Just a simple shoutout is all I ask. :)</p><p>And now, here are the recommended settings:</p><p></p><h3 id=\"recommended-settings(vae-is-baked-in):-5xmbwh5xg\"><strong>Recommended Settings(VAE is baked in):</strong></h3><p><strong>Res: 832*1216 (For Portrait, but any SDXL Res will work fine)</strong></p><p><strong>Sampler: DPM++ 2M SDE</strong></p><p><strong>Steps: 30-40</strong></p><p><strong>CFG: 3-6 (less is a bit more realistic)</strong></p><p><strong>Negative: Start with no negative, and add afterwards the Stuff you donÂ´t wanna see in that image.</strong></p><p><strong>VAE is already Baked In</strong></p><p><strong>HiRes: 4xNMKD-Siax_200k with 15 Steps and 0.3 Denoise + 1.5 Upscale</strong></p><p><br />And now, have fun trying it out. As always, I'm eagerly waiting for your pictures in the Gallery :)</p><p>If you liked the model, please leave a Like. In the end, that's what helps me the most as a creator on CivitAI. :)</p><p>Last but not least, I'd like to thank a few people without whom Juggernaut XL probably wouldn't have come to fruition:</p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"http://Dreamlook.AI\">Dreamlook.AI</a> (Trained 3 Side Sets)</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/chillpixel/models\">Chillpixel</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/SilasAI6609/models\">SilasAI6609</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://twitter.com/Colorblind_Adam\">Adam</a></p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581053+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "4629",
    "prompt": "Deep Negative V1.x\n<p>This embedding will tell you what is <strong>REALLY DISGUSTING</strong>ğŸ¤¢ğŸ¤®</p><p>So please put it in <strong><u>negative prompt</u></strong>ğŸ˜œ</p><p></p><p><u>âš This model is not trained for SDXL and may bring undesired results when used in SDXL.</u></p><p><u>If you use </u><strong><u>SDXL</u></strong><u>, recommended this ğŸ‘‡</u></p><p>another deep-negative:</p><ul><li><p>pony version: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/831971/deep-negative-pony\">https://civitai.com/models/831971</a></p></li><li><p>SDXL version: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/407448\">https://civitai.com/models/407448</a></p></li></ul><p></p><h3 id=\"top-qanda-7m62mf8cx\">TOP Q&amp;A</h3><ul><li><p>how to use TI model?</p></li></ul><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Textual-Inversion\">https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Textual-Inversion</a></p><ul><li><p>what is negative prompt?</p></li></ul><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Negative-prompt\">https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Negative-prompt</a></p><p></p><p><strong>[Special Reminder]</strong> If your webui reports the following errors:</p><p>- <code>CUDA: CUDA error: device-side assert triggered</code></p><p>- <code>Assertion -sizes[i] &lt;= index &amp;&amp; index &lt; sizes[i] &amp;&amp; \"index out of bounds\" failed</code></p><p>- <code>XXX object has no attribute 'text_cond'</code></p><p>Please try using a model version other than 75T.</p><p>&gt; The reason is that many scripts do not handle overly long negative prompt words (greater than 75 tokens) properly, so choosing a smaller token version can improve this situation.</p><p></p><h3 id=\"update:230120-what-does-it-do-vgja91pxb\">[Update:230120] What does it do?</h3><p>These embedding learn what disgusting compositions and color patterns are, including faulty human anatomy, offensive color schemes, upside-down spatial structures, and more. Placing it in the negative can go a long way to avoiding these things.</p><p>-</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/00f10479-531c-4dc8-8021-f2af1c697700/width=525\" /></p><p></p><p></p><h3 id=\"what-is-2t-4t-16t-32t-t5rkaw49k\">What is 2T 4T 16T 32T?</h3><p>Number of vectors per token</p><p></p><h3 id=\"update:230120-what-is-64t-75t-x1f6t2460\">[Update:230120] What is 64T 75Tï¼Ÿ</h3><p><strong>64T</strong>: Train over <u>30,000</u> steps on mixed datasets.</p><p><strong>75T</strong>: embedding limit maximum size, training 10,000 steps on a <u>special dataset</u> (generated by many different sd models and special reverse processing)</p><p></p><h3 id=\"which-one-should-choose-x50v8knte\">Which one should choose?</h3><ul><li><p><strong>75T</strong>: The most â€easy to useâ€œ embedding, which is trained from its accurate dataset created in a special way with almost <strong>no side effects</strong>. And it contains enough information to cover various usage scenarios. But for some <u>\"good-trained-model\"</u> may hard to effect</p><p>and, change about may be subtle and not drastic enough.</p></li><li><p><strong>64T</strong>: It works for all models, but has side effect. so, some tuning is required to find the best weight. <u>recommend</u>: [( NG_DeepNegative_V1_64T :0.9) :0.1]</p></li><li><p><strong>32T</strong>: Useful, but too more</p></li><li><p><strong>16T</strong>: Reduces the chance of drawing bad anatomy, but may draw ugly faces. Suitable for raising <strong>architecture</strong> level.</p></li><li><p><strong>4T</strong>: Reduces the chance of drawing bad anatomy, but has a little effect on light and shadow</p></li><li><p><strong>2T</strong>: â€easy to useâ€œ like T75, but just a little effect</p></li></ul><p></p><h3 id=\"suggestion-g10t4z116\">Suggestion</h3><p>Because this embedding is learning how to create <strong>disgusting concepts</strong>, it cannot improve the picture quality accurately, so it is best used with <u>(worst quality, low quality, logo, text, watermark, username)</u> these negative prompts.</p><p>Of course, it is completely fine to use with other similar negative embeddings.</p><p></p><h3 id=\"more-examples-and-tests-vdclnno03\">More examples and tests</h3><ul><li><p>draw building: <a target=\"_blank\" rel=\"ugc\" href=\"https://imgur.com/5aX9yrP\">https://imgur.com/5aX9yrP</a></p></li><li><p>hand fix: <a target=\"_blank\" rel=\"ugc\" href=\"https://imgur.com/rDlsrgS\">https://imgur.com/rDlsrgS</a></p></li><li><p>portrait (with <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4514/pure-eros-face\">PureErosFace</a>): <a target=\"_blank\" rel=\"ugc\" href=\"https://imgur.com/1Lqq595\">https://imgur.com/1Lqq595</a> <a target=\"_blank\" rel=\"ugc\" href=\"https://imgur.com/V5kXBXz\">https://imgur.com/V5kXBXz</a></p></li><li><p>fusion body fix:</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ac167975-eadc-4c28-e87e-0d8ed2bec000/width=525\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/61bd2d45-b21e-47dd-a9c4-cbad326dc200/width=525\" /></p><p></p></li></ul><p></p><h3 id=\"how-is-it-work-z282wbmyy\">How is it work?</h3><p>I tried to make SD learn what is really disgusting with deepdream algorithm, the dataset is imagenet-mini (1000 images chosen randomly from the dataset again)</p><p>deepdream is <strong>REALLLLLLLLLLLLLLLLLLLLLY</strong> disgusting ğŸ¤® and process of training this model really made me experience physical discomfort ğŸ˜‚</p><p></p><h3 id=\"backup-sokvc4jev\">Backup</h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/lenML/DeepNegative/tree/main\">https://huggingface.co/lenML/DeepNegative/tree/main</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581059+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "6755",
    "prompt": "Cetus-Mix\n<p><strong>NOTICE</strong>:<strong>LET ME KNOW</strong> before you put this model on <u>commercial usage</u>.</p><p>My twitter account:<strong>@eagelaxis </strong>:) Contact me if needed.</p><p>Discord Account:<strong>Eagelaxis#7818</strong></p><p><strong>Version Choosing Advice</strong>:<strong>V2f,V3,Coda and V3.5</strong> are recommended,especially <strong>CODA</strong> for first-time users.</p><p>Hard to tell how many models used to merge.</p><p>Check the example images to recognize this model's art style</p><p>For more example images, just take a look at <a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art\">https://pixai.art</a></p><p>More attention on shades and backgrounds compared with former models(<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6408/andromeda-mix\">Andromeda-Mix | Stable Diffusion Checkpoint | Civitai)</a></p><p>Hands-fix is still waiting to be improved.</p><p>Highres-fix(upscaler) is strongly recommended(using the SwinIR_4x,R-ESRGAN 4x+anime6B by myself) in order to not make blurry images.</p><p>(Sorry for the misunderstanding caused by myself.\"Bad_prompt_v2:1.4\" is a kind of embedding recognized as collection of normal negative prompts such as\"lowres,bad anatomy\".)</p><p>Recommend: Clip skip 2 Sampler:DPM++2M Karras Steps:20+</p><p>CFG scale:4-8 Vae:<a target=\"_blank\" rel=\"ugc\" href=\"http://Pastel-Waifu-Diffusion.vae.pt\">Pastel-Waifu-Diffusion.vae.pt</a>(The vae used by Pastel-mix si just good enough)</p><p>Highres.fix:SwinIR_4x Hires steps:10+ Denoising strength:0.4+ Upscale by: 1.5+</p><p>Loras along with embeddings on hands-fix are strongly recommended.</p><p>V4.5 should be coming soon.</p><p>Looking forward to your reviews!</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581062+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "372465",
    "prompt": "Pony Realism ğŸ”®\n<p><a target=\"_blank\" rel=\"ugc\" href=\"http://ko-fi.com/zyloo\"><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b1ed0fa2-119a-44f2-a1df-efcf794f4484/width=525/b1ed0fa2-119a-44f2-a1df-efcf794f4484.jpeg\" /></a>âœ¨ <strong><em>Latest </em></strong>| ğŸŒ <strong><em>Main </em></strong>| âš¡ï¸ <strong><em>Ligthning/Hyper </em></strong>| ğŸŒ€ <strong><em>Alt version </em></strong>| ğŸ–Œ <strong><em>Inpaint </em></strong>| ğŸ“¦ <strong><em>Old</em></strong></p><h3 id=\"all-versions-include-vae-vote-which-version-do-you-prefer-on-the-generator\"><em>ğŸ”¸</em><strong><em>All Versions include VAE</em></strong><br /><strong><br /></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://strawpoll.com/X3nkP75JjgE\"><strong><em>ğŸ“© Vote which version do you prefer on the generator</em></strong></a><strong><br /></strong></h3><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0e647003-b439-44f5-8061-5def6fb9ee28/width=525/0e647003-b439-44f5-8061-5def6fb9ee28.jpeg\" />âœ¨<strong>v2.3</strong> <span style=\"color:rgb(255, 197, 38)\"><strong><em>U</em></strong></span><span style=\"color:rgb(255, 170, 59)\"><strong><em>L</em></strong></span><span style=\"color:rgb(240, 162, 60)\"><strong><em>T</em></strong></span><span style=\"color:rgb(237, 161, 19)\"><strong><em>R</em></strong></span><span style=\"color:rgb(227, 143, 9)\"><strong><em>A </em></strong></span><strong>is a distinct variant of the standard v2.3.</strong><br />While it technically improves overall output, my intention is to treat this version as <strong>experimental</strong>, exploring potential directions for future updates.</p><p>This release brings more natural and balanced lighting (also darkness), enhanced skin detail and an increased realism.</p><p>If you're using this model for <strong>Furry or Fur-based prompts</strong>, make sure to use the <strong>\"Furry\" trigger</strong>, or pair it with my <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1565117/fur-enhancer\"><strong>Fur Enhancer LoRA</strong> </a>for best results.</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5874745d-addb-47c3-becd-c3eac1f32309/width=525/5874745d-addb-47c3-becd-c3eac1f32309.jpeg\" /></p><ul><li><p><span style=\"color:rgb(255, 235, 184)\"><strong><em>v2.3: (Latest) </em></strong></span>âœ¨</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/372465?modelVersionId=1763661\"><strong><em>Main Version</em></strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/372465?modelVersionId=1920896\"><strong><em>ULTRA Version</em></strong></a></p></li></ul></li><li><p><strong><em>v2.2:</em></strong></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/372465?modelVersionId=914390\"><strong>Main Version</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/372465?modelVersionId=987210\"><strong>4 Step Hyper Version</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/372465?modelVersionId=987238\"><strong>8 Step Hyper Version</strong></a></p></li></ul><p></p></li></ul><p><span style=\"color:rgb(64, 192, 87)\"><strong><em><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/53e3a929-f33c-4551-860a-870547f2f4e0/width=525/53e3a929-f33c-4551-860a-870547f2f4e0.jpeg\" /></em></strong></span>I have written an <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/6621\"><strong><em>article </em></strong></a>that explains and provides some useful resources to help you achieve great generation results. You can check it out for detailed insights and recommendations.</p><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/84343c41-81b6-41f4-ba99-240ef0bc3205/width=525/84343c41-81b6-41f4-ba99-240ef0bc3205.jpeg\" />ğŸ”<em> </em><strong><em>Samplers</em></strong></p><ul><li><p>DPM++ 2M SDE Karras</p></li><li><p>DPM++ 2S a Karras</p></li><li><p>DPM++ SDE Karras</p></li><li><p>DPM++ 2M SDE Exponential</p></li><li><p>DPM2 a</p></li><li><p>DPM++ 2S a</p></li><li><p>DPM++ 3M *</p></li><li><p>Euler A</p></li></ul><p>âš™ï¸ <strong><em>Generation Settings</em></strong></p><ul><li><p><strong>Steps:</strong> 30 or more</p></li><li><p><strong>CFG Scale:</strong> 6â€“7</p></li><li><p><strong>Clip Skip:</strong> 2</p></li><li><p><strong>Resolution:</strong> Greater than 1024px</p></li></ul><p>ğŸ—’ï¸ <strong><em>Notes</em></strong></p><ul><li><p>Use <strong>Danbooru</strong> tags</p></li><li><p>Keep individual <strong>prompt weights â‰¤ 1.5</strong></p></li><li><p>Use \"<strong>female</strong>/<strong>male</strong>\" instead of \"<strong>woman</strong>/<strong>man</strong>\" for better tagging compatibility</p></li></ul><p>ğŸ–‹ï¸ <strong><em>Prompt Style</em></strong></p><ul><li><p><strong>Positive Prompt Tags:</strong> <code>score_9</code>, <code>score_8_up</code>, <code>score_7_up</code>, <code>BREAK</code></p></li><li><p><strong>Negative Prompt Tags:</strong> <code>score_4</code>, <code>score_5</code>, <code>score_6</code></p><p></p></li></ul><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e67486ae-cd61-499b-a714-1580af685503/width=525/e67486ae-cd61-499b-a714-1580af685503.jpeg\" />âš ï¸ <span style=\"color:rgb(250, 176, 5)\"><strong>Avoid </strong></span><strong>DPM++ 2M Karras</strong> (Not recommended for generation)</p><p>âœ… <strong>Recommended Samplers</strong></p><ul><li><p><strong>Euler A</strong></p></li><li><p><strong>DPM2 A</strong> <em>(Best for detail)</em></p><p></p></li></ul><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7f442c78-b21c-4e27-9d58-0faa0ef532a5/width=525/7f442c78-b21c-4e27-9d58-0faa0ef532a5.jpeg\" /></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/480835/pony-amateur\">Pony Amateur âœ¨</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/927305/pony-realism-enhancer\">Pony Realism Enhancer âœ¨</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1371405/pony-skin-enhancer\">Pony Skin Enhancer âœ¨</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1565117/fur-enhancer\">Pony Fur Enhancer âœ¨</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/633524/background-detail-enhancer\">Background Detail Enhancerâœ¨</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/432586/cinematic-shot\">Cinematic Shotâœ¨</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1608469?modelVersionId=1820245\">Pony Realism v2.2 Style/Support Blend âœ¨</a></p></li></ul><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ae770c78-95eb-4731-9709-7a46b50e91be/width=525/ae770c78-95eb-4731-9709-7a46b50e91be.jpeg\" /><em>Read the following </em><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/5545/pony-realism-lora-training-and-preset\"><strong><em>article </em></strong></a><em>for tips and my training preset</em></p><p></p><h3 id=\"buzz-for-the-best-images\">âš¡ï¸ <span style=\"color:rgb(253, 126, 20)\">Buzz for the Best Images </span>âš¡ï¸</h3><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581082+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "25694",
    "prompt": "epiCRealism\n<h2 id=\"heading-41\">Natural Sin Final and last of epiCRealism</h2><p><em><s>Since SDXL is right around the corner</s>, let's say it is the final version for now since I put a lot effort into it and probably cannot do much more.</em></p><p>I tried to refine the understanding of the Prompts, Hands and of course the Realism.<br /><strong>Let's see what you guys can do with it.</strong></p><p>Thanks to <span data-type=\"mention\" class=\"mantine-1yiar0p\" data-id=\"mention:1008701\" data-label=\"drawaline\">@drawaline</span> for the in-depth <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/25694?modal=commentThread&amp;commentId=178540\">review</a>, so i'd like to give some advices to use this model.<br />[<em>expand to see Advices</em>]</p><h3 id=\"heading-494\">Advices</h3><ul><li><p><strong>use simple prompts</strong></p></li><li><p><strong>no need</strong> to use keywords like \"masterpiece, best quality, 8k, intricate, high detail\" or \"(extremely detailed face), (extremely detailed hands), (extremely detailed hair)\" since it doesn't produce appreciable change</p></li><li><p><strong>use simple negatives </strong>or<strong> small negative embeddings</strong>. gives most realistic look <em><span style=\"color:rgb(134, 142, 150)\">(check samples to get an idea of negatives i used</span>)</em></p></li><li><p>add \"asian, chinese\" to negative if you're looking for ethnicities other than Asian</p></li><li><p>Light, shadows, and details are excellent without extra keywords</p></li><li><p>If you're looking for a natural effect, avoid \"cinematic\"</p></li><li><p>avoid using \"1girl\" since it pushes things to render/anime style</p></li><li><p>to much description of the face will turn out bad mostly</p></li><li><p>for a more fantasy like output use 2M Karras Sampler</p></li><li><p>no extra noise-offset needed, but u can if you like to ğŸ˜‰</p></li></ul><p></p><h3 id=\"heading-495\">How to use?</h3><p><strong>Prompt: </strong>simple explanation of the image <em><span style=\"color:rgb(134, 142, 150)\">(try first without extra keywords)</span></em><br /><strong>Negative:</strong> \"cartoon, painting, illustration, (worst quality, low quality, normal quality:2)\"<br /><strong>Steps:</strong> &gt;20 <em><span style=\"color:rgb(134, 142, 150)\">(if image has errors or artefacts use higher Steps)</span></em><br /><strong>CFG Scale:</strong> 5 <em><span style=\"color:rgb(134, 142, 150)\">(higher config scale can lose realism, depends on prompt, sampler and Steps)</span></em><br /><strong>Sampler:</strong> Any Sampler <em><span style=\"color:rgb(134, 142, 150)\">(SDE, DPM-Sampler will result in more realism)</span></em><br /><strong>Size:</strong> 512x768 or 768x512<br /><strong>Hires upscaler:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://upscale.wiki/wiki/Model_Database\">4x_NMKD-Superscale-SP_178000_G</a> (Denoising: 0.35, Upscale: 2x)</p><p></p><h3 id=\"heading-87\">Useful Extensions</h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\">!After Detailer</a> | <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Mikubill/sd-webui-controlnet\">ControlNet</a> | <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/ArtVentureX/sd-webui-agent-scheduler\">Agent Scheduler</a> | <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Coyote-A/ultimate-upscale-for-automatic1111\">Ultimate SD Upscale</a></p><p></p><p><strong>â‰ No VAE needed </strong>but it is better to use one for more vibrant colors</p><p>â­ Feel free to leave Reviews and Samples - and always have fun creating â¤</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581102+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "140272",
    "prompt": "Hassaku XL (Illustrious)\n<p>Hassaku aims to be a anime model with a bright and distinct anime style. <br /><br /><span style=\"color:rgb(193, 194, 197)\"><em>You can run Hassaku XL and use its API on SinkIn: </em></span><a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/JWknjgr\"><span style=\"color:rgb(34, 139, 230)\"><em>https://sinkin.ai/m/JWknjgr</em></span></a><br /></p><p>My <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/zSR5FcYWWE\"><strong>Discord</strong></a> for everything related to anime models and art. </p><p></p><p>____________________________________________________________<br /><strong><u>Supporters:</u></strong></p><p>Thanks to my supporters <strong>Riyu, SETI and Kodokuna</strong><br /></p><p>____________________________________________________________<br /><strong><u>Using the model:</u></strong></p><ul><li><p><span style=\"color:rgb(219, 222, 225)\">The model is trained using images with minimal disruptive elements such as floating text, logos, speech bubbles, and signatures. If any of these elements are present in an image, please include the prompt \"signature\" as a negative prompt</span></p></li><li><p>Metadata and franchise tags are excludedâ€”please do not use them. Tags such as \"highres\" and franchise-related tags like \"re:zero kara hajimeru isekai seikatsu\" are not used in training</p></li><li><p>Look at the example images, to see how the model should be used</p></li><li><p>Model is trained to be not complicated in use, tag order:<br />First are the number of person, then character names, rest.<br />Example: 1girl, rem \\(re:zero\\), standing, masterpiece, upper body</p></li><li><p>NoobAIs Loras working for the most part better in compare to <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/795765/illustrious-xl\"><span style=\"color:rgb(209, 213, 219)\">Illustrious loras</span></a></p></li><li><p>Here are some <span style=\"color:rgb(242, 242, 242)\">resolution </span>options for SDXL:</p><ul><li><p>1536 x 640</p></li><li><p>1344 x 768</p></li><li><p>1216 x 832</p></li><li><p>1152 x 896</p></li><li><p>1024 x 1024</p></li><li><p>896 x 1152</p></li><li><p>832 x 1216 (most recommended)</p></li><li><p>768 x 1344</p></li><li><p>640 x 1536</p></li></ul></li></ul><p><br />______________________________________________________</p><p><strong><u>Version and License info</u></strong><span style=\"color:rgb(193, 194, 197)\"><u>:</u></span></p><ul><li><p><span style=\"color:rgb(209, 213, 219)\">Below V1 </span>merges <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/260267\">ANIMAGINE XL 3.0</a></p></li><li><p><span style=\"color:rgb(209, 213, 219)\">Version V1 use </span><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/795765/illustrious-xl\"><span style=\"color:rgb(209, 213, 219)\">Illustrious-XL</span></a><span style=\"color:rgb(209, 213, 219)\"> &amp;</span><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/827184?modelVersionId=1068947\"><span style=\"color:rgb(209, 213, 219)\"> WAI-NSFW-illustrious-SDXL</span></a><span style=\"color:rgb(209, 213, 219)\"> with additional training</span></p></li><li><p>V2 is trained on its own and don't include any extra merge. Base was <span style=\"color:rgb(209, 213, 219)\">V1</span>, <span style=\"color:rgb(209, 213, 219)\">it is trained to include newer or missing characters. It was also used for further training tests</span></p></li><li><p><span style=\"color:rgb(209, 213, 219)\">V3 is a merge of </span><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/795765/illustrious-xl\"><span style=\"color:rgb(209, 213, 219)\">Illustrious-XL</span></a><span style=\"color:rgb(209, 213, 219)\"> and V2, to fix some issues and was also trained to include newer or missing characters</span></p><p></p><p><span style=\"color:rgb(209, 213, 219)\">All Models using the </span><a target=\"_blank\" rel=\"ugc\" href=\"https://freedevproject.org/faipl-1.0-sd/\"><strong>Fair AI Public License 1.0-SD</strong></a><span style=\"color:rgb(209, 213, 219)\"> license</span>. <br /><br /></p></li></ul><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581113+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "264290",
    "prompt": "Not Artists Styles for Pony Diffusion V6 XL\n<p>Styles are trained on synthetic data and do not copy the styles of artists!</p><p>Photo 2 - is trained on real data (Dataset from Unsplash)</p><p>[M] Merged LoRAs</p><p>Recommended LoRA Strength (Weight): 0.8-1</p><p>Preview generated without using ADetailer &amp; Hires. fix</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581127+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "9409",
    "prompt": "ä¸‡è±¡ç†”ç‚‰ | Anything XL\n<p><strong><span style=\"color:rgb(250, 82, 82)\">ä¸‹è½½æ¨¡å‹ä¹‹å‰ï¼Œè¯·ä»”ç»†æŸ¥çœ‹æ¨¡å‹ä»‹ç»</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">Please review the model introduction carefully before downloading the model</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å‰ã«ã€ãƒ¢ãƒ‡ãƒ«ç´¹ä»‹ã‚’ã‚ˆãè¦‹ã¦ãã ã•ã„</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">æœ¬ç³»åˆ—æ¨¡å‹åŠè¡ç”Ÿæ¨¡å‹ï¼Œç¦æ­¢ä¸Šä¼ LiblibAIæˆ–ShakkerAI</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">This series of models and their derivatives are prohibited from being uploaded to LiblibAI or ShakkerAI</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">ã“ã®ã‚·ãƒªãƒ¼ã‚ºã®ãƒ¢ãƒ‡ãƒ«ãŠã‚ˆã³ãã®æ´¾ç”Ÿãƒ¢ãƒ‡ãƒ«ã¯ã€LiblibAIã¾ãŸã¯ShakkerAIã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã¯ç¦æ­¢ã•ã‚Œã¦ã„ã¾ã™</span></strong></p><h3 id=\"-07dpl19o7\"><strong>æ³¨æ„ï¼š</strong></h3><h3 id=\"anything-syqu3ufe0\"><strong>ğŸ‘‡ä¸‹é¢çš„Anythingæ¨¡å‹ä¸ºå†’ç”¨åç§°ï¼Œå¹¶éæœ¬äººåˆ¶ä½œï¼Œè¯·ä¸è¦è¿›è¡Œä»˜è´¹</strong></h3><h3 id=\"this-anything-model-is-an-unauthorized-use-of-the-name-and-was-not-created-by-me.-please-do-not-make-any-payments.-umhtkc5hs\"><strong>ğŸ‘‡This Anything model is an unauthorized use of the name and was not created by me. Please do not make any payments.</strong></h3><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/be33da04-6da9-4328-b17d-85053bed9971/width=525/be33da04-6da9-4328-b17d-85053bed9971.jpeg\" /></p><p></p><h1 id=\"-350ce2yvm\"><strong>â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</strong></h1><h2 id=\"ai-art-should-be-looked-like-ai-not-like-humans.-bp2ytwful\"><strong><em><span style=\"color:rgb(250, 82, 82)\">AI </span><span style=\"color:rgb(230, 73, 128)\">art</span> <span style=\"color:rgb(190, 75, 219)\">should</span> <span style=\"color:rgb(121, 80, 242)\">be</span> <span style=\"color:rgb(76, 110, 245)\">looked</span> <span style=\"color:rgb(34, 139, 230)\">like</span> <span style=\"color:rgb(21, 170, 191)\">AI,</span> <span style=\"color:rgb(18, 184, 134)\">not</span> <span style=\"color:rgb(130, 201, 30)\">like</span> <span style=\"color:rgb(250, 176, 5)\">humans</span><span style=\"color:rgb(253, 126, 20)\">.</span></em></strong></h2><h1 id=\"-cmqpj4xi0\"><strong>â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</strong></h1><h1 id=\"anything-xl-68cfk8kvz\"><strong>Anything-XL</strong></h1><p>AnythingXL Î² 4 is the AnythingXL here. If you download the previous model, there is no need to download it again.</p><p><span style=\"color:rgb(193, 194, 197)\">AnythingXLbeta4 is another product encouraged by friends in the group. The premise is the highly developed SDXL model, with the quality of the trained model getting higher and higher. The negative hint word in the display graph's embedding name is only copied, and it actually has no effect. Beta4 was created because the model with the fourth test version was the only one I could tolerate looking at. Model fusion is a dead end, with a complete mess in terms of artistic style diversity and the accuracy of some prompt words.</span></p><h2 id=\"formula:-ygzp3cp2c\"><strong>Formula:</strong></h2><pre><code>aingdiffusionXL_V0.6       x 0.144375\nanimagineXLV3              x 0.144375\ncutecore_xl                x 0.12375\nkohakuXLDelta_rev1         x 0.1375\nBAXLBArtstyleXLv2          x 0.3375\nponyV6                     x 0.1125</code></pre><p>Model order only represents fusion order and has nothing to do with model quality</p><p>Model merge is implemented using the Webui-Supermerge plugin. According to FairAIPublicLicense1.0-SD, the recipe needs to be publicly disclosed, and any merged models that merged this model must also disclose the merge recipe in accordance with this license.</p><h2 id=\"parameters+-ific52v27\"><strong>Parameters+ï¼š</strong></h2><p>Prompt words are different from SD1.5, and for best results, it is recommended to follow a structured prompt template:</p><pre><code>&lt;|special|&gt;, \n&lt;|artist|&gt;, \n&lt;|special(optional)|&gt;, \n&lt;|characters name|&gt;, &lt;|copyrights|&gt;, \n&lt;|quality|&gt;, &lt;|meta|&gt;, &lt;|rating|&gt;ï¼Œâ€¦â€¦\n\n&lt;|tags|&gt;, </code></pre><p>special(optional):These prompt words only need to be typed once, put in the front, there is no need to put in the back</p><h3 id=\"special-tags-orj8xpit3\"><strong>Special tagsï¼š</strong></h3><p>The model can still be used without these special cue words, but incorporating these special tags when necessary can help steer the generated results towards the desired direction.</p><p><strong>years:</strong></p><p>These words help guide the results towards modern and retro anime art styles, with a specific timeframe of approximately 2005 to 2023</p><pre><code>newest\t        2021 to 2024\nrecent\t        2018 to 2020\nmid\t            2015 to 2017\nearly\t        2011 to 2014\nold             2005 to 2010</code></pre><p><strong>NSFWï¼š</strong></p><p>These words help guide the results towards adult content, but generally do not generate adult content if rating words are not included.</p><p>Of course, you can also put it in negative prompts.</p><pre><code>safe\t            General\nsensitive\t        Sensitive\nnsfw\t            Questionable\nexplicit, nsfw\t    Explicit</code></pre><p><strong>qualityï¼š</strong></p><p>While this model can function without quality words, in practice, these words can still be used to adjust the output.</p><pre><code>masterpiece\t            &gt; 95%\nbest quality\t        &gt; ?\ngreat quality\t        &gt; ?\ngood quality\t        &gt; ?\nnormal quality\t        &gt; ?\nlow quality\t            &gt; ?\nworst quality\t        â‰¤ 10%</code></pre><p><strong>Resolutionï¼š</strong></p><p>You are free to use the vast majority of reasonable resolutions, whether it is the resolution used by SD1.5 at 512*768 or higher resolutions above 2048, each will have a different effect. However, using images that are too large or too small may cause the picture to break down or the character/background structure to become distorted.</p><p><strong>Tagsï¼š</strong></p><p>If you want to generate high-quality pictures, you can use negative prompts, such as:</p><pre><code>nsfw, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, artist name</code></pre><p>Negative tags can include common negative tags, but it is best not to assign too high of a weight to their content, for example (ugly:2.8).</p><p>Because of models merge, some labels in the original model that have not been fully trained may be lost, and some labels may need to have a weight of over 1.5 in order to be effective.</p><h3 id=\"resolution-z7ubsr43p\"><strong>Resolutionï¼š</strong></h3><p>A resolution greater than 1024Ã—1024 is recommended, and hires fix is recommended if you want higher resolution or quality</p><p>Most of the generation parameters of the example graph are:</p><pre><code>euler_a | 20steps | no hires fix | CFG7</code></pre><pre><code>2048 x 2048     not recommended\nâ€¦â€¦\n1280 x 2048     \n1280 x 1536     \n960  x 1536     Recommended\n1024 x 1024\t    1:1   Square\nâ€¦â€¦ \n960  x 640                \n768  x 512      SD1.5\nâ€¦â€¦\n2048 x 512      Â¿  Unable to guarantee the quality\n512  x 2048     Â¿  Unable to guarantee the quality</code></pre><h2 id=\"disclaimer:-fpml81eib\"><strong>Disclaimer:</strong></h2><p><strong><span style=\"color:rgb(250, 82, 82)\">All images generated by the model are created by the users themselves, and the model author cannot control the images generated by the users. The model author will not be held responsible for any potential copyright infringement or unsafe images.</span></strong></p><h2 id=\"license:-bu0z358o8\"><strong>License:</strong></h2><p>Anything now uses the <a target=\"_blank\" rel=\"ugc\" href=\"https://freedevproject.org/faipl-1.0-sd/\"><strong><u>Fair AI Public License 1.0-SD</u></strong></a>, compatible with Stable Diffusion models.<strong>All versions of the models in the Anything series are open source using this protocol</strong>. Key points:</p><ul><li><p><strong>Modification Sharing:</strong> If you modify Anything, you must share both your changes and the original license.</p></li><li><p><strong>Source Code Accessibility:</strong> If your modified version is network-accessible, provide a way (like a download link) for others to get the source code. This applies to derived models too.</p></li><li><p><strong>Distribution Terms:</strong> Any distribution must be under this license or another with similar rules.</p></li><li><p><strong>Compliance:</strong> Non-compliance must be fixed within 30 days to avoid license termination, emphasizing transparency and adherence toopen-sourcevalues.</p></li></ul><h1 id=\"-0sz67drmd\"><strong>â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”</strong></h1><p><strong><span style=\"color:rgb(76, 110, 245)\">æ‚¨æ‰€çœ‹åˆ°çš„æ˜¯å•ç‹¬ç»™æ—¥æœ¬å’Œä¸­å›½AIç©å®¶çš„å¤‡æ³¨ï¼š</span></strong></p><p>â‘ é™¤ééœ€è¦ç”Ÿæˆ2048x2048ä»¥ä¸Šçš„å›¾æˆ–è€…é‡åˆ°ä¸¥é‡é—®é¢˜ï¼Œå¦åˆ™è¯·æ”¾å¼ƒé«˜æ¸…ä¿®å¤ã€‚</p><p>â‘¡å¦‚æœä½ æ„Ÿè§‰æ¨¡å‹åå‘æŸæ–¹é¢ï¼Œè¯·å…ˆæ£€æŸ¥æç¤ºè¯ã€‚ä¸€äº›æç¤ºè¯åœ¨ä¹‹å‰ä½¿ç”¨çš„æ¨¡å‹ä¸Šå¯èƒ½æ— æ•ˆï¼Œåœ¨è¿™é‡Œå¯èƒ½æœ‰æ•ˆã€‚</p><p>â‘¢è¯·ä¸è¦ç”¨SD1.5çš„ä½¿ç”¨ä¹ æƒ¯æ¥ä½¿ç”¨SDXLï¼Œå› ä¸ºä¸¤ä¸ªæ¨¡å‹æœ¬è´¨ä¸Šä¸åŒã€‚å¦‚æœ‰å¿…è¦ï¼Œè¯·ä½¿ç”¨ç®€ä»‹ä¸­çš„è´¨é‡è¯ï¼Œè€Œä¸æ˜¯8ké«˜æ¸…ç­‰ã€‚</p><p>â‘£æœ€å¥½ä¸è¦å’ŒNegativeXLä¸€èµ·ä½¿ç”¨ï¼Œä¹Ÿä¸å»ºè®®ä½¿ç”¨é«˜æƒé‡çš„è´Ÿé¢æç¤ºè¯ï¼Œå¦‚(ugly:2)ã€‚</p><p>â‘¤æƒ³è¦ä¸€å¼ å¥½å›¾ç‰‡ï¼Œè¯·å°½å¯èƒ½è¯¦ç»†æè¿°å†…å®¹ï¼Œè€Œä¸è¦ä»…æ ‡æ³¨\"1girl, nsfw\"ï¼Œè¿™æ ·æ— æ³•å¾—åˆ°å¥½çš„å›¾ç‰‡ã€‚</p><p><strong><span style=\"color:rgb(76, 110, 245)\">ã‚ãªãŸãŒè¦‹ã¦ã„ã‚‹ã®ã¯ã€æ—¥æœ¬ã¨ä¸­å›½ã®AIãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¸ã®å˜ç‹¬ã®å‚™è€ƒã§ã™ï¼š</span></strong></p><p>â‘ 2048x2048ä»¥ä¸Šã®ç”»åƒã‚’ç”Ÿæˆã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã€æ·±åˆ»ãªå•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã‚‹å ´åˆã‚’é™¤ãã€é«˜ç”»è³ªä¿®å¾©ã‚’ã‚„ã‚ã¦ãã ã•ã„ã€‚</p><p>â‘¡ãƒ¢ãƒ‡ãƒ«ãŒç‰¹å®šã®å´é¢ã«åã£ã¦ã„ã‚‹å ´åˆã‚„ä»–ã®å•é¡ŒãŒã‚ã‚‹å ´åˆã¯ã€ãƒ’ãƒ³ãƒˆãƒ¯ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ä¸€éƒ¨ã®ãƒ’ãƒ³ãƒˆãƒ¯ãƒ¼ãƒ‰ã¯ä»¥å‰ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯æ©Ÿèƒ½ã—ãªã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ãŒã€ã“ã“ã§ã¯æœ‰åŠ¹ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚</p><p>â‘¢SD1.5ã®ä½¿ç”¨æ³•ã§ã¯ãªãã€SDXLã®ä½¿ç”¨æ³•ã¯ç•°ãªã‚‹ãŸã‚ã€æ³¨æ„ã—ã¦ãã ã•ã„ã€‚å¿…è¦ãªå ´åˆã¯ã€8kã®é«˜ç”»è³ªãªã©ã§ã¯ãªãã€ä»¥ä¸‹ã«ç¤ºã™å“è³ªã®è¨€è‘‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚</p><p>â‘£NegativeXLã¨ã®çµ„ã¿åˆã‚ã›ã¯é¿ã‘ã‚‹ã¹ãã§ã‚ã‚Šã€(ugly:2)ã®ã‚ˆã†ãªå¤§ããªã‚¦ã‚§ã‚¤ãƒˆã®ãƒã‚¬ãƒ†ã‚£ãƒ–ãªãƒ’ãƒ³ãƒˆãƒ¯ãƒ¼ãƒ‰ã®ä½¿ç”¨ã‚‚ãŠã™ã™ã‚ã—ã¾ã›ã‚“ã€‚</p><p>â‘¤è‰¯ã„ç”»åƒãŒå¿…è¦ãªå ´åˆã¯ã€å†…å®¹ã‚’å¯èƒ½ãªé™ã‚Šè©³ç´°ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚å˜ã«ã€Œ1girl, nsfwã€ã¨ã„ã†ãƒ©ãƒ™ãƒ«ã‚’ä»˜ã‘ã‚‹ã ã‘ã§ã¯è‰¯ã„ç”»åƒãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã€‚</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581154+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "36520",
    "prompt": "GhostMix\n<p><a rel=\"ugc\" href=\"https://civitai.com/models/312431/ghostxl\"><strong>My New SDXL Model (GhostXL) already release on Civitai, please check it out. I think it will give you a surprise !</strong></a></p><p>Any questions or corporations? Find me at <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/576hznSTS7\">Discord</a> or by Wechat: ghostinshell10. Thanks</p><p><strong>You can run GhostMix on the cloud at Mage &amp; SinkIn.ai:</strong></p><p><span style=\"color:rgb(219, 222, 225)\">My model is now supported to create a short-form animation with the new \"Animate\" feature on Mage!</span></p><p><span style=\"color:rgb(193, 194, 197)\">GhostMix V2 at: </span><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/model/ghostmix-v2\">https://www.mage.space/model/ghostmix-v2</a></p><p><span style=\"color:rgb(193, 194, 197)\">GhostXL at: </span><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/model/ghostxl_v10BakedVAE\">https://www.mage.space/model/ghostxl_v10BakedVAE</a></p><p>SinkIn.ai<span style=\"color:rgb(193, 194, 197)\"> GhostMix model at: </span><a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/DY5rYnx\">https://sinkin.ai/m/DY5rYnx</a></p><p></p><h2 id=\"important-matters\"><em><u>IMPORTANT MATTERS(é‡è¦äº‹é¡¹)</u></em></h2><ol><li><p>I think compacity is the most important thing of a checkpoint, that's why I don't merge ANY LORA in GhostMix. Checkpoint solves the CAN DO problem and Lora solves the DO IT RIGHT problem. ï¼ˆæˆ‘è®¤ä¸ºcheckpointæœ€ç»ˆè¦çš„æ˜¯å…¼å®¹æ€§ï¼Œæ‰€ä»¥æˆ‘æ²¡æœ‰èä»»ä½•loraè¿›checkpointï¼Œcheckpointåº”è¯¥è§£å†³çš„æ˜¯åšçš„åˆ°çš„é—®é¢˜ï¼Œè€Œloraè§£å†³çš„æ˜¯åšçš„å¯¹çš„é—®é¢˜ï¼‰</p></li><li><p><strong>Highres-Fix is A Must! </strong>Highres-Fix: 2x, denoising:0.4-0.5 or 1.5x, denoising:0.5-0.65. (<strong>ä¸€å®šè¦åšé«˜æ¸…ä¿®å¤</strong>! é«˜æ¸…ä¿®å¤: 2å€, é‡ç»˜å¹…åº¦:0.4-0.5 æˆ– 1.5å€, é‡ç»˜å¹…åº¦:0.5-0.65)</p></li><li><p><strong>Make Sure you are in the right CLIP</strong> if you want to replicate my job, some themes are CLIP=1,while others are CLIP=2.Suggest download the image and put it into PNG info to check the setting <strong>(å¦‚æœæƒ³è¦å¤ç°,ç¡®ä¿CLIPå€¼è¦å¯¹! </strong>CLIP1å’ŒCLIP2è¦å¯¹!å»ºè®®æŠŠå›¾ä¸‹ä¸‹æ¥ç„¶åæ”¾åˆ°PNGä¿¡æ¯é‡Œé¢å»æŸ¥è®¾ç½®<strong>)</strong></p></li><li><p><strong>Most Prompts in Previous Version of GhostMix can produce similiar result in New Version of GhostMix (ä¹‹å‰ç”¨çš„å¤§å¤šæ•°Promptsåœ¨æ–°ç‰ˆæœ¬ä¹Ÿå¯ä»¥ç”Ÿæˆç›¸ä¼¼çš„ç»“æœ)</strong></p></li><li><p>Textual Inversion&amp;VAE: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4629/deep-negative-v1x\">ng_deepnegative_v1_75t </a>and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\">easynegative</a> ,don't use Bad-Hand V4 &amp; V5ï¼ï¼ˆç”¨ <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4629/deep-negative-v1x\">ng_deepnegative_v1_75t</a>å’Œ<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\">easynegative</a>,åˆ«ç”¨BadHandV4,V5)</p></li><li><p>Sampler Suggest : DPM++ series , Steps: 20-30, CFG:5-7(7 is best)ï¼ˆé‡‡æ ·æ–¹æ³•å»ºè®® DPM++ç³»åˆ— , æ­¥æ•°20-30, CFG:5-7(7æœ€å¥½) ï¼‰</p></li><li><p>Suggest resolution: 512,768! mechanical girl theme is very sensitive to the resolution, not suggest make the aspect ratio too low.(å»ºè®®åˆ†è¾¨ç‡:512,768! æœºæ¢°å°‘å¥³ä¸»é¢˜å¯¹åˆ†è¾¨ç‡è®¾ç½®éå¸¸æ•æ„Ÿï¼Œä¸å»ºè®®è®¾å¤ªä½çš„å®½é«˜æ¯”)</p></li></ol><p>If you want to support me, please buy me a coffee : <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/ghostshell\">https://ko-fi.com/ghostshell</a></p><p>å›½å†…æ”¯ä»˜å®ã€å¾®ä¿¡ç”¨æˆ·å¯ä»¥é€šè¿‡çˆ±å‘ç”µç»™æˆ‘ä¹°æ¯å’–å•¡ï¼š<a target=\"_blank\" rel=\"ugc\" href=\"https://afdian.net/a/ghostmix\">https://afdian.net/a/ghostmix</a></p><p></p><p>I create the <strong>world's first checkpoint review framework GhostReview,</strong> by using LAION Aesthetics, Clipscore, HPS, StyleLoss to measure ckpts quantitatively in Image Quality,Style Compatibility and LoRA Compatibility. If you want to see the detail, please check the article link below.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/1548/ghostreview-the-worlds-first-checkpoint-review-framework-by-ghostmix-creator\">https://civitai.com/articles/1548/ghostreview-the-worlds-first-checkpoint-review-framework-by-ghostmix-creator</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/drnighthan/GhostReview\"><u>GhostReview Github Project: https://github.com/drnighthan/GhostReview</u></a></p><p></p><h2 id=\"2023521-ghostmix-v20-fp16-pruned-ver-replaced\"><em>2023.5.21 GhostMix-V2.0 (fp16 pruned ver replaced)</em></h2><h3 id=\"update-detail\"><u>UPDATE DETAIL(ä¸­æ–‡æ›´æ–°è¯´æ˜åœ¨ä¸‹é¢)</u></h3><p>Hello everyone, this is Ghost_Shell, the creator. The GhostMix-V2.0Â significantly improves the realism of faces and also greatly increases the good image rate. In my tests at 512,768 resolution, the good image rate of theÂ Prompts I used before was above 50%. It is more user-friendly. During making the GhostMix-V2.0, I adjusted 47 versions of the model and finally chose one of them.</p><p>å¤§å®¶å¥½ï¼Œè¿™é‡Œæ˜¯ä½œè€…Ghost_Shellã€‚è¿™æ¬¡GhostMix-V2.0å¤§å¹…æå‡äº†è„¸çš„çœŸå®æ€§ï¼Œä¹Ÿå¤§å¹…æå‡äº†è‰¯å›¾ç‡ï¼Œåœ¨æˆ‘æµ‹çš„512,768åˆ†è¾¨ç‡ä¹‹ä¸‹ï¼Œä¹‹å‰ç”¨çš„Promptsè‰¯å›¾ç‡éƒ½åœ¨50%ä»¥ä¸Šï¼Œå¯¹ç”¨æˆ·æ›´åŠ å‹å¥½ã€‚è¿™æ¬¡åœ¨æµ‹è¯•ä¸­ä¸€å…±è°ƒäº†47ä¸ªç‰ˆæœ¬çš„æ¨¡å‹ï¼Œæœ€ç»ˆé€‰äº†ä¸€ä¸ªã€‚</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9ade01d7-6a5e-40e5-92cb-67f7c2c818c9/width=525/9ade01d7-6a5e-40e5-92cb-67f7c2c818c9.jpeg\" /></p><h3 id=\"other-words-i-want-to-say\"><u>Other Words I want to say(é¢˜å¤–è¯):</u></h3><p>To be honest, this may be the last version of GhostMix.On one hand, it is really inefficient to use 3060ti to make models. In the past two weeks, I have almost no free time except for making models and testing them. On the other hand, I temporarily feel that this model is almost at its limit and the space for improvement is really not high. I hope you like it. If you like the model, I hope you can post your images to Civitai. <strong>Many of the prompts I tested for GhostMix-V2.0Â are from your posts, which is really important for me to test the model. If you can give it a 5-star rating, that would be great.</strong> If you are willing to support my work, please click: <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/ghostshell\">https://ko-fi.com/ghostshell</a>. My goal is to buy a 4070 and work more efficiently on making models. Using a 3060ti to make models is really inefficient and it basically cannot be used to test high resolution images.</p><p>è¯´å®è¯ï¼Œè¿™å¯èƒ½æ˜¯GhostMixçš„æœ€åä¸€ä¸ªæ¨¡å‹ï¼Œä¸€æ–¹é¢3060tiå»åšæ¨¡å‹çœŸçš„æ•ˆç‡å¤ªä½äº†â€¦æœ€è¿‘ä¸¤ä¸ªæ˜ŸæœŸåŸºæœ¬æ²¡æœ‰ç©ºé—²æ—¶é—´ï¼Œé™¤äº†åšæ¨¡å‹ï¼Œå°±æ˜¯æµ‹æ¨¡å‹ã€‚å¦å¤–ä¸€æ–¹é¢ï¼Œæˆ‘æš‚æ—¶è§‰å¾—è¿™ä¸ªæ¨¡å‹è¿‘ä¹æé™ï¼Œèƒ½æå‡çš„ç©ºé—´ç¡®å®ä¸é«˜äº†ï¼Œå¸Œæœ›å¤§å®¶å–œæ¬¢ã€‚<strong>å¦‚æœå¤§å®¶å–œæ¬¢æ¨¡å‹ï¼Œå¸Œæœ›å¤§å®¶èƒ½postè‡ªå·±çš„ä½œå“åˆ°Civitaiï¼Œè¿™æ¬¡æµ‹è¯•çš„å¾ˆå¤šPromptså°±æ˜¯ä»ä½ ä»¬posté‡Œé¢æ¥çš„ï¼Œè¿™å¯¹æˆ‘æµ‹è¯•æ¨¡å‹çœŸçš„å¾ˆå…³é”®ï¼Œå¦‚æœèƒ½5æ˜Ÿè¯„ä»·å°±æ›´å¥½ã€‚</strong>å¦‚æœæ„¿æ„æ”¯æŒæˆ‘çš„å·¥ä½œï¼Œè¯·ç‚¹å‡»ï¼š<a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/ghostshellã€‚\">https://ko-fi.com/ghostshellã€‚</a> æˆ‘çš„ç›®æ ‡å°±å¸Œæœ›èƒ½æ¢ä¸€å—4070ï¼Œæ›´é«˜æ•ˆçš„å»åšæ¨¡å‹ï¼Œ3060tiçœŸçš„æµ‹æ¨¡å‹æ•ˆç‡å¤ªä½äº†ï¼Œè€Œä¸”åŸºæœ¬æ²¡æ³•æµ‹æ›´é«˜åˆ†è¾¨ç‡çš„å›¾ç‰‡ã€‚</p><p></p><h2 id=\"202351-ghostmix-v12-fp16-version-uploaded\"><em>2023.5.1 GhostMix-V1.2 (fp16 version uploaded)</em></h2><h3 id=\"update-detail\"><u>UPDATE DETAIL(ä¸­æ–‡æ›´æ–°è¯´æ˜åœ¨ä¸‹é¢)</u></h3><p><strong>THIS IS NOT A 3D MODEL! THIS IS NOT A 3D MODEL! THIS IS NOT A 3D MODEL!</strong></p><p><strong>If you like my modelï¼Œplease give me 5 Stars ,it will encourage me a lot. Thanks!</strong></p><p><strong>Color Problem ï¼šCheck VAE is kl-f8-anime2 ï¼Ÿé¢œè‰²é—®é¢˜ï¼šæŸ¥VAEæ˜¯å¦ä¸ºkl-f8-anime2ï¼Ÿ</strong></p><p>GhostMix V1.2 is an absolutely astonishing model, and I think it is the strongest 2.5D model in Civitai right now. I think a update of the model should improve the modelâ€™s compatibility, good image rate and image details given the main structure of 90% generated images doesnâ€™t change. So I use layer combination to combine models layer by layer. And I got this model after 9 different versions of â€œthe final version of GhostMix V1.2â€,LOL.This version of GhostMix V1.2 is a balance in terms of compatibility, good image rate and image details, although sometimes using the same Promts of GhostMix V1.1, may comes up a different result.But this doesnâ€™t happen too much.</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/057f494c-a5a7-4861-de03-259304c88e00/width=525/057f494c-a5a7-4861-de03-259304c88e00.jpeg\" /></p><p>PS: The first image of GhostMix V1.2 is a nod to Mamoru Oshiiâ€™s version of Ghost in Shell in 1995, and my name Ghost_Shell is also a nod to this movie.</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/896fd995-5423-4de4-fa6a-5ab31be74a00/width=525/896fd995-5423-4de4-fa6a-5ab31be74a00.jpeg\" /></p><h3 id=\"heading-397\"><u>ä¸­æ–‡æ›´æ–°è¯´æ˜</u></h3><p>GhostMix V1.2æ˜¯ç»å¯¹è®©ä½ æƒŠè‰³çš„æ¨¡å‹ï¼Œä¹Ÿæ˜¯è‡ªå·±è®¤ä¸ºç°åœ¨æœ€å¼ºçš„2.5Dæ¨¡å‹ã€‚æˆ‘è®¤ä¸ºæ¨¡å‹çš„æ›´æ–°åº”è¯¥æ˜¯åŸºäºç°æœ‰çš„ç”»é¢æ•´ä½“ä¸å¤§å˜çš„å‰æä¸‹ï¼Œæé«˜æ¨¡å‹çš„æˆå›¾ç‡ï¼Œå…¼å®¹æ€§å’Œç”»é¢ç»†èŠ‚ã€‚æ‰€ä»¥æˆ‘é‡‡ç”¨äº†åˆ†å±‚èåˆï¼Œä¸€å…±åšäº†9ä¸ªç‰ˆæœ¬çš„â€œGhostMix V1.2æœ€ç»ˆç‰ˆæœ¬â€ï¼Œæœ€ç»ˆå¾—åˆ°äº†ç°åœ¨è¿™ä¸ªç‰ˆæœ¬çš„GhostMix V1.2ã€‚è¿™ä¸ªç‰ˆæœ¬çš„GhostMix V1.2åœ¨å…¼å®¹æ€§ï¼Œæˆå›¾ç‡å’Œç”»é¢ç»†èŠ‚è¡¨ç°æ¯”è¾ƒå¹³è¡¡ï¼Œè™½ç„¶æœ‰æ—¶å€™ä¼šå‡ºç°åŒæ ·çš„Promtsï¼Œå‡ºå›¾æ”¹å˜çš„æƒ…å†µï¼Œä½†å®æµ‹ä¸å¤šã€‚</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/057f494c-a5a7-4861-de03-259304c88e00/width=525/057f494c-a5a7-4861-de03-259304c88e00.jpeg\" /></p><p>PSï¼šGhostMixV1.2çš„å¤´å›¾æ˜¯è‡´æ•¬1995æŠ¼äº•å®ˆç‰ˆGhost in Shell æ”»å£³æœºåŠ¨é˜Ÿçš„ç”Ÿæˆçš„ï¼ŒGhost in Shellä¹Ÿæ˜¯ä½œè€…åå­—çš„ç”±æ¥ã€‚</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/896fd995-5423-4de4-fa6a-5ab31be74a00/width=525/896fd995-5423-4de4-fa6a-5ab31be74a00.jpeg\" /></p><p></p><h2 id=\"2023311-ghostmix-v10\"><em>2023.3.11 GhostMix-V1.0</em></h2><h3 id=\"introduction\"><u>Introduction(ä¸­æ–‡ç®€ä»‹åœ¨ä¸‹é¢)</u></h3><p>First of all , I want to thank all the people who use this Checkpoint. And this is my first Checkpoint.All the sample image can be reproduced. This Checkpoint works well on both SFW and NSFW.THE NSFW PART IS VERY GOOD!!!<br />I uploaded this Checkpoint yesterday and from yesterday to today , I am still trying all the possibility of this Checkpoint. So if you try the model and find some good promts , I hope you can upload it and share with me, it will help me for the next version of GhostMix, Thank you agian!</p><h3 id=\"recommend-some-promts\"><u>Recommend Some Promts:</u></h3><ol><li><p><strong>Fractal Artï¼ˆhighly recommendï¼Œawsomeï¼‰</strong></p></li></ol><pre><code>(masterpiece, top quality, best quality, official art, beautiful and aesthetic:1.2), (1girl:1.3), (fractal art:1.3),</code></pre><ol><li><p><strong>Color Art</strong></p></li></ol><pre><code>(flat color:1.3),(colorful:1.3),(masterpiece:1.2), best quality, masterpiece, original, extremely detailed wallpaper, looking at viewer,1girl,solo,floating colorful water</code></pre><h3 id=\"vaeandtextual-inversion\"><u>VAE&amp;Textual Inversion:</u></h3><p>VAE: kl-f8-anime2 or vae-ft-mse-840000-ema-pruned(anime suggest: kl-f8-anime2)</p><p>Textual Inversion: ng_deepnegative_v1_75t, easynegative</p><p></p><h3 id=\"about-image-reproduction\"><u>About Image Reproduction:</u></h3><p>Some user said that they can not reproduce my result.Maybe the setting goes wrong.I just reproduce my cover image. If you want to reproduce my result, Checkpoint Modelï¼ŒPostive Promtï¼ŒNegative Promtï¼ŒTextual Inversionï¼ŒSampler Stepsï¼ŒSamplerï¼ŒCFGï¼ŒResolutionï¼ŒSeed , ALL the things should be the SAME! Then be careful if you open controlnet or lora ,don't make them influnence your result.</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d644a081-4d69-441e-ea1c-81d6b1934800/width=525/d644a081-4d69-441e-ea1c-81d6b1934800.jpeg\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f7062462-6f14-4555-7176-0ec8fdb67600/width=525/f7062462-6f14-4555-7176-0ec8fdb67600.jpeg\" /></p><p></p><h2 id=\"heading-398\"><u>ä¸­æ–‡ç®€ä»‹</u></h2><p>é¦–å…ˆæ„Ÿè°¢æ¯ä¸€ä¸ªä½¿ç”¨è¿™ä¸ªCheckpointçš„äººï¼Œè¿™æ˜¯æˆ‘èçš„ç¬¬ä¸€ä¸ªCheckpointã€‚æ‰€æœ‰æ ·å›¾è‡ªæµ‹éƒ½å¯ä»¥å¤ç°ã€‚SFWå’ŒNSFWçš„å›¾éƒ½æŒºæ¼‚äº®çš„ï¼ŒNSFWçš„å›¾éå¸¸æ£’ã€‚è¿™ä¸ªæ¨¡å‹æ˜¨å¤©ä¸Šä¼ åˆ°ä»Šå¤©ï¼Œæˆ‘ä¸€ç›´åœ¨å°è¯•è¿™ä¸ªæ¨¡å‹çš„å¯èƒ½æ€§ã€‚å¸Œæœ›ä½¿ç”¨è¿™ä¸ªCheckpointçš„æœ‹å‹ä»¬ï¼Œå¦‚æœä½ è¯•äº†ï¼Œè§‰å¾—æœ‰ä¸é”™Promtsï¼Œæ¬¢è¿ä¸Šä¼ å›¾åˆ†äº«ï¼Œè®©æˆ‘ä¹Ÿäº†è§£ä¸€ä¸‹è¿™ä¸ªCheckpointçš„å¯èƒ½æ€§ï¼Œä¹Ÿå¯ä»¥å¸®åŠ©æˆ‘è°ƒä¸‹ä¸€ä¸ªç‰ˆæœ¬GhostMixï¼Œå†æ¬¡æ„Ÿè°¢ã€‚</p><h3 id=\"promts\"><u>æ¨èPromts:</u></h3><ol><li><p><strong>åˆ†å‹è‰ºæœ¯ï¼ˆè¶…çº§æ¨èï¼Œå¿…å‡ºå¥½å›¾ï¼‰</strong></p></li></ol><pre><code>(masterpiece, top quality, best quality, official art, beautiful and aesthetic:1.2), (1girl:1.3), (fractal art:1.3),</code></pre><ol><li><p><strong>è‰²å½©è‰ºæœ¯</strong></p></li></ol><pre><code>(flat color:1.3),(colorful:1.3),(masterpiece:1.2), best quality, masterpiece, original, extremely detailed wallpaper, looking at viewer,1girl,solo,floating colorful water</code></pre><h3 id=\"vaeandtextual-inversion\"><u>VAE&amp;Textual Inversion:</u></h3><p>VAE:kl-f8-anime2æˆ–è€…vae-ft-mse-840000-ema-pruned(åŠ¨ç”»é£å»ºè®®kl-f8-anime2)</p><p>Textual Inversion:ng_deepnegative_v1_75t,easynegative</p><p></p><h3 id=\"heading-399\"><u>å…³äºå›¾ç‰‡å¤ç°:</u></h3><p>æœ‰åŒå­¦å¥½åƒæ²¡æ³•å¤ç°æˆ‘çš„å›¾ï¼Œå¯èƒ½æ˜¯è®¾ç½®æœ‰ç‚¹é—®é¢˜ï¼Œåˆšåˆšæˆ‘æ‰æŠŠå¤´å›¾ç»™å¤ç°äº†ã€‚æ³¨æ„å‡ ä¸ªç‚¹ï¼šCheckpoint æ¨¡å‹ï¼Œæ­£å‘Promtï¼Œåå‘Promtï¼ŒTextual Inversionï¼Œè¿­ä»£æ­¥æ•°ï¼Œè¿­ä»£æ–¹æ³•ï¼ŒCFGï¼Œåˆ†è¾¨ç‡ï¼Œéšæœºç§å­éƒ½å¿…é¡»ä¸€æ¨¡ä¸€æ ·ï¼ç„¶åå¤ç°çš„è¯ï¼Œè¦æŠŠcontrolnetå’Œloraå…³æ‰ï¼Œæ€•å½±å“å¤ç°ã€‚</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/978438b2-a581-4740-a0b5-1531a2c47300/width=525/978438b2-a581-4740-a0b5-1531a2c47300.jpeg\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/87b94620-4032-4ba5-1949-cb07e18cfa00/width=525/87b94620-4032-4ba5-1949-cb07e18cfa00.jpeg\" /></p><h1 id=\"heading-400\"></h1>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581169+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "439889",
    "prompt": "Prefect Pony XL\n<p>If you like my work, drop a 5 review and hit the heart icon. it's free and keeps me motivated</p><h2 id=\"all-my-models-are-officially-hosted-and-maintained-by-me-on-tensor.art-.-use-my-exclusive-and-public-model-for-free-on-tensor.art-eeq913jiq\"><span style=\"color:rgb(250, 176, 5)\">All my models are officially hosted and maintained by me on</span> <a target=\"_blank\" rel=\"ugc\" href=\"http://Tensor.art\">Tensor.art</a> . use my <span style=\"color:rgb(250, 82, 82)\">Exclusive</span> and <span style=\"color:rgb(64, 192, 87)\">public</span> model for free on <a target=\"_blank\" rel=\"ugc\" href=\"http://tensor.art\">tensor.art</a></h2><p></p><h3 id=\"v5.0-civitai-onsite-generation-enabled-:-040125-t75gquk9a\"><strong><span style=\"color:rgb(130, 201, 30)\">v5.0 civitai onsite generation enabled : 04/01/25</span></strong></h3><h3 id=\"v5.0-final-release-:-010125-6vfl76nb1\"><strong><span style=\"color:rgb(64, 192, 87)\">v5.0 final release : 01/01/25</span></strong></h3><p><strong><u>v5.0 pre relelase update : 25/12/24</u></strong></p><p><strong><u>Check </u></strong><a target=\"_blank\" rel=\"ugc\" href=\"http://tensor.art\"><strong><u>tensor.art</u></strong></a><strong><u> for V1,V2,V3 online generation support</u></strong></p><h3 id=\"you-can-run-prefect-pony-xl-and-use-its-api-on-sinkin-7t3mg6rbn\"><span style=\"color:rgb(250, 176, 5)\">You can run Prefect Pony XL and use its API on </span><a rel=\"ugc\" href=\"https://sinkin.ai/m/6zv9aDj\"><span style=\"color:#228be6\">SinkIn</span></a></h3><p><strong><em><span style=\"color:rgb(250, 82, 82)\">currently, only v5 and v4 are available for civitai generation.</span></em></strong><em><span style=\"color:rgb(250, 82, 82)\"><br />v3,v2,v1 are retired from civitai generation. check other version details for alternative on site generation service.<br /></span></em></p><p><br /><span style=\"color:rgb(250, 176, 5)\">WIP: Realistic</span></p><h3 id=\"v5-update-:-3dk13unaf\"><span style=\"color:rgb(76, 110, 245)\">V5 Update :</span></h3><p><span style=\"color:rgb(76, 110, 245)\">onsite generation : </span><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/815661199413897287\"><span style=\"color:rgb(76, 110, 245)\">https://tensor.art/models/815661199413897287</span></a></p><p><strong><u>pre-release : </u></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/810892802167877454\"><strong><u>https://tensor.art/models/810892802167877454</u></strong></a></p><ul><li><p><span style=\"color:rgb(76, 110, 245)\">Added trained Lora</span></p></li><li><p><span style=\"color:rgb(76, 110, 245)\">Cleaned style</span></p></li><li><p><span style=\"color:rgb(76, 110, 245)\">Baked in VAE</span></p></li><li><p><span style=\"color:rgb(76, 110, 245)\">Extra trained data of 15000 steps</span></p></li><li><p><span style=\"color:rgb(76, 110, 245)\">Better Lora support.</span></p><p></p></li></ul><h3 id=\"v4-update-:-zo4vtl05o\"><span style=\"color:rgb(190, 75, 219)\">V4 Update :</span></h3><ul><li><p>onsite generation : <a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/794513755405953653/Prefect-Pony-XL-v4\">https://tensor.art/models/794513755405953653/Prefect-Pony-XL-v4</a></p></li><li><p><span style=\"color:rgb(190, 75, 219)\">Added trained Lora</span></p></li><li><p><span style=\"color:rgb(190, 75, 219)\">Cleaned style</span></p></li><li><p><span style=\"color:rgb(190, 75, 219)\">Baked in VAE</span></p></li><li><p><span style=\"color:rgb(190, 75, 219)\">Extra trained data of 15000 steps</span></p></li><li><p><span style=\"color:rgb(190, 75, 219)\">Better Lora support.</span></p></li></ul><h3 id=\"v3-update-:-in42v0bc5\"><br /><strong><u><span style=\"color:rgb(64, 192, 87)\">V3 Update</span><span style=\"color:rgb(250, 176, 5)\"> :</span></u></strong></h3><ul><li><p>onsite generation <a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/772139385270444718\">https://tensor.art/models/772139385270444718</a></p></li><li><p><strong><u><span style=\"color:rgb(64, 192, 87)\">added some style to it</span></u></strong></p></li><li><p><strong><u><span style=\"color:rgb(64, 192, 87)\">should give better face and eyes</span></u></strong></p></li><li><p><strong><u><span style=\"color:rgb(64, 192, 87)\">better NSFW supports</span></u></strong></p></li><li><p><strong><u><span style=\"color:rgb(64, 192, 87)\">wide range of Lora support</span></u></strong></p></li></ul><h3 id=\"v1-lightning-:-ep418cndn\"><strong><u><span style=\"color:rgb(250, 176, 5)\">V1 lightning :</span></u></strong></h3><ul><li><p><strong><u>8-steps</u></strong></p></li><li><p><strong>DPM++ 2M</strong></p></li></ul><h3 id=\"v2-update:-zk16vgh71\"><strong><span style=\"color:rgb(250, 82, 82)\">V2 update:</span></strong></h3><ul><li><p>onsite generation <a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/754887012743423435\">https://tensor.art/models/754887012743423435</a></p></li><li><p><strong>has less style influence</strong></p></li><li><p><strong>can work with wide range of loras</strong></p></li><li><p><strong>better anatomy</strong></p></li><li><p><strong>better color</strong></p></li></ul><h3 id=\"v1-update:-46il4dpa5\"><strong><span style=\"color:rgb(253, 126, 20)\">V1 update:</span></strong></h3><ul><li><p><strong><span style=\"color:rgb(250, 82, 82)\">On site generation closed for v1 on civitai for limitation of civitai.</span></strong></p></li><li><p><strong><span style=\"color:rgb(250, 82, 82)\">try </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"http://tensor.art\"><strong><span style=\"color:rgb(250, 82, 82)\">tensor.art</span></strong></a><strong><span style=\"color:rgb(250, 82, 82)\"> if you want to use the online generation for v1</span></strong></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/724940954567461228/Prefect-Pony-XL-v1.0\">https://tensor.art/models/724940954567461228/Prefect-Pony-XL-v1.0</a></p></li></ul><p>If you like my work then drop a 5 review and hit the heart icon. it's free and keeps me motivated</p><h3 id=\"-wk7b1pwct\"></h3><p><strong><span style=\"color:rgb(64, 192, 87)\">Suggested settings:</span></strong></p><ul><li><p>I had CLIP skip 2 on every image</p></li><li><p>I had <em>ENSD</em>: 31337 all of them</p></li><li><p>All of them had <strong>highres.fix</strong> or img2img at higher resolution.</p></li><li><p>I <strong>don't use restore faces</strong></p></li><li><p><strong>I use afterdetailer for face details</strong></p></li><li><p><strong>Tiled diffusion for img2img upscaling and sometimes Noise Inversion for some more extra details.</strong></p></li><li><p><strong>4x-Ultrasharp upscaler</strong></p></li></ul><p>NOTE: if you find any prompt of the preview images look familiar it's because I've taken them from other model review images, Credits to the original authors. Thanks for the benchmark.</p><h3 id=\"commission-open-in-patreon.-tczr9qqzt\">Commission open in <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/hinokiart\">Patreon</a><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/goofyai\">.</a></h3><h3 id=\"get-early-access-and-exclusive-nsfw-lora-in-my-patreon-.-ec4b3afdy\"><span style=\"color:rgb(64, 192, 87)\">Get early access and Exclusive </span><span style=\"color:rgb(253, 126, 20)\">NSFW </span><span style=\"color:rgb(64, 192, 87)\">Lora in my </span><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/hinokiart\"><span style=\"color:rgb(250, 82, 82)\">Patreon</span></a><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/GoofyAi\"><span style=\"color:rgb(250, 82, 82)\"> </span><span style=\"color:rgb(146, 147, 149)\">.</span></a></h3><p><span style=\"color:rgb(253, 126, 20)\">Support my work by joining any one of them and get early access to all my upcoming loras and other perks such as fan requests and Discord role.</span></p><h3 id=\"join-my-discord-server-y8zexxmdn\">Join my <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/M8yAsU9ZhC\"><strong><u>Discord Server</u></strong></a></h3><p></p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581175+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "443821",
    "prompt": "CyberRealistic Pony\n<p><span style=\"color:rgb(250, 176, 5)\">Like what I build here? Youâ€™ll <em>love</em> the chaos behind the scenes - </span><a target=\"_new\" rel=\"ugc\" href=\"https://patreon.com/cyberdelia\"><span style=\"color:rgb(250, 176, 5)\"><u>Check my Patreon</u></span></a></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e727677f-17fd-4bbf-b4f2-c3f7bc15daeb/width=525/e727677f-17fd-4bbf-b4f2-c3f7bc15daeb.jpeg\" /><span style=\"color:rgb(230, 73, 128)\"><strong>You can run CyberRealistic Pony and use its API on SinkIn: </strong></span><a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/Z9jVny2\"><span style=\"color:rgb(230, 73, 128)\"><strong>https://sinkin.ai/m/Z9jVny2</strong></span></a><span style=\"color:rgb(230, 73, 128)\"><br /></span><span style=\"color:rgb(250, 82, 82)\">Give CyberRealistic Pony a try </span><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/892064490751798485/CyberRealistic-Pony-v12.7\"><span style=\"color:rgb(250, 82, 82)\"><u>here</u></span></a><span style=\"color:rgb(250, 82, 82)\">! Want unlimited access? Take a look at the one-time purchase for full use.</span></p><p>CyberRealistic Pony blends all the charm of Pony Diffusion with the striking realism of CyberRealistic. The vibe? You get everything from adorable to bold (sometimes both at once) with crazy-detailed textures, moody cinematic lighting, and a hint of AI flair.</p><hr /><p>ğŸ§  <span style=\"color:rgb(21, 170, 191)\"><strong>How to Use It</strong></span></p><pre><code>Sampling method: DPM++ SDE Karras / DPM++ 2M Karras / Euler a\nSampling steps: 30+ Steps\nResolution: 896x1152 / 832x1216\nCFG: 5\nClip Skip: 2</code></pre><p></p><hr /><p>âœ… <span style=\"color:rgb(21, 170, 191)\"><strong>Recommended Prompts</strong></span></p><pre><code>score_9, score_8_up, score_7_up, (SUBJECT), </code></pre><p><strong>Negative Prompt examples:</strong></p><pre><code>score_6, score_5, score_4, (worst quality:1.2), (low quality:1.2), (normal quality:1.2), lowres, bad anatomy, bad hands, signature, watermarks, ugly, imperfect eyes, skewed eyes, unnatural face, unnatural body, error, extra limb, missing limbs</code></pre><p>it's also possible to remove the normal pony tags:</p><pre><code>(SUBJECT), </code></pre><p><strong>Negative Prompt examples:</strong></p><pre><code>(worst quality:1.2), (low quality:1.2), (normal quality:1.2), lowres, bad anatomy, bad hands, signature, watermarks, ugly, imperfect eyes, skewed eyes, unnatural face, unnatural body, error, extra limb, missing limbs</code></pre><hr /><p>ğŸ›  <span style=\"color:rgb(21, 170, 191)\"><strong>ADetailer Settings</strong></span></p><pre><code>Adetailer model: face_yolov9c.pt\nIf you only want the main face being refined set 'Mask only the top k largest' to 1.</code></pre><p></p><hr /><p>â˜•<span style=\"color:rgb(21, 170, 191)\"><strong> Support</strong></span><br />Enjoying the ride? [<a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/cyberdelia\">Buy me a coffee</a>] â€“ but only if the Pony delivered something you <em>actually</em> like.<br /></p><hr /><p>âš ï¸ <span style=\"color:rgb(21, 170, 191)\"><strong>Disclaimer</strong></span><br />This model might generate sensitive content. Whatever you make with it is on you. Donâ€™t do anything weird and try to blame the horse.<br /></p><hr /><p>ğŸ”— <span style=\"color:rgb(21, 170, 191)\"><strong>Links</strong></span><br />Backup location: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/cyberdelia/CyberRealisticPony/tree/main\">huggingface</a></p><p></p><hr /><p>ğŸ’¡<span style=\"color:rgb(21, 170, 191)\"><strong> Need Better Prompts?</strong></span><br />This custom ChatGPT was made to whip up top-tier prompts just for this model:<br />ğŸ”— [<a target=\"_blank\" rel=\"ugc\" href=\"https://chatgpt.com/g/g-6834133e3ab881918a91b3ec6b9eb01f-cyberrealistic-prompt-helper\">Try it now on ChatGPT</a>]</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581188+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "47274",
    "prompt": "XXMix_9realistic\n<p></p><ul><li><p>I found a new AI tool Shakker, a best image to image tool. You can try it via <a target=\"_blank\" rel=\"ugc\" href=\"https://www.shakker.ai\">https://www.shakker.ai</a> </p></li><li><p>YouÂ canÂ runÂ XXMix_9realisticÂ onÂ <a target=\"_blank\" rel=\"ugc\" href=\"http://sinkin.ai\">sinkin.ai</a>:Â <a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/Y99mNKb\">https://sinkin.ai/m/Y99mNKb</a></p></li></ul><p></p><ul><li><p>feelÂ freeÂ toÂ <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/zyx_xx\">buyÂ meÂ aÂ coffeeÂ â˜•</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/119860/xxmixunreal\">XXMixunrealï¼š</a><span style=\"color:rgb(193, 194, 197)\">æˆ‘çš„2.5Dæ–°æ¨¡å‹ï¼Œä¸€ä¸ªæå…·ç‰¹è‰²çš„æ¨¡å‹ï¼Œå¯ä»¥æ ¹æ®å…³é”®è¯è¿›è¡Œå˜ç§ï¼Œåˆ›é€ å±äºè‡ªå·±çš„é£æ ¼åŒ–å›¾ç‰‡ã€‚A highly distinctive model that can generate variations based on keywords, creating personalized, stylized images.</span><br /></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/110810?modelVersionId=119495\"><strong>XXMix_Petrichor:</strong></a>è¿™æ˜¯æˆ‘æ–°çš„ç³»åˆ—æ¨¡å‹ï¼Œæ¯”è¾ƒåç½‘çº¢å›¾ç‰‡è´¨æ„Ÿä¸€äº›ï¼Œå¸Œæœ›å¤§å®¶å¯ä»¥æ”¯æŒä¸‹è½½å°è¯•ä¸€ä¸‹</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/110810?modelVersionId=119495\"><strong>XXMix_Petrichor:</strong></a><span style=\"color:rgb(201, 209, 217)\">This is my new series of models, which are more focused on the aesthetic of internet celebrity images. I hope everyone can support and download them to give them a try</span></p></li></ul><p></p><p></p><p>å¯ä»¥å°è¯•ä¸‹è¿™ä¸ªé«˜æ¸…ä¿®å¤çš„ç®—æ³•ï¼Œæˆ‘è®¤ä¸ºåœ¨æŸäº›å›¾ç‰‡é‡Œç”¨è¿™ä¸ªæ”¾å¤§ç®—æ³•çš„æ•ˆæœè¦æ›´å¥½ï¼Œç”»é¢ä¹Ÿæ›´é£æ ¼åŒ–ä¸€äº›ï¼Œhfåœ°å€åœ¨ä¸‹é¢ï¼Œå–œæ¬¢çš„æœ‹å‹å¯ä»¥å°è¯•ä¸€ä¸‹ã€‚</p><p><span style=\"color:rgb(201, 209, 217)\">You can try this high-definition restoration algorithm. I believe that in some pictures, the effect of using this magnification algorithm is better, and the picture is more stylized. The link to the high-frequency (hf) is below, and those who are interested can give it a try.</span><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9ffa500f-72ca-4225-acbf-f04818546bf6/width=525/9ffa500f-72ca-4225-acbf-f04818546bf6.jpeg\" /></p><p>1x_NMKDDetoon_97500_G</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/utnah/esrgan/tree/main\">https://huggingface.co/utnah/esrgan/tree/main</a></p><p>------------------------------------------------------------------------------------------------------</p><p></p><p>v4.0</p><p>æœ€è¿‘çƒ­æƒ…æœ‰æ‰€ä¸‹é™ï¼Œå–œæ¬¢å›¾ä¾‹çš„ç›´æ¥copyå§ï¼Œæ²¡æœ‰ç‰¹åˆ«çš„ç‰ˆæœ¬è¯´æ˜ã€‚</p><p>------------------------------------------------------------------------------------------------------</p><p></p><p>æˆ‘è®¤ä¸ºä¿®æ‰‹æœ€å¥½çš„æ˜¯<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/58390/detail-tweaker-lora-lora\"><strong>Detail Tweaker LoRA (ç»†èŠ‚è°ƒæ•´LoRA)ï¼Œå…¶ä»–éƒ½æ˜¯åƒåœ¾0 0</strong></a></p><p>v3.0ç‰ˆæœ¬è¯´æ˜ï¼š</p><ul><li><p>å›¾ç‰‡ä¿¡æ¯é‡Œçš„XXMix_4_v2893æ¨¡å‹å°±æ˜¯v30ç‰ˆæœ¬ï¼Œå›¾ç‰‡æ˜¯åœ¨æ¨¡å‹æ”¹åå‰ç”Ÿæˆçš„</p></li><li><p>1.å¾ˆé«˜å…´å‘å¤§å®¶ä»‹ç»XXMix_9ç³»åˆ—çš„3.0ç‰ˆæœ¬ã€‚è¿™ä¸ªç‰ˆæœ¬åœ¨æ³›ç”¨æ€§å’Œå¯¹LORAçš„æ”¯æŒä¸Šéƒ½æœ‰æ˜æ˜¾çš„åŠ å¼ºï¼Œå¹¶ä¸”æ‰‹éƒ¨çš„è¡¨ç°è¦æ˜æ˜¾å¥½äºä¹‹å‰çš„ç‰ˆæœ¬ã€‚3.0ç‰ˆæœ¬æ˜¯ç”±v2.5ã€v2.6å’Œ<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/47919/xxmix4reupload\">XXMix_4</a>è¿™ä¸‰ä¸ªç‰ˆæœ¬Mixè€Œæ¥ã€‚ç”Ÿæˆçš„å›¾ç‰‡æˆ‘å°½é‡æ²¡æœ‰ç”¨ä»»ä½•Embeddingæ¨¡å‹ï¼Œå› ä¸ºæˆ‘å‘ç°æœ‰äº›Embeddingæ¨¡å‹æ¯”è¾ƒéšæ™¦ï¼Œä½ ä¸çŸ¥é“å“ªäº›Embeddingæ¨¡å‹èµ·äº†ä½œç”¨å“ªäº›æ²¡èµ·ä½œç”¨ï¼Œä»è€Œä¸èƒ½è¿˜åŸå›¾ä¾‹ã€‚</p></li><li><p>2.å¦‚æœä½ æƒ³è¿˜åŸå›¾ä¾‹ï¼Œè¯·å…ˆå®‰è£…ä»¥ä¸‹æ‰©å±•ï¼š</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\"><u>Adetailer</u></a><u>:å»ºè®®åœ¨ç”Ÿæˆå›¾ç‰‡æ—¶å§‹ç»ˆå¼€å¯ï¼ˆå¦‚æœä½ æƒ³90%ä»¥ä¸Šè¿˜åŸå›¾ä¾‹ï¼Œé‚£ä¹ˆå»ºè®®ä½ åœ¨å›¾ç‰‡ä¿¡æ¯å†…æŸ¥çœ‹adetaileræ˜¯å¦å·²å¼€å¯ï¼‰ã€‚</u></p></li><li><p><u>æ³¨æ„:Adetaileréœ€è¦ä¸‹è½½ä¸€äº›æ¨¡å‹</u><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Bingsu/adetailer/tree/mainï¼Œè¿™é‡Œæ˜¯æ¨¡å‹åœ°å€ã€‚æ¨¡å‹å­˜æ”¾è·¯å¾„ï¼šwebui/models/adetailerã€‚æ²¡æœ‰æ‰¾åˆ°adetaileræ–‡ä»¶å¤¹è‡ªå·±å»ºä¸€ä¸ªå³å¯ã€‚\"><u>https://huggingface.co/Bingsu/adetailer/tree/mainï¼Œè¿™é‡Œæ˜¯æ¨¡å‹åœ°å€ã€‚æ¨¡å‹å­˜æ”¾è·¯å¾„ï¼šwebui/models/adetailerã€‚æ²¡æœ‰æ‰¾åˆ°adetaileræ–‡ä»¶å¤¹è‡ªå·±å»ºä¸€ä¸ªå³å¯ã€‚</u></a></p></li><li><p><u>Adetailerè§†é¢‘æ•™ç¨‹ï¼Œè¿™é‡Œæˆ‘å°±è´´</u><a target=\"_blank\" rel=\"ugc\" href=\"https://space.bilibili.com/8095370\"><u>å¨œä¹Œæ–¯å˜‰çš„æ•™ç¨‹å–½</u></a><a target=\"_blank\" rel=\"ugc\" href=\"https://www.bilibili.com/video/BV13s4y197cK/?spm_id_from=333.337.search-card.all.click&amp;vd_source=8c2a86ab53df9752cdd75679f58834a6\"><u>https://www.bilibili.com/video/BV13s4y197cK/?spm_id_from=333.337.search-card.all.click&amp;vd_source=8c2a86ab53df9752cdd75679f58834a6</u></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/mcmonkeyprojects/sd-dynamic-thresholding\"><u>CFG Scale Fix</u></a><u>:æœ‰éœ€æ±‚çš„æ—¶å€™å¼€å¯ï¼Œä¼šæé«˜ç”»é¢çš„è´¨æ„Ÿã€‚æˆ‘ç”¨çš„é»˜è®¤æ•°å€¼7å·¦å³ï¼Œå¦‚æœæ˜¯ç™½å¤©CFGæ•°å€¼å¯ä»¥ç¨å¾®å¤§ä¸€äº›ï¼Œæ™šä¸Šæ•°å€¼è¦å°ä¸€äº›ã€‚</u></p></li><li><p><u>ï¼ˆç»è¿‡æˆ‘çš„æµ‹è¯•ï¼Œåœ¨ç¬¬äºŒå°ç”µè„‘ä¸Šæ²¡æœ‰åŠæ³•100%è¿˜åŸå›¾ä¾‹ï¼Œæˆ‘ç°åœ¨è¿˜ä¸çŸ¥é“æ˜¯ä»€ä¹ˆåŸå› ï¼Œæœ‰å¯èƒ½æ˜¯CFG Scale Fixè¿™ä¸ªæ‰©å±•çš„é—®é¢˜ï¼Œä¹Ÿæœ‰å¯èƒ½æ˜¯åˆ†å—VAEçš„é—®é¢˜ï¼Œä¸è¿‡åŸºæœ¬ä¸Šä½ å¯ä»¥è¿˜åŸåˆ°90%-95%å·¦å³ï¼Œå¯¹ç”»é¢çš„å½±å“ä¸æ˜¯å¾ˆå¤§ã€‚ï¼‰</u></p></li><li><p>3.å¯¹äºç”Ÿæˆå›¾ç‰‡ï¼Œä¸ªäººçš„å°å¿ƒå¾—ï¼šå¦‚æœä½ å¾—åˆ°äº†ä¸€å¼ éå¸¸å–œæ¬¢çš„å›¾ç‰‡ï¼Œä½†æ˜¯æ‰‹éƒ¨æˆ–å…¶ä»–éƒ¨ä½çš„é—®é¢˜å¾ˆä¸¥é‡ï¼Œå¦‚æœä½ ä¸æƒ³ç”¨å±€éƒ¨é‡ç»˜ä¿®æ”¹çš„è¯ï¼Œé‚£ä¹ˆå»ºè®®ä½ åœ¨å›ºå®šå¥½seedä¹‹åï¼Œå¾®è°ƒCFGçš„æ•°å€¼ï¼ˆæ¯æ¬¡è°ƒæ•´0.2-0.3è¿™ç§å¹…åº¦æ¥å°è¯•ï¼‰ï¼Œè¿™æ ·ä½ å°±æœ‰å¯èƒ½åœ¨ä¿æŒåŸå›¾çš„åŸºç¡€ä¸Šå¾—åˆ°ä¸€å¼ å®Œç¾çš„å›¾ç‰‡ã€‚</p></li><li><p>4.åœ¨è¿™é‡Œï¼Œæˆ‘è¿˜æƒ³åˆ†äº«ä¸€ä¸ªæˆ‘å–œæ¬¢çš„åç¼€å¥å­ï¼Œå®ƒå¯ä»¥è®©ç”»é¢çš„è¡¨ç°åŠ›æ›´å¼ºã€‚å½“ç„¶ï¼Œä½ å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹å¥å­ä¸­çš„å•è¯æ¥å¾®è°ƒç”»é¢é£æ ¼ã€‚è¿™äº›å•è¯åŒ…æ‹¬ï¼š<strong><em>fantasy, high contrast, ink strokes, explosions, over exposure, purple and red tone impression , abstract, ((watercolor painting by John Berkey and Jeremy Mann )) brush strokes, negative space,</em></strong></p></li><li><p>5.æœ€åï¼Œå¦‚æœä½ å–œæ¬¢è¿™æ¬¡æ¨¡å‹çš„æ›´æ–°ï¼Œå¸Œæœ›ä½ å¯ä»¥æŠŠç”Ÿæˆçš„å¥½çœ‹å›¾ç‰‡åˆ†äº«å‡ºæ¥ã€‚</p></li></ul><p>Version 3.0 Description:</p><ul><li><p>The XXMix_4_v2893 model in the image information is actually the v3.0 version, but the images were generated before the model was renamed.</p></li><li><p>Pleased to introduce the 3.0 version of the XXMix_9 series. This version has significantly improved in versatility and support for LORA, and the hand performance is significantly better than the previous versions. The 3.0 version is a mix of v2.5, v2.6, and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/47919/xxmix4reupload\">XXMix_4</a>. When generating images, I try not to use any Embedding models as much as possible because I have found that some Embedding models are more obscure, and you don't know which ones are working and which ones are not, which makes it difficult to restore the example.</p></li><li><p>If you want to restore the example, please install the following extensions first:</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\">Adetailer</a>: It is recommended to always enable it when generating images. If you want to restore the example by more than 90%, it is recommended to check whether Adetailer is enabled in the image information.</p></li><li><p>Note: Adetailer requires downloading some models from <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Bingsu/adetailer/tree/main\">https://huggingface.co/Bingsu/adetailer/tree/main</a>. Here is the model address. The model should be stored in the path: webui/models/adetailer. If you cannot find the adetailer folder, please create one yourself.</p></li><li><p>Adetailer Chinese Video Tutorialï¼Œè¿™é‡Œæˆ‘å°±è´´<a target=\"_blank\" rel=\"ugc\" href=\"https://space.bilibili.com/8095370\"><strong>å¨œä¹Œæ–¯å˜‰çš„æ•™ç¨‹å–½</strong></a><a target=\"_blank\" rel=\"ugc\" href=\"https://www.bilibili.com/video/BV13s4y197cK/?spm_id_from=333.337.search-card.all.click&amp;vd_source=8c2a86ab53df9752cdd75679f58834a6\">https://www.bilibili.com/video/BV13s4y197cK/?spm_id_from=333.337.search-card.all.click&amp;vd_source=8c2a86ab53df9752cdd75679f58834a6</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/mcmonkeyprojects/sd-dynamic-thresholding\">CFG Scale Fix</a>: Enable it when needed, it will improve the quality of the image. I use the default value of about 7. If it is daytime, the CFG value can be slightly larger, and at night, the value should be smaller. (After my test, I cannot restore the example 100% on the second computer. I still don't know the reason. It may be a problem with the CFG Scale Fix extension or the Tiled VAE. However, you can basically restore it to about 90%-95%, and the impact on the image is not significant.)</p></li><li><p>For generating images, here is my personal experience: If you get a picture that you really like, but there are serious problems with the hands or other parts, and you don't want to use local redraw to modify it, then it is recommended to adjust the CFG value slightly (0.2-0.3 range) after fixing the seed. This way, you may get a perfect picture while keeping the original image.</p></li><li><p>Here, I would like to share a suffix sentence that I like, which can make the image more expressive. Of course, you can modify the words in the sentence to fine-tune the image style. These words include: <strong><em>fantasy, high contrast, ink strokes, explosions, overexposure, purple and red tone impression, abstract, brush strokes ((watercolor painting by John Berkey and Jeremy Mann)), negative space.</em></strong></p></li><li><p>Finally, if you like the updates of this model, we hope you can share the beautiful images you generated.</p></li></ul><p>------------------------------------------------------------------------------------------------------</p><p>v26-fp16-no-ema update</p><p>------------------------------------------------------------------------------------------------------</p><p>v2.6ç‰ˆæœ¬è¯´æ˜:</p><p>è¿™ç‰ˆç®—å°æ›´æ–°ï¼Œä¼˜åŒ–äº†è„¸å‹ï¼Œæ‰‹çš„é—®é¢˜æœ‰ä¼˜åŒ–ï¼Œä¸è¿‡ä¸»è¦è¿˜æ˜¯æŠ½å¡ã€‚å¤§é—®é¢˜ä¸‹ä¸ªç‰ˆæœ¬è§£å†³ã€‚</p><p>Version 2.6 release notes:</p><p>This version is a minor update that optimizes the face and hand issues. However, the main focus is still on the gacha system. The major issues will be addressed in the next version.</p><p></p><p>------------------------------------------------------------------------------------------------------</p><p></p><p></p><p><strong><u>æœ‰äººç•™è¨€è¯´æ¨¡å‹åŸºæœ¬ä¸èƒ½ç”¨ï¼Œéº»çƒ¦æ–°æœ‹å‹çœ‹ä¸‹è‡ªå·±çš„è®¾ç½®æ˜¯å¦å’Œå›¾ä¾‹çš„è®¾ç½®ä¸€æ ·ï¼Œé™¤äº†å…¨èº«å›¾ä¼šæœ‰IMG2IMGæ”¾å¤§çš„æ“ä½œï¼Œå…¶ä»–å›¾éƒ½æ˜¯ç›´å‡ºçš„ã€‚è¯·ä¸€å®šå…ˆç¡®å®šè‡ªå·±è®¾ç½®æ˜¯å¦å’Œå›¾é‡Œä¸€æ ·å“ˆï¼ï¼ï¼</u></strong></p><p>V2.5ç‰ˆæœ¬çš„å…‰å½±æ•ˆæœè¡¨ç°æ›´å¥½ï¼Œæ”¯æŒæ›´å¤šå¹»æƒ³å†…å®¹ï¼Œè°ƒæ•´äº†åŸºç¡€è„¸å‹ï¼Œåœºæ™¯æ–¹é¢çš„è¡¨ç°æ›´å¥½ã€‚</p><p>V2.5 version has better lighting effects and supports more fantasy content. The basic face shape has been adjusted, and the performance in scenes has been improved.</p><p>------------------------------------------------------------------------------------------------------</p><p><strong>é€‚å½“è°ƒå°(CFG Scale)çš„æ•°å€¼ï¼Œå¯ä»¥å¾—åˆ°ä¸ä¼—ä¸åŒçš„æ•ˆæœã€‚</strong></p><p>V2ç‰ˆæœ¬è¯´æ˜:</p><p>1.æ›´æ¢äº†é»˜è®¤è„¸ã€‚</p><p>2.æ›´å¥½çš„å…‰å½±è¡¨ç°ã€‚</p><p>3.èåˆäº†æ›´å¤šæ¨¡å‹ï¼Œåé¢è¿˜ä¼šç»§ç»­è¿­ä»£ã€‚</p><p>4.å¦‚æœæƒ³å¾—åˆ°æ›´å¥½çš„çš®è‚¤è´¨æ„Ÿï¼Œé‚£ä¹ˆç”Ÿæˆå›¾ç‰‡çš„æ—¶å€™ä¸è¦å¼€å¯é«˜æ¸…ä¿®å¤ï¼Œè€Œæ˜¯å°†ç”Ÿæˆçš„å›¾ç‰‡ä¼ å…¥å›¾ç”Ÿå›¾æ¨¡å¼ï¼Œå¯ç”¨<a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111\">Tiled Diffusion</a>ï¼Œæ¥è¿›è¡Œæ”¾å¤§ï¼Œä»è€Œå¾—åˆ°æ›´çœŸå®çš„çš®è‚¤è´¨æ„Ÿã€‚</p><p>5.æˆ‘ä¼šç»§ç»­æ›´æ–°è¿­ä»£è¿™ä¸ªå¤§æ¨¡å‹ï¼Œå¸Œæœ›èƒ½ä¸æ–­å¡«å……å†…å®¹ï¼Œè®©æ¨¡å‹æ›´å…·è¶£å‘³æ€§ã€‚</p><p>è°¢è°¢æ‚¨çš„æ”¯æŒï¼</p><p>Version 2 Release Notes:</p><ol><li><p>Changed the default face.</p></li><li><p>Improved lighting and shadow effects.</p></li><li><p>Added more models and will continue to iterate in the future.</p></li><li><p>For better skin texture, do not enable Hires Fix when generating images. Instead, use the \"Tiled Diffusion\" mode to enlarge the generated image and achieve a more realistic skin texture.</p></li><li><p>I will continue to update and iterate on this large model, hoping to add more content and make it more interesting.</p></li></ol><p>Thank you for your support!</p><p>------------------------------------------------------------------------------------------------------</p><p>æ¨èå‚æ•°</p><p>Recommended Parameters:</p><p>Sampler: DPM++ 2M Karras alt Karras or DPM++ SDE Karras</p><p>Steps: 20~40</p><p>Hires upscaler:4x-UltraSharp</p><p>Hires upscale: 2</p><p>Hires steps: 15</p><p>Denoising strength: 0.2~0.5</p><p>CFG scale: 6-8</p><p>clip skip 2</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581203+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "25494",
    "prompt": "Beautiful Realistic Asians\n<p>Im currently preparing and collecting dataset for SDXL, Its gonna be huge and a monumental task. I wanna thank everyone for supporting me so far, and for those that support the creation of SDXL BRA model. Thank you thank you thank you</p><p><a target=\"_blank\" rel=\"ugc\" href=\"http://Ko-fi.com/bankaiplease\">Ko-fi.com/bankaiplease</a></p><p>(Recommended)</p><p><span style=\"color:rgb(219, 222, 225)\">Mage provides unlimited generations for my model with amazing features. They also share their revenue per content generation with me! Go check it out here: </span><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/\">https://www.mage.space/</a></p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581206+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "12597",
    "prompt": "å¢¨å¿ƒ MoXin\n<h3><strong>ã€Šå¢¨å¿ƒã€‹â€”â€” æ˜”æ¶“å­ã€Šç´å¿ƒã€‹ï¼Œç‹å­™ã€Šå·§å¿ƒã€‹ï¼Œå¿ƒå“‰ç¾çŸ£ï¼Œæ•…ç”¨ä¹‹ç„‰ã€‚</strong></h3><p>æœ¬å“ç”±å®‰å‰å´ä»“çŸ³ã€å…´åŒ–æ¿æ¡¥å…ˆç”Ÿã€å…«å¤§å±±äººã€å±±é˜´ä¼¯å¹´ç­‰å¤§å¸ˆä¹‹å¤§å°å†™æ„ä½œå“è¾…ä»¥ç°ä»£äººç‰©è®­ç»ƒè€Œæˆã€‚è¾…ä»¥æ°å½“ä¹‹æç¤ºè¯ï¼Œè¯µå…ˆè´¤å°Šå·ï¼Œè¥„å¤ä»Šå¹¶ç”¨ä¹‹æ„ï¼Œæ˜é›…ä¿—å…±ä¸¾ä¹‹ç¾ã€‚</p><p></p><h3><strong>ã€Šç–å¯èµ°é©¬ã€‹â€”â€” <em>å­—ç”»ç–å¤„å¯ä»¥èµ°é©¬ï¼Œå¯†å¤„ä¸ä½¿é€é£ã€‚</em></strong></h3><p>è¿™æ˜¯ä¸€ä¸ªå’Œ<strong>å¢¨å¿ƒ</strong>æ­é…ä½¿ç”¨çš„æ„å›¾Lora, ä¸€æ—¦ä½¿ç”¨å¹¶å†æœ€å‰å‰ç½®æç¤ºè¯åï¼Œå°±ä¼šé‡‡ç”¨è¾ƒå¤§é¢ç§¯ç•™ç™½çš„æ„å›¾é£æ ¼ã€‚å¯ä»¥åœ¨ç‰ˆæœ¬å¤„æ‰¾åˆ°ä»–</p><p></p><p></p><p>æ³¨æ„äº‹é¡¹ï¼š<br />1.ï¼‰CFGèŒƒå›´å°†ä¼šæ”¹å˜é£æ ¼</p><ul><li><p>1~3 : å¤§å°å†™æ„</p></li><li><p>3~7 : é€æ¸å·¥ç¬”</p></li></ul><p>2.ï¼‰æ¨èåŸºç¡€æ¨¡å‹ä¸ºChilloutMixã€å›½é£3.2ç­‰</p><p>3.ï¼‰ã€Šå¢¨å¿ƒã€‹çš„æ¨èLoraæƒé‡ä¸º0.85ä»¥ä¸‹</p><p>4.ï¼‰ã€Šç–å¯èµ°é©¬ã€‹æ¨èLoraæƒé‡ä¸º0.7~1</p><p>====================================</p><p></p><p><strong>\"MoXin\"<br /><em>Xi Juanzi \"Qinxin\". Wangsun \"QiaoXin\", Xin zai mei yi, gu yong zhi yan.</em></strong></p><p>MoXin is a Lora trained from on Chinese painting Masters lived in Ming and Qing dynasties.</p><p><br />â€œ<strong>Shukezoumaâ€<em><br />Zi hua shu chu ke yi zou ma, mi chu bu shi tou feng.</em></strong><br />This is a Lora that major functions in Traditionla Chinese painting composition. Once it is used and preceded by \"shukezouma\" prompts in the very beginning, it adopts a composition style featuring a large area of negative space.</p><p></p><p>Tips:</p><p>1.) The result style will change within the following CFG ranges:</p><ul><li><p>1~3 : Xieyi Painting</p></li><li><p>3~7 : Gongbi Painting</p></li></ul><p>2.) It is recommended to use with ChilloutMix, GuoFeng3.2, etc.</p><p>3.) It is recommended to use \"MoXin\"'s Lora weight of 0.85 or lower.</p><p>4.) It is recommended to use \"Shukezouma\"'s Lora weight between 0.7~1</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581211+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "15003",
    "prompt": "CyberRealistic\n<p><span style=\"color:rgb(250, 176, 5)\">Like what I build here? Youâ€™ll <em>love</em> the chaos behind the scenes - </span><a target=\"_new\" rel=\"ugc\" href=\"https://patreon.com/cyberdelia\"><span style=\"color:rgb(250, 176, 5)\"><u>Check my Patreon</u></span></a></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/17febe49-5713-4d68-bb17-6789ae5675e7/width=525/17febe49-5713-4d68-bb17-6789ae5675e7.jpeg\" /><span style=\"color:rgb(250, 82, 82)\">Give CyberRealistc a try </span><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/878750700945827383/CyberRealistic-v9.0\"><span style=\"color:rgb(250, 82, 82)\"><u>here</u></span></a><span style=\"color:rgb(250, 82, 82)\">! Want unlimited access? Take a look at the one-time purchase for full use.</span></p><p>CyberRealistic is a flexible, easy-to-use photorealistic model built from nonstop testing, custom blends, and just the right amount of chaos. The backstory? Itâ€™s honestly a wild mashup of different checkpoints, but what really counts is what you get in the end: sharp, expressive, clean renders that just work.</p><p>Itâ€™s tuned for both textual inversion and LoRA, so itâ€™s great for anyone from total beginners to hardcore prompt wizards. If youâ€™re making portraits, messing around with new styles, or just want a model that steps aside and does its job, CyberRealistic wonâ€™t let you down.</p><hr /><p><span style=\"color:rgb(21, 170, 191)\"><strong>âš™ï¸ Suggested Settings</strong></span></p><pre><code>Sampling method: DPM++ SDE Karras / DPM++ 2M Karras  \nVAE: is already Baked In\nSampling steps: 30 Steps\nResolution: 512x768\nCFG: 5\nUpscale: 2x\nUpscaler: 4x_NickelbackFS_72000_G\nDenoising strength: 0.3</code></pre><p></p><hr /><p><span style=\"color:rgb(21, 170, 191)\"><strong>ğŸ§  Prompting</strong></span></p><p><strong>Negative prompt examples</strong></p><pre><code>lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry</code></pre><p></p><hr /><p><span style=\"color:rgb(21, 170, 191)\"><strong>ğŸ’¾ Backup &amp; Resources</strong></span><br />backup location: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/cyberdelia/CyberRealistic/tree/main\">huggingface</a></p><p></p><hr /><p><span style=\"color:rgb(21, 170, 191)\"><strong>â˜• Support the Project</strong></span><br />If this model helped you hit your vision faster, cleaner, or just plain better â€” consider [<a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/cyberdelia\">buying me a coffee</a>]. It keeps the updates coming and the experiments wild.</p><p></p><hr /><p><span style=\"color:rgb(193, 194, 197)\">ğŸ’¡</span><span style=\"color:rgb(21, 170, 191)\"><strong> Need Better Prompts?</strong></span><br /><span style=\"color:rgb(193, 194, 197)\">This custom ChatGPT was made to top-tier prompts just for this model:</span><br /><span style=\"color:rgb(193, 194, 197)\">ğŸ”— [</span><a target=\"_blank\" rel=\"ugc\" href=\"https://chatgpt.com/g/g-6834133e3ab881918a91b3ec6b9eb01f-cyberrealistic-prompt-helper\">Try it now on ChatGPT</a><span style=\"color:rgb(193, 194, 197)\">]</span></p><p></p><hr /><p><span style=\"color:rgb(21, 170, 191)\"><strong>âš ï¸ Friendly Warning</strong></span><br />This model can generate mature content. Use responsibly. Respect laws, platforms, and people.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581222+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "56519",
    "prompt": "negative_hand Negative Embedding \n<h2>negative_hand Negative Embedding</h2><h3>Problem with Negative Embedding's</h3><p>Currently, there are more and more negative embedding, while many are also very good and easy to use. However, almost all of them currently have a big problem... They change the main or initial artstyle of the used model. Best example would be my bad_prompt_version2 Negative Embedding. It helps enormously with the quality of an image, but drastically changes the artstyle of the model. That's not the point of it. For this reason, I have now trained my new Negative Embedding negative_hand!</p><p>An example of the issue:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/images/667829?modelVersionId=60938&amp;prioritizedUserIds=162020&amp;period=AllTime&amp;sort=Most%20Reactions&amp;limit=20\">Image Link</a></p><p></p><h3>So what is negative_hand?</h3><p>negative_hand is supposed to fix the said issue. That means it should improve the quality of the image, but without changing the initial artstyle of the model.</p><p>Pro:</p><ul><li><p>The artstyle of the model can be used without any problems and without possible artstyle changes.</p></li><li><p>The quality of the image and incorrect anatomy like hands are improved.</p></li></ul><p>Con:</p><ul><li><p>Since this embedding cannot drastically change the artstyle and composition of the image, not one hundred percent of any faulty anatomy can be improved.</p></li></ul><p></p><h3>Usage</h3><p>To use this embedding you have to download the file aswell as drop it into the \"\\stable-diffusion-webui\\embeddings\" folder.</p><p><strong>Please put the embedding in the negative prompt to get the right results!</strong></p><p>For special negative tags such as \"malformed sword\", you still need to add them yourself. The negative embedding is trained on a basic skeleton for the negative prompt, which should provide a high-resolution image as a result.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581225+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "618692",
    "prompt": "FLUX\n<p><span style=\"color:#e64980\">Please check out the</span> <a rel=\"ugc\" href=\"https://education.civitai.com/quickstart-guide-to-flux-1\">Quickstart Guide to Flux </a><span style=\"color:#e64980\">for all the info you need to get started!</span></p><p></p><p><code>FLUX.1 [dev]</code> is a 12 billion parameter rectified flow transformer capable of generating images from text descriptions. For more information, please read our <a target=\"_blank\" rel=\"ugc\" href=\"https://blackforestlabs.ai/announcing-black-forest-labs/\"><strong><u>blog post</u></strong></a>.</p><h1 id=\"key-features-325mmh6sm\">Key Features</h1><ol><li><p>Cutting-edge output quality, second only to our state-of-the-art model <code>FLUX.1 [pro]</code>.</p></li><li><p>Competitive prompt following, matching the performance of closed source alternatives .</p></li><li><p>Trained using guidance distillation, making <code>FLUX.1 [dev]</code> more efficient.</p></li><li><p>Open weights to drive new scientific research, and empower artists to develop innovative workflows.</p></li><li><p>Generated outputs can be used for personal, scientific, and commercial purposes as described in the <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/licence.md\"><strong><u>flux-1-dev-non-commercial-license</u></strong></a>.</p></li></ol><h1 id=\"usage-y9h8q18hm\">Usage</h1><p>We provide a reference implementation of <code>FLUX.1 [dev]</code>, as well as sampling code, in a dedicated <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/black-forest-labs/flux\"><strong><u>github repository</u></strong></a>. Developers and creatives looking to build on top of <code>FLUX.1 [dev]</code> are encouraged to use this as a starting point.<br /><br />Learn More Here: <br /><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/black-forest-labs/FLUX.1-dev\">https://huggingface.co/black-forest-labs/FLUX.1-dev</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581230+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "16014",
    "prompt": "Anime Lineart / Manga-like (çº¿ç¨¿/ç·šç”»/ãƒãƒ³ã‚¬é¢¨/æ¼«ç”»é£) Style\n<h2>Update information</h2><p></p><p>V3.0 updated. Fine-tuned LoRA to improve the effects of generating characters with complex body limbs and backgrounds. The overall styling is more toward manga style rather than simple lineart. A lower CFG scale can make lines thinner.</p><p></p><p>V3.0æ›´æ–°ã€‚å¯¹LoRAè¿›è¡Œäº†å¾®è°ƒï¼Œæ”¹å–„ç”Ÿæˆäººç‰©è‚¢ä½“å’Œå¤æ‚èƒŒæ™¯çš„æ•ˆæœã€‚æ•´ä½“æ›´è¶‹å‘æ¼«ç”»é£è€Œéçº¯çº¿ç¨¿ã€‚ä½CFG scaleå¯ä»¥è®©çº¿æ¡å˜ç»†ã€‚</p><p></p><h2>Recommend settings</h2><p>Model: Anything V4.5</p><p>VAE: Orangemix (the same with NAI)</p><p>LoRA Strength: 1</p><p>Sampler: DPM++ 2M Karras</p><p>Sampling steps: 20</p><p>CFG: 7</p><p>Negative embedding: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\">EasyNegative</a>ã€<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16993/badhandv4-animeillustdiffusion\">badhandv4</a></p><p>Highres fix is also recommended.</p><p>Note: all the LoRA names used in sample images are my local name, you need to change them to your saved LoRA filename!</p><p>åŸºæ¨¡ï¼šAnything V4.5</p><p>VAEï¼šOrangemixï¼ˆåŒNAIï¼‰</p><p>LoRAå¼ºåº¦ï¼š1</p><p>é‡‡æ ·å™¨ï¼šDPM++ 2M Karras</p><p>é‡‡æ ·æ­¥æ•°ï¼š20</p><p>CFGï¼š7</p><p>è´Ÿé¢embeddingï¼š<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\">EasyNegative</a>ã€<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16993/badhandv4-animeillustdiffusion\">badhandv4</a></p><p>æ¨èä½¿ç”¨é«˜æ¸…ä¿®å¤ã€‚</p><p>æ³¨æ„ï¼šæ ·å›¾ä¸­çš„LoRAåç§°æ˜¯æˆ‘æœ¬åœ°æ–‡ä»¶åï¼Œè¦æ”¹æˆä½ ä¿å­˜çš„æ–‡ä»¶åï¼</p><p></p><h2>Difference</h2><p></p><p>Here's a comparision of V2.0 and V3.0 (locally called V3 and V4 on my machine - V2 on my machine is not published):</p><p>V2.0å’ŒV3.0çš„å¯¹æ¯”ï¼ˆåœ¨æˆ‘çš„æœ¬åœ°æœºå™¨ä¸Šå‘½åä¸ºV3å’ŒV4â€”â€”æœ¬åœ°çš„V2æˆ‘å¹¶æœªå‘å¸ƒï¼‰ï¼š</p><p></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/38354d83-7523-4334-c3de-1a3a493e5a00/width=525/38354d83-7523-4334-c3de-1a3a493e5a00\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cc03ae1f-4391-4ff5-4850-d9478d78c600/width=525/cc03ae1f-4391-4ff5-4850-d9478d78c600\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/4c7eaa16-9f4d-4545-dc36-c2d3f43b9d00/width=525/4c7eaa16-9f4d-4545-dc36-c2d3f43b9d00\" /><p></p><p>Comparision of different CFG scale:</p><p>ä¸åŒCFG scaleå¯¹æ¯”ï¼š</p><p></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/845cf24a-c5c6-4ee0-a999-d7130ecb7e00/width=525/845cf24a-c5c6-4ee0-a999-d7130ecb7e00\" />",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581238+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "82098",
    "prompt": "Add More Details - Detail Enhancer / Tweaker (ç»†èŠ‚è°ƒæ•´) LoRA\n<h2 id=\"heading-734\">Add More Details - Detail Enhancer / Tweaker</h2><p><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> ğŸ…¿ï¸ or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> â˜•</strong><br /></p><p>I've been using the (great) Detail Tweaker by CyberAIchemist for a while now, and I was really curious. I really just wanted to know if I was capable of doing something similar. </p><p>I had a lot of fun doing this, and I think it came out pretty great. I wil ldefinitely incorporate it in most of my work going forward. </p><p>You should use this <strong>between 0.5 and 1 weight</strong>, depending on your preference. You can go lower than 0.5 for a more subtle effect, of course.</p><p>I also found out that this gives some interesting results at negative weight, sometimes. See the examples to see what I mean. <br /></p><p><strong>How to use LoRA's in auto1111:</strong></p><ul><li><p>Update webui (use <code>git pull</code> <a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/embed/mn8fMF10XN4?start=31&amp;end=60\">like here</a> or redownload it)</p></li><li><p>Copy the file to <code>stable-diffusion-webui/models/lora</code></p></li><li><p>Select your LoRA like in <a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/watch?v=-bMeyXOZwN0\">this video</a></p></li><li><p><strong>Make sure to change the weight</strong> (by default it's <code>:1</code> which is usually too high)</p></li></ul>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581246+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "112902",
    "prompt": "DreamShaper XL\n<h1 id=\"heading-4\">DreamShaper XL - Now Turbo!</h1><h3 id=\"heading-134\"><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384/dreamshaper\">Also check out the 1.5 DreamShaper page</a></h3><p><strong>Check the version description below (bottom right) for more info and add a â¤ï¸ to receive future updates.</strong><br /><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> ğŸ…¿ï¸ to get exclusive tips and tutorials, or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> â˜•</strong></p><p></p><h3 id=\"heading-135\">Join my <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/uAhsmDq7GC\">Discord Server</a></h3><p></p><p><strong><span style=\"color:rgb(64, 192, 87)\">Alpha2 is a bit old now. I suggest you switch to the Turbo or Lightning version.</span></strong><br /><strong>DreamShaper</strong> is a<em> general purpose </em>SD model that aims at doing everything well, photos, art, anime, manga. It's designed to go against other general purpose models and pipelines like Midjourney and DALL-E.</p><p></p><h2 id=\"heading-634\">\"It's Turbotime\"</h2><p><strong>Turbo </strong>version should be used at <u><span style=\"color:rgb(253, 126, 20)\">CFG scale 2</span></u> and with around <u><span style=\"color:rgb(253, 126, 20)\">4-8 sampling steps</span></u>. This should work only with <strong><u><span style=\"color:rgb(253, 126, 20)\">DPM++ SDE Karras</span></u></strong> (NOT 2M). You can use this with LCM sampler, but don't do it unless you need speed vs quality. <br /><strong><span style=\"color:rgb(130, 201, 30)\">Sampler comparison at 8 steps:</span></strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/951781\">https://civitai.com/posts/951781</a><br /><strong><span style=\"color:rgb(250, 82, 82)\">UPDATE: </span><span style=\"color:rgb(18, 184, 134)\">Lightning </span></strong>version targets <u><span style=\"color:rgb(253, 126, 20)\">3-6 sampling steps</span></u> at <u><span style=\"color:rgb(253, 126, 20)\">CFG scale 2</span></u> and should also work only with <strong><u><span style=\"color:rgb(253, 126, 20)\">DPM++ SDE Karras</span></u></strong>. Avoid going too far above 1024 in either direction for the 1st step.</p><p>No need to use refiner and this model itself can be used for highres fix and tiled upscaling. <br />Examples have been generated using Auto1111, but you can achieve similar results with this ComfyUI Workflow: <a target=\"_blank\" rel=\"ugc\" href=\"https://pastebin.com/79XN01xs\">https://pastebin.com/79XN01xs</a></p><p><strong>Basic style comparison: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/images/4427452\">https://civitai.com/images/4427452</a></p><p><strong>If you train on this, make sure to use <u><span style=\"color:rgb(253, 126, 20)\">DPM++ SDE</span></u> sampler and appropriate steps/cfg.</strong></p><p><strong>Keep in mind <span style=\"color:rgb(250, 82, 82)\">Turbo currently cannot be used commercially unless you get permission from StabilityAI.</span> </strong>Get a membership here: <a target=\"_blank\" rel=\"ugc\" href=\"https://stability.ai/membership\">https://stability.ai/membership</a></p><p>You can use the Turbo version (<strong>not Lightning</strong>) as a non-Turbo model with DPM++ <strong><u>2M</u> </strong>SDE Karras / Euler at cfg 6 and 20-40 steps. Here is a comparison I made with some of the best non-Turbo XL models (with regular settings and turbo settings): <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/1414848ï¿¼ï¿¼\">https://civitai.com/posts/1414848<br /></a>I have no idea why anyone would prefer 40 steps over 8, but you have the option.</p><p></p><div data-youtube-video><iframe width=\"640\" height=\"480\" allowfullscreen=\"true\" autoplay=\"false\" disablekbcontrols=\"false\" enableiframeapi=\"false\" endtime=\"0\" ivloadpolicy=\"0\" loop=\"false\" modestbranding=\"false\" origin playlist src=\"https://www.youtube.com/embed/l71ZCs7tUu8\" start=\"0\"></iframe></div><p></p><h2 id=\"heading-635\"><u>Old</u> description referring to <u>Alpha 2</u> and before</h2><p><strong>Finetuned over SDXL1.0.</strong><br />Even if this is still an alpha version, I think it's already much better compared to the first alpha based on xl0.9.<br />For the workflows you need Math plugins for comfy (or to reimplement some parts manually).<br />Basically I do the first gen with DreamShaperXL, then I upscale to 2x and finally a do a img2img steo with either DreamShaperXL itself, or a 1.5 model that i find suited, such as DreamShaper7 or AbsoluteReality.</p><p><strong>What does it do better than SDXL1.0?</strong></p><ul><li><p>No need for refiner. Just do highres fix (upscale+i2i)</p></li><li><p>Better looking people</p></li><li><p>Less blurry edges</p></li><li><p>75% better dragons ğŸ‰</p></li><li><p>Better NSFW</p></li></ul><p></p><h3 id=\"heading-226\">Old DreamShaper XL 0.9 Alpha Description</h3><p>Finally got permission to share this. It's based on SDXL0.9, so it's just a training test. It definitely has room for improvement.</p><p>Workflow for this one is a bit more complicated than usual, as it's using AbsoluteReality or DreamShaper7 as \"refiner\" (meaning I'm generating with DreamShaperXL and then doing \"highres fix\" with AR or DS7). <br /><br />Results are quite nice for such an early stage. <br /><br />I might disable the comment section as I'm sure some people will judge this even if it's early stage. I also don't think this is on par with SD1.5 DreamShaper yet, but it's useless to pour resources into this as SDXL1.0 is about to be released. <br /><br />Have fun and make sure to add a <strong>â¤ï¸ </strong>to receive future updates.<br /><br /><s>Non commercial license is forced by Stability at the moment.</s></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581262+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "212532",
    "prompt": "All Disney Princess XL LoRA Model from Ralph Breaks the Internet\n<h1 id=\"heading-45\"><strong>All Disney Princess XL LoRA Model - Ralph Breaks the Internet</strong></h1><p>If You Like This Model, Give It a â¤ï¸</p><p>This LoRA model is trained on screen capture images featuring beloved Disney princesses from the movie Ralph Breaks the Internet, including Rapunzel, Snow White, Ariel, Aurora, Belle, Cinderella, Elsa, Anna, Jasmine, Mulan, Merida, Tiana, Moana, and Pocahontas. It's designed to be an All-in-One Model for your creative endeavors.</p><p></p><p>Check out SD1.5 Version Here: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/202866/all-princesses-from-disneys-ralph-2-ralph-breaks-the-internet-or-all-in-one-lora-model\">https://civitai.com/models/202866/all-princesses-from-disneys-ralph-2-ralph-breaks-the-internet-or-all-in-one-lora-model</a></p><p></p><h2 id=\"heading-46\"><strong>Bonus Characters</strong></h2><p>Additionally, this model includes representations of other characters like Vanellope, Shank, Raya, Namaari, Asha, and Rapunzel with short hair. While these extras are included, the quality may vary.</p><p></p><h2 id=\"heading-47\"><strong>Quick Tips</strong></h2><ul><li><p><strong>Direct Name Usage</strong>: You can generate any princess by directly prompting their names, such as <code>Anna</code>, <code>Ariel</code>, <code>Aurora</code>, <code>Belle</code>, <code>Cinderella</code>, <code>Elsa</code>, <code>Asha</code>, <code>Jasmine</code>, <code>Merida</code>, <code>Moana</code>, <code>Mulan</code>, <code>Namaari</code>, <code>Pocahontas</code>, <code>Rapunzel</code>, <code>Raya</code>, <code>Shank</code>, <code>Snow White</code>, <code>Tiana</code>, <code>Vanellope</code>.</p><ul><li><p>More Character in v2 including: <code>Alice</code>, <code>Chel</code>,<code>Esmerada</code>, <code>Jane Porter</code>, <code>Kida</code>, <code>Megera</code>,<code>Mirabel Madrigal</code>, <code>Isabela Madrigal</code>, <code>Dolores Madrigal</code> and some secret character! </p></li></ul></li><li><p><strong>LoRA Scale</strong>: Optimal LoRA scales range between 0.6-0.7 for close-up character generation and 0.3-0.5 for full-body generation. Combining these scales using the ADetailer plugin can yield enhanced results. Ensure an adequate number of sampling steps for better output.</p></li><li><p><strong>Base Models</strong>: Although various base models can function, models with animation styles like DreamShaper or RealCartoon are preferred for optimal performance.</p></li></ul><p>Enjoy exploring the LoRA!</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581266+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "24149",
    "prompt": "Mistoon_Anime\n<p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b8f7dc5a-4261-44ec-9abc-2c1ca3c60c5e/width=525/b8f7dc5a-4261-44ec-9abc-2c1ca3c60c5e.jpeg\" /><strong>You can use this model on SeaArt </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.seaart.ai/models/detail/588bb5f910028a5c341822e4f5667e41\"><strong>here</strong></a><strong>.</strong></p><p>Mistoon_Anime is my blend of SD models that tries to achieve a more \"cartoony\" anime style with thick borders and brighter colors. The aim of this model is not to mimic a particular style, but to achieve an aestethic I like.</p><p>This merge has been created using a lot of different models. In the start I've used popular models (and also nieche ones), but now I'm mostly using my custom LoRAs to finetune the model in the way I like.</p><p>This model is oriented towards creating girls portraits, but the V2 and V3 is also capable of creating male characters in a convincing way.</p><p>If you plan to do some inpainting there is also an inpainting version available for you to download.</p><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b28baea5-472a-41d7-a5cc-542c4578cd39/width=525/b28baea5-472a-41d7-a5cc-542c4578cd39.jpeg\" />The idea behind Mistoon_Anime is to achieve the modern anime style while keeping it as colorful as possible. A lot of checkpoints available now are mostly based on anime illustrations oriented towards 2.5, but I prefer the bright 2d anime aesthetic.</p><p>It creates realistic and expressive characters with a \"cartoony\" twist. Unlike other anime models that tend to have muted or dark colors, Mistoon_Anime uses bright and vibrant colors to make the characters stand out.</p><p>This model can easily do both SFW and NSFW stuff (V1 has a bias towards NSFW keep that in mind).</p><p>Do you want a softer style? Try out: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/319650/mistoonxlcopper\">https://civitai.com/models/319650/mistoonxlcopper</a></p><h3 id=\"-kpu5h7kho\"></h3><h3 id=\"v1-ntfz8opos\"><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/20885ddf-b4d1-469e-9ae4-722b2bf0534a/width=525/20885ddf-b4d1-469e-9ae4-722b2bf0534a.jpeg\" />V1</h3><p>The v1 version is the original Mistoon_Anime that a lot of you already know. It's bright, cartoony and likes tight clothes ğŸ˜‚. If you've never used the original version I highly recommend to check out the gallery and see if it is for you. <strong>If you want to use the V1 you'll need a VAE, I highly suggest you to use </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/iZELX1/Grapefruit/resolve/main/Grapefruit.vae.pt\"><strong>this one</strong></a><strong>.</strong></p><p>If you want a more traditional anime style, you'll probably want the newest version.</p><p></p><h3 id=\"v2-vwxhsknep\">V2</h3><ul><li><p>Is WAY better at producing images depicting males</p></li><li><p>Has lower distortion at lower resolutions</p></li><li><p>Is way more detailed</p></li><li><p>Has better backgrounds consistency</p></li><li><p>Eyes are more detailed and consistent</p></li><li><p>Is incredibly detailed when working with close-ups or upper body portrait</p></li><li><p>Is better with NSFW than the previous version</p></li><li><p><strong>Works better with CLIP skip set to 2</strong></p></li><li><p><strong>Has already a VAE embedded.</strong></p></li></ul><p></p><h3 id=\"v3-0tl5idd1j\">V3</h3><ul><li><p>I've merged it back the original version of Mistoon_Anime to give it a more similar vibe to the original</p></li><li><p>I've merged it with Mistoon_Pearl to give it more flexibility and versatility</p></li><li><p>The model should now be able to create more interesting poses</p></li><li><p>The model has now an improved level of detail on both full body portraits and close-ups</p></li><li><p>The model should be capable of generating high quality 512x768 pictures (especially close-ups)</p></li><li><p><strong>Works better with CLIP set to 2</strong></p></li><li><p><strong>Has already a VAE embedded.</strong></p></li></ul><p></p><h3 id=\"pony-(alpha)-26hpwz8l5\">Pony (Alpha)</h3><p>After a long wait the alpha for the Mistoon Anime pony version is here! There are a few things you'll need to know:</p><ul><li><p>All my generations have been done with:</p><ul><li><p>UI: <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Panchovix/stable-diffusion-webui-reForge\">Panchovix/stable-diffusion-webui-reForge (</a><a target=\"_blank\" rel=\"ugc\" href=\"http://github.com\">github.com</a><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Panchovix/stable-diffusion-webui-reForge\">)</a></p></li><li><p>Sampler: Euler A</p></li><li><p>Scheduler: SGM Uniform</p></li><li><p>CFG: 2,5/3</p></li><li><p>Width/Height: 768x1152 -&gt; 1024x1536 -&gt; 1280x1920</p></li><li><p>Sampling Steps: 8</p></li></ul></li><li><p>My workflow is the same as usual:</p><ul><li><p>Generate a bunch of 768x1152 pictures</p></li><li><p>Choose the best one and send it to img2img</p></li><li><p>Run the same prompt but with higher resolution (1024x1536) and denoising set to 0.5</p></li><li><p>Take the best result and send it again to img2img</p></li><li><p>Run again with higher resolution (1280x1920) and denoising set to 0.2</p></li></ul></li><li><p>Right now, there are a few issues (and that's the reason I consider this to be an alpha):</p><ul><li><p>Sometimes the area around the eyes is distorted due to excessive training</p></li><li><p>Sometimes the colors are off, especially in areas hit by sunlight</p></li><li><p>It's not as flexible as the base pony model</p></li><li><p>It does not always maintain a consistent style</p></li></ul></li></ul><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3bd064dd-e9da-4b9a-8f69-fedbd240e9d1/width=525/3bd064dd-e9da-4b9a-8f69-fedbd240e9d1.jpeg\" />Learn more about how I create the examples here: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/3318\">From Noise to Illustrations: How I Generate AI Pictures with Stable Diffusion | Civitai</a></p><p>In the past few months I've had a lot of people asking me why their pictures are not as detailed or clean as mine. I've written a few articles about SD, but if you want to learn my exact workflow I highly recommend you to check out my latest one: <a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/p/6be78130eb9e\">My Workflow</a></p><p>If you want to test this (or other models), I have made an extension to help me create pictures using a variety of different tags. The previews images have been generated using my custom extension <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Inzaniak/sd-webui-ranbooru\">Ranbooru </a>which scrapes tags from random images on gelbooru, safebooru and rule34.</p><p>If you want to learn more about my workflow, check out the guides below.</p><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/900abc6f-a55f-4f93-8109-e03a7e96f427/width=525/900abc6f-a55f-4f93-8109-e03a7e96f427.jpeg\" />Learn how to create pictures like mine with my step-by-step tutorials:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/p/bd7dbcd5ce4b\">Beginner's Guide</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/p/35eacb3dc5f4\">Prompting</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/@inzaniak/stable-diffusion-ultimate-guide-pt-3-high-resolution-a4f5d7b60f38\">High Resolution</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/p/772ea69472c9\">Inpainting</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/@inzaniak/stable-diffusion-ultimate-guide-pt-5-controlnet-6f45e9614119\">ControlNet</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/p/6be78130eb9e\">My Workflow</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/p/e2b299a70421\">Tips and Tricks</a></p></li></ul><p>Other stuff here on CivitAI:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/3318/from-noise-to-illustrations-how-i-generate-ai-pictures-with-stable-diffusion\">Learn how I create my examples</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/3357/ranbooru-the-comprehensive-guide\">Learn how to master the Ranbooru Extension</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/3716\">Learn how to master the Workflow Extension</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/10480/my-workflow-invokeai\">2025 Workflow</a></p></li></ul><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/80a56b01-6eed-43ac-94fb-e73e96d76ca0/width=525/80a56b01-6eed-43ac-94fb-e73e96d76ca0.jpeg\" />I've got a lot of models here on CivitAI (and even more on Patreon), here's some of them:</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a357f034-3ab6-4585-8534-5ca2903ce490/width=525/a357f034-3ab6-4585-8534-5ca2903ce490.jpeg\" /></p><p>Initially I used to release every LoRA here on CivitAI, but after a while it became very time-consuming, so I started releasing only my favourite new LoRAs here on CivitAI while still releasing all the models <strong>for free</strong> on Patreon.</p><p>So, if you don't want to miss a release be sure to follow me on Patreon (for free you don't need to sub if you don't want to) here:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Inzaniak\">https://www.patreon.com/Inzaniak</a></p><p>If you want to check out my other models you'll find them here:</p><ul><li><p>Civitai: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Inzaniak\">Civitai | Share your models</a></p></li><li><p>Patreon (Free): <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Inzaniak?filters[tag]=public\">Inzaniak | Generative Art and Tech Blogging | Patreon</a></p></li><li><p>Patreon (All): <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Inzaniak?filters[tag]=lora\"><u>Inzaniak | Generative Art and Tech Blogging | Patreon</u></a></p><p></p><p></p></li></ul><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/336304e8-65f5-4070-a1b8-fe59b651cf7a/width=525/336304e8-65f5-4070-a1b8-fe59b651cf7a.jpeg\" />I've started developing custom models for myself a few months ago just to check out how SD worked, but in the last few months it has become a new hobby I like to practice in my free time. All my checkpoints and LoRAs will always be released for free on Patreon or CivitAI, but if you want to support my work and get early access to all my models feel free to check out my Patreon:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Inzaniak\">https://www.patreon.com/Inzaniak</a></p><p></p><p>If you want to support my work for <strong>free</strong>, you can also check out my music/art here:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://inzaniak.bandcamp.com/\">Bandcamp</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.deviantart.com/inzaniak\">DeviantArt</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.threads.net/@inzaniak_aiart\">Threads</a></p></li></ul><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/12bf0a72-1930-4f17-8ad9-7233a8ebd8de/width=525/12bf0a72-1930-4f17-8ad9-7233a8ebd8de.jpeg\" /></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581292+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "24779",
    "prompt": "Dark Sushi Mix å¤§é¢—å¯¿å¸Mix\n<p>Recommend:</p><p>vae-ft-mse-840000-ema</p><p></p><p>use highres fix to improve quality.</p><p></p><p></p><p></p><p>æ‰“äº†ä¸€ä¸ªæœˆç‹å›½ä¹‹æ³ªåé‡æ“æ—§ä¸šã€‚</p><p>æ–°ç‰ˆæœ¬ç®—æ˜¯å¯¹2.5dçš„æ•´åˆï¼Œä¿ç•™æ•´ä½“äºŒæ¬¡å…ƒç”»é£çš„åŒæ—¶è‚¢ä½“ä¸Šæ¯”å‰å‡ ä¸ªç‰ˆæœ¬è¦å¥½ï¼Œè„¸å‹ä¹Ÿè¦æ›´å¤šæ ·åŒ–ä¸€ç‚¹ã€‚</p><p>ä½†å…‰å½±å’Œçº¿æ¡ä¸Šå°±å’Œ2.5Dæ›´åƒä¸€äº›ï¼Œæˆ‘ä¹Ÿçº ç»“äº†å¾ˆä¹…ç©¶ç«Ÿè¯¥æ”¾åœ¨å“ªè¾¹ï¼Œæœ€ç»ˆè¿˜æ˜¯æ”¾åœ¨è¿™äº†ã€‚äºæ˜¯å¹²è„†èµ·ä¸ª2.25dçš„ç‰ˆæœ¬åå§ï¼Œè‡³äºå­°å¥½å­°åå°±è§ä»è§æ™ºäº†ã€‚</p><p><s>å¤šå°‘æœ‰ç‚¹èƒŒç¦»åˆè¡·äº†ï¼Œä¸€ç‚¹éƒ½ä¸æš—äº†ã€‚æƒ³æš—çš„è¯è¿˜æ˜¯è‡ªå·±åŠ noiseoffsetå§</s></p><p></p><p>After playing Tears of the Kingdom for a month, I resumed my old work. The new version is an integration of 2.5d, which retains the overall anime style while being better than the previous versions on the limbs, but the light and shadow and lines are more like 2.5D, so i simply call it 2.25d version.</p><p></p><p></p><p></p><p></p><p>èµ·ååºŸç©çƒ‚æ¢—ç³»åˆ—ï¼Œäº‹åæƒ³æƒ³èµ·çš„ä¸é”™ã€‚</p><p>é¦–å…ˆæš—å›¾æ•ˆæœæ¯”è¾ƒå¥½ï¼Œdarkåˆé€‚ï¼Œè‡ªå·±èçš„æ—¶å€™å·®ä¸å¤šä¹Ÿæ˜¯å¯¿å¸é‚£æ ·ä»€ä¹ˆéƒ½å¡ç‚¹ï¼Œdark å¯¿å¸æ²¡æ¯›ç—…ã€‚</p><p>å…‰æ•ˆæ¯”è¾ƒå¥½ï¼Œèƒ½ç”Ÿæˆæ¯”è¾ƒæš—çš„å›¾ï¼Œæ­£å¸¸äº®åº¦çš„å›¾ç‰‡ä¹Ÿæœ‰ä¸é”™çš„å…‰å½±è¡¨ç°ã€‚</p><p>èäº†ç¾¤å‹ç§æ¨¡å’Œä¸€å¤§å †æˆ‘ä¹Ÿè®°ä¸ä½ç»„æˆçš„ä»¥å‰çš„è‡ªèæ¨¡</p><p>èƒ½ç¡®å®šåŒ…å«çš„æ˜¯è‡ªå·±ä¹‹å‰çš„äº”ä»<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/21409/five-nuts-mixed-mix\">Five Nuts Mixed äº”ä»æœˆé¥¼Mix | Stable Diffusion Checkpoint | Civitai </a>å’Œ<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/23905/unrule\">Unrule | Stable Diffusion Checkpoint | Civitai</a></p><p>ä»¥åŠç¾¤å‹çš„TmndMix ï¼Œç»å¯¹çš„æ°ä½œï¼Œæ¨èå¤§å®¶éƒ½å»è¯•è¯• <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/27259\">https://civitai.com/models/27259</a></p><p>darkerç‰ˆæœ¬é‡Œè¿˜åŠ äº†noiseoffsetçš„loraï¼Œç”Ÿå›¾è¦æ¯”brighterç‰ˆæœ¬æš—ä¸€äº›ï¼Œå…‰å½±è¡¨ç°ä¸Šè¦å¼ºä¸€ç‚¹ï¼Œä½†ç¼ºç‚¹å°±æ˜¯æ­£å¸¸ç”Ÿå›¾ä¹Ÿä¼šæ¯”è¾ƒæš—ã€‚å¤§å®¶ä¸€èˆ¬ç”¨brighterç‰ˆå†è‡ªå·±è°ƒç”¨noiseoffsetçš„loraä¹Ÿèƒ½è¾¾åˆ°ç±»ä¼¼æ•ˆæœã€‚</p><p></p><p>Intro:</p><p>named from a dark soul's meme in Chinese community.</p><p></p><p>merged with my friend's pravite model and some other models merged by myself.</p><p>Including <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/21409/five-nuts-mixed-mix\">Five Nuts Mixed äº”ä»æœˆé¥¼Mix | Stable Diffusion Checkpoint | Civitai </a>,</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/23905/unrule\">Unrule | Stable Diffusion Checkpoint | Civitai</a></p><p>and my friend's TmndMix <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/27259\">https://civitai.com/models/27259</a> .it's definitely a masterpiece.</p><p>if you like dark sushi ,you should also try tmnd.</p><p>noiseoffset lora is merged into the darker version. So the imgs generated by the darker version will be darker ,and have better light and shadow performance. you can use brighter version and noiseoffset lora to get similar effect.</p><p></p><p></p><p></p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581297+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "23900",
    "prompt": "AnyLoRA - Checkpoint\n<h1 id=\"heading-232\">AnyLoRA</h1><p><strong>Add a â¤ï¸ to receive future updates.</strong><br /><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> ğŸ…¿ï¸ or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> â˜•</strong></p><p><strong><span style=\"color:rgb(253, 126, 20)\">For LCM read the version description.</span></strong></p><p><strong>Available on the following websites with GPU acceleration:</strong></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/WLRRBnv\"><strong>Sinkin.ai</strong></a></p></li></ul><h2 id=\"heading-233\"><strong>Remember to use the <u>pruned</u> version when training</strong> (less vram needed).<br />Also this is mostly for training on anime, drawings and cartoon.</h2><p>I made this model to ensure my future LoRA training is compatible with newer models, plus to get a model with a style neutral enough to get accurate styles with any style LoRA. Training on this model is much more effective compared to NAI, so at the end you might want to adjust the weight or offset (I suspect that's because NAI is now much diluted in newer models). I usually find good results at 0.65 weigth that I later offset to 1 (very easy to do with ComfyUI).</p><p>This is good for inference (again, especially with styles) even if I made it mainly for training. It ended up being super good for generating pics and it's now my go-to anime model. It also eats very little vram.</p><p>Get the pruned versions for training, as they consume less VRAM. </p><p>Make sure you use CLIP skip 2 and booru style tags when training.</p><p>Remember to use a good vae when generating, or images wil look desaturated. Or just use the baked vae versions.</p><h2 id=\"heading-234\"></h2><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581305+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "300005",
    "prompt": "Incase Style [PonyXL]\n<p>Version Guide:</p><p>V1: Weakest style, but high compatibility, struggles with details at lower resolutions.</p><p>V2: Recommended for beginners - Good style, good compatibility, hard to mess up.</p><p>V3: Best style/colors, maybe reduced compatibility with some other loras.</p><p>Top tag counts:</p><pre><code>penis                153  (81%)\nfemale               144  (76%)\nbreasts              117  (62%)\nmale                 107  (56%)\ncum                  102  (54%)\nerection             96  (51%)\nnipples              91  (48%)\noral                 83  (44%)\n1girl                82  (43%)\nfellatio             75  (39%)\nstraight             72  (38%)\nareolae              64  (34%)\nsex                  60  (32%)\nballs                55  (29%)\ncum inside           55  (29%)\nnude                 54  (28%)\nlarge breasts        54  (28%)\nlipstick             54  (28%)\nlight-skinned male   53  (28%)\ncum in mouth         50  (26%)\nfutanari             49  (26%)\nhuman                48  (25%)\nblue eyes            46  (24%)\ndark skin            44  (23%)\npussy                41  (22%)\nblush                41  (22%)\npubic hair           41  (22%)\nopen mouth           40  (21%)\n1boy                 39  (21%)\nblack hair           38  (20%)\nsaliva               37  (19%)\nbig breasts          36  (19%)\npenetration          36  (19%)\ncum on face          36  (19%)\noriginal             35  (18%)\ntongue out           35  (18%)\nlight skin           33  (17%)\nlong hair            33  (17%)\nclothing             32  (17%)\nhandjob              31  (16%)\nfreckles             31  (16%)\npointy ears          31  (16%)\ntongue               31  (16%)\nglasses              30  (16%)\nthighhighs           30  (16%)\nintersex             30  (16%)\nvaginal penetration  30  (16%)\ncum on breasts       30  (16%)\ntesticles            30  (16%)\n2boys                29  (15%)\nblonde hair          29  (15%)\n1futa                28  (15%)\ntext                 27  (14%)\nspread legs          27  (14%)\nlight-skinned female 27  (14%)\nfacial               27  (14%)\ninterracial          26  (14%)\nred hair             26  (14%)\npiercing             26  (14%)\nanal                 26  (14%)\ndark-skinned male    26  (14%)\nfuta on female       25  (13%)\nearrings             25  (13%)\ngloves               25  (13%)\norange hair          25  (13%)\nmakeup               25  (13%)\nclothed              24  (13%)\nass                  23  (12%)\ncleavage             23  (12%)\ndickgirl             22  (12%)\n2girls               22  (12%)\nnipple piercing      22  (12%)\nanal sex             22  (12%)\nfemboy               22  (12%)\nlipstick on penis    22  (12%)\nhumanoid             22  (12%)\nhair                 22  (12%)\nlarge penis          21  (11%)\nbig penis            21  (11%)\nfemale focus         20  (11%)\nkneeling             20  (11%)\nelf                  19  (10%)\ndemon                19  (10%)\nmilf                 19  (10%)</code></pre>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581311+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "147759",
    "prompt": "Remacri\n<p>This upscaler is not mine, all the credit goes to: <a target=\"_blank\" rel=\"ugc\" href=\"https://openmodeldb.info/users/foolhardy\"><strong>FoolhardyVEVO</strong></a></p><p>Official WIKI page: <a target=\"_blank\" rel=\"ugc\" href=\"https://openmodeldb.info/models/4x-Remacri\"><strong>openmodeldb</strong></a></p><p>License of use it: <a target=\"_blank\" rel=\"ugc\" href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\"><strong>CC-BY-NC-SA-4.0</strong></a></p><p></p><p><strong>HOW TO INSTALL:</strong></p><p>Copy the file <code>4x_foolhardy_Remacri.safetensors</code> inside the folder: <code>stable-diffusion/models/ESRGAN</code> <span style=\"background-color:rgb(26, 27, 30);color:rgb(193, 194, 197);font-family:-apple-system, system-ui, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;;font-size:16px\">orÂ </span><code>ComfyUI/models/upscale_models</code></p><p>Restart/Reload you Stable Diffusion instance</p><p>The upscaler should be visible for hi-res and extras tabs</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581315+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "10415",
    "prompt": "å›½é£3 GuoFeng3\n<p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0f6b6abd-75c6-4a33-be22-2497f0efc937/width=525/0f6b6abd-75c6-4a33-be22-2497f0efc937.jpeg\" /></p><h3 id=\"ai\"><strong><u><span style=\"color:rgb(134, 142, 150)\">æœ¬äººéƒ‘é‡å£°æ˜ï¼šæœ¬æ¨¡å‹ç¦æ­¢ç”¨äºè®­ç»ƒåŸºäºæ˜æ˜Ÿã€å…¬ä¼—äººç‰©è‚–åƒçš„é£æ ¼æ¨¡å‹è®­ç»ƒï¼Œå› ä¸ºè¿™ä¼šå¸¦æ¥äº‰è®®ï¼Œå¯¹AIç¤¾åŒºçš„å‘å±•é€ æˆä¸è‰¯çš„è´Ÿé¢å½±å“ã€‚</span></u></strong></h3><h3 id=\"heading-31\"><strong><u><span style=\"color:rgb(134, 142, 150)\">æœ¬æ¨¡å‹æ³¨æ˜ï¼šè®­ç»ƒç´ æä¸­ä¸åŒ…å«ä»»ä½•çœŸäººç´ æã€‚</span></u></strong></h3><p></p><p><span style=\"color:rgb(130, 201, 30)\">å›½é£åå†™å®ç‰ˆæœ¬æ¨è-Recommended Realistic Version of National Styleï¼š</span><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/77650/guofengrealmix\">https://civitai.com/models/77650/guofengrealmix</a></p><p><span style=\"color:rgb(250, 82, 82)\">åŸºäºSDXL1.0è®­ç»ƒçš„å›½é£4-National Style 4 Based on SDXL1.0 Training:</span><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/118009/4-guofeng4\"><span style=\"color:rgb(250, 82, 82)\">https://civitai.com/models/118009/4-guofeng4</span></a></p><p></p><p><strong>ä¸€äº›ç­”ç–‘</strong></p><p><strong><span style=\"color:rgb(193, 194, 197)\">TIPï¼šå›½é£2æˆ–å›½é£3ä»¥åŠå¤§ç‰ˆæœ¬ä¸‹çš„å°ç‰ˆæœ¬ï¼Œéƒ½æ˜¯ç‹¬ç«‹å­˜åœ¨ï¼Œä¸åŒç‰ˆæœ¬çš„ç”»é£ï¼Œå…³é”®è¯ï¼Œå¯¹åº”å†…å®¹éƒ½ä¼šæœ‰ç›¸åº”åŒºåˆ«ï¼Œå»ºè®®ä¸‹è½½æ—¶å¯ä»¥æ ¹æ®æ•ˆæœå›¾æˆ–è€…æ¨¡å‹çš„ç‹¬ç«‹ä»‹ç»å»ä¸‹è½½ã€‚</span></strong></p><p><strong><span style=\"color:rgb(193, 194, 197)\">TIP2ï¼šå›½é£2ä»£ä¸3ä»£çš„åŒºåˆ«ï¼šæˆ‘å¯¹å¤§ç‰ˆæœ¬çš„åˆ’åˆ†æ˜¯è®­ç»ƒè´¨é‡ä¸åŒ(æ¯”å¦‚ç´ æåˆ†è¾¨ç‡ï¼Œè®­ç»ƒè®¾ç½®æ‰€æ¶ˆè€—çš„æ˜¾å­˜é‡ï¼Œæœ‰æ—¶å€™ä¹Ÿä¼šå’Œç´ æé‡æœ‰å…³)ã€‚</span></strong></p><p></p><p>===========</p><p></p><h2 id=\"update-history\"><strong><span style=\"color:rgb(230, 73, 128)\">æ›´æ–°å†å² - Update History</span></strong></h2><p></p><p><span style=\"color:rgb(134, 142, 150)\">2023.6.29 å¢åŠ äº†v3.4ç‰ˆæœ¬</span></p><p><span style=\"color:rgb(134, 142, 150)\">2023.4.05 å¢åŠ äº†v3.3ç‰ˆæœ¬</span></p><p><span style=\"color:rgb(134, 142, 150)\">2023.3.02 å¢åŠ äº†v3.2_lightç‰ˆæœ¬</span></p><p><span style=\"color:rgb(134, 142, 150)\">2023.2.27 å¢åŠ äº†safetensorsæ ¼å¼</span></p><p><span style=\"color:rgb(134, 142, 150)\">-</span></p><p><span style=\"color:rgb(134, 142, 150)\">2023.6.29 added v3.4 version</span></p><p><span style=\"color:rgb(134, 142, 150)\">2023.4.05 added v3.3 version</span></p><p><span style=\"color:rgb(134, 142, 150)\">2023.3.02 added v3.2_Light version</span></p><p><span style=\"color:rgb(134, 142, 150)\">2023.2.27 added safetensors format</span></p><p></p><p>===========</p><p></p><h2 id=\"model-introduction\"><strong><span style=\"color:rgb(230, 73, 128)\">æ¨¡å‹ä»‹ç» - Model Introduction</span></strong></h2><p></p><p><span style=\"color:rgb(250, 82, 82)\">æ¬¢è¿ä½¿ç”¨GuoFeng3æ¨¡å‹ - è¿™æ˜¯ä¸€ä¸ªä¸­å›½åä¸½å¤é£é£æ ¼æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥è¯´æ˜¯ä¸€ä¸ªå¤é£æ¸¸æˆè§’è‰²æ¨¡å‹ï¼Œå…·æœ‰2.5Dçš„è´¨æ„Ÿã€‚</span></p><p><span style=\"color:rgb(253, 126, 20)\">GuoFeng3:åŸå§‹æ¨¡å‹</span></p><p><span style=\"color:rgb(253, 126, 20)\">GuoFeng3.1:å¯¹GuoFeng3äººåƒè¿›è¡Œäº†å¾®è°ƒä¿®å¤</span></p><p><span style=\"color:rgb(253, 126, 20)\">GuoFeng3.2:å¦‚æœä½ ä¸çŸ¥é“é€‰æ‹©GuoFeng3è¿˜æ˜¯GuoFeng2ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨æ­¤ç‰ˆæœ¬</span></p><p><span style=\"color:rgb(253, 126, 20)\">GuoFeng3.2_light:é€šè¿‡GuoFeng3.2èåˆäº†åŸºäº Noise Offset è®­ç»ƒçš„Loraä½¿å¾—æ¨¡å‹èƒ½å¤Ÿç”»å‡ºæ›´æ¼‚äº®çš„å…‰å½±æ•ˆæœ(Lora:epi_noiseoffset/Theovercomer8's Contrast Fix)</span></p><p><span style=\"color:rgb(253, 126, 20)\">GuoFeng3.3:æ­¤ç‰ˆæœ¬æ˜¯åŸºäº3.2çš„ä¸€æ¬¡è¾ƒå¤§çš„æ›´æ–°ä¸æ”¹è¿›ï¼Œå¯ä»¥é€‚é…full bodyï¼Œå³ä½¿ä½ çš„tagä¸å¤ªå¥½ï¼Œæ¨¡å‹ä¹Ÿä¼šå¯¹ç”»é¢è¿›è¡Œè‡ªåŠ¨ä¿®æ”¹ï¼Œä¸è¿‡å› æ­¤æ¨¡å‹å‡ºçš„è„¸ä¼šæ¯”è¾ƒé›·åŒã€‚</span></p><p><span style=\"color:rgb(253, 126, 20)\">GuoFeng3.4:æ­¤ç‰ˆæœ¬é‡æ–°è¿›è¡Œäº†æ–°çš„è®­ç»ƒï¼Œé€‚é…å…¨èº«å›¾ï¼ŒåŒæ—¶å†…å®¹ä¸Šä¸å‰å‡ ä¸ªç‰ˆæœ¬æœ‰è¾ƒå¤§ä¸åŒã€‚å¹¶è°ƒæ•´äº†æ•´ä½“ç”»é£ï¼Œé™ä½äº†è¿‡æ‹Ÿåˆç¨‹åº¦ï¼Œä½¿å…¶èƒ½ä½¿ç”¨æ›´å¤šçš„loraå¯¹ç”»é¢ä¸å†…å®¹è¿›è¡Œè°ƒæ•´ã€‚</span></p><p>å…¶å®ƒä¸ªäººæ¨¡å‹ï¼š</p><p>åŒæ¬¾æ¨¡å‹ç”»é£çš„Loraç‰ˆæœ¬ï¼š<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/11352/guofeng3lora\">https://civitai.com/models/11352/guofeng3lora</a></p><p>è¥¿å¹»æ¨¡å‹ï¼š<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/10818/westmagic\">https://civitai.com/models/10818/westmagic</a></p><p>-</p><p><span style=\"color:rgb(34, 139, 230)\">Welcome to GuoFeng3 model - This is a Chinese gorgeous antique style model, which can also be said to be an antique game role model with a 2.5D texture.</span></p><p><span style=\"color:rgb(250, 176, 5)\">GuoFeng3: original model</span></p><p><span style=\"color:rgb(250, 176, 5)\">GuoFeng3.1: The portrait of GuoFeng3 has been fine-tuned and repaired</span></p><p><span style=\"color:rgb(250, 176, 5)\">GuoFeng3.2: If you don't know whether to choose GuoFeng3 or GuoFeng2, you can use this version directly</span></p><p><span style=\"color:rgb(250, 176, 5)\">GuoFeng3.2_Light: Through GuoFeng3.2, Lora based on Noise Offset training is integrated to enable the model to draw more beautiful light and shadow effects (Lora: epi_noiseoffset/Theovercolor8's Contrast Fix)</span></p><p><span style=\"color:rgb(250, 176, 5)\">GuoFeng3.3:This version is a major update and improvement based on 3.2, which can adapt to full bodies. Even if your tag is not very good, the model will automatically modify the screen, but therefore the faces produced by the model will be quite similar.</span></p><p><span style=\"color:rgb(250, 176, 5)\">GuoFeng3.4: This version has undergone new training to adapt to the full body image, and the content is significantly different from previous versions.At the same time, the overall painting style has been adjusted, reducing the degree of overfitting, allowing it to use more Lora to adjust the screen and content.</span></p><p>Lora version of the same model painting style:<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/11352/guofeng3lora\">https://civitai.com/models/11352/guofeng3lora</a></p><p>Western fantasy model:<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/10818/westmagic\">https://civitai.com/models/10818/westmagic</a></p><p></p><p>===========</p><p></p><h2 id=\"3lora-guofeng3dlclora\"><strong><span style=\"color:rgb(230, 73, 128)\">å›½é£3å¯é€‰Lora - GuoFeng3DLC(Lora)</span></strong></h2><p></p><p>1.æ¢¦ Dream (<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/44310/dream-based-on-guofeng3\">https://civitai.com/models/44310/dream-based-on-guofeng3</a>)</p><p>2.æ­¦å¢¨ WuMo (<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/47728/wumo\">https://civitai.com/models/47728/wumo</a>)</p><p></p><p>===========</p><p></p><h2 id=\"recommended-settings\"><strong><span style=\"color:rgb(230, 73, 128)\">å»ºè®®çš„è®¾ç½® - Recommended settings</span></strong></h2><p></p><p>Sampling steps:<strong>30 or 50</strong></p><p>Sampler:<strong>DPM++ SDE Karras</strong></p><p>VAE<strong>:vae-ft-mse-840000 </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\">stabilityai/sd-vae-ft-mse-original at main (</a><a target=\"_blank\" rel=\"ugc\" href=\"http://huggingface.co\">huggingface.co</a>)</p><p>======</p><p><span style=\"color:rgb(250, 82, 82)\">å¦‚æœä½ çš„å‡ºå›¾å…¨èº«å›¾æ—¶å‡ºç°è„¸éƒ¨å´©åå»ºè®®åˆ é™¤full bodyå…³é”®è¯æˆ–è€…ä½¿ç”¨è„¸éƒ¨è‡ªåŠ¨ä¿®å¤æ’ä»¶ï¼š</span></p><p><span style=\"color:rgb(250, 82, 82)\">å›½å¤–æºåœ°å€ï¼š</span><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/ototadana/sd-face-editor.git\">https://github.com/ototadana/sd-face-editor.git</a></p><p><span style=\"color:rgb(250, 82, 82)\">å›½å†…åŠ é€Ÿåœ°å€ï¼š</span><a target=\"_blank\" rel=\"ugc\" href=\"https://jihulab.com/xiaolxl_pub/sd-face-editor.git\">https://jihulab.com/xiaolxl_pub/sd-face-editor.git</a></p><p>-</p><p><span style=\"color:rgb(34, 139, 230)\">If you experience facial collapse during the full body image, it is recommended to delete the full body keyword or use the facial automatic repair plugin:</span></p><p><span style=\"color:rgb(34, 139, 230)\">Foreign source address:</span><span style=\"color:rgb(76, 110, 245)\"> </span><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/ototadana/sd-face-editor.git\">https://github.com/ototadana/sd-face-editor.git</a></p><p><span style=\"color:rgb(34, 139, 230)\">Domestic acceleration address: </span><a target=\"_blank\" rel=\"ugc\" href=\"https://jihulab.com/xiaolxl_pub/sd-face-editor.git\">https://jihulab.com/xiaolxl_pub/sd-face-editor.git</a></p><p>=====</p><p>å…³é”®è¯ - key word:</p><pre><code>best quality, masterpiece, highres, 1girl,china dress,Beautiful face</code></pre><p>è´Ÿé¢è¯ - Negative words:</p><pre><code>NSFW, lowres,bad anatomy,bad hands, text, error, missing fingers,extra digit, fewer digits, cropped, worstquality, low quality, normal quality,jpegartifacts,signature, watermark, username,blurry,bad feet</code></pre><p>æ›´å¥½çš„è´Ÿé¢è¯ - Better negative words:</p><pre><code>(((simple background))),monochrome ,lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, lowres, bad anatomy, bad hands, text, error, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, ugly,pregnant,vore,duplicate,morbid,mut ilated,tran nsexual, hermaphrodite,long neck,mutated hands,poorly drawn hands,poorly drawn face,mutation,deformed,blurry,bad anatomy,bad proportions,malformed limbs,extra limbs,cloned face,disfigured,gross proportions, (((missing arms))),(((missing legs))), (((extra arms))),(((extra legs))),pubic hair, plump,bad legs,error legs,username,blurry,bad feet</code></pre><p>å¦‚æœæƒ³å…ƒç´ æ›´ä¸°å¯Œï¼Œå¯ä»¥æ·»åŠ ä¸‹æ–¹å…³é”®è¯ - If you want to enrich the elements, you can add the following keywords</p><pre><code>Beautiful face,\nhair ornament, solo,looking at viewer,smile,closed mouth,lips\nchina dress,dress,hair ornament, necklace, jewelry, long hair, earrings, chinese clothes,\narchitecture,east asian architecture,building,outdoors,rooftop,city,cityscape</code></pre>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581330+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "30240",
    "prompt": "ToonYou\n<h1 id=\"toonyou-beta-3-is-up\">ToonYou - Beta 6 is up!</h1><p>Silly, stylish, and.. kind of cute? ğŸ˜…</p><p>A bit of detail with a cartoony feel, it keeps getting better!</p><p>With your support, ToonYou has come this far, Thx!</p><h3 id=\"heading-18\">â¬‡Please read the information belowğŸ™</h3><h3 id=\"heading-3326\">1ï¸âƒ£Recommended Settings</h3><pre><code>- VAE is included starting with Alpha2 (840000)\n- Clip skip: 2\n- CFG scale: 8</code></pre><pre><code>- Sampler: DPM++ SDE Karras\n    Sampling Steps : 30+</code></pre><pre><code>- Upscaler (Hires. fix): R-ESRGAN 4x+ Anime6B\n    Hires steps: 14\n    Denoising strength: 0.35\n    Upscale by: 1.5+</code></pre><pre><code>- Default prompts  \n    Pos: (best quality, masterpiece), ... \n    Neg: (worst quality, low quality, letterboxed), ...</code></pre><h3 id=\"heading-3327\">2ï¸âƒ£Using <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\">Adetailer</a></h3><pre><code>- Main UI &gt; Extensions &gt; Install from URL\n    This fixes problems with the character's eyes and face in most situations\n    The default usage is to simply enable it and leave it alone</code></pre><h3 id=\"heading-3328\">âœ…Now you're good to go!</h3><p>For more information, please continue below</p><p></p><h3 id=\"heading-3329\">â„¹ï¸Why is my image different from yours?</h3><ul><li><p><strong>I can't give you any technical help, sorry</strong></p></li><li><p>Keep your prompts <strong>simple and correct</strong></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/DominikDoom/a1111-sd-webui-tagcomplete\"><strong>Tag auto complete extension</strong> </a>to find the appropriate tags</p></li><li><p>Tags like 'Realistic, 8k, ...' sometimes ruin an image</p><ul><li><p>Also These tags are often more useless than you might think</p></li><li><p>Neg Tags like 'mutated arms' are useless than you might think</p></li></ul></li><li><p><strong>Neg embedding</strong> can have a <strong>significant impact</strong> on the characteristics of a model</p><ul><li><p>These are not as perfect as you might think</p></li></ul></li></ul></li></ul><p></p><h3 id=\"heading-2458\">ğŸ’Contact &amp; Support</h3><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"mailto:ux.arihan@gmail.com\"><strong>ux.arihan@gmail.com</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/bradcatt\"><strong>A cup of coffee would be nice! ğŸ˜‰</strong></a></p></li></ul><p></p><h3 id=\"heading-3330\">âš ï¸Warning</h3><ul><li><p><strong>You are solely responsible for any legal liability resulting from unethical use of this model</strong></p></li></ul><ul><li><p><strong>Don't use my model as bait to drive people to your paid generation service without permission</strong></p></li><li><p><strong>For anything other than general personal use, please be sure to contact me</strong></p></li></ul>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581340+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "404154",
    "prompt": "WAI-ANI-NSFW-PONYXL\n<p>If you want to use more my checkpoint online generation, please visit here.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/u/762555264535746522\">https://tensor.art/u/762555264535746522</a></p><p></p><p></p><p><span style=\"color:rgb(193, 194, 197)\">You can run WAI-ANI-NSFW-PONYXL and use its API on SinkIn:</span></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/2zgReX9\"><span style=\"color:rgb(34, 139, 230)\">https://sinkin.ai/m/2zgReX9</span></a></p><p></p><hr /><h1 id=\"v14-released.-0dd7br8zl\"><span style=\"color:rgb(250, 82, 82)\">V14 released.</span></h1><p></p><p><strong><span style=\"color:#fab005\">Increased composition diversity and improved model accuracy now allow images to be generated with fewer steps.</span></strong></p><p></p><p></p><h2 id=\"recommended-setting-kqfs7j4n7\"><span style=\"color:rgb(64, 192, 87)\">Recommended Setting</span></h2><h3 id=\"steps:20-30-a2841j4w3\"><span style=\"color:rgb(250, 82, 82)\">Steps:20-30</span></h3><h3 id=\"cfg-scale:-5-7-hge3gwra1\"><span style=\"color:rgb(250, 82, 82)\">CFG scale: 5-7</span></h3><h3 id=\"sampler:-euler-adpm++-2m-karras-7gc2n7sm9\"><span style=\"color:rgb(250, 82, 82)\">Sampler: Euler a/DPM++ 2M Karras</span></h3><h3 id=\"adetailer-face_yolov8ns.pt-use-can-fix-eyes-9wc2h6jcw\"><strong><span style=\"color:rgb(250, 82, 82)\">ADetailer face_yolov8n/s.pt use can fix eyes</span></strong></h3><p></p><h3 id=\"for-the-example-images-qds2h65da\"><strong><span style=\"color:rgb(250, 176, 5)\">For the example images</span></strong></h3><p><span style=\"color:rgb(250, 176, 5)\">I used 1024x1360,</span></p><p><span style=\"color:rgb(250, 176, 5)\">generated directly without AD or hires fix.</span></p><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>worst quality,bad quality,jpeg artifacts, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark,</code></pre><p></p><p></p><hr /><h1 id=\"v13-released.-poprjihzr\"><span style=\"color:rgb(250, 82, 82)\">V13 released.</span></h1><p></p><ul><li><p><strong><span style=\"color:rgb(250, 176, 5)\">Increased body stability and accuracy.</span></strong></p></li><li><p><strong><span style=\"color:rgb(250, 176, 5)\">overall balance adjustment.</span></strong></p></li></ul><p></p><p></p><h2 id=\"recommended-setting-u0qh3zebz\"><span style=\"color:rgb(64, 192, 87)\">Recommended Setting</span></h2><h3 id=\"steps:-30-wv1nst4jf\"><span style=\"color:rgb(250, 82, 82)\">Steps: 30</span></h3><h3 id=\"cfg-scale:-7-ait3luw3w\"><span style=\"color:rgb(250, 82, 82)\">CFG scale: 7</span></h3><h3 id=\"sampler:-euler-adpm++-2m-karras-o6o23533p\"><span style=\"color:rgb(250, 82, 82)\">Sampler: Euler a/DPM++ 2M Karras</span></h3><h3 id=\"adetailer-face_yolov8ns.pt-use-can-fix-eyes-g62djd3n6\"><strong><span style=\"color:rgb(250, 82, 82)\">ADetailer face_yolov8n/s.pt use can fix eyes</span></strong></h3><p></p><h3 id=\"for-the-example-images-ai92tf9rz\"><strong><span style=\"color:rgb(250, 176, 5)\">For the example images</span></strong></h3><p><span style=\"color:rgb(250, 176, 5)\">I used 1024x1360,</span></p><p><span style=\"color:rgb(250, 176, 5)\">generated directly without AD or hires fix.</span></p><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>worst quality,bad quality,jpeg artifacts, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark,</code></pre><p></p><p></p><hr /><h1 id=\"v12-released.-rf2308ahd\"><span style=\"color:rgb(250, 82, 82)\">V12 released.</span></h1><p></p><ul><li><p><span style=\"color:rgb(250, 176, 5)\">Style adjustment, background adjustment, and increased stability.</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Added more compositions.</span></p></li></ul><p></p><p></p><h2 id=\"recommended-setting-vor7cury3\"><span style=\"color:rgb(64, 192, 87)\">Recommended Setting</span></h2><h3 id=\"steps:-30-forgzmpw8\"><span style=\"color:rgb(250, 82, 82)\">Steps: 30</span></h3><h3 id=\"cfg-scale:-7-lvvc2hvsl\"><span style=\"color:rgb(250, 82, 82)\">CFG scale: 7</span></h3><h3 id=\"sampler:-euler-adpm++-2m-karras-82o2n084x\"><span style=\"color:rgb(250, 82, 82)\">Sampler: Euler a/DPM++ 2M Karras</span></h3><h3 id=\"adetailer-face_yolov8ns.pt-use-can-fix-eyes-ptr9gwc6h\"><strong><span style=\"color:rgb(250, 82, 82)\">ADetailer face_yolov8n/s.pt use can fix eyes</span></strong></h3><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>score_6, score_5, score_4, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark,</code></pre><p></p><p></p><hr /><h1 id=\"v11-dmmzd6ilc\">v11</h1><h3 id=\"-r28kaeyl4\"></h3><h3 id=\"weight-adjustment-balancing-the-art-style-mdijozia6\"><strong><span style=\"color:rgb(190, 75, 219)\">Weight adjustment, balancing the art style</span></strong></h3><p></p><p><strong><span style=\"color:rgb(250, 176, 5)\">All example images(Except the cover) are generated at 1024x1360, without using AD and hires fix.</span></strong></p><p></p><h2 id=\"recommended-setting-0yvhg3h0r\"><span style=\"color:rgb(64, 192, 87)\">Recommended Setting</span></h2><p><strong><span style=\"color:rgb(250, 82, 82)\">Steps: 30</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">CFG scale: 7</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">Sampler: Euler a/DPM++ 2M Karras</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">ADetailer face_yolov8n/s.pt use can fix eyes</span></strong></p><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>worst quality,bad quality,jpeg artifacts, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark, </code></pre><hr /><p></p><p></p><h1 id=\"v10-2bajuxpz1\"><span style=\"color:rgb(250, 82, 82)\">V10</span></h1><ul><li><p><span style=\"color:rgb(250, 176, 5)\">Better Background</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Clothes details up</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Better mature female</span></p><p></p></li></ul><p></p><h2 id=\"recommended-setting-m1vaq9cng\"><span style=\"color:rgb(64, 192, 87)\">Recommended Setting</span></h2><p><strong><span style=\"color:rgb(250, 82, 82)\">Steps: 30</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">CFG scale: 7</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">Sampler: Euler a/DPM++ 2M Karras</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">ADetailer face_yolov8n/s.pt use can fix eyes</span></strong></p><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>worst quality,bad quality,jpeg artifacts, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark, </code></pre><p></p><p>++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</p><h2 id=\"v9-hyper12step-0k6r0qsl6\"><span style=\"color:rgb(64, 192, 87)\">V9 Hyper12step</span></h2><h3 id=\"please-refer-to-the-instructions-on-the-right-side-of-v9-hyper12step-for-usage.-9qp2vzfbk\"><span style=\"color:rgb(250, 176, 5)\">Please refer to the instructions on the right side of V9 Hyper12step for usage.</span></h3><h1 id=\"v9-released.-2m4qfkrww\"><span style=\"color:rgb(250, 82, 82)\">V9 released.</span></h1><h3 id=\"v8-greaterv9-vo47a7xib\"><span style=\"color:rgb(250, 176, 5)\">v8-&gt;v9</span></h3><ul><li><p>adjusted the facial data to make it more versatile, allowing for easier generation of faces across various ages.</p></li><li><p>added more NSFW materials.</p></li><li><p>attempted to reduce the generation of some unnecessary details.</p></li></ul><p></p><h2 id=\"-5iwvq1ujq\"></h2><h2 id=\"recommended-setting-vp04o1mlv\"><span style=\"color:rgb(64, 192, 87)\">Recommended Setting</span></h2><p><strong><span style=\"color:rgb(250, 82, 82)\">Steps: 30</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">CFG scale: 7</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">Sampler: Euler a/DPM++ 2M Karras</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">ADetailer face_yolov8n/s.pt use can fix eyes</span></strong></p><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>worst quality,bad quality,jpeg artifacts, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark, </code></pre><p></p><p></p><p>__________________________________________________________________________________________________</p><p></p><p></p><p></p><h3 id=\"hyper12step-released.-5lioxxzfd\"><span style=\"color:rgb(250, 176, 5)\">hyper12step released.</span></h3><p><span style=\"color:rgb(250, 176, 5)\">about size</span></p><p><span style=\"color:rgb(250, 176, 5)\">Various combinations from 768x768 to 1360x1360 can produce good images.</span></p><p><span style=\"color:rgb(64, 192, 87)\">Recommended Setting</span></p><p><span style=\"color:rgb(250, 82, 82)\">Steps: </span><span style=\"color:rgb(250, 176, 5)\">12</span></p><p><span style=\"color:rgb(250, 82, 82)\">CFG scale: </span><span style=\"color:rgb(250, 176, 5)\">3.5</span></p><p><span style=\"color:rgb(250, 82, 82)\">Sampler: Euler a</span></p><p><span style=\"color:rgb(250, 82, 82)\">Not very necessary to use ADetailer correction</span></p><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>score_6, score_5, score_4, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark,</code></pre><p></p><h3 id=\"ps.the-example-images-use-a-size-of-896x1192.-no-ad-no-hires.-fix-soqzlyiuy\"><strong><span style=\"color:rgb(250, 82, 82)\">PS.The example images use a size of 896x1192. no AD no Hires. fix</span></strong></h3><p>__________________________________________________________________________________________________</p><h3 id=\"version-8-released.-cdrr4xcso\"><span style=\"color:rgb(250, 176, 5)\">Version 8 released.</span></h3><p><span style=\"color:rgb(250, 176, 5)\">v7-&gt;v8</span></p><ul><li><p><span style=\"color:rgb(250, 176, 5)\">Added some training related to camera angles and backgrounds.</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Added more NSFW materials for additional training.</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Added some training for special effects.</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Optimization of overall composition logic.</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Fixed some minor issues.</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">better eyes and hands.</span></p></li></ul><p></p><h3 id=\"recommended-setting-h3xiwnufc\"><span style=\"color:rgb(230, 73, 128)\">Recommended Setting</span></h3><h1 id=\"same-as-v7-9x5tr5gm8\"><span style=\"color:rgb(250, 176, 5)\">Same as v7</span></h1><p></p><p></p><p>__________________________________________________________________________________________________</p><p></p><h3 id=\"version-7-9yvvvzl0o\"><span style=\"color:rgb(121, 80, 242)\">Version 7</span></h3><p><span style=\"color:rgb(121, 80, 242)\">v6-&gt;v7</span></p><ul><li><p><span style=\"color:rgb(121, 80, 242)\">Fixed the issue where images appeared entirely covered with snowflakes.</span></p></li><li><p><span style=\"color:rgb(121, 80, 242)\">Revised the composition logic to be more suitable for general scenarios.</span></p></li><li><p><span style=\"color:rgb(121, 80, 242)\">Added new assets for backgrounds, mature women, and clothing.</span></p></li><li><p><span style=\"color:rgb(121, 80, 242)\">Ensured consistency with the previous model and further fixed the issue of blurry eyes in medium and long shots.</span></p></li><li><p><span style=\"color:rgb(121, 80, 242)\">Fixed some minor issues.</span></p></li></ul><p></p><h1 id=\"v7-recommended-setting-x2ap9wrt8\"><span style=\"color:rgb(64, 192, 87)\">V7 Recommended Setting</span></h1><h3 id=\"steps:-30-k55h036h4\"><span style=\"color:rgb(250, 82, 82)\">Steps: 30</span></h3><h3 id=\"cfg-scale:-7-1aw715qhk\"><span style=\"color:rgb(250, 82, 82)\">CFG scale: 7</span></h3><h3 id=\"sampler:-euler-adpm++-2m-karras-xt48l5suu\"><span style=\"color:rgb(250, 82, 82)\">Sampler: Euler a/DPM++ 2M Karras</span></h3><h3 id=\"adetailer-face_yolov8ns.pt-use-can-fix-eyes-4ej2ph4rr\"><strong><span style=\"color:rgb(250, 82, 82)\">ADetailer face_yolov8n/s.pt use can fix eyes</span></strong></h3><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>score_6, score_5, score_4, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark,</code></pre><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p>________________________________________________________________________________________________</p><p><span style=\"color:rgb(250, 82, 82)\">Regarding the 8step model, it is a lightweight model that can generate images in as few as 8 steps. However, the quality and text comprehension will be relatively lower. If speed is not a major concern for you, it is recommended to continue using version 6.0.</span></p><p></p><h3 id=\"8-step-setting-qw3s638uu\"><span style=\"color:rgb(230, 73, 128)\">8 STEP Setting</span></h3><p>Steps: 8-12</p><p>CFG scale: 3</p><p>Sampler: Euler a</p><p><strong>ADetailer face_yolov8n/s.pt use can fix eyes</strong></p><p>Positive Prompt and Negative Prompt same 6.0</p><p>__________________________________________________________________________________________________</p><h3 id=\"6.0-t5dizlz1j\"><span style=\"color:rgb(34, 139, 230)\">6.0</span></h3><h3 id=\"v5-greaterv6-change-point-pemeolnrq\"><span style=\"color:rgb(34, 139, 230)\">v5-&gt;v6 Change point</span></h3><ul><li><p><span style=\"color:rgb(34, 139, 230)\">Better Background</span></p></li><li><p><span style=\"color:rgb(34, 139, 230)\">better eyes</span></p></li><li><p><span style=\"color:rgb(34, 139, 230)\">fix vae</span></p></li></ul><p></p><h1 id=\"recommended-setting-yqn47j4s2\"><span style=\"color:rgb(64, 192, 87)\">Recommended Setting</span></h1><h3 id=\"steps:-30-vj1c8s575\">Steps: 30</h3><h3 id=\"cfg-scale:-7-7rxotcvfk\">CFG scale: 7</h3><h3 id=\"sampler:-euler-adpm++-2m-karras(better-eyes)-pu6yrkipe\">Sampler: Euler a/<span style=\"color:rgb(250, 82, 82)\">DPM++ 2M Karras(better eyes)</span></h3><h3 id=\"adetailer-face_yolov8ns.pt-use-can-fix-eyes-39l0e6jub\"><strong>ADetailer face_yolov8n/s.pt use can fix eyes</strong></h3><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,BREAK</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>score_6, score_5, score_4, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark,</code></pre><p></p><p></p><h3 id=\"you-can-view-the-supported-art-styles-from-https:civitai.comarticles5715-vbflweqoa\"><span style=\"color:rgb(250, 82, 82)\">You can view the Supported art styles from </span><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/5715\"><span style=\"color:rgb(34, 139, 230)\">https://civitai.com/articles/5715</span></a></h3><h3 id=\"thank-you-deepdark_fantasy514-for-providing-the-test.-1wfpzltwt\"><span style=\"color:rgb(250, 82, 82)\">Thank you, DeepDark_Fantasy514, for providing the test.</span></h3><h3 id=\"-y8h3kh9k3\"></h3><p></p><p><span style=\"color:rgb(250, 176, 5)\">v4-&gt;v5 Change point</span></p><ul><li><p><span style=\"color:rgb(250, 176, 5)\">Better Background</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Clothes details up</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Add some mature female</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Little better hands and eyes</span></p><p></p><p></p></li></ul><p>Recommended Setting</p><ul><li><p>Steps: 30</p></li><li><p>CFG scale: 7</p></li><li><p>Sampler: Euler a</p></li><li><p><strong>ADetailer face_yolov8n/s.pt use can fix eyes</strong></p></li></ul><p></p><p>Positive Prompt</p><pre><code>score_9, score_8_up, score_7_up,</code></pre><p>Negative Prompt (<strong>THX for <span style=\"color:rgb(193, 194, 197)\">snipsnapsnipsnap recommend </span></strong>)</p><ul><li><p>Base:score_6, score_5, score_4, source_cartoon</p></li><li><p>Optional: source_furry, source_pony <strong><span style=\"color:rgb(250, 82, 82)\">can bleaches skin</span></strong></p></li><li><p>else: 3d, (censor),monochrome,blurry, lowres,watermark,</p></li></ul><p>I often use it now</p><p>[score_6, score_5, score_4, source_cartoon,</p><p>3d, (censor),monochrome,blurry, lowres,watermark, ]</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581352+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "14171",
    "prompt": "Cute_girl_mix4\n<p>work with Chilloutmix, can generate natural, cute, girls.</p><p>Mix from chinese tiktok influencers, not any specific real person.</p><p></p><p>The third example used my other lora <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/15271\"><strong>20D.</strong></a></p><p></p><p>&lt;lora:cuteGirlMix4_v10:<strong>(<u>recommend0.4-0.7 here)</u></strong>&gt;,</p><p><strong>Trigger Word is '<u>mix4</u>' .</strong></p><p></p><p><strong>hope to receive your works!!!</strong></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581355+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "16993",
    "prompt": "badhandv4\n<h1 id=\"heading-1238\"><strong>ä»‹ç»ï¼ˆChinese Versionï¼‰</strong></h1><h2 id=\"heading-1239\"><strong>ç®€ä»‹</strong></h2><p>æ­¤æ–‡æœ¬åµŒå…¥ï¼ˆtext embeddingï¼‰ä¸º <strong><span style=\"color:#fa5252\">è´Ÿé¢æ–‡æœ¬åµŒå…¥</span></strong>ã€‚å®ƒèƒ½å¤Ÿåœ¨å¯¹ç”»é£å½±å“è¾ƒå°çš„å‰æä¸‹æ”¹å–„AIç”Ÿæˆå›¾ç‰‡çš„æ‰‹éƒ¨ç»†èŠ‚ã€‚å¦‚æœå®ƒè®©ä½ çš„æ¨¡å‹è¡¨ç°å¾—æ¯”ä»¥å‰æ›´ç³Ÿï¼Œè¯·å‹¿ä½¿ç”¨å®ƒã€‚æ‚¨å¯ä¸å…¶ä»–è´Ÿé¢æ–‡æœ¬åµŒå…¥ä¸€åŒä½¿ç”¨ã€‚è™½ç„¶å®ƒæ˜¯ä¸º AnimeIllustDiffusion æ¨¡å‹è®¾è®¡çš„ï¼Œä½†æ‚¨ä¹Ÿå¯ä»¥åœ¨å…¶ä»–æ¨¡å‹ä¸Šä½¿ç”¨ã€‚</p><p>å®ƒ<strong>ä¼¼ä¹</strong>åœ¨è¾ƒé«˜çš„ CFG Scale ä¸‹ï¼ˆ&gt;=11ï¼‰è¡¨ç°å¾—æ›´å¥½ã€‚</p><p></p><h2 id=\"heading-1240\"><strong>å¦‚ä½•ä½¿ç”¨</strong></h2><p><strong>å¯¹äº AUTOMATIC1111 WebUI ç”¨æˆ·</strong></p><ol><li><p>ä¸‹è½½æ¨¡å‹æ–‡ä»¶ <a target=\"_blank\" rel=\"ugc\" href=\"http://badhandv4.pt\">badhandv4.pt</a>ï¼›</p></li><li><p>å°†æ¨¡å‹æ–‡ä»¶æ”¾ç½®äºæ‚¨ Stable Diffusion WebUI ç›®å½•ä¸‹çš„ \"embeddings\" æ–‡ä»¶å¤¹å†…ï¼›</p></li><li><p>æ‰“å¼€ WebUIï¼Œåœ¨è´Ÿé¢æç¤ºè¯æ¡†å†…å¡«å…¥ â€œbadhandv4â€ ä»¥è§¦å‘æ•ˆæœã€‚</p></li></ol><p></p><p><strong>å¯¹äº ComfuUI ç”¨æˆ·</strong></p><ol><li><p>ä¸‹è½½æ¨¡å‹æ–‡ä»¶ <a target=\"_blank\" rel=\"ugc\" href=\"http://badhandv4.pt\">badhandv4.pt</a>ï¼›</p></li><li><p>å°†æ¨¡å‹æ–‡ä»¶æ”¾ç½®äºæ‚¨ ComfyUI ç›®å½•ä¸‹çš„ \"models/embeddings\" æ–‡ä»¶å¤¹å†…ï¼›</p></li><li><p>æ‰“å¼€ ComfyUIï¼Œåœ¨ <strong>è´Ÿé¢æç¤ºè¯æ¡†å†… </strong>å¡«å…¥ â€œembedding:badhandv4â€ ä»¥è§¦å‘æ•ˆæœã€‚</p></li></ol><p></p><h2 id=\"heading-1241\"><strong>SDXL ç‰ˆæœ¬</strong></h2><p>æˆ‘å°† badhandv4 ç§»æ¤åˆ°äº† SDXL æ ¼å¼çš„ embedding ä¸Šã€‚ä¸‹è½½åœ°å€å‚è§ï¼š</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/144327/negative-embeddings-aidxl-series-models\">Negative Embeddings - AIDXL Series Models - v0.4 | Stable Diffusion Embedding | Civitai</a></p><p></p><h1 id=\"heading-1242\"><strong>Introduction</strong> (è‹±æ–‡ç‰ˆæœ¬)</h1><h2 id=\"heading-13\"><strong>Introduction</strong></h2><p>This text embedding is a <strong><span style=\"color:#fa5252\">negative text embedding</span></strong>. It can improve the hand details of AI-generated images with less impact on the style of painting. If it makes your model behave worse than before, please do not use it. You can use it with other negative text embeddings.</p><p>Although it was designed for AnimeIllustDiffusion model, you can use it on other models as well.</p><p>It performs better with higher CFG scale (&gt;=11).</p><p></p><h2 id=\"heading-1244\"><strong>Quick Start</strong></h2><p><strong>For AUTOMATIC1111 WebUI User</strong></p><ol><li><p>Download model file <a target=\"_blank\" rel=\"ugc\" href=\"http://badhandv4.pt\">badhandv4.pt</a>;</p></li><li><p>Move the model file to the \"embeddings\" folder in your Stable Diffusion WebUI directory;</p></li><li><p>Lanuch WebUI. Enter \"badhandv4\" into the <strong>negative prompt</strong> box to trigger its effect.</p></li></ol><p></p><p><strong>For ComfyUI User</strong></p><ol><li><p>Download model file <a target=\"_blank\" rel=\"ugc\" href=\"http://badhandv4.pt\">badhandv4.pt</a>;</p></li><li><p>Move the model file to the \"models/embeddings\" folder in your ComfyUI directory;</p></li><li><p>Lanuch ComfyUI. Enter \"embedding:badhandv4\" into the negative prompt box to trigger its effect.</p></li></ol><p></p><h2 id=\"heading-1245\"><strong>SDXL version</strong></h2><p>I converted badhandv4 to SDXL format embedding.<span style=\"color:rgb(60, 64, 67)\"> </span>For downloading, see:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/144327/negative-embeddings-aidxl-series-models\">Negative Embeddings - AIDXL Series Models - v0.4 | Stable Diffusion Embedding | Civitai</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581360+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "10028",
    "prompt": "NeverEnding Dream (NED)\n<h2>NeverEnding Dream (a.k.a. NED)</h2><h3><strong>This is a dream that you will never want to wake up from</strong></h3><p><strong>Add a â¤ï¸ to receive future updates. This took much time and effort, please be supportive </strong>ğŸ«‚<br /><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> ğŸ…¿ï¸ or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> â˜•</strong></p><p><strong>V1.22 update: </strong>thanks to Bokus for some of the preview images and the tests.</p><p><strong>Available on the following websites with GPU acceleration:</strong></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/\"><strong>Mage.space</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"http://Sinkin.ai\"><strong>Sinkin.ai</strong></a></p></li><li><p><a rel=\"ugc\" href=\"https://randomseed.co/model/59\"><strong>RandomSeed</strong></a></p></li></ul><p></p><p>It has been a while since I made a model. I've been making LoRA's non stop for the last month, but I felt like I needed something. A big problem with <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384\">DreamShaper</a> is that it wasn't much compatibles with the LoRA's I was making. So I wanted to create a model that was \"artistic\" like DreamShaper but also able to use my LoRA's and booru tags for generating images. Plus I wanted this to be able to make <strong>good </strong>anime stuff out of the box, without needing an additional LoRA.</p><p>After a lot of tests and also fine tuning (plus LoRA merges) here is my newest model.</p><p>It came out a bit more realistic then I wanted, but I won't complain.</p><p><strong>What is this model great at?</strong></p><ul><li><p>Generating cosplay images</p></li><li><p>Generating anime pictures</p></li><li><p>Work accurately with character LoRA</p></li><li><p>Generating good looking people</p></li><li><p>Generating realistic animals</p></li><li><p>Generating images using booru-like tags</p></li></ul><p><strong>What is this model not too good at?</strong></p><ul><li><p>Generating pictures from complex sentences</p></li><li><p>Making fantasy/sci-fi paintings</p></li></ul><p>So this basically complements <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384\">DreamShaper</a>, and it also doesn't include Dreamlike in the mix.</p><p></p><p>I hope you'll enjoy it!</p><p></p><p><strong>Some tips:</strong></p><ul><li><p>Use CLIP skip 2.</p></li><li><p>Select \"auto\" as vae if you're using the baked vae version.</p></li><li><p>Use highres fix or img2img to upscale the images after you get a preview. See the examples generation data for settings suggestions, I've tested various techniques.</p></li><li><p>If you're making images where the subject is far, remember you can inpaint eyes and faces selecting \"only masked\".</p></li><li><p>Stable Diffusion is great, have fun with it!</p></li></ul><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581378+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "260267",
    "prompt": "Animagine XL V3.1\n<p><strong>Animagine XL 3.1 </strong>is an update in the Animagine XL V3 series, enhancing the previous version, Animagine XL 3.0. This open-source, anime-themed text-to-image model has been improved for generating anime-style images with higher quality. It includes a broader range of characters from well-known anime series, an optimized dataset, and new aesthetic tags for better image creation. Built on Stable Diffusion XL, Animagine XL 3.1 aims to be a valuable resource for anime fans, artists, and content creators by producing accurate and detailed representations of anime characters.</p><h2 id=\"heading-2230\">Model Details</h2><ul><li><p><strong>Developed by</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/cagliostrolab\"><strong><u>Cagliostro Research Lab</u></strong></a></p></li><li><p><strong>In collaboration with</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"http://SeaArt.ai\"><strong><u>SeaArt.ai</u></strong></a></p></li><li><p><strong>Model type</strong>: Diffusion-based text-to-image generative model</p></li><li><p><strong>Model Description</strong>: Animagine XL 3.1 generates high-quality anime images from textual prompts. It boasts enhanced hand anatomy, improved concept understanding, and advanced prompt interpretation.</p></li><li><p><strong>License</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://freedevproject.org/faipl-1.0-sd/\"><strong><u>Fair AI Public License 1.0-SD</u></strong></a></p></li><li><p><strong>Fine-tuned from</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/cagliostrolab/animagine-xl-3.0\"><strong><u>Animagine XL 3.0</u></strong></a></p></li></ul><p></p><h2 id=\"heading-2231\"><strong>Usage Guidelines</strong></h2><h3 id=\"heading-2232\">Tag Ordering</h3><p>For optimal results, it's recommended to follow the structured prompt template because we train the model like this:</p><pre><code>1girl/1boy, character name, from what series, everything else in any order.\n</code></pre><h2 id=\"heading-2233\">Special Tags</h2><p>Animagine XL 3.1 utilizes special tags to steer the result toward quality, rating, creation date and aesthetic. While the model can generate images without these tags, using them can help achieve better results.</p><h3 id=\"heading-2234\">Quality Modifiers</h3><p>Quality tags now consider both scores and post ratings to ensure a balanced quality distribution. We've refined labels for greater clarity, such as changing 'high quality' to 'great quality'.</p><pre><code>\nQuality Modifier\tScore Criterion\nmasterpiece\t        &gt; 95%\nbest quality\t        &gt; 85% &amp; â‰¤ 95%\ngreat quality\t        &gt; 75% &amp; â‰¤ 85%\ngood quality\t        &gt; 50% &amp; â‰¤ 75%\nnormal quality\t        &gt; 25% &amp; â‰¤ 50%\nlow quality\t        &gt; 10% &amp; â‰¤ 25%\nworst quality\t        â‰¤ 10%</code></pre><h3 id=\"heading-2235\">Rating Modifiers</h3><p>We've also streamlined our rating tags for simplicity and clarity, aiming to establish global rules that can be applied across different models. For example, the tag 'rating: general' is now simply 'general', and 'rating: sensitive' has been condensed to 'sensitive'.</p><pre><code>\nRating Modifier\t    Rating Criterion\nsafe\t            General\nsensitive\t    Sensitive\nnsfw\t            Questionable\nexplicit, nsfw\t    Explicit</code></pre><h3 id=\"heading-2236\">Year Modifier</h3><p>We've also redefined the year range to steer results towards specific modern or vintage anime art styles more accurately. This update simplifies the range, focusing on relevance to current and past eras.</p><pre><code>\nYear Tag\tYear Range\nnewest\t        2021 to 2024\nrecent\t        2018 to 2020\nmid\t        2015 to 2017\nearly\t        2011 to 2014\noldest\t        2005 to 2010</code></pre><h3 id=\"heading-2237\">Aesthetic Tags</h3><p>We've enhanced our tagging system with aesthetic tags to refine content categorization based on visual appeal. These tags are derived from evaluations made by a specialized ViT (Vision Transformer) image classification model, specifically trained on anime data. For this purpose, we utilized the model <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/shadowlilac/aesthetic-shadow-v2\"><strong><u>shadowlilac/aesthetic-shadow-v2</u></strong></a>, which assesses the aesthetic value of content before it undergoes training. This ensures that each piece of content is not only relevant and accurate but also visually appealing.</p><pre><code>\nAesthetic Tag\t       Score Range\nvery aesthetic\t       &gt; 0.71\naesthetic\t       &gt; 0.45 &amp; &lt; 0.71\ndispleasing\t       &gt; 0.27 &amp; &lt; 0.45\nvery displeasing       â‰¤ 0.27</code></pre><h2 id=\"heading-2238\">Recommended settings</h2><p>To guide the model towards generating high-aesthetic images, use negative prompts like:</p><pre><code>nsfw, lowres, (bad), text, error, fewer, extra, missing, worst quality, jpeg artifacts, low quality, watermark, unfinished, displeasing, oldest, early, chromatic aberration, signature, extra digits, artistic error, username, scan, [abstract]\n</code></pre><p>For higher quality outcomes, prepend prompts with:</p><pre><code>masterpiece, best quality, very aesthetic, absurdres\n</code></pre><p>itâ€™s recommended to use a lower classifier-free guidance (CFG Scale) of around 5-7, sampling steps below 30, and to use Euler Ancestral (Euler a) as a sampler.</p><h3 id=\"heading-2239\">Multi Aspect Resolution</h3><p>This model supports generating images at the following dimensions:</p><pre><code>Dimensions\tAspect Ratio\n1024 x 1024\t1:1 Square\n1152 x 896\t9:7\n896 x 1152\t7:9\n1216 x 832\t19:13\n832 x 1216\t13:19\n1344 x 768\t7:4 Horizontal\n768 x 1344\t4:7 Vertical\n1536 x 640\t12:5 Horizontal\n640 x 1536\t5:12 Vertical</code></pre><h3 id=\"heading-2240\"><strong>Acknowledgements</strong></h3><p>The development and release of Animagine XL 3.1 would not have been possible without the invaluable contributions and support from the following individuals and organizations:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"http://SeaArt.ai\"><strong><u>SeaArt.ai</u></strong></a>: Our collaboration partner and sponsor.</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/shadowlilac\"><strong><u>Shadow Lilac</u></strong></a>: For providing the aesthetic classification model, <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/shadowlilac/aesthetic-shadow-v2\"><strong><u>aesthetic-shadow-v2</u></strong></a>.</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/derrian-distro\"><strong><u>Derrian Distro</u></strong></a>: For their custom learning rate scheduler, adapted from <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/derrian-distro/LoRA_Easy_Training_Scripts/blob/main/custom_scheduler/LoraEasyCustomOptimizer/CustomOptimizers.py\"><strong><u>LoRA Easy Training Scripts</u></strong></a>.</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/kohya-ss\"><strong><u>Kohya SS</u></strong></a>: For their comprehensive training scripts.</p></li><li><p><strong>Cagliostrolab Collaborators</strong>: For their dedication to model training, project management, and data curation.</p></li><li><p><strong>Early Testers</strong>: For their valuable feedback and quality assurance efforts.</p></li><li><p><strong>NovelAI</strong>: For their innovative approach to aesthetic tagging, which served as an inspiration for our implementation.</p></li></ul><p>Thank you all for your support and expertise in pushing the boundaries of anime-style image generation.</p><p></p><h2 id=\"heading-2241\"><strong>Limitations</strong></h2><p>While Animagine XL 3.1 represents a significant advancement in anime-style image generation, it is important to acknowledge its limitations:</p><ol><li><p><strong>Anime-Focused</strong>: This model is specifically designed for generating anime-style images and is not suitable for creating realistic photos.</p></li><li><p><strong>Prompt Complexity</strong>: This model may not be suitable for users who expect high-quality results from short or simple prompts. The training focus was on concept understanding rather than aesthetic refinement, which may require more detailed and specific prompts to achieve the desired output.</p></li><li><p><strong>Prompt Format</strong>: Animagine XL 3.1 is optimized for Danbooru-style tags rather than natural language prompts. For best results, users are encouraged to format their prompts using the appropriate tags and syntax.</p></li><li><p><strong>Anatomy and Hand Rendering</strong>: Despite the improvements made in anatomy and hand rendering, there may still be instances where the model produces suboptimal results in these areas.</p></li><li><p><strong>Dataset Size</strong>: The dataset used for training Animagine XL 3.1 consists of approximately 870,000 images. When combined with the previous iteration's dataset (1.2 million), the total training data amounts to around 2.1 million images. While substantial, this dataset size may still be considered limited in scope for an \"ultimate\" anime model.</p></li><li><p><strong>NSFW Content</strong>: Animagine XL 3.1 has been designed to generate more balanced NSFW content. However, it is important to note that the model may still produce NSFW results, even if not explicitly prompted.</p></li></ol><p>By acknowledging these limitations, we aim to provide transparency and set realistic expectations for users of Animagine XL 3.1. Despite these constraints, we believe that the model represents a significant step forward in anime-style image generation and offers a powerful tool for artists, designers, and enthusiasts alike.</p><h2 id=\"heading-2242\">License</h2><p>Based on Animagine XL 3.0, Animagine XL 3.1 falls under <a target=\"_blank\" rel=\"ugc\" href=\"https://freedevproject.org/faipl-1.0-sd/\"><strong><u>Fair AI Public License 1.0-SD</u></strong></a> license, which is compatible with Stable Diffusion modelsâ€™ license. Key points:</p><ol><li><p><strong>Modification Sharing:</strong> If you modify Animagine XL 3.1, you must share both your changes and the original license.</p></li><li><p><strong>Source Code Accessibility:</strong> If your modified version is network-accessible, provide a way (like a download link) for others to get the source code. This applies to derived models too.</p></li><li><p><strong>Distribution Terms:</strong> Any distribution must be under this license or another with similar rules.</p></li><li><p><strong>Compliance:</strong> Non-compliance must be fixed within 30 days to avoid license termination, emphasizing transparency and adherence to open-source values.</p></li></ol><p>The choice of this license aims to keep Animagine XL 3.1 open and modifiable, aligning with open source community spirit. It protects contributors and users, encouraging a collaborative, ethical open-source community. This ensures the model not only benefits from communal input but also respects open-source development freedoms.<br /><br />Finally Cagliostro Lab Server open to public <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/cqh9tZgbGc\"><strong><u>https://discord.gg/cqh9tZgbGc</u></strong></a></p><p>Feel free to join our discord server.<br />If you want to donate or buy us a coffee you can donate <a rel=\"ugc\" href=\"https://ko-fi.com/linaqruf\"><strong><u>Here</u></strong></a></p><p>Thank you very much ^_^</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581393+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "5414",
    "prompt": "Pastel-Mix [Stylized Anime Model]\n<p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/pastel-mix\">Huggingface repository goes here.</a><br /><br />Interested in supporting me? <a target=\"_blank\" rel=\"ugc\" href=\"https://www.buymeacoffee.com/andite\">Buy me a coffee.</a><br /><br />A stylized anime model. This model is made with the thought of imitating pastel-like art while introducing the potential of merging LORAs into a model altogether to create a fantastic mix.</p><h2><strong>Guide</strong></h2><p>For the settings or parameters, I recommend using these settings.</p><p></p><pre><code>Sampler: DPM++ 2M Karras\n\nSteps: 20\n\nCFG Scale: 7\n\nHires. Fix: On\n\nUpscaler: Latent (MUST!)\n\nHires Steps: 20\n\nDenoising Strength: 0.\n</code></pre><p>I prefer using 0.6 since it's the sweet spot of this model. If you can find a better setting for this model, then good for you lol.</p><p>Latent upscaler is the best setting for me since it retains or enhances the pastel style. Other upscalers like Lanczos or Anime6B tends to smoothen them out, removing the pastel-like brushwork.</p><p>Please use the <strong>VAE</strong> that I uploaded in this repository. It is from the <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/tree/main/vae\"><strong><u>Waifu Diffusion</u></strong></a> team. Credits to <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei\"><strong><u>haru</u></strong></a> for letting me rename and upload it.</p><h2><strong>Tip (Optional)</strong></h2><p>Putting mksks style in the beginning of the prompt can further influence the pastel-like style and make the output better. It is optional though, so it's up to you. You don't really need it.</p><p></p><p>Recipe for the mix can be found inside the HF repository.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581397+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "81458",
    "prompt": "AbsoluteReality\n<h1 id=\"heading-6674\">AbsoluteReality</h1><h2 id=\"heading-6675\">That feeling after you wake up from a dream</h2><p><strong>Add a â¤ï¸ to receive future updates. This took much time and effort, please be supportive </strong>ğŸ«‚<br /><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> ğŸ…¿ï¸ or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> â˜•</strong></p><p></p><p><strong><span style=\"color:rgb(253, 126, 20)\">For LCM read the version description.</span></strong><br /><br /><strong>Additional ecamples for V1.6: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/353121\">https://civitai.com/posts/353121</a><br /><strong>Additional examples for V1</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/259634\">https://civitai.com/posts/259634</a><br /><strong>Amazing gallery by qf22:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/260939\">https://civitai.com/posts/260939</a><br />Quick face alteration examples using celebrity names and mixing them: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/274268\">https://civitai.com/posts/274268</a></p><h3 id=\"heading-91\">Available on <a target=\"_blank\" rel=\"ugc\" href=\"http://sinkin.ai\"><strong>sinkin.ai</strong></a><strong>, </strong><a target=\"_blank\" rel=\"ugc\" href=\"http://Mage.space\"><strong>Mage.space</strong></a><strong> and many other services</strong></h3><h3 id=\"heading-6676\">Suggestions</h3><ul><li><p>Use between 4.5 and 10 CFG Scale and between 25 and 30 Steps with DPM++ SDE Karras. Worse samplers might need more steps.</p></li><li><p><strong>To reproduce my results you MIGHT have to change these settings:</strong></p><ul><li><p><strong>Set \"Do not make DPM++ SDE deterministic across different batch sizes.\" (mostly for v1 examples)</strong></p></li><li><p><strong>Set the ETA Noise Seed Delta (ENSD) to 31337</strong></p></li><li><p><strong>Set CLIP Skip to 2</strong></p></li><li><p><strong>DISABLE face restore. It's terrible, never use it</strong></p></li></ul></li><li><p>Use simple prompts<strong>.</strong> Complex prompts might make less realistic pictures because of CLIP bleeding. More complex prompts does not mean better results. Keep it simple.</p></li><li><p>Use <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\">ADetailer</a> to enhance faces. Basically every <strong>solo </strong>portrait I made uses it. You can get my settings by clicking on \"copy generation data\". <strong>I suggest you use denoising under 0.3 to avoid getting always the same face.</strong></p></li><li><p>Use <strong>BadDream </strong>and <strong>UnrealisticDream </strong>negative embeddings (<code>BadDream, (UnrealisticDream:1.2)</code>). Add weight to UnrealisticDream between 1.2 and 1.5. <strong>Do not use FastNegative or EasyNegative if you aim at realism</strong>. However, they're good for artworks.</p></li><li><p><strong>Use Highres.fix</strong> with the following settings: <code>Denoising strength: 0.45, Hires steps: 20, Hires upscaler: 8x_NMKD-Superscale_150000_G</code> and as much upscale as you can (my gpu only handles up to x1.8 at 512x768 base resolution, but you can go higher). If you don't have <code>8x_NMKD-Superscale_150000_G</code> you can probably use another GAN, but it should be easy to find on Google. You can also try Latent with a denoise higher than 0.6, but the result will be harder to control.</p></li><li><p>Try to condition faces by prompting for eye colors, hairstyles, hair color, ethnicity and so on. Even celebrity names do work. This model is pretty good at not making a single face if you play with the context.</p></li><li><p>If the pic is too clean, try to add some ISO noise. Even as a post processing with external tools it will trick the brain enough to make you think \"damn, this is a real photo.</p></li><li><p>If you feel the grounded nature of this model is limiting your imagination, try generating on DS6 and then do img2img with this one to bump up the realism.</p></li></ul><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/images/986207?period=AllTime&amp;periodMode=published&amp;sort=Newest&amp;view=categories&amp;modelVersionId=86437&amp;modelId=81458&amp;postId=259728\">Pruned vs full comparison (not highres fixed)</a></p><h3 id=\"heading-6677\"><br />Brief story of this model</h3><p>While working on <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384/dreamshaper\">DreamShaper 6</a> I made many other models and a crap ton of tests. Some of them were strange mixes with photorealistic models I had previously made, plus new ones and some ISO noise LoRA I made. When I tested the various release candidates of DS6 for photography prompts, this came out on top. While mostly on the losing side with regards to range, flexibility and LoRA compatibility compared to what became DS6, I noticed this was pretty good at recreating photos with very simple and minimalistic prompts. So, why not, I gave it some love and kept working on it, just in time for its initial release.</p><p></p><h3 id=\"heading-6710\">Difference with DreamShaper</h3><p>Long story short, DS aims at art, this aims at realism. They might overlap a bit, but they have different objectives and different things they're good at. DreamShaper is total freedom and can basically do everything at a high level. This does about one thing and does it extremely well. This still uses DreamShaper as base, so it's capable of doing art to a lesser degree.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581411+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "139562",
    "prompt": "RealVisXL V5.0\n<p><strong><span style=\"color:rgb(21, 170, 191)\">Check my exclusive models on Mage: </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/4371756b27bf52e7a1146dc6fe2d969c\"><strong><span style=\"color:rgb(230, 73, 128)\">ParagonXL</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/df67a9f27f19629a98cb0fb619d1949a\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/d8db06ae964310acb4e090eec03984df\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL Lightning</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/541da1e10976ab82976a5cacc770a413\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL V2</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/a56d2680c464ef25b8c66df126b3f706\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL Pony</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/b0ab6733c3be2408c93523d57a605371\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL Pony Lightning</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/e3b01cd493ed86ed8e4708751b1c9165\"><strong><span style=\"color:rgb(230, 73, 128)\">RealDreamXL</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/ef062fc389c3f8723002428290c1158c\"><strong><span style=\"color:rgb(230, 73, 128)\">RealDreamXL Lightning</span></strong></a></p><p><strong><span style=\"color:rgb(250, 82, 82)\">If you are using Hires.Fix with V5 Lightning, then use my recommended settings for Hires.Fix (3 Sampling Steps, Denoising strength: 0.5 and CFG Scale 1.0 - 2.0) or other settings you find better for you.</span></strong></p><p><strong><span style=\"color:rgb(0, 255, 111)\">Use Turbo models with DPM++ SDE Karras sampler, 4-10 steps and CFG Scale 1-2.5</span></strong></p><p><strong><span style=\"color:rgb(0, 255, 111)\">Use Lightning models with DPM++ SDE Karras / DPM++ SDE sampler, 4-6 steps and CFG Scale 1-2</span></strong></p><p><strong>Please pay attention to the model file name, the part of the name after the underscore is the true version of the model.</strong></p><p><strong>The model is already available on</strong> <a target=\"_blank\" rel=\"ugc\" href=\"http://Mage.Space\"><strong><u><span style=\"color:rgb(253, 126, 20)\">Mage.Space</span></u></strong></a><strong> (main sponsor)</strong></p><p><strong><span style=\"color:rgb(193, 194, 197)\">You can also support me directly on</span></strong><span style=\"color:rgb(193, 194, 197)\"> </span><a target=\"_blank\" rel=\"ugc\" href=\"https://boosty.to/sg_161222\"><strong><u><span style=\"color:rgb(250, 176, 5)\">Boosty</span></u></strong></a><span style=\"color:rgb(193, 194, 197)\">.</span></p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/collections/SG161222/realvisxl-sdxl-656daeb4adba74cd5ea2ef44\"><strong><u><span style=\"color:rgb(253, 126, 20)\">RealVisXL Hugging Face Full Collection</span></u></strong></a></p><p></p><p><strong>The model is aimed at photorealism. Can produce sfw and nsfw images of decent quality.</strong></p><p><span style=\"color:rgb(44, 45, 46)\">á… </span></p><p><strong><u>Recommended Negative Prompt:</u></strong></p><p>(worst quality, low quality, illustration, 3d, 2d, painting, cartoons, sketch), open mouth</p><p><strong>or another negative prompt</strong></p><p><span style=\"color:rgb(44, 45, 46)\">á… </span></p><p><strong><u>Recommended Generation Parameters:</u></strong><br /><strong>Sampling Method:</strong> <span style=\"color:rgb(179, 188, 201)\">DPM++ SDE Karras (30+ Sampling Steps) or DPM++ 2M Karras (50+ Sampling Steps)</span></p><p><span style=\"color:rgb(44, 45, 46)\">á… </span></p><p><strong><u>Hires Fix Parameters:</u></strong></p><p><strong>Upscaler: </strong><span style=\"color:rgb(179, 188, 201)\">4x-NMKD-Superscale-SP_178000_G / 4x-UltraSharp upscaler / or another</span></p><p><strong>Denoising strength: </strong>0.1-0.3</p><p><strong>Upscale by: </strong>1.1-1.5</p><p><span style=\"color:rgb(44, 45, 46)\">á… </span></p><p><strong><u>Optional Parameters:</u></strong></p><p><strong>ENSD: </strong>31337</p><p><span style=\"color:rgb(44, 45, 46)\">á… </span></p><p><strong><u>This model is:</u></strong></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8ac18d6c-3ba5-43bb-a965-b7aeff47fde0/width=525/8ac18d6c-3ba5-43bb-a965-b7aeff47fde0.jpeg\" /></p><p><span style=\"color:rgb(44, 45, 46)\">á… </span></p><p><strong>Huge thanks to the creators of these great models that were used in the merge.</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/112902/dreamshaper-xl10\"><strong>DreamShaper XL1.0</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Lykon\"><strong>Lykon</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/133005/juggernaut-xl\"><strong>Juggernaut XL</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/KandooAI\"><strong>KandooAI</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/118114/sdvn6-realxl\"><strong>SDVN6-RealXL</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/StableDiffusionVN\"><strong>StableDiffusionVN</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/119202/talmendoxl-sdxl-uncensored-full-model\"><strong>TalmendoXL - SDXL Uncensored Full Model</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/talmendo\"><strong>talmendo</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5273/wyvernmix-15-and-xl\"><strong>WyvernMix (1.5 &amp; XL)</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/wier\"><strong>wier</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/122822/crystal-clear-xl\"><strong>Crystal Clear XL</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/WarAnakin\"><strong>WarAnakin</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/125703?modelVersionId=144229\"><strong>ProtoVision XL</strong></a><strong> and </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/122606?modelVersionId=169718\"><strong>DynaVision XL</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/socalguitarist\"><strong>socalguitarist</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/131843/cinemax-alpha-or-sdxl-or-cinema-or-filmic-or-nsfw\"><strong>Cinemax Alpha | SDXL | Cinema | Filmic | NSFW</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/viakole\"><strong>viakole</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/243445?modelVersionId=274687\"><strong>Imperfect portrait</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/MakeThemComeAliveAIArt\"><strong>MakeThemComeAliveAIArt</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/194768?modelVersionId=335740\"><strong>Jib Mix Realistic XL</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/J1B\"><strong>J1B</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/43977/leosams-helloworld-xl?modelVersionId=338512\"><strong>LEOSAM's HelloWorld XL</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/LEOSAM\"><strong>LEOSAM</strong></a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581422+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "43977",
    "prompt": "LEOSAM's HelloWorld XL\n<p>ğŸ–¥ï¸Welcome to try out the open-source <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/jiayev/GPT4V-Image-Captioner\"><strong><u>GPT4V-Image-Captioner</u></strong></a>, developed by my friend and me. It offers a one-click installation and comes integrated with multiple features including image pre-compression, image tagging, and tag statistics. Recently, we also launched the <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/SleeeepyZhou/sd-webui-GPT4V-Image-Captioner\"><strong><u>webui plugin version</u></strong></a> of this tool, everyone is welcome to use it!</p><p>ğŸŒ<span style=\"color:rgba(255, 255, 255, 0.8)\">æ¬¢è¿åŠ å…¥</span>QQç¾¤\"å…”ç‹²Â·AIGCæ¢¦å·¥åŒ—å‚\"ï¼Œç¾¤å· ï¼š<span style=\"color:rgb(250, 176, 5)\">780132897</span> ï¼›\"å…”ç‹²Â·AIGCæ¢¦å·¥å—å‚\"ï¼Œç¾¤å· ï¼š<span style=\"color:rgb(250, 176, 5)\">835297318</span>ï¼ˆå…¥ç¾¤ç­”æ¡ˆï¼šå…”ç‹²ï¼‰ã€‚<span style=\"color:rgba(255, 255, 255, 0.8)\">Telegramç¾¤èŠâ€œå…”ç‹²çš„SDXLç™¾è€æ±‡â€ï¼Œé“¾æ¥ï¼š</span><a target=\"_blank\" rel=\"ugc\" href=\"https://t.me/+KkflmfLTAdwzMzI1\"><span style=\"color:rgb(250, 176, 5)\">https://t.me/+KkflmfLTAdwzMzI1</span></a></p><p></p><h3 id=\"helloworld-7.0-update-june-13-2024-lgbhpvueb\"><strong>ğŸ“–HelloWorld 7.0 Update - June 13, 2024</strong></h3><p><strong><u>One-sentence update summary: </u></strong>HelloWorld 7.0 is an iteratively optimized version, with the best body performance in the entire series, and further enhanced concept scope and detail richness.</p><p>Update details:</p><ol><li><p>By adding negative training images, strengthening pose training, and optimizing the clip model, the accuracy of the model's limbs and hands has been improved compared to previous versions. The recommended negative prompt words are: \"bad hand, bad anatomy, worst quality, ai generated images, low quality, average quality\".</p></li><li><p>Extracted the fine-tuned LoRA from the<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/SPO-Diffusion-Models/SPO-SDXL_4k-p_10ep\"> official SPO model</a> and incorporated it into HelloWorld 7.0. SPO is a further improvement of the DPO method. The SPO base model is used for better performance than the DPO XL base model and the original SDXL base model. The SPO LoRA can enhance image details &amp; contrast and beautify images. Thanks to the technical team behind SPO.</p></li><li><p>Continued to expand the concept scope of the training set, but optimized and streamlined the training set (large training set fine-tuning is too expensive, and H800 is difficult to rent recently, can't afford the local training time). The current total training set is 20,821 images. The training set resolution distribution is as follows, and it is recommended to use several resolutions with a larger number of images for output:</p><pre><code>(832, 1248) - Count: 7128\n(896, 1152) - Count: 6250\n(1248, 832) - Count: 2402\n(1024, 1024) - Count: 1639\n(1360, 768) - Count: 928\n(1152, 896) - Count: 870\n(768, 1360) - Count: 432\n(960, 1088) - Count: 506\n(992, 1056) - Count: 162\n(1088, 960) - Count: 140\n(704, 1472) - Count: 120\n(1056, 992) - Count: 122\n(1472, 704) - Count: 115\n(1632, 640) - Count: 75\n(640, 1632) - Count: 12</code></pre></li><li><p>Used GPT4O to re-label all datasets. This time, a structured labeling method was used, with the specific structure being: \"one-sentence summary description + multiple image element tags + inspired by XXX + aesthetic quality description words\", where the aesthetic quality description words are divided into five levels: worst quality, low quality, average quality, best quality, and masterpiece. A typical labeling example is as follows:</p><pre><code>conceptual art featuring a human hand wrapped in red and beige ribbons, isolated against a plain, light background, realistic style, minimalist color scheme, smooth textures, elongated and surreal aesthetic, inspired by salvador dalÃ­'s surrealist works, masterpiece</code></pre></li></ol><p>The \"High-Frequency Tagging Word List\" and the \"High-Frequency Art Style List\" involved in the Inspired by XXX for the HelloWorld 7.0 version will only be provided to commercial licensing users. Partners who have purchased Helloworld XL series model authorization in the past, please contact me if there are any omissions to get it for free.</p><p>Players can refer to the <a target=\"_blank\" rel=\"ugc\" href=\"https://picturesque-soup-93d.notion.site/LEOSAM-HelloWorld-6-0-Top-250-High-Frequency-Tagging-Word-List-1be4971bafb84c22a231ee2f6da29cc1\">High-Frequency Tagging Word List of HelloWorld 6.0</a>. In addition, I have also provided 150+ high-quality HelloWorld 7.0 example images in the gallery, which can be used as a reference for everyone's output. Model making is not easy, thank you players for your understanding and tolerance!</p><p></p><h3 id=\"helloworld-6.0-update-april-20-2024-ru0h3cl08\"><strong>ğŸ“–</strong>HelloWorld 6.0 Update - April 20, 2024</h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://picturesque-soup-93d.notion.site/LEOSAM-HelloWorld-6-0-Top-250-High-Frequency-Tagging-Word-List-1be4971bafb84c22a231ee2f6da29cc1?pvs=4\"><strong><u>LEOSAM HelloWorld 6.0 Top 250 High-Frequency Tagging Word List</u></strong></a></p><p>Thank you for your patience. I have been job hunting recently, which caused some delays in the HelloWorld updates. Here are the main updates in version 6.0:</p><ul><li><p>HelloWorld 6.0 is an iterative improvement based on version 5.0. Based on my own testing, the realism effect is not significantly different from version 5.0. The main advantage of version 6.0 lies in its broader coverage of concepts in the training set. According to feedback, enhancements have been made in various themes including surrealism, boudoir, group photos, masks, origami, 3D renders, cars, dragons, and maternity photography. Some examples are provided in the illustrations.</p></li><li><p>HelloWorld 6.0 intentionally includes some low-quality images in the training to enhance the model's response to negative prompts. It is recommended to use the following terms in negative prompts: \"low quality, jpeg artifacts, blurry, poorly drawn, ugly, worst quality\".</p></li><li><p>The main body of the HelloWorld 6.0 training set employs GPT4v tagging. For images that GPT4v cannot tag, cogVQA guided by blip2-opt-6.7b is used for tagging. The tagging language style of these multimodal models differs significantly from the traditional WD1.4 tagger. To facilitate more accurate triggering of different concepts in the training set, I have compiled the top 250 high-frequency tagging words from the HelloWorld 6.0 training set. You can view these high-frequency words in<a target=\"_blank\" rel=\"ugc\" href=\"https://www.notion.so/LEOSAM-HelloWorld-6-0-Top-250-High-Frequency-Tagging-Word-List-1be4971bafb84c22a231ee2f6da29cc1\"> this document</a>.</p></li></ul><p>Finally, although SD3 is about to be released, I will still update to HelloWorld XL 7.0, hoping to achieve greater enhancements in version 7.0!</p><p></p><h3 id=\"2024.2.22-introducing-&quot;hw5.0_euler_a_lightning&quot;-3k0ze75dh\"><strong>ğŸ“–</strong><u>2024.2.22 Introducing </u>\"HW5.0_Euler_a_Lightning\"</h3><p>This model is a run-accelerated version of the HelloWorld SDXL base model, incorporating both <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/ByteDance/SDXL-Lightning/tree/main\">SDXL-Lightning</a> technologies. <strong>Equipped with the Eular a sampler and CFG 1, it is capable of generating images in 6-8 steps, which is three times faster than the original SDXL version</strong>. Moreover, upon comparison, <strong>its imaging results are superior to those of LCM or Turbo versions</strong>.</p><p>The recommended parameters for generating images with this model are:</p><p><strong>Sampler</strong>: Eular a (Important! The model is specifically adapted to Eular a, other samplers may not yield as good results)</p><p><strong>CFG scale</strong>: 1</p><p><strong>Sampling steps</strong>: 8 steps (6~8 steps are acceptable)</p><p><strong>Hires algorithm</strong>: ESRGAN 4x / 8x_NMKD-Faces_160000_G</p><p><strong>Hires Upscale factor</strong>: 1.5x</p><p><strong>Hires steps</strong>: 8 steps</p><p><strong>Hires Denoising strength</strong>: 0.3</p><h3 id=\"2024.2.11-introducing-&quot;helloworld-5.0-gpt4v&quot;-3xc4ya3hl\"><strong>ğŸ“–</strong><u>2024.2.11 Introducing \"HelloWorld 5.0 GPT4V\"</u></h3><p>HelloWorld 5.0 is the most substantial update in the history of the HelloWorld series, tagged with GPT-4v, and has undergone significant fine-tuning in fields such as science fiction, animals, architecture, and illustration.</p><p>Comparative tests show improvements in this version include:</p><p>1. More varied and dynamic character poses and image compositions, creating visually engaging pictures;</p><p>2. The film dataset has been extensively trained. While the film texture was weak from versions 2.0 to 4.0, many fans missed the leogirl style of version 1.0. Therefore, this update has specifically strengthened the film texture without compromising other photographic qualities. The film texture can be triggered by phrases such as <strong><span style=\"color:rgb(250, 176, 5)\">film grain texture</span></strong> and <strong><span style=\"color:rgb(250, 176, 5)\">analog photography aesthetic</span></strong>;</p><p>3. Enhanced expressiveness in themes like science fiction, thriller, and animals, with mechas and other subjects having a more designed feel. Animals like snow leopard, red panda, giant panda, tiger, the Pallas's cat, and domestic cats and dogs are more lifelike;</p><p>4. Thanks to GPT tagging, prompt adherence and conceptual accuracy have been further improved.</p><p>However, the drawbacks of this version include:</p><p>1. As this is a substantial fine-tuning update, the error rate for limbs and such may slightly increase, a normal phenomenon when moving out of a comfort zone into new areas of relative optimization. Previous versions underwent extensive limb testing for improvements, while the new version had limited time for such enhancements. Nevertheless, the accuracy of limbs in this version is at least higher than in version 1.0, and I will continue to make improvements in future updates.</p><p>2. Due to the reinforced film texture, even though GPT tagging is as accurate as possible, there can be an unavoidable default warm tone in images. However, you can use prompts like <strong>studio light</strong> or <strong>sharp focus</strong> to produce high-definition studio-quality images, and with proper use of prompts, the output can have better skin tones and visual appeal than previous versions.</p><p>3. This version includes more full-body character images to enhance the full-body effect, so the model may produce wider scenes than before if no specific character composition is directed. Currently, the facial details in 1024 resolution full-body shots might be less sharp compared to half-body or close-up shots. However, this can be improved by adetailer and a 1.5x Hires. fix at 0.3 intensity, or by using prompts like specifying composition to avoid generating full-body images.</p><p>4. Since a small number of high-quality illustration datasets have been added, there is a chance that prompts related to animated styles will produce animated images. If this concerns you, please adjust your prompts accordingly.</p><p>These are the main updates for this version. Training the SDXL base model is challenging, and when the training set approaches ten thousand images, the cost for tagging and training for each model exceeds 300 USD. I welcome everyone to use the model and appreciate any feedback you can provide! If you find this model satisfactory, I would be immensely grateful if you could help spread the word about it.</p><h3 id=\"2024.1.31-introducing-&quot;helloworld-4.0&quot;-kw58jshiy\"><strong>ğŸ“–</strong><u>2024.1.31 Introducing \"HelloWorld 4.0\"</u></h3><p>HelloWorld4.0 is a progressive transitional version from tagging with blip+clip to tagging with GPT4V. I initially trained a pure GPT4V tagging model, and then merged it with a large proportion of the HelloWorld3.2 version and 0.05 proportion of Juggernaut XL (to adjust the skin tone). The new version has shown improvements in prompt compliance and concept coverage compared to the 3.2 version.</p><p>The new GPT4V tagging training set has doubled from the 4000 images of the helloworld3 series to 8000 images, covering not only portraits but also animals, architecture, nature, food, illustrations, and more. However, the pure GPT4V version encountered an overfitting problem, which is preliminarily attributed to the doubling of the number of training images. One of the next steps in iterative optimization is to find out how to include as many non-portrait concepts as possible while ensuring sufficient training of portraits. At this stage, a fusion of the new and old versions has been used for fine-tuning to ensure a smooth transition between versions, so the expanded concept set and the advantages brought by GPT4V tagging are not very perceptible at the moment. These advantages will become increasingly apparent in the subsequent generations 5 and 6 of the model.</p><h3 id=\"2024.1.5-introducing-&quot;helloworld-3.2&quot;-rhw3t9si5\"><strong>ğŸ“–</strong><u>2024.1.5 Introducing \"HelloWorld 3.2\"</u></h3><p><span style=\"color:rgb(193, 194, 197)\">Version 3.2 is an iteration optimized with </span><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/qqingzheng/AI-Self-Training-DPO-SDXL/tree/main\">DPO</a><span style=\"color:rgb(193, 194, 197)\"> technology, and compared to version 3.0, there are optimizations in skin tone and limb accuracy, but the improvements are not significant. That's why this version is marked as 3.2 rather than being labeled as 4.0.</span></p><h3 id=\"2023.12.15-introducing-&quot;helloworld-3.0&quot;-6xkr3cgn7\"><strong>ğŸ“–</strong><u>2023.12.15 Introducing \"HelloWorld 3.0\"</u></h3><ol><li><p>The new version has expanded the training set, enhancing the model's ability to express in different artistic styles, including science fiction and art.</p></li><li><p>It has integrated a self-made quality enhancement LoCon (created using slider technology), to improve image texture and alleviate issues of distortion in fingers and limbs.</p></li></ol><h3 id=\"2023.11.17-introducing-&quot;helloworld-2.0&quot;-bb85dqdsy\"><strong>ğŸ“–</strong><u>2023.11.17 Introducing \"HelloWorld 2.0\"</u></h3><p>Thank you all for your patience. After overcoming various challenges, the HelloWorld 2.0 version is finally ready to be presented to you all in a state that I'm satisfied with. The main differences between HelloWorld 2.0 and 1.0 are as follows:</p><ol><li><p>HelloWorld 2.0 no longer requires trigger words, and the results are comparable in quality to version 1.0 with trigger words.. The trigger word 'leogirl' in 1.0 was highly associated with East Asians. After the cancellation of the trigger words, while words like '1girl' will still likely generate East Asian portraits when race is not specified, you can now specify the race by using keywords like nationality, skin color, etc. For example, the trigger effects for words like 'Chinese', 'Russian', 'Iranian', 'Jamaican', 'Kenyan', 'dark-skinned', 'pale-skinned', etc., are listed below.</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/be3e96e6-33bd-40a1-9770-0e4a216c965f/width=525/be3e96e6-33bd-40a1-9770-0e4a216c965f.jpeg\" /></p><p>You can also get different styles of characters by writing the names of people from different countries and genders in the prompt, such as Han Meimei (China), Sophie Martin (France), Priya Patel (India), Fatima Al-Hassan (Arab), Wanjiru Mwangi (Kenya). The above prompts are just examples, there are many available prompts and ways to play, and you're welcome to explore and share them by yourself.</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/da4d543c-df00-4ae1-8663-dc54a28c2ed5/width=525/da4d543c-df00-4ae1-8663-dc54a28c2ed5.jpeg\" /></p></li><li><p>HelloWorld 2.0 has balanced the quality/color and offers more style options. The 1.0 version, when used with 'leogirl', would likely produce images with a strong film texture. HelloWorld 2.0 is no longer tied to a film texture and can be customized with some quality-related prompts. Some prompts that have been tested and work well include:</p><p>high-end fashion photoshoot, product introduction photo, popular Korean makeup, aegyo sal, Sharp High-Quality Photo, studio light, medium format photo, Mamiya photography, analog film, Medium Portrait with Soft Light, real-life image, refined editorial photograph, raw photo, real photo, Scanned Photo, film still</p><p>The color effects of these prompts are as follows:</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6c2b58b8-e34c-4292-9237-311d8ddc48db/width=525/6c2b58b8-e34c-4292-9237-311d8ddc48db.jpeg\" /></p></li><li><p>The training set for HelloWorld 2.0 significantly increased the proportion of full-body photos to improve the effects of SDXL in generating full-body and distant view portraits. Although it has improved compared to version 1.0, it is still strongly recommended to use 'adetailer' in the process of generating full-body photos. Also, for users with enough video memory (24g), it is recommended to perform 1.5x high-resolution repair on the image, which can significantly improve facial details.</p></li></ol><p></p><h3 id=\"2023.8.29-introducing-&quot;helloworld&quot;-sdxl-base-model-kaxnezy2g\"><strong>ğŸ“–</strong><u>2023.8.29 Introducing \"HelloWorld\" SDXL Base Model</u></h3><p><strong><u>Special reminder</u>: <span style=\"color:rgb(34, 139, 230)\">When using the HelloWorld 1.0 model, please remember to add the trigger word \"leogirl\".</span></strong></p><p>Distinct from SD1.5 base model â€œMoonFilmâ€, â€œHelloWorldâ€ is a brand new realistic SDXL base model series, . In order to allow more users to discover HelloWorld, I have retained the original Moonfilm's model link. It can be perceived as a spiritual continuation of Moonfilm on the SDXL new platform, but HelloWorld aims to achieve more than just the pursuit of realism and film-like quality in portraits. Thanks to the far superior amount of information and text understanding capabilities of SDXL compared to SD1.5, HelloWorld is a base model that seeks to realistically depict all things, or in other words, I hope to gradually build a virtual photography world using HelloWorld.</p><p>The realistic base model of SD1.5 has developed to a quite mature stage, and it is unlikely to have a significant performance improvement. Unless there is a breakthrough technology for SD1.5 platform, the Moonfilm &amp; MoonMix series will basically stop updating. I will devote my main energy to the development of the HelloWorld SDXL large model. The 1.0 version is now available for download, and the 2.0 version is being developed urgently and is expected to be updated in early September.</p><p>As a brand new SDXL model, there are three differences between HelloWorld and traditional SD1.5 models:</p><ol><li><p>Unlike SD1.5 base models, which typically do not include trigger words, please remember to use the trigger word \"<strong><span style=\"color:rgb(34, 139, 230)\">leogirl</span></strong>\" when using HelloWorld 1.0. This ensures that the SDXL model triggers the training set effect more stably.</p></li><li><p>The HelloWorld model supports direct output at a resolution of 1024*1024 pixels, eliminating the need for high-resolution magnification. The quality of close-up portrait directly output is not inferior to the SD1.5 version, but there are still flaws when outputting distant portraits directly. Therefore, it is suggested to use <strong><span style=\"color:rgb(34, 139, 230)\">ADetailer</span></strong> plugin, which can effectively correct the problems of distant faces.</p></li><li><p>SDXL now allows for easier output using <strong><span style=\"color:rgb(34, 139, 230)\">simple natural language prompts</span></strong>. It is recommended to try more natural language prompts, which will result in better outcomes when outputting AI realistic photos.</p></li></ol><p>After multiple rounds of testing, the suggested drawing parameter settings are:</p><ul><li><p>Steps â‰¥ 25</p></li><li><p>Sampler: DPM++ 2M Karras</p></li><li><p>CFG scale: 10</p></li><li><p>Size â‰¥ 1024x1024</p></li><li><p>ADetailer: open</p></li></ul><p>Everyone is welcome to try HelloWorld and provide plenty of feedback. Your valuable opinions are very important for the next step of model improvement!</p><p></p><h3 id=\"copyright-statement:-zwepllh9o\"><strong>Copyright Statement:</strong></h3><p>The HelloWorld series of models (hereinafter \"the Model\") has been crafted by myself (hereinafter \"the Owner\") with the assistance of the LiblibAI platform. Republishing the Model on platforms excluding LiblibAI and Civitai is unauthorized by the Owner.</p><p>The Owner permits the use of images generated by the Model for non-commercial educational or informative purposes at no cost, on the condition that:</p><p>- Users adhere to applicable laws and do not violate the rights of the Model or any third-party.</p><p>- Attribution for the images must be clearly stated as \"created by LEOSAM's HelloWorld base model\".</p><p>For any form of commercial utilization, a prior commercial license agreement with the Owner is required. For inquiries related to commercial licensing and model personalization, please reach out to the Owner via the contact information available on the Owner's homepage.</p><p>The development and free distribution of the SDXL model represent significant endeavors. The Owner pledges ongoing complimentary updates to the HelloWorld model for individual enthusiasts as a token of appreciation for the community's contributions to open-source development. Collaborative commercial engagements are vital for the Model's advancement and refinement. The Owner appreciates every user for their understanding and support.</p><p>Unauthorized use may breach applicable laws and carry legal repercussions. The Owner retains exclusive rights to interpret this statement, which is governed by prevailing laws and regulations.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581463+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "8730",
    "prompt": "Hipoly 3D Model LoRA\n<p><strong><u>(æ—¥æœ¬èªã¯å¾ŒåŠã«ã‚ã‚Šã¾ã™)</u></strong></p><p></p><h2>High-poly 3D Model LoRA</h2><p>This is a LoRA trained on high-polygon 3D model images.</p><p>It can provide clean, high-resolution skin and hair materials, as well as detailed clothing elements.</p><p></p><p>For those interested, I have compiled the technical insights gained during the training of ver.2 in the following article.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://note.com/takumi__ncr/n/n21016c358ea5\">https://note.com/takumi__ncr/n/n21016c358ea5</a></p><p></p><h2>Changes in 2.0</h2><ul><li><p>Increased the number of training images</p></li><li><p>Increased the training resolution (ver.1: 768, ver.2: 896)</p></li><li><p>Revised the tagging</p><ul><li><p>Removed the trigger word as well</p></li></ul></li><li><p>Reviewed the training parameters</p></li></ul><p></p><h2>Improvements in 2.0</h2><ul><li><p>It can reproduce a more 3D-like texture and stereoscopi effect than ver.1</p></li><li><p>LoRA can be applied without a trigger word</p></li><li><p>The style can be controlled using <code>3d</code> and <code>realistic</code> tags</p><ul><li><p>When added to Positive Prompt, it enhances the 3D feel</p></li><li><p>When added to Negative Prompt, it adds details such as clothing while maintaining the model's art style</p></li></ul></li><li><p>The issue of eroding the model's art style with tags such as <code>intricate</code>, <code>detailed</code> has been alleviated</p></li></ul><p></p><h2>Additional information</h2><p>The effect of LoRA was confirmed using the following my custom merged models:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/38606/alstroemeria-mix\">Alstroemeria Mix</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/38619/bougainvillea-mix\">Bougainvillea Mix</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/38636/chrysanthemum-mix\">Chrysanthemum Mix</a></p></li></ul><p></p><p></p><p></p><h2>High-poly 3D Model LoRA</h2><p>ãƒã‚¤ãƒãƒªã‚´ãƒ³ 3D ãƒ¢ãƒ‡ãƒ«ç”»åƒã‚’å­¦ç¿’ã—ãŸ LoRA ã§ã™ã€‚</p><p>3D ã‚‰ã—ã„ã‚¯ãƒªãƒ¼ãƒ³ã§é«˜ç²¾ç´°ãªè‚Œãƒ»é«ªã®è³ªæ„Ÿã‚„ã€è¡£æœã®ãƒ‡ã‚£ãƒ†ãƒ¼ãƒ«ã‚’ä¸ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</p><p></p><p>ver.2 ã®å­¦ç¿’æ™‚ã«å¾—ã‚‰ã‚ŒãŸæŠ€è¡“çš„çŸ¥è¦‹ã‚’ã¾ã¨ã‚ã¾ã—ãŸã®ã§ã€èˆˆå‘³ãŒã‚ã‚‹æ–¹ã¯æ¬¡ã®è¨˜äº‹ã‚’ã”è¦§ãã ã•ã„ã€‚</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://note.com/takumi__ncr/n/n2fb9d265ffa9\">https://note.com/takumi__ncr/n/n2fb9d265ffa9</a></p><p></p><h2>2.0 ã§ã®å¤‰æ›´ç‚¹</h2><ul><li><p>æ•™å¸«ç”»åƒã‚’å¢—ã‚„ã—ã¾ã—ãŸ</p></li><li><p>å­¦ç¿’è§£åƒåº¦ã‚’å‘ä¸Šã—ã¾ã—ãŸ (ver.1: 768, ver.2: 896)</p></li><li><p>ã‚¿ã‚°ä»˜ã‘ã‚’è¦‹ç›´ã—ã¾ã—ãŸ</p><ul><li><p>ãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚‚å‰Šé™¤ã—ã¾ã—ãŸ</p></li></ul></li><li><p>å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¦‹ç›´ã—ã¾ã—ãŸ</p></li></ul><p></p><h2>2.0 ã§ã®æ”¹å–„ç‚¹</h2><ul><li><p>ver.1 ã‚ˆã‚Šã‚‚ 3D ã‚‰ã—ã„ãƒ†ã‚¯ã‚¹ãƒãƒ£æ„Ÿã€å¥¥è¡Œãæ„ŸãŒå†ç¾ã§ãã¾ã™</p></li><li><p>ãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãªã—ã§ LoRA ã‚’é©ç”¨ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™</p></li><li><p><code>3d</code>, <code>realistic</code> ã‚¿ã‚°ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§çµµæŸ„ã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãŒå¯èƒ½ã§ã™</p><ul><li><p>Positive Prompt ã«å…¥ã‚ŒãŸå ´åˆã€ã‚ˆã‚Š 3D æ„Ÿã‚’å¼·åŒ–ã—ã¾ã™</p></li><li><p>Negative Prompt ã«å…¥ã‚ŒãŸå ´åˆã€ãƒ¢ãƒ‡ãƒ«ã®çµµæŸ„ã‚’ä¿ã¡ã¤ã¤ã€è¡£è£…ãªã©ã®ãƒ‡ã‚£ãƒ†ãƒ¼ãƒ«ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™</p></li></ul></li><li><p><code>intricate</code>, <code>detailed</code> ãªã©ã®ã‚¿ã‚°ã«ã‚ˆã£ã¦ãƒ¢ãƒ‡ãƒ«ã®çµµæŸ„ã‚’ä¾µé£Ÿã—ã¦ã—ã¾ã†å•é¡ŒãŒç·©å’Œã•ã‚Œã¾ã—ãŸ</p></li></ul><p></p><h2>ãã®ä»–</h2><p>LoRA ã®å‹•ä½œç¢ºèªã¯ä»¥ä¸‹ã®è‡ªä½œãƒãƒ¼ã‚¸ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦è¡Œã„ã¾ã—ãŸã€‚</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/38606/alstroemeria-mix\">Alstroemeria Mix</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/38619/bougainvillea-mix\">Bougainvillea Mix</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/38636/chrysanthemum-mix\">Chrysanthemum Mix</a></p></li></ul>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581470+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  }
]