[
  {
    "id": "257749",
    "prompt": "Pony Diffusion V6 XL\n<p><a target=\"_blank\" rel=\"ugc\" href=\"https://fictional.ai/?ref=v6-card\"><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0061ed7a-2afa-4513-b855-e0e82d78b3cb/width=525/0061ed7a-2afa-4513-b855-e0e82d78b3cb.jpeg\" /></a>(and don't worry, coming to your computer very soon - Astra)</p><p></p><h2 id=\"pony-diffusion-v6-is-a-versatile-sdxl-finetune-capable-of-producing-stunning-sfw-and-nsfw-visuals-of-various-anthro-feral-or-humanoids-species-and-their-interactions-based-on-simple-natural-language-prompts.-9rf16zav8\">Pony Diffusion V6 is a versatile SDXL finetune capable of producing stunning SFW and NSFW visuals of various anthro, feral, or humanoids species and their interactions based on simple natural language prompts.</h2><p>CHECK \"ABOUT THIS VERSION\" ON THE RIGHT IF YOU ARE NOT ON \"V6\" FOR IMPORTANT INFORMATION.</p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/pYsdjMfu3q\">Please join our Discord Server to support development of new versions of this model and get access to free SD bot </a>and <a target=\"_blank\" rel=\"ugc\" href=\"https://purplesmart.ai/collection/top?nsfw=0&amp;page=1&amp;model=11&amp;order=created_desc\">check out more examples of this model capabilities on our prompt sharing website </a>or <a target=\"_blank\" rel=\"ugc\" href=\"https://twitter.com/AstraliteHeart\">follow the author on Twitter</a>.</p><h2 id=\"important-information-rzlb1z46m\">Important information</h2><p></p><p><strong>Make sure you load this model with clip skip 2 (or -2 in some software), otherwise you will be getting low quality blobs.</strong></p><p></p><p><span style=\"color:rgb(219, 222, 225)\">This model supports a wide array of styles and aesthetics but provides an opinionated default prompt template that allows generation of high quality samples with no negative prompt and otherwise default settings</span></p><pre><code>score_9, score_8_up, score_7_up, score_6_up, score_5_up, score_4_up, just describe what you want, tag1, tag2</code></pre><p>(previous Pony Diffusion models used a simpler <code>score_9</code> quality modifier, the longer version of V6 XL version is a training issue that was too late to correct during training, you can still use <code>score_9</code> but it has a much weaker effect compared to full string. You can learn more about these tags <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/4248\">here</a>).</p><p></p><p>The model is designed to not need negative prompts in most cases and does not need other quality modifiers like \"hd\", \"masterpiece\", etc...</p><p></p><p>Other special data selection tags include, 'source_pony', 'source_furry', 'source_cartoon' and 'source_anime' and ratings of 'rating_safe', 'rating_questionable' and 'rating_explicit'.</p><p></p><p><strong>This model is capable of recognizing many popular and obscure characters and series.</strong></p><p></p><p>If you are looking specifically for pony style, I recommend using one of the two following templates `anthro/feral pony, rest of the prompt` or `source_pony, rest of the prompt`.</p><p></p><p>This model is trained on combination of natural language prompts and tags and is capable of understanding both, so describing intended result using normal language works in most cases, although you can add some tags after the main prompt to boost them.</p><p></p><p>Using Euler a with 25 steps and resolution of 1024px is recommended although model generally can do most supported SDXL resolution.</p><p></p><p>This model will sometimes generate pseudo signatures that are hard to remove even with negative prompts, this is unfortunately a training issue that would be corrected in future models. If that's an issue for you I suggest trying V5.5 or inpainting.</p><p></p><h2 id=\"special-thanks-a8immpgql\">Special thanks</h2><ul><li><p><strong>Iceman</strong> for helping to procure necessary training resources</p></li><li><p><strong>Haru</strong> for assistance with captioning efforts</p></li><li><p><strong>Cookie</strong> for technical expertise in training</p></li><li><p><strong>PSAI Server Subscribers</strong> for supporting the project costs</p></li><li><p><strong>PSAI Server Moderators</strong> for being vigilant and managing the community</p></li></ul><h2 id=\"technical-details-jb1ydvwaq\">Technical details</h2><p>The model has been trained on ~2.6M images aesthetically ranked based on authors personal preferences, with roughly 1:1 ratio between anime/cartoon/furry/pony datasets and 1:1 ratio between safe/questionable/explicit ratings. About 50% of all images has been captioned with high quality detailed captions, which results in very strong natural language capabilities.</p><p></p><p>All images has been trained with both captions (when available) and tags, artists' names have been removed and source data has been filtered based on our Opt-in/Opt-out <a target=\"_blank\" rel=\"ugc\" href=\"https://purplesmart.ai/artist\">program</a>. Any explicit content involving underage characters has been filtered out.</p><h2 id=\"license-ubky7ouqn\">License</h2><p>This model is licensed under a modified <span style=\"color:rgb(193, 194, 197)\">Fair AI Public License 1.0-SD</span><a target=\"_blank\" rel=\"ugc\" href=\"https://freedevproject.org/faipl-1.0-sd/\"> </a><span style=\"color:rgb(193, 194, 197)\">(</span><a target=\"_blank\" rel=\"ugc\" href=\"https://freedevproject.org/faipl-1.0-sd/\">https://freedevproject.org/faipl-1.0-sd/</a><span style=\"color:rgb(193, 194, 197)\">) license</span>.</p><p></p><p><strong>The following modifications have been added to <span style=\"color:rgb(193, 194, 197)\">Fair AI Public License</span>:</strong></p><p>You are not permitted to run inference of this model on websites or applications allowing any form of monetization (paid inference, faster tiers, etc.). This applies to any derivative models or model merges.</p><p>If you want to use this model commercially, please reach us at <a target=\"_blank\" rel=\"ugc\" href=\"mailto:contact@purplesmart.ai\">contact@purplesmart.ai</a>.</p><p>Explicit permission for commercial inference has been granted to <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/\">CivitAi </a>and <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/\"><u>Hugging Face</u></a>.</p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.580971+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "43331",
    "prompt": "majicMIX realistic 麦橘写实\n<p>V7 is here. So far so good for me.</p><h3 id=\"asian-alert!-n3n8dvt66\"><strong><span style=\"color:rgb(250, 82, 82)\">ASIAN ALERT!</span></strong></h3><h2 id=\"recommended-parameters-for-v7:-2wbt1xre9\"><span style=\"color:rgb(253, 126, 20)\">推荐参数 Recommended Parameters for V7:</span></h2><p>Sampler: <strong>Euler a, Euler, restart</strong></p><p>Steps: 20~40</p><p>Hires upscaler: <strong>ESRGAN 4x or 4x-UltraSharp or 8x_NMKD-Superscale_150000_G</strong></p><p>Hires upscale: 2+</p><p>Hires steps: 15+</p><p>Hires denoising strength: 0.05~0.5</p><p><strong>clip skip 2</strong></p><p></p><h3 id=\"after-detailer.-sy61gp8o5\"><strong>如果要修复脸部，请使用after detailer.</strong></h3><h3 id=\"if-your-face-comes-out-badly-use-after-detailer-instead-of-face-restoration.-032yvj7g2\"><strong>If your face comes out badly, use after detailer instead of face restoration.</strong></h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\"><strong>https://github.com/Bing-su/adetailer</strong></a></p><p></p><h3 id=\"dynamic-thresholdingcfg1~20-jn2df8b47\"><strong>我习惯开启Dynamic Thresholding来更好控制cfg值，1~20都可以尝试一下。</strong></h3><h3 id=\"use-dynmaic-thresholding-to-control-cfg.-you-can-try-from-1~20.-2tq8t65mn\"><strong>Use Dynmaic Thresholding to control CFG. You can try from 1~20.</strong></h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/mcmonkeyprojects/sd-dynamic-thresholding\">https://github.com/mcmonkeyprojects/sd-dynamic-thresholding</a></p><p></p><h3 id=\"bmab.-xwemseufr\"><strong>如果要添加滤镜效果、噪点，请使用BMAB.</strong></h3><h3 id=\"if-you-want-to-add-noise-like-me-use-bmab.-bozbavi5z\"><strong>If you want to add noise like me, use BMAB.</strong></h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/portu-sim/sd-webui-bmab\">GitHub - portu-sim/sd-webui-bmab: Auto masking and inpainting for person, face, hand. Resizing image using detection model.</a></p><p></p><hr /><p><strong>v2.5 is here</strong>. Note that this is not v7, but an upgrade for v2. V7 may need to address more issues, which I am still trying to do. In the process, I have created a model worth sharing.</p><p>This model can restore the light and shadow of the original majicmix v2, but with increased realism while still keeping the basic aesthetic of the face. I have tested other face loras and they work fine. Please use adetailer and put the face lora in it.</p><p>请注意，这不是v7，而是对v2的修缮。v7可能需要突破更多问题，这个目前我还在尝试。在这个过程中我融合出一个模型，我认为也值得分享。</p><p>本模型可以还原初代majicmix的光影，但是增加写实度，脸部还是保持基本调性的审美，我测试了其他脸部lora都没问题。请使用adetailer然后把脸部lora放在里面使用。</p><p></p><hr /><p>v5对我来说不够好，对你们来说也是的，而且不够写实。所以v6很迫切需要。用Euler画特写，用euler a 画其他的。不要！不要！不要开脸部修复！用adetailer来修脸。我的例图都用了。</p><p><strong>v6 is here</strong>. v5 is not good as I played for a while and see the results from yours. Therefore a v6 is urgent.</p><p>Use Euler for close up, and Euler a for others. Again, don't use facial restoration, use After detailer instead! All my samples used adetailer without lora.</p><p></p><hr /><p>第五版先行版来了，先把赛博永生小姐姐娜乌斯嘉融进来做个例子，也算是公测吧。</p><p>5th edtion is coming soon. I've posted a preview version with the face of nwsj.</p><p>推荐使用Euler作为采样器。</p><p>Use Euler as sampler.</p><p></p><hr /><h2 id=\"-ak6ows6o8\"><span style=\"color:rgb(250, 82, 82)\">听我一句劝，不要开脸部修复！</span></h2><h2 id=\"please-don't-use-face-restoration!-a55utx8rw\"><strong><span style=\"color:rgb(250, 82, 82)\">Please don't use Face Restoration!</span></strong></h2><p><strong>如果要修复脸部，请使用after detailer.</strong></p><p><strong>If your face comes out badly, use after detailer instead.</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\"><strong>https://github.com/Bing-su/adetailer</strong></a></p><p></p><p><strong>我习惯开启Dynamic Thresholding来更好控制cfg值，1~20都可以尝试一下。</strong></p><p><strong>Use Dynmaic Thresholding to control CFG. You can try from 1~20.</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/mcmonkeyprojects/sd-dynamic-thresholding\">https://github.com/mcmonkeyprojects/sd-dynamic-thresholding</a></p><p>很抱歉在之前的例图中我使用了分层的lora让大家困惑，也让大家复刻我的例图变得困难。所以新一版的例图我没有使用任何lora。想了解lora分层的可以参考：<a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/hako-mikan/sd-webui-lora-block-weight\">GitHub - hako-mikan/sd-webui-lora-block-weight</a></p><p>I apologize for using lora block weight in the example images of the previous edition, which confused most of you and made it difficult for you to replicate my examples. Therefore, in the newer editions, I did not use any lora in my showcase. If you would like to learn about lora block weight, please refer to: <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/hako-mikan/sd-webui-lora-block-weight\">https://github.com/hako-mikan/sd-webui-lora-block-weight</a></p><p></p><p></p><hr /><p><br />融合了多种模型，可以生成好看的脸部，也能有效应对暗部处理。远距离脸部需要inpaint以达成最好效果。也可以使用after detailer.</p><p>A good looking model, suitable for NSFW and dark scene (because I added noiseoffset). long-range facial detail require inpainting to achieve the best results. You can also use after detailer.<br /><br />推荐关键词 recommended positive prompts: <em>Best quality, masterpiece, ultra high res, (photorealistic:1.4), 1girl</em><br /><br />如果想要更暗的图像 if you want darker picture, add: <em>in the dark, deep shadow, low key</em>, etc.<br /><br />负面关键词 use <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4629/deep-negative-v1x\"><em>ng_deepnegative_v1_75t</em> </a>and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16993/badhandv4-animeillustdiffusion\"><em>badhandv4</em> </a>in negative prompt</p><p><br /><strong>I've used a bug-fixed version of DPM++ 2M Karras, you can check this out: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/35966/dpm-2m-alt-karras-sampler\">https://civitai.com/models/35966/dpm-2m-alt-karras-sampler</a></p><p>推荐参数Recommended Parameters:</p><p>Sampler: Euler a, Euler, DPM++ 2M Karras (bug-fixed) or DPM++ SDE Karras</p><p>Steps: 20~40</p><p>Hires upscaler: R-ESRGAN 4x+ or 4x-UltraSharp</p><p>Hires upscale: 2</p><p>Hires steps: 15</p><p>Denoising strength: 0.2~0.5</p><p>CFG scale: 6-8</p><p>clip skip 2<br /><br />basic formula:<br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/24591/kanpiromix\"><strong>KanPiroMix</strong></a> + <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/31473/xsmix\"><strong>XSMix</strong></a> + <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9871/chikmix\"><strong>ChikMix</strong></a></p><p><strong>关注我的TG频道看更多例图：</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://t.me/majic_NSFW\"><strong>https://t.me/majic_NSFW</strong></a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.580999+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "827184",
    "prompt": "WAI-NSFW-illustrious-SDXL\n<p>If you want to use more my checkpoint online generation, please visit here.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/u/762555264535746522\">https://tensor.art/u/762555264535746522</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.seaart.ai/models/detail/d8300cd33eb1ab8018baa6685ec4a7e9\">WAI-NSFW-illustrious-SDXL - SeaArt AI Model</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.shakker.ai/modelinfo/0f204323a06f40e18f8ffc5b1813df5a/WAI-NSFW-illustrious-SDXL-NSFW-illustrious-SDXL-NSFW-illustrious-SDXL-NSFW-illustrious-SDXL?from=personal_page\">WAI_NSFW-illustrious-SDXL_NSFW-illustrious-SDXL_NSFW-illustrious-SDXL_NSFW-illustrious-SDXL-Checkpoint-WAI-Shakker</a></p><hr /><h3 id=\"if-you-are-using-webui-please-be-sure-to-use-this-plugin-as-it-can-conveniently-generate-combinations-of-characters-and-actions.\"><span style=\"color:rgb(250, 82, 82)\"><strong>If you are using WEBUI, please be sure to use this plugin as it can conveniently generate combinations of characters and actions.</strong></span></h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/10754/wai-nsfw-illustrious-sdxl-v80-built-in-character-prompt-generator-v8\">WAI-NSFW-illustrious-SDXL V8.0 模型人物提示器 / Built-in Character Prompt Generator (對應V8以上版本) | Civitai</a></p><p><span style=\"color:rgb(250, 176, 5)\"><strong>This plugin can directly suggest thousands of existing character models, along with a feature for randomly selecting characters.</strong></span></p><p><span style=\"color:rgb(250, 176, 5)\"><strong>V8-V12 are all well compatible.</strong></span></p><h3 id=\"character-select-saa\"><span style=\"color:rgb(250, 82, 82)\"><strong>Character Select SAA</strong></span></h3><p><span style=\"color:rgb(250, 82, 82)\"><strong>This is a Stand Alone App with AI prompt, Semi-auto Tag Complete and ComfyUI/WebUI API support.</strong></span></p><p><span style=\"color:rgb(250, 82, 82)\"><strong>Now supports 5058 (includes multiple costumes) Character list.</strong></span></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/mirabarukaso/character_select_stand_alone_app\">https://github.com/mirabarukaso/character_select_stand_alone_app</a></p><p><span style=\"color:rgb(250, 176, 5)\">One-Click embedded package<br />In case you don't know how to build your own Python enverment, try the embeded_env_for_SAA<br />Down and unzip to your computer<br />Db-click #run_XX.bat</span></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/datasets/flagrantia/character_select_stand_alone_app/resolve/main/embeded_env_for_SAA.zip\">https://huggingface.co/datasets/flagrantia/character_select_stand_alone_app/resolve/main/embeded_env_for_SAA.zip</a><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/datasets/flagrantia/character_select_stand_alone_app/resolve/main/embeded_env_for_SAA.zip￼￼【群主】oOk̥ͣͫͥami(4955241)\"><br /></a>下载解压到任意目录，运行 #run_CN  <br />Download and extract to any directory. Run #run_CN or #run_EN</p><hr /><h2 id=\"online-quick-search-character\"><strong>Online Quick search character</strong></h2><h2 id=\"character-select-saa-a-hugging-face-space-by-flagrantia\"><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/spaces/flagrantia/character_select_saa\"><strong>Character Select Saa - a Hugging Face Space by flagrantia</strong></a></h2><p></p><h3 id=\"please-do-not-add-too-many-quality-and-aesthetic-related-tags-nor-overly-long-negative-prompts-as-this-will-actually-reduce-image-quality-and-make-it-more-blurry.\"><span style=\"color:rgb(250, 176, 5)\"><strong>Please do not add too many quality and aesthetic-related tags, nor overly long negative prompts, as this will actually reduce image quality and make it more blurry.</strong></span></h3><p></p><h1 id=\"v15\"><span style=\"color:rgb(250, 82, 82)\"><strong>v15</strong></span></h1><p></p><ol><li><p><span style=\"color:rgb(190, 75, 219)\"><strong>Base ill 1.0</strong></span></p></li><li><p><span style=\"color:rgb(190, 75, 219)\"><strong>added data (roughly up to May 2025, mainly popular social games and some anime).</strong></span><span style=\"color:rgb(250, 82, 82)\"><strong><u>PS:</u></strong></span><span style=\"color:rgb(250, 82, 82)\"><strong><u>The new character data hasn’t been fully fixed yet. I’ll continue to improve it in the upcoming versions.</u></strong></span></p></li><li><p><span style=\"color:rgb(190, 75, 219)\"><strong>Data adjustment, trying to reduce the chance of watermarks appearing.</strong></span></p></li></ol><h3 id=\"recommended-settings:\"><span style=\"color:rgb(230, 73, 128)\">Recommended settings:</span></h3><p><span style=\"color:rgb(250, 82, 82)\">Steps: </span><span style=\"color:rgb(250, 176, 5)\">15-30</span></p><p><span style=\"color:rgb(250, 82, 82)\">CFG scale: </span><span style=\"color:rgb(250, 176, 5)\">5-7</span></p><p><span style=\"color:rgb(250, 82, 82)\">Sampler: </span><span style=\"color:rgb(250, 176, 5)\">Euler a</span></p><p></p><p><span style=\"color:rgb(250, 82, 82)\">The VAE is already integrated, please do not ask such questions anymore.</span></p><p></p><p><span style=\"color:rgb(250, 176, 5)\">use size larger than1024x1024 for the original dimensions.</span></p><p></p><p><span style=\"color:rgb(190, 75, 219)\">Hires upscale: 1.5, Hires steps: 20, Hires upscaler: R-ESRGAN 4x+ Anime6B,Denoising strength: 0.35~0.5</span></p><p></p><p><span style=\"color:rgb(130, 201, 30)\">There are four safety rating tags: </span><span style=\"color:rgb(250, 176, 5)\"><strong>general, sensitive, nsfw,explicit</strong></span><span style=\"color:rgb(130, 201, 30)\">.<br />Users are expected to consciously add \"nsfw\" to negative prompts to filter inappropriate content.</span></p><p></p><p>Positive Prompt</p><pre><code>masterpiece,best quality,</code></pre><p></p><p>Negative Prompt</p><pre><code>bad quality,worst quality,worst detail,</code></pre><h3></h3><p></p><hr /><h1 id=\"v5-v14-user-manual\">V5-V14 User Manual</h1><h3 id=\"v1-v4-are-outdatedplease-do-not-download-them-anymore.\"><span style=\"color:rgb(255, 255, 255)\">V1-V4 are outdated,please do not download them anymore.</span></h3><p></p><p><span style=\"color:rgb(190, 75, 219)\"><br /></span></p><p></p><p><span style=\"color:rgb(255, 255, 255)\">This is a list of characters that have been tested and are implementable on V11.</span></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/datasets/sieecc/WAI-NSFW-illustrious-SDXL/tree/main\">sieecc/WAI-NSFW-illustrious-SDXL at main</a></p><p><span style=\"color:rgb(255, 255, 255)\">These are just temporary and not all tests have been completed yet; more will be added subsequently.</span></p><p></p><p></p><h3 id=\"recommended-settings:\"><span style=\"color:rgb(230, 73, 128)\">Recommended settings:</span></h3><p><span style=\"color:rgb(250, 82, 82)\">Steps: </span><span style=\"color:rgb(250, 176, 5)\">25-40</span></p><p><span style=\"color:rgb(250, 82, 82)\">CFG scale: </span><span style=\"color:rgb(250, 176, 5)\">5-7</span></p><p><span style=\"color:rgb(250, 82, 82)\">Sampler: </span><span style=\"color:rgb(250, 176, 5)\">Euler a</span></p><p></p><p><span style=\"color:rgb(250, 82, 82)\">The VAE is already integrated, please do not ask such questions anymore.</span></p><p></p><p><span style=\"color:rgb(250, 176, 5)\">use size larger than1024x1024 for the original dimensions.</span></p><p></p><p><span style=\"color:rgb(190, 75, 219)\">Hires upscale: 1.5, Hires steps: 20, Hires upscaler: R-ESRGAN 4x+ Anime6B,Denoising strength: 0.35~0.5</span></p><p></p><p><span style=\"color:rgb(130, 201, 30)\">There are four safety rating tags: </span><span style=\"color:rgb(250, 176, 5)\"><strong>general, sensitive, nsfw,explicit</strong></span><span style=\"color:rgb(130, 201, 30)\">.<br />Users are expected to consciously add \"nsfw\" to negative prompts to filter inappropriate content.</span></p><p></p><p>Positive Prompt</p><pre><code>masterpiece,best quality,amazing quality,</code></pre><p></p><p>Negative Prompt</p><pre><code>bad quality,worst quality,worst detail,sketch,censor,</code></pre><h3></h3><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581010+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "4384",
    "prompt": "DreamShaper\n<h1 id=\"heading-133\">DreamShaper - V∞!</h1><h3 id=\"heading-134\">Please check out my other <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Lykon/models?tag=base+model\">base models</a>, including <u>SDXL</u> ones!</h3><p><strong>Check the version description below (bottom right) for more info and add a ❤️ to receive future updates.</strong><br /><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> 🅿️ to get exclusive tips and tutorials, or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> ☕</strong><br />🎟️ <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/lykon/commissions\"><strong>Commissions on Ko-Fi</strong></a></p><p></p><h3 id=\"heading-135\">Join my <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/uAhsmDq7GC\">Discord Server</a></h3><p><strong><span style=\"color:rgb(253, 126, 20)\">For LCM read the version description.</span></strong></p><p></p><p><strong>Available on the following websites with GPU acceleration:</strong></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/\"><strong>Mage.space</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/4zdwGOB\"><strong>Sinkin.ai</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://randomseed.co/model/20?via=lykon\"><strong>RandomSeed</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"http://AnimeMaker.ai\"><strong>AnimeMaker.ai</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://rendernet.ai/creator/Lykon\"><strong>Rendernet.ai</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/u/600303455797521413\">https://tensor.art/u/600303455797521413</a></p></li></ul><p><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/spaces/Lykon/DreamShaper-webui\"><strong>Live demo available on HuggingFace</strong></a><strong> (CPU is slow but free).</strong></p><p><strong>New Negative Embedding for this: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/72437?modelVersionId=77169\"><strong>Bad Dream</strong></a><strong>.</strong><br /></p><h2 id=\"heading-210\"><strong>Message from the author</strong></h2><p>Hello hello, my fellow <strong>AI Art</strong> lovers. Version 8 just released. Did you like the cover with the ∞ symbol? This version holds a special meaning for me.<br /><br />DreamShaper started as a model to have an alternative to MidJourney in the open source world. I didn't like how MJ was handled back when I started and how closed it was and still is, as well as the lack of freedom it gives to users compared to SD. Look at all the tools we have now from TIs to LoRA, from ControlNet to Latent Couple. We can do anything. The purpose of DreamShaper has always been to make \"a better Stable Diffusion\", a model capable of doing everything on its own, to <em>weave dreams</em>. <br />With SDXL (and, of course, <strong>DreamShaper XL</strong> 😉) just released, I think the \"<em>swiss knife</em>\" type of model is closer then ever. That model architecture is big and heavy enough to accomplish that the pretty easily. But what about all the resources built on top of SD1.5? Or all the users that don't have 10GB of vram? It might just be a bit too early to let go of DreamShaper. <br /><br />Not before one. Last. Push. <br /><br />And here it is, I hope you enjoy. And thank you for all the support you've given me in the recent months.</p><p><strong>PS: </strong>the primary goal is still towards art and illustrations. Being good at everything comes second.</p><p><br /><strong>Suggested settings:</strong><br />- I had CLIP skip 2 on some pics, the model works with that too. <br />- I have <em>ENSD</em> set to 31337, in case you need to reproduce some results, but it doesn't guarantee it. <br />- All of them had <strong>highres.fix</strong> or img2img at higher resolution. Some even have ADetailer. Careful with that tho, as <strong><span style=\"color:rgb(250, 82, 82)\">it tends to make all faces look the same</span>.</strong><br />- I <strong>don't use \"restore faces\"</strong>.</p><p><strong>For old versions:</strong><br />- Versions &gt;4 require no LoRA for anime style. For version 3 I suggest to use one of these LoRA networks at 0.35 weight: <br />-- <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4219\">https://civitai.com/models/4219</a> (the girls with glasses or if it says <code>wanostyle</code>)<br />-- <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/closertodeath/dpepmkmp/blob/main/last.pt\">https://huggingface.co/closertodeath/dpepmkmp/blob/main/last.pt</a> (if it says <code>mksk style</code>)<br />-- <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4982/anime-screencap-style-lora\">https://civitai.com/models/4982/anime-screencap-style-lora</a> (not used for any example but works great).</p><h3 id=\"heading-252\"><strong>LCM</strong></h3><p>Being a distilled model it has lower quality compared to the base one. However it's MUCH faster and perfect for video and real time applications.</p><p>Use it with 5-15 steps, ~2 cfg. <strong><u><span style=\"color:rgb(253, 126, 20)\">IT WORKS ONLY WITH LCM SAMPLER</span></u></strong> (as of December 2023, Auto1111 requires an external plugin for it).</p><p>Comparison with V7 LCM <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/951513\">https://civitai.com/posts/951513</a><br /><br /><strong>NOTES</strong></p><ul><li><p>Version 8 focuses on improving what V7 started. Might be harder to do photorealism compared to realism focused models, as it might be hard to do anime compared to anime focused models, but it can do both pretty well if you're skilled enough. <u>Check the examples!</u></p></li><li><p>Version 7 improves lora support, NSFW and realism. If you're interested in \"absolute\" realism, try <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/81458\">AbsoluteReality</a>.</p></li><li><p>Version 6 adds more lora support and more style in general. It should also be better at generating directly at 1024 height (but be careful with it). 6.x are all improvements.</p></li><li><p>Version 5 is the best at photorealism and has noise offset.</p></li><li><p>Version 4 is much better with anime (can do them with no LoRA) and booru tags. IT might be harder to control if you're used to caption style, so you might still want to use version 3.31.</p></li><li><p>V4 is also better with eyes at lower resolutions. Overall is like a \"fix\" of V3 and shouldn't be too much different.</p></li><li><p>Results of version 3.32 \"clip fix\" will vary from the examples (produced on 3.31, which I personally prefer).</p></li><li><p>I get no money from any generative service, but you can buy me a coffee.</p></li><li><p>You should use 3.32 for mixing, so the clip error doesn't spread.</p></li><li><p><strong>Inpainting models are only for inpaint and outpaint, not txt2img or mixing. </strong><br /></p></li></ul><p><strong>Original v1 description:</strong> <br />After a lot of tests I'm finally releasing my <s>mix</s> model. This started as a model to make good portraits that do not look like cg or photos with heavy filters, but more like actual paintings. The result is a model capable of doing portraits like I wanted, but also great backgrounds and anime-style characters. Below you can find some suggestions, including LoRA networks to make anime style images. <br /><br />I hope you'll enjoy it as much as I do.<br /></p><p>Official HF repository: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Lykon/DreamShaper\">https://huggingface.co/Lykon/DreamShaper</a><br /></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581017+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "4201",
    "prompt": "Realistic Vision V6.0 B1\n<p><strong><span style=\"color:rgb(21, 170, 191)\">Check my exclusive models on Mage: </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/4371756b27bf52e7a1146dc6fe2d969c\"><strong><span style=\"color:rgb(230, 73, 128)\">ParagonXL</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/df67a9f27f19629a98cb0fb619d1949a\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/d8db06ae964310acb4e090eec03984df\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL Lightning</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/541da1e10976ab82976a5cacc770a413\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL V2</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/a56d2680c464ef25b8c66df126b3f706\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL Pony</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/b0ab6733c3be2408c93523d57a605371\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL Pony Lightning</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/e3b01cd493ed86ed8e4708751b1c9165\"><strong><span style=\"color:rgb(230, 73, 128)\">RealDreamXL</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/ef062fc389c3f8723002428290c1158c\"><strong><span style=\"color:rgb(230, 73, 128)\">RealDreamXL Lightning</span></strong></a></p><p><strong><span style=\"color:rgb(130, 201, 30)\">Recommendations for using the Hyper model:</span><br /><span style=\"color:rgb(130, 201, 30)\">Sampler = </span><u><span style=\"color:rgb(130, 201, 30)\">DPM SDE++ Karras</span></u><span style=\"color:rgb(130, 201, 30)\"> or </span><u><span style=\"color:rgb(130, 201, 30)\">another</span></u><span style=\"color:rgb(130, 201, 30)\"> / 4-6+ steps<br />CFG Scale = 1.5-2.0 (</span><u><span style=\"color:rgb(130, 201, 30)\">the lower the value, the more mutations, but the less contrast</span></u><span style=\"color:rgb(130, 201, 30)\">)</span></strong></p><p><strong><span style=\"color:rgb(130, 201, 30)\">I also recommend using </span><u><span style=\"color:rgb(130, 201, 30)\">ADetailer</span></u><span style=\"color:rgb(130, 201, 30)\"> for generation (some examples were generated with ADetailer, this will be noted in the image comments).</span></strong></p><p>This model is available on <a target=\"_blank\" rel=\"ugc\" href=\"http://Mage.Space\"><strong>Mage.Space</strong></a><strong> (main sponsor)</strong>.<br />You can also support me directly on <a target=\"_blank\" rel=\"ugc\" href=\"https://boosty.to/sg_161222\"><strong><u><span style=\"color:rgb(250, 176, 5)\">Boosty</span></u></strong></a>.</p><pre><code>Realistic Vision V6.0 (B2 - Full Re-train) Status (Updated: Apr. 4, 2024):\n- Training Images: +3400 (B1: 3000)\n- Training Steps: +724k (B1: 664k)\n- Approximate percentage of completion: ~30%</code></pre><p>All models, including <strong>Realistic Vision (VAE / noVAE)</strong> are also on <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/SG161222\"><strong>Hugging Face</strong></a></p><p><span style=\"color:rgb(44, 45, 46)\">ᅠ</span></p><p><strong>Please read this! How to remove strong contrast.</strong></p><p>To make the image less contrasty you can use LoRA <strong>[</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/58390/detail-tweaker-lora-lora\"><strong>Detail Tweaker LoRA</strong></a><strong>]</strong> in a negative value.</p><p><span style=\"color:rgb(44, 45, 46)\">ᅠ</span></p><p><strong><span style=\"color:rgb(253, 126, 20)\">Orange Color</span></strong> <strong>= Optional</strong></p><p><span style=\"color:rgb(44, 45, 46)\">ᅠ</span></p><p><strong>I use this template to get good generation results:</strong></p><p><span style=\"color:rgb(44, 45, 46)\">ᅠ</span></p><p><strong>Prompt:</strong></p><p>RAW photo, <em>subject</em>, 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3</p><p><span style=\"color:rgb(44, 45, 46)\">ᅠ</span></p><p><strong>Negative Prompt:</strong></p><p></p><ul><li><p>(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime), text, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/72437/baddream-unrealisticdream-negative-embeddings\"><strong><span style=\"color:rgb(253, 126, 20)\">UnrealisticDream</span></strong></a></p><p></p></li><li><p>(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime, mutated hands and fingers:1.4), (deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs, mutation, mutated, ugly, disgusting, amputation, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/72437/baddream-unrealisticdream-negative-embeddings\"><strong><span style=\"color:rgb(253, 126, 20)\">UnrealisticDream</span></strong></a></p></li></ul><p><span style=\"color:rgb(44, 45, 46)\">ᅠ</span></p><p><strong>Euler A or DPM++ SDE Karras</strong></p><p><strong>CFG Scale 3,5 - 7</strong></p><p><strong><span style=\"color:rgb(253, 126, 20)\">Hires. fix</span> with </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/lokCX/4x-Ultrasharp/tree/main\"><strong><span style=\"color:rgb(253, 126, 20)\">4x-UltraSharp upscaler</span></strong></a></p><p><strong>Denoising strength <span style=\"color:rgb(253, 126, 20)\">0.25-0.45</span></strong></p><p><strong>Upscale by 1.1-2.0</strong></p><p><strong>Clip Skip 1-2</strong></p><p><strong><span style=\"color:rgb(253, 126, 20)\">ENSD 31337</span></strong></p><p><span style=\"color:rgb(44, 45, 46)\">ᅠ</span></p><p><strong>Thanks to the creators of these models for their work. Without them it would not have been possible to create this model.</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1173?modelVersionId=4635\"><strong>HassanBlend 1.5.1.2</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/sdhassan\"><strong>sdhassan</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2661?modelVersionId=15640\"><strong>Uber Realistic Porn Merge (URPM)</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/saftle\"><strong>saftle</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3666?modelVersionId=4048\"><strong>Protogen x3.4 (Photorealism)</strong></a><strong> + </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3816?modelVersionId=4229\"><strong>Protogen x5.3 (Photorealism)</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/darkstorm2150\"><strong>darkstorm2150</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3950?modelVersionId=5180\"><strong>Art &amp; Eros (aEros)</strong></a><strong> + </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1654?modelVersionId=1798\"><strong>RealEldenApocalypse</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/aine_captain\"><strong>aine_captain</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3811?modelVersionId=4224\"><strong>Dreamlike Photoreal 2.0</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/sviasem\"><strong>sviasem</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3758?modelVersionId=4167\"><strong>HASDX</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/bestjammer\"><strong>bestjammer</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1265/analog-diffusion\"><strong>Analog Diffusion</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/wavymulder\"><strong>wavymulder</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4041/woopwoop-photo\"><strong>WoopWoop-Photo</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/zoidbb\"><strong>zoidbb</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16804?modelVersionId=29682\"><strong>Life Like Diffusion</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/lutherjonna409\"><strong>lutherjonna409</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/81458?modelVersionId=86437\"><strong>AbsoluteReality</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Lykon\"><strong>Lykon</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/15003?modelVersionId=89680\"><strong>CyberRealistic</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Cyberdelia\"><strong>Cyberdelia</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8030?modelVersionId=101080\"><strong>Analog Madness</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/CornmeisterNL\"><strong>CornmeisterNL</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/57319/a-zovya-photoreal\"><strong>A-Zovya Photoreal</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Zovya\"><strong>Zovya</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/28059?modelVersionId=109115\"><strong>ICBINP - \"I Can't Believe It's Not Photography\"</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/residentchiefnz\"><strong>residentchiefnz</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/25694?modelVersionId=105035\"><strong>epiCRealism</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/epinikion\"><strong>epinikion</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/46422?modelVersionId=106157\"><strong>Juggernaut</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/KandooAI\"><strong>KandooAI</strong></a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581023+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "7808",
    "prompt": "EasyNegative\n<p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/datasets/gsdf/EasyNegative\"><strong>Original Hugging Face Repository</strong></a><br /><strong>Counterfeit-V3 (which has 2.5 and 2.5 as well) on Civitai - </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4468/counterfeit-v25\"><strong>https://civitai.com/models/4468/counterfeit-v25</strong></a><br /><strong>If you like this embedding, please consider taking the time to give the repository a like and browsing their other work on HuggingFace.</strong><br /></p><p><strong>This embedding should be used in your NEGATIVE prompt. Adjust the strength as desired (seems to scale well without any distortions), the strength required may vary based on positive and negative prompts. Use the EasyNegative_pt (PickleTensors) version if you are unable to use SafeTensors embeddings.</strong><br /><br /><strong>Samples are, in order:</strong></p><ol><li><p><strong>sample01 - Counterfeit-V2.0.safetensors</strong></p></li><li><p><strong>sample02 - AbyssOrangeMix2_sfw.safetensors</strong></p></li><li><p><strong>sample03 - anything-v4.0-pruned.safetensors</strong></p></li><li><p><strong>Strength comparison using AbyssOrangeMix2_sfw.</strong></p></li></ol><p><br /><strong>From Author</strong><br />\"This is a Negative Embedding trained with Counterfeit. Please use it in the \"\\stable-diffusion-webui\\embeddings\" folder. It can be used with other models, but the effectiveness is not certain.\"</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581027+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "4468",
    "prompt": "Counterfeit-V3.0\n<p>high quality anime style model.</p><p>Support☕ <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/sfa837348\">https://ko-fi.com/sfa837348</a></p><p>more info. <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/gsdf/Counterfeit-V2.0\">https://huggingface.co/gsdf/Counterfeit-V2.0</a></p><p>Verson2.5 <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/gsdf/Counterfeit-V2.5\">https://huggingface.co/gsdf/Counterfeit-V2.5</a></p><p>Verson3.0 <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/gsdf/Counterfeit-V3.0\">https://huggingface.co/gsdf/Counterfeit-V3.0</a></p><p>EasyNegative <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/datasets/gsdf/EasyNegative\">https://huggingface.co/datasets/gsdf/EasyNegative</a></p><p>(Use clip: openai/clip-vit-large-patch14-336)<br />EasyNegative(Negative Embedding) <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/datasets/gsdf/EasyNegative\">https://huggingface.co/datasets/gsdf/EasyNegative</a></p><p></p><p><span style=\"color:rgb(209, 213, 219)\">Official hosting for online AI image generator. </span></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://rendernet.ai/\">https://rendernet.ai/</a></p></li></ul>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581032+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "7240",
    "prompt": "MeinaMix\n<p><strong>MeinaMix objective </strong>is to be<strong> </strong>able to do good art with little prompting.<br /><span style=\"color:rgb(193, 194, 197)\">I have a </span><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/F6yeQtEQ98\">discord</a><span style=\"color:rgb(193, 194, 197)\"> where you can </span><strong>share images</strong><span style=\"color:rgb(193, 194, 197)\">, </span><strong>discuss prompt</strong><span style=\"color:rgb(193, 194, 197)\"> and </span><strong>ask for help</strong><span style=\"color:rgb(193, 194, 197)\">. </span><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/F6yeQtEQ98\">https://discord.gg/meinaverse</a><br /><span style=\"color:rgb(193, 194, 197)\">我有个可以让你分享图片和参与讨论与询问问题的discord群。</span><br /><br />I also have a <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/meina\"><strong>ko-fi</strong></a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/MeinaMix\"><strong>Patreon</strong></a> page where you can support me or buy me a coffee &lt;3 , <strong>it will be very much appreciated:</strong><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/meina\"><strong>https://ko-fi.com/meina</strong></a><strong> and </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/MeinaMix\"><strong>https://www.patreon.com/MeinaMix</strong></a><br /><br /><strong>MeinaMix is officially hosted for online generation in:</strong></p><p>-<strong> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.seaart.ai/models/detail/3fae6b919ed209006e0a56248183fdff\">SeaArt</a><br />- <a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/e151cb844760205954e7f7b130fcc525\">Mage.space</a> ( with animate feature )<br /><br /><strong>MeinaMix and the other of Meinas will ALWAYS be FREE.</strong><br /><strong>Cover image lora made by: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/FallenIncursio\">FallenIncursio | Civitai</a><br /><br /><strong>Recommendations of use:</strong><br />--------------------------------------------------------------------------------<br /><strong>Enable Quantization in K samplers.</strong><br /><br /><strong>Hires.fix is needed for prompts where the character is far away</strong> in order to make decent images, it drastically improve the quality of face and eyes!<br />---------------------------------------------<br /><strong>Recommended parameters:</strong><br /><strong>Sampler:</strong> DPM++ SDE Karras: 20 to 30 steps.<br /><strong>Sampler:</strong> DPM++ 2M Karras: 20 to 60 steps.<br /><strong>Sampler:</strong> Euler a: 40 to 60 steps.<br /><strong>CFG Scale:</strong> 4 to 9.<br /><strong>Resolutions:</strong> 512x768, 512x1024 for Portrait!<br /><strong>Resolutions: </strong>768x512, 1024x512, 1536x512 for Landscape!<br /><strong>Hires.fix:</strong> R-ESRGAN 4x+Anime6b, with 10 steps at 0.3 up to 0.6 denoising.<br /><strong>Clip Skip:</strong> 2.<br /><strong>Negatives:</strong> ' (worst quality, low quality), (zombie, interlocked fingers) '<br /><strong>Negatives if you can't use Hires.fix:</strong><br />'(worst quality:1.6, low quality:1.6), (zombie, sketch, interlocked fingers, comic)'<br />--------------------------------------------------------------------------------<br /><br /><strong>In the merged models list: MeinaMix V1~11, MeinaPastel V3~6, MeinaHentai V2~5, Night Sky YOZORA Style Model, PastelMix, Facebomb, MeinaAlterV3 </strong>i do not have the exact recipe because i did multiple mixings using block weighted merges with multiple settings and kept the better version of each merge.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581036+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "7371",
    "prompt": "ReV Animated\n<p><em>April 28, 2024: added V2 Rebirth pruned</em></p><h1 id=\"heading-46\"><span style=\"color:rgb(64, 192, 87)\">v2:REBIRTH</span></h1><p><span style=\"color:rgb(230, 73, 128)\">Thanks to </span><span style=\"color:rgb(250, 82, 82)\">S6yx</span><span style=\"color:rgb(230, 73, 128)\"> for the creation of this beautiful model. Enjoyed by millions. With their permission, I, </span><span style=\"color:rgb(250, 82, 82)\">Zovya</span><span style=\"color:rgb(230, 73, 128)\">, will be maintaining it moving forward.</span></p><p></p><p><em>April 4, 2024: fp16 and +VAE added</em></p><p><em>April 2, 2024: Rebirth</em></p><p><em>Update 3: Disclaimer/Permissions updated</em></p><p><em>Update 2: I am no longer maintaining/updating this model</em></p><p><em>Update 1: I've been a bit burnt out on SD model development (SD in general tbh) and that is the reason there have not been an update. Looking to come back around and develop again by next month or so.Thank you everyone who sends reviews and enjoy my model</em><br /></p><p><strong>Pay attention to the <em><u>About this version</u></em></strong> <strong>section </strong>of model page<strong> for specific version information. ➡️➡️➡️➡️➡️</strong></p><h3 id=\"heading-416\"><br /><u>Model Overview:</u></h3><ul><li><p><u>rev</u> or <u>revision</u>: The concept of how the model generates images is likely to change as I see fit.</p></li><li><p><u>Animated</u>: The model has the ability to create 2.5D like image generations. This model is a checkpoint merge, meaning it is a product of other models to create a product that derives from the originals.</p></li><li><p>Kind of generations:</p><ul><li><p>Fantasy</p></li><li><p>Anime</p></li><li><p>semi-realistic</p></li><li><p><em>decent Landscape</em></p></li></ul></li><li><p>LoRA friendly</p></li><li><p>It works <strong><em><u>best on these resolution dimensions:</u></em></strong></p><ul><li><p>512x512</p></li><li><p>512x768</p></li><li><p>768x512</p></li></ul></li></ul><p></p><h3 id=\"heading-417\"><u>VAE</u>:</h3><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs/blob/main/VAEs/orangemix.vae.pt\"><u>orangemix.vae.pt</u></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/tree/main/vae\">kl-f8-anime2.ckpt</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/NoCrypt/blessed_vae/blob/main/blessed2.vae.pt\">Blessed2.vae.pt</a></p><p><br /></p></li></ul><h3 id=\"heading-418\"><u>Prompting</u>:</h3><ul><li><p><strong>Order matters</strong> - words near the front of your prompt are weighted more heavily than the things in the back of your prompt.</p></li><li><p><strong>Prompt order</strong> - content type &gt; description &gt; style &gt; composition</p></li><li><p><strong>This model likes</strong>: ((best quality)), ((masterpiece)), (detailed) in beginning of prompt if you want anime-2.5D type</p></li><li><p>This model does great on<strong> <u>PORTRAITS</u></strong></p></li></ul><p></p><p><strong><u>Negative Prompt Embeddings:</u></strong></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/embed/EasyNegative/tree/main\">EasyNegative</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4629/deep-negative-v1x\">Deep Negative</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/embed/bad_prompt/blob/main/bad_prompt_version2.pt\">bad_prompt_version2</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nick-x-hacker/bad-artist/blob/main/bad-artist.pt\">bad-artist</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nick-x-hacker/bad-artist/blob/main/bad-artist-anime.pt\">bad-artist-anime</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/p1atdev/badquality/tree/main\">bad-quality</a></p></li><li><p>Make use of weights in negative prompts (i.e (worst quality, low quality:1.4))</p><p></p></li></ul><p></p><h3 id=\"heading-419\"><u>Video Features</u></h3><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://youtu.be/Nl43zR5dVuM?t=192\">Olivio Sarikas - Why Is EVERYONE Using This Model?! - Rev Animated for Stable Diffusion / A1111</a></p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/watch?v=A6dQPMy_tHY\">Olivio Sarikas - ULTRA SHARP Upscale! - Don't miss this Method!!! / A1111 - NEW Model</a><br /><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/watch?v=ezNDCWhv4pQ\">AMAZING SD Models - And how to get the MOST out of them!</a></p><p></p><p></p><h2 id=\"heading-420\"><strong><u>Disclaimer (Updated 10/31/2023):</u></strong><br /></h2><p>The license type is <a target=\"_blank\" rel=\"ugc\" href=\"https://creativecommons.org/licenses/by-nc-nd/4.0\">CC BY-NC-ND 4.0</a> <br /><strong>Do not sell</strong> this model on any website without permissions from creator (me)</p><p><strong>Credit</strong> me if you use my model in your own merges</p><p><strong><u>You can use derivative models which uses ReV Animated for Buzz points and site-based currency that does not convert over to real world currency.</u></strong></p><p>Do not use this model to <strong><u>monetize</u></strong> on other platforms without expressed written consent. <br /><br /></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581040+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "122359",
    "prompt": "Detail Tweaker XL\n<p>Detail tweaker for SDXL.</p><p>Works with weights [-3, 3]</p><p>Use positive weight to increase details and negative weight to reduce details.</p><p>Good weight depends on your prompt and number of sampling steps, I recommend starting at 1.5 and then adjusting it.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581043+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "288584",
    "prompt": "AutismMix SDXL\n<p>Mix of pony with some stuff. It's an attempt at making pony more predictable and less dependent on schizo negatives without removing its comprehension and artist knowledge. Personally I'm using AutismMix_confetti for general use and AutismMix_pony for certain loras. If you want to train a lora on top of autism I recommend doing so in the AutismMix_pony version for better compatibility. The Lightning versions require specific settings to work, read the \"about model\" information under download.</p><p></p><p>What is the difference between the models:</p><p>AutismMix_confetti is a small amount of AnimeConfettiTune and AutismMix_pony. Has less style swing than pony and better hands. I prefer this one.</p><p>AutismMix_pony is a merge of ponyv6 with loras, its more compatible with certain styles made for the base ponydiffusion model.</p><p>AutismMix_DPO is AutismMix_confetti+DPO lora, made by request. Very similar to confetti version.</p><p></p><p>Add 3d to negs if you want a more traditional anime style. Quality tags should be same as ponyv6, but feel free to experiment: \"score_9, score_8_up, score_7_up, score_6_up, score_5_up, score_4_up, source_anime, BREAK\"</p><p>From my testing schizo negatives and those negative embeds made for SDXL/pony make it worse, but do whatever you want.</p><p>If you have any issues running this model I suggest using this webui: <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/lllyasviel/stable-diffusion-webui-forge\">https://github.com/lllyasviel/stable-diffusion-webui-forge</a></p><p>As well as this extension if you get noise outputs:<br /><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/hako-mikan/sd-webui-prevent-artifact\">https://github.com/hako-mikan/sd-webui-prevent-artifact</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581046+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "58390",
    "prompt": "Detail Tweaker LoRA (细节调整LoRA)\n<p>HF: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/OedoSoldier/detail-tweaker-lora\">https://huggingface.co/OedoSoldier/detail-tweaker-lora</a></p><p>This is a LoRA for enhancing/diminishing detail while keeping the overall style/character; it works well with all kinds of base models (incl anime &amp; realistic models)/style LoRA/character LoRA, etc.</p><p>Apply your own weight; this LoRA can be utilized for any weight up/down to 2/-2!</p><p><strong>Note: use a negative weight to reduce details!</strong></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581049+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "133005",
    "prompt": "Juggernaut XL\n<p><strong><u>Updated the Prompting Guide</u></strong></p><p><span style=\"color:rgb(219, 222, 225)\">For business inquires, commercial licensing, custom models, and consultation contact me under </span><a target=\"_blank\" rel=\"ugc\" href=\"mailto:juggernaut@rundiffusion.com\"><span style=\"color:rgb(219, 222, 225)\">juggernaut@rundiffusion.com</span></a></p><p><span style=\"color:rgb(219, 222, 225)\">Join Juggernaut now on </span><a target=\"_blank\" rel=\"ugc\" href=\"https://twitter.com/Juggernaut_AI\"><span style=\"color:rgb(76, 110, 245)\">X/Twitter</span></a><br /><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://learn.rundiffusion.com/prompt-guide-for-juggernaut-xiii-ragnarok-by-rundiffusion/\"><span style=\"color:rgb(76, 110, 245)\">Prompting Guide for Juggernaut Ragnarok by Adam</span></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://learn.rundiffusion.com/prompt-guide-for-juggernaut-xi-and-xii/\"><span style=\"color:rgb(76, 110, 245)\">Prompting Guide by Adam for XI &amp; XII</span></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/RunDiffusion/Juggernaut-XI-v11\">Juggernaut on HuggingFace</a></p><p>A big thanks goes to <a target=\"_blank\" rel=\"ugc\" href=\"http://rundiffusion.com/?utm_source=Civitai&amp;utm_medium=referral&amp;utm_campaign=Kandoo\">RunDiffusion</a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://twitter.com/Colorblind_Adam\">Adam</a>, who diligently helped me make it work :) (Leave some love for them ;) )</p><p></p><p><strong>Hey everyone,</strong></p><p>It’s been 8 months since the last version was released here on CivitAI.<br />Of course, I haven’t been idle during that time . I completed several projects to ensure I’d have the financial means to keep exploring new architectures and possibly do full finetunes on them in the future.</p><p>Juggernaut Flux (and its many sub-variants) was a ton of work, but ultimately, I’ve wrapped that chapter up. The training process gave me way too many headaches. To keep my sanity, I spent my spare time working on Juggernaut SDXL with the hope of maybe releasing one final version for you all.<br />And that day has finally come. :)</p><p>I won’t waste too much time on technical details.<br />I started by training a photographic dataset using <strong>Jug XII</strong> as the base to shift the focus back toward photorealism (Jug XII was leaning more into an artistic direction).<br />Then I re-captioned my set with <strong>Booru tags</strong> and trained it using <strong>SDXL</strong> as the base.<br />I merged these two sets (at a 0.15 ratio), but ultimately I wasn’t satisfied.</p><p>So I ran the same Set again, this time using <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/573152/lustify-sdxl-nsfw-checkpoint\"><strong>Lustify</strong></a> by <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/coyotte\">Coyotte</a> as the base model.<br />That version was then added to the earlier one (at a 0.1 ratio) as a stabilizer for the output.<br />Since the Dataset was captioned using Booru tags, both Booru tagging and the captioning style from versions X–XII work extremely well with <strong>Ragnarok</strong>.</p><p></p><p><strong>Juggernaut Ragnarok</strong> has improved in many areas: <strong>photorealism, digital painting, poses, hands, feet</strong>, and much more.<br />That said, it’s still an <strong>SDXL model</strong>, and I don’t recommend comparing it to models like Flux, Reve, or Sora. For example, it still has limitations when it comes to text rendering or faces at a distance.</p><p>I recommend using it <strong>as part of a pipeline</strong> for your projects. Example setup:<br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/618692/flux\"><strong>FluxDev</strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/141592/pixelwave\"><strong>Pixelwave</strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.rundiffusion.com/juggernaut-flux\"><strong>Jug Flux Pro</strong></a> → <strong>Juggernaut Ragnarok</strong></p><p>A quick personal note about Juggernaut:<br />Honestly, I don’t know what comes next.<br />After the release of Sora and similar tools, the open-source image generation space feels a bit dull in comparison.<br />Nothing has really excited me enough to dive back into training (yes, I’m talking about HiDream too).<br />So I’m seeing <strong>Juggernaut Ragnarok</strong> as a kind of <strong>farewell</strong>, especially since it’s unclear where things are headed with CivitAI in general.<br />(You can download <strong>all Juggernaut versions</strong> from HuggingFace, by the way.)</p><p><strong>Last but not least:</strong><br />Have fun with the model, share your creations, and good luck with your projects!<br />And in case you’re wondering: <strong>Yes, you can do anything you want with Juggernaut</strong> : merge it, train it, sell the image outputs, etc.<br />Just a simple shoutout is all I ask. :)</p><p>And now, here are the recommended settings:</p><p></p><h3 id=\"recommended-settings(vae-is-baked-in):-5xmbwh5xg\"><strong>Recommended Settings(VAE is baked in):</strong></h3><p><strong>Res: 832*1216 (For Portrait, but any SDXL Res will work fine)</strong></p><p><strong>Sampler: DPM++ 2M SDE</strong></p><p><strong>Steps: 30-40</strong></p><p><strong>CFG: 3-6 (less is a bit more realistic)</strong></p><p><strong>Negative: Start with no negative, and add afterwards the Stuff you don´t wanna see in that image.</strong></p><p><strong>VAE is already Baked In</strong></p><p><strong>HiRes: 4xNMKD-Siax_200k with 15 Steps and 0.3 Denoise + 1.5 Upscale</strong></p><p><br />And now, have fun trying it out. As always, I'm eagerly waiting for your pictures in the Gallery :)</p><p>If you liked the model, please leave a Like. In the end, that's what helps me the most as a creator on CivitAI. :)</p><p>Last but not least, I'd like to thank a few people without whom Juggernaut XL probably wouldn't have come to fruition:</p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"http://Dreamlook.AI\">Dreamlook.AI</a> (Trained 3 Side Sets)</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/chillpixel/models\">Chillpixel</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/SilasAI6609/models\">SilasAI6609</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://twitter.com/Colorblind_Adam\">Adam</a></p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581053+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "4629",
    "prompt": "Deep Negative V1.x\n<p>This embedding will tell you what is <strong>REALLY DISGUSTING</strong>🤢🤮</p><p>So please put it in <strong><u>negative prompt</u></strong>😜</p><p></p><p><u>⚠This model is not trained for SDXL and may bring undesired results when used in SDXL.</u></p><p><u>If you use </u><strong><u>SDXL</u></strong><u>, recommended this 👇</u></p><p>another deep-negative:</p><ul><li><p>pony version: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/831971/deep-negative-pony\">https://civitai.com/models/831971</a></p></li><li><p>SDXL version: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/407448\">https://civitai.com/models/407448</a></p></li></ul><p></p><h3 id=\"top-qanda-7m62mf8cx\">TOP Q&amp;A</h3><ul><li><p>how to use TI model?</p></li></ul><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Textual-Inversion\">https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Textual-Inversion</a></p><ul><li><p>what is negative prompt?</p></li></ul><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Negative-prompt\">https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Negative-prompt</a></p><p></p><p><strong>[Special Reminder]</strong> If your webui reports the following errors:</p><p>- <code>CUDA: CUDA error: device-side assert triggered</code></p><p>- <code>Assertion -sizes[i] &lt;= index &amp;&amp; index &lt; sizes[i] &amp;&amp; \"index out of bounds\" failed</code></p><p>- <code>XXX object has no attribute 'text_cond'</code></p><p>Please try using a model version other than 75T.</p><p>&gt; The reason is that many scripts do not handle overly long negative prompt words (greater than 75 tokens) properly, so choosing a smaller token version can improve this situation.</p><p></p><h3 id=\"update:230120-what-does-it-do-vgja91pxb\">[Update:230120] What does it do?</h3><p>These embedding learn what disgusting compositions and color patterns are, including faulty human anatomy, offensive color schemes, upside-down spatial structures, and more. Placing it in the negative can go a long way to avoiding these things.</p><p>-</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/00f10479-531c-4dc8-8021-f2af1c697700/width=525\" /></p><p></p><p></p><h3 id=\"what-is-2t-4t-16t-32t-t5rkaw49k\">What is 2T 4T 16T 32T?</h3><p>Number of vectors per token</p><p></p><h3 id=\"update:230120-what-is-64t-75t-x1f6t2460\">[Update:230120] What is 64T 75T？</h3><p><strong>64T</strong>: Train over <u>30,000</u> steps on mixed datasets.</p><p><strong>75T</strong>: embedding limit maximum size, training 10,000 steps on a <u>special dataset</u> (generated by many different sd models and special reverse processing)</p><p></p><h3 id=\"which-one-should-choose-x50v8knte\">Which one should choose?</h3><ul><li><p><strong>75T</strong>: The most ”easy to use“ embedding, which is trained from its accurate dataset created in a special way with almost <strong>no side effects</strong>. And it contains enough information to cover various usage scenarios. But for some <u>\"good-trained-model\"</u> may hard to effect</p><p>and, change about may be subtle and not drastic enough.</p></li><li><p><strong>64T</strong>: It works for all models, but has side effect. so, some tuning is required to find the best weight. <u>recommend</u>: [( NG_DeepNegative_V1_64T :0.9) :0.1]</p></li><li><p><strong>32T</strong>: Useful, but too more</p></li><li><p><strong>16T</strong>: Reduces the chance of drawing bad anatomy, but may draw ugly faces. Suitable for raising <strong>architecture</strong> level.</p></li><li><p><strong>4T</strong>: Reduces the chance of drawing bad anatomy, but has a little effect on light and shadow</p></li><li><p><strong>2T</strong>: ”easy to use“ like T75, but just a little effect</p></li></ul><p></p><h3 id=\"suggestion-g10t4z116\">Suggestion</h3><p>Because this embedding is learning how to create <strong>disgusting concepts</strong>, it cannot improve the picture quality accurately, so it is best used with <u>(worst quality, low quality, logo, text, watermark, username)</u> these negative prompts.</p><p>Of course, it is completely fine to use with other similar negative embeddings.</p><p></p><h3 id=\"more-examples-and-tests-vdclnno03\">More examples and tests</h3><ul><li><p>draw building: <a target=\"_blank\" rel=\"ugc\" href=\"https://imgur.com/5aX9yrP\">https://imgur.com/5aX9yrP</a></p></li><li><p>hand fix: <a target=\"_blank\" rel=\"ugc\" href=\"https://imgur.com/rDlsrgS\">https://imgur.com/rDlsrgS</a></p></li><li><p>portrait (with <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4514/pure-eros-face\">PureErosFace</a>): <a target=\"_blank\" rel=\"ugc\" href=\"https://imgur.com/1Lqq595\">https://imgur.com/1Lqq595</a> <a target=\"_blank\" rel=\"ugc\" href=\"https://imgur.com/V5kXBXz\">https://imgur.com/V5kXBXz</a></p></li><li><p>fusion body fix:</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ac167975-eadc-4c28-e87e-0d8ed2bec000/width=525\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/61bd2d45-b21e-47dd-a9c4-cbad326dc200/width=525\" /></p><p></p></li></ul><p></p><h3 id=\"how-is-it-work-z282wbmyy\">How is it work?</h3><p>I tried to make SD learn what is really disgusting with deepdream algorithm, the dataset is imagenet-mini (1000 images chosen randomly from the dataset again)</p><p>deepdream is <strong>REALLLLLLLLLLLLLLLLLLLLLY</strong> disgusting 🤮 and process of training this model really made me experience physical discomfort 😂</p><p></p><h3 id=\"backup-sokvc4jev\">Backup</h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/lenML/DeepNegative/tree/main\">https://huggingface.co/lenML/DeepNegative/tree/main</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581059+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "6755",
    "prompt": "Cetus-Mix\n<p><strong>NOTICE</strong>:<strong>LET ME KNOW</strong> before you put this model on <u>commercial usage</u>.</p><p>My twitter account:<strong>@eagelaxis </strong>:) Contact me if needed.</p><p>Discord Account:<strong>Eagelaxis#7818</strong></p><p><strong>Version Choosing Advice</strong>:<strong>V2f,V3,Coda and V3.5</strong> are recommended,especially <strong>CODA</strong> for first-time users.</p><p>Hard to tell how many models used to merge.</p><p>Check the example images to recognize this model's art style</p><p>For more example images, just take a look at <a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art\">https://pixai.art</a></p><p>More attention on shades and backgrounds compared with former models(<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6408/andromeda-mix\">Andromeda-Mix | Stable Diffusion Checkpoint | Civitai)</a></p><p>Hands-fix is still waiting to be improved.</p><p>Highres-fix(upscaler) is strongly recommended(using the SwinIR_4x,R-ESRGAN 4x+anime6B by myself) in order to not make blurry images.</p><p>(Sorry for the misunderstanding caused by myself.\"Bad_prompt_v2:1.4\" is a kind of embedding recognized as collection of normal negative prompts such as\"lowres,bad anatomy\".)</p><p>Recommend: Clip skip 2 Sampler:DPM++2M Karras Steps:20+</p><p>CFG scale:4-8 Vae:<a target=\"_blank\" rel=\"ugc\" href=\"http://Pastel-Waifu-Diffusion.vae.pt\">Pastel-Waifu-Diffusion.vae.pt</a>(The vae used by Pastel-mix si just good enough)</p><p>Highres.fix:SwinIR_4x Hires steps:10+ Denoising strength:0.4+ Upscale by: 1.5+</p><p>Loras along with embeddings on hands-fix are strongly recommended.</p><p>V4.5 should be coming soon.</p><p>Looking forward to your reviews!</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581062+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "372465",
    "prompt": "Pony Realism 🔮\n<p><a target=\"_blank\" rel=\"ugc\" href=\"http://ko-fi.com/zyloo\"><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b1ed0fa2-119a-44f2-a1df-efcf794f4484/width=525/b1ed0fa2-119a-44f2-a1df-efcf794f4484.jpeg\" /></a>✨ <strong><em>Latest </em></strong>| 🌐 <strong><em>Main </em></strong>| ⚡️ <strong><em>Ligthning/Hyper </em></strong>| 🌀 <strong><em>Alt version </em></strong>| 🖌 <strong><em>Inpaint </em></strong>| 📦 <strong><em>Old</em></strong></p><h3 id=\"all-versions-include-vae-vote-which-version-do-you-prefer-on-the-generator\"><em>🔸</em><strong><em>All Versions include VAE</em></strong><br /><strong><br /></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://strawpoll.com/X3nkP75JjgE\"><strong><em>📩 Vote which version do you prefer on the generator</em></strong></a><strong><br /></strong></h3><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0e647003-b439-44f5-8061-5def6fb9ee28/width=525/0e647003-b439-44f5-8061-5def6fb9ee28.jpeg\" />✨<strong>v2.3</strong> <span style=\"color:rgb(255, 197, 38)\"><strong><em>U</em></strong></span><span style=\"color:rgb(255, 170, 59)\"><strong><em>L</em></strong></span><span style=\"color:rgb(240, 162, 60)\"><strong><em>T</em></strong></span><span style=\"color:rgb(237, 161, 19)\"><strong><em>R</em></strong></span><span style=\"color:rgb(227, 143, 9)\"><strong><em>A </em></strong></span><strong>is a distinct variant of the standard v2.3.</strong><br />While it technically improves overall output, my intention is to treat this version as <strong>experimental</strong>, exploring potential directions for future updates.</p><p>This release brings more natural and balanced lighting (also darkness), enhanced skin detail and an increased realism.</p><p>If you're using this model for <strong>Furry or Fur-based prompts</strong>, make sure to use the <strong>\"Furry\" trigger</strong>, or pair it with my <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1565117/fur-enhancer\"><strong>Fur Enhancer LoRA</strong> </a>for best results.</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5874745d-addb-47c3-becd-c3eac1f32309/width=525/5874745d-addb-47c3-becd-c3eac1f32309.jpeg\" /></p><ul><li><p><span style=\"color:rgb(255, 235, 184)\"><strong><em>v2.3: (Latest) </em></strong></span>✨</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/372465?modelVersionId=1763661\"><strong><em>Main Version</em></strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/372465?modelVersionId=1920896\"><strong><em>ULTRA Version</em></strong></a></p></li></ul></li><li><p><strong><em>v2.2:</em></strong></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/372465?modelVersionId=914390\"><strong>Main Version</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/372465?modelVersionId=987210\"><strong>4 Step Hyper Version</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/372465?modelVersionId=987238\"><strong>8 Step Hyper Version</strong></a></p></li></ul><p></p></li></ul><p><span style=\"color:rgb(64, 192, 87)\"><strong><em><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/53e3a929-f33c-4551-860a-870547f2f4e0/width=525/53e3a929-f33c-4551-860a-870547f2f4e0.jpeg\" /></em></strong></span>I have written an <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/6621\"><strong><em>article </em></strong></a>that explains and provides some useful resources to help you achieve great generation results. You can check it out for detailed insights and recommendations.</p><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/84343c41-81b6-41f4-ba99-240ef0bc3205/width=525/84343c41-81b6-41f4-ba99-240ef0bc3205.jpeg\" />🔁<em> </em><strong><em>Samplers</em></strong></p><ul><li><p>DPM++ 2M SDE Karras</p></li><li><p>DPM++ 2S a Karras</p></li><li><p>DPM++ SDE Karras</p></li><li><p>DPM++ 2M SDE Exponential</p></li><li><p>DPM2 a</p></li><li><p>DPM++ 2S a</p></li><li><p>DPM++ 3M *</p></li><li><p>Euler A</p></li></ul><p>⚙️ <strong><em>Generation Settings</em></strong></p><ul><li><p><strong>Steps:</strong> 30 or more</p></li><li><p><strong>CFG Scale:</strong> 6–7</p></li><li><p><strong>Clip Skip:</strong> 2</p></li><li><p><strong>Resolution:</strong> Greater than 1024px</p></li></ul><p>🗒️ <strong><em>Notes</em></strong></p><ul><li><p>Use <strong>Danbooru</strong> tags</p></li><li><p>Keep individual <strong>prompt weights ≤ 1.5</strong></p></li><li><p>Use \"<strong>female</strong>/<strong>male</strong>\" instead of \"<strong>woman</strong>/<strong>man</strong>\" for better tagging compatibility</p></li></ul><p>🖋️ <strong><em>Prompt Style</em></strong></p><ul><li><p><strong>Positive Prompt Tags:</strong> <code>score_9</code>, <code>score_8_up</code>, <code>score_7_up</code>, <code>BREAK</code></p></li><li><p><strong>Negative Prompt Tags:</strong> <code>score_4</code>, <code>score_5</code>, <code>score_6</code></p><p></p></li></ul><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e67486ae-cd61-499b-a714-1580af685503/width=525/e67486ae-cd61-499b-a714-1580af685503.jpeg\" />⚠️ <span style=\"color:rgb(250, 176, 5)\"><strong>Avoid </strong></span><strong>DPM++ 2M Karras</strong> (Not recommended for generation)</p><p>✅ <strong>Recommended Samplers</strong></p><ul><li><p><strong>Euler A</strong></p></li><li><p><strong>DPM2 A</strong> <em>(Best for detail)</em></p><p></p></li></ul><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7f442c78-b21c-4e27-9d58-0faa0ef532a5/width=525/7f442c78-b21c-4e27-9d58-0faa0ef532a5.jpeg\" /></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/480835/pony-amateur\">Pony Amateur ✨</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/927305/pony-realism-enhancer\">Pony Realism Enhancer ✨</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1371405/pony-skin-enhancer\">Pony Skin Enhancer ✨</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1565117/fur-enhancer\">Pony Fur Enhancer ✨</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/633524/background-detail-enhancer\">Background Detail Enhancer✨</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/432586/cinematic-shot\">Cinematic Shot✨</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1608469?modelVersionId=1820245\">Pony Realism v2.2 Style/Support Blend ✨</a></p></li></ul><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ae770c78-95eb-4731-9709-7a46b50e91be/width=525/ae770c78-95eb-4731-9709-7a46b50e91be.jpeg\" /><em>Read the following </em><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/5545/pony-realism-lora-training-and-preset\"><strong><em>article </em></strong></a><em>for tips and my training preset</em></p><p></p><h3 id=\"buzz-for-the-best-images\">⚡️ <span style=\"color:rgb(253, 126, 20)\">Buzz for the Best Images </span>⚡️</h3><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581082+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "25694",
    "prompt": "epiCRealism\n<h2 id=\"heading-41\">Natural Sin Final and last of epiCRealism</h2><p><em><s>Since SDXL is right around the corner</s>, let's say it is the final version for now since I put a lot effort into it and probably cannot do much more.</em></p><p>I tried to refine the understanding of the Prompts, Hands and of course the Realism.<br /><strong>Let's see what you guys can do with it.</strong></p><p>Thanks to <span data-type=\"mention\" class=\"mantine-1yiar0p\" data-id=\"mention:1008701\" data-label=\"drawaline\">@drawaline</span> for the in-depth <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/25694?modal=commentThread&amp;commentId=178540\">review</a>, so i'd like to give some advices to use this model.<br />[<em>expand to see Advices</em>]</p><h3 id=\"heading-494\">Advices</h3><ul><li><p><strong>use simple prompts</strong></p></li><li><p><strong>no need</strong> to use keywords like \"masterpiece, best quality, 8k, intricate, high detail\" or \"(extremely detailed face), (extremely detailed hands), (extremely detailed hair)\" since it doesn't produce appreciable change</p></li><li><p><strong>use simple negatives </strong>or<strong> small negative embeddings</strong>. gives most realistic look <em><span style=\"color:rgb(134, 142, 150)\">(check samples to get an idea of negatives i used</span>)</em></p></li><li><p>add \"asian, chinese\" to negative if you're looking for ethnicities other than Asian</p></li><li><p>Light, shadows, and details are excellent without extra keywords</p></li><li><p>If you're looking for a natural effect, avoid \"cinematic\"</p></li><li><p>avoid using \"1girl\" since it pushes things to render/anime style</p></li><li><p>to much description of the face will turn out bad mostly</p></li><li><p>for a more fantasy like output use 2M Karras Sampler</p></li><li><p>no extra noise-offset needed, but u can if you like to 😉</p></li></ul><p></p><h3 id=\"heading-495\">How to use?</h3><p><strong>Prompt: </strong>simple explanation of the image <em><span style=\"color:rgb(134, 142, 150)\">(try first without extra keywords)</span></em><br /><strong>Negative:</strong> \"cartoon, painting, illustration, (worst quality, low quality, normal quality:2)\"<br /><strong>Steps:</strong> &gt;20 <em><span style=\"color:rgb(134, 142, 150)\">(if image has errors or artefacts use higher Steps)</span></em><br /><strong>CFG Scale:</strong> 5 <em><span style=\"color:rgb(134, 142, 150)\">(higher config scale can lose realism, depends on prompt, sampler and Steps)</span></em><br /><strong>Sampler:</strong> Any Sampler <em><span style=\"color:rgb(134, 142, 150)\">(SDE, DPM-Sampler will result in more realism)</span></em><br /><strong>Size:</strong> 512x768 or 768x512<br /><strong>Hires upscaler:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://upscale.wiki/wiki/Model_Database\">4x_NMKD-Superscale-SP_178000_G</a> (Denoising: 0.35, Upscale: 2x)</p><p></p><h3 id=\"heading-87\">Useful Extensions</h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\">!After Detailer</a> | <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Mikubill/sd-webui-controlnet\">ControlNet</a> | <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/ArtVentureX/sd-webui-agent-scheduler\">Agent Scheduler</a> | <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Coyote-A/ultimate-upscale-for-automatic1111\">Ultimate SD Upscale</a></p><p></p><p><strong>⁉ No VAE needed </strong>but it is better to use one for more vibrant colors</p><p>⭐ Feel free to leave Reviews and Samples - and always have fun creating ❤</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581102+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "140272",
    "prompt": "Hassaku XL (Illustrious)\n<p>Hassaku aims to be a anime model with a bright and distinct anime style. <br /><br /><span style=\"color:rgb(193, 194, 197)\"><em>You can run Hassaku XL and use its API on SinkIn: </em></span><a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/JWknjgr\"><span style=\"color:rgb(34, 139, 230)\"><em>https://sinkin.ai/m/JWknjgr</em></span></a><br /></p><p>My <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/zSR5FcYWWE\"><strong>Discord</strong></a> for everything related to anime models and art. </p><p></p><p>____________________________________________________________<br /><strong><u>Supporters:</u></strong></p><p>Thanks to my supporters <strong>Riyu, SETI and Kodokuna</strong><br /></p><p>____________________________________________________________<br /><strong><u>Using the model:</u></strong></p><ul><li><p><span style=\"color:rgb(219, 222, 225)\">The model is trained using images with minimal disruptive elements such as floating text, logos, speech bubbles, and signatures. If any of these elements are present in an image, please include the prompt \"signature\" as a negative prompt</span></p></li><li><p>Metadata and franchise tags are excluded—please do not use them. Tags such as \"highres\" and franchise-related tags like \"re:zero kara hajimeru isekai seikatsu\" are not used in training</p></li><li><p>Look at the example images, to see how the model should be used</p></li><li><p>Model is trained to be not complicated in use, tag order:<br />First are the number of person, then character names, rest.<br />Example: 1girl, rem \\(re:zero\\), standing, masterpiece, upper body</p></li><li><p>NoobAIs Loras working for the most part better in compare to <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/795765/illustrious-xl\"><span style=\"color:rgb(209, 213, 219)\">Illustrious loras</span></a></p></li><li><p>Here are some <span style=\"color:rgb(242, 242, 242)\">resolution </span>options for SDXL:</p><ul><li><p>1536 x 640</p></li><li><p>1344 x 768</p></li><li><p>1216 x 832</p></li><li><p>1152 x 896</p></li><li><p>1024 x 1024</p></li><li><p>896 x 1152</p></li><li><p>832 x 1216 (most recommended)</p></li><li><p>768 x 1344</p></li><li><p>640 x 1536</p></li></ul></li></ul><p><br />______________________________________________________</p><p><strong><u>Version and License info</u></strong><span style=\"color:rgb(193, 194, 197)\"><u>:</u></span></p><ul><li><p><span style=\"color:rgb(209, 213, 219)\">Below V1 </span>merges <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/260267\">ANIMAGINE XL 3.0</a></p></li><li><p><span style=\"color:rgb(209, 213, 219)\">Version V1 use </span><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/795765/illustrious-xl\"><span style=\"color:rgb(209, 213, 219)\">Illustrious-XL</span></a><span style=\"color:rgb(209, 213, 219)\"> &amp;</span><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/827184?modelVersionId=1068947\"><span style=\"color:rgb(209, 213, 219)\"> WAI-NSFW-illustrious-SDXL</span></a><span style=\"color:rgb(209, 213, 219)\"> with additional training</span></p></li><li><p>V2 is trained on its own and don't include any extra merge. Base was <span style=\"color:rgb(209, 213, 219)\">V1</span>, <span style=\"color:rgb(209, 213, 219)\">it is trained to include newer or missing characters. It was also used for further training tests</span></p></li><li><p><span style=\"color:rgb(209, 213, 219)\">V3 is a merge of </span><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/795765/illustrious-xl\"><span style=\"color:rgb(209, 213, 219)\">Illustrious-XL</span></a><span style=\"color:rgb(209, 213, 219)\"> and V2, to fix some issues and was also trained to include newer or missing characters</span></p><p></p><p><span style=\"color:rgb(209, 213, 219)\">All Models using the </span><a target=\"_blank\" rel=\"ugc\" href=\"https://freedevproject.org/faipl-1.0-sd/\"><strong>Fair AI Public License 1.0-SD</strong></a><span style=\"color:rgb(209, 213, 219)\"> license</span>. <br /><br /></p></li></ul><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581113+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "264290",
    "prompt": "Not Artists Styles for Pony Diffusion V6 XL\n<p>Styles are trained on synthetic data and do not copy the styles of artists!</p><p>Photo 2 - is trained on real data (Dataset from Unsplash)</p><p>[M] Merged LoRAs</p><p>Recommended LoRA Strength (Weight): 0.8-1</p><p>Preview generated without using ADetailer &amp; Hires. fix</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581127+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "9409",
    "prompt": "万象熔炉 | Anything XL\n<p><strong><span style=\"color:rgb(250, 82, 82)\">下载模型之前，请仔细查看模型介绍</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">Please review the model introduction carefully before downloading the model</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">モデルをダウンロードする前に、モデル紹介をよく見てください</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">本系列模型及衍生模型，禁止上传LiblibAI或ShakkerAI</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">This series of models and their derivatives are prohibited from being uploaded to LiblibAI or ShakkerAI</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">このシリーズのモデルおよびその派生モデルは、LiblibAIまたはShakkerAIにアップロードすることは禁止されています</span></strong></p><h3 id=\"-07dpl19o7\"><strong>注意：</strong></h3><h3 id=\"anything-syqu3ufe0\"><strong>👇下面的Anything模型为冒用名称，并非本人制作，请不要进行付费</strong></h3><h3 id=\"this-anything-model-is-an-unauthorized-use-of-the-name-and-was-not-created-by-me.-please-do-not-make-any-payments.-umhtkc5hs\"><strong>👇This Anything model is an unauthorized use of the name and was not created by me. Please do not make any payments.</strong></h3><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/be33da04-6da9-4328-b17d-85053bed9971/width=525/be33da04-6da9-4328-b17d-85053bed9971.jpeg\" /></p><p></p><h1 id=\"-350ce2yvm\"><strong>—————————————————</strong></h1><h2 id=\"ai-art-should-be-looked-like-ai-not-like-humans.-bp2ytwful\"><strong><em><span style=\"color:rgb(250, 82, 82)\">AI </span><span style=\"color:rgb(230, 73, 128)\">art</span> <span style=\"color:rgb(190, 75, 219)\">should</span> <span style=\"color:rgb(121, 80, 242)\">be</span> <span style=\"color:rgb(76, 110, 245)\">looked</span> <span style=\"color:rgb(34, 139, 230)\">like</span> <span style=\"color:rgb(21, 170, 191)\">AI,</span> <span style=\"color:rgb(18, 184, 134)\">not</span> <span style=\"color:rgb(130, 201, 30)\">like</span> <span style=\"color:rgb(250, 176, 5)\">humans</span><span style=\"color:rgb(253, 126, 20)\">.</span></em></strong></h2><h1 id=\"-cmqpj4xi0\"><strong>—————————————————</strong></h1><h1 id=\"anything-xl-68cfk8kvz\"><strong>Anything-XL</strong></h1><p>AnythingXL β 4 is the AnythingXL here. If you download the previous model, there is no need to download it again.</p><p><span style=\"color:rgb(193, 194, 197)\">AnythingXLbeta4 is another product encouraged by friends in the group. The premise is the highly developed SDXL model, with the quality of the trained model getting higher and higher. The negative hint word in the display graph's embedding name is only copied, and it actually has no effect. Beta4 was created because the model with the fourth test version was the only one I could tolerate looking at. Model fusion is a dead end, with a complete mess in terms of artistic style diversity and the accuracy of some prompt words.</span></p><h2 id=\"formula:-ygzp3cp2c\"><strong>Formula:</strong></h2><pre><code>aingdiffusionXL_V0.6       x 0.144375\nanimagineXLV3              x 0.144375\ncutecore_xl                x 0.12375\nkohakuXLDelta_rev1         x 0.1375\nBAXLBArtstyleXLv2          x 0.3375\nponyV6                     x 0.1125</code></pre><p>Model order only represents fusion order and has nothing to do with model quality</p><p>Model merge is implemented using the Webui-Supermerge plugin. According to FairAIPublicLicense1.0-SD, the recipe needs to be publicly disclosed, and any merged models that merged this model must also disclose the merge recipe in accordance with this license.</p><h2 id=\"parameters+-ific52v27\"><strong>Parameters+：</strong></h2><p>Prompt words are different from SD1.5, and for best results, it is recommended to follow a structured prompt template:</p><pre><code>&lt;|special|&gt;, \n&lt;|artist|&gt;, \n&lt;|special(optional)|&gt;, \n&lt;|characters name|&gt;, &lt;|copyrights|&gt;, \n&lt;|quality|&gt;, &lt;|meta|&gt;, &lt;|rating|&gt;，……\n\n&lt;|tags|&gt;, </code></pre><p>special(optional):These prompt words only need to be typed once, put in the front, there is no need to put in the back</p><h3 id=\"special-tags-orj8xpit3\"><strong>Special tags：</strong></h3><p>The model can still be used without these special cue words, but incorporating these special tags when necessary can help steer the generated results towards the desired direction.</p><p><strong>years:</strong></p><p>These words help guide the results towards modern and retro anime art styles, with a specific timeframe of approximately 2005 to 2023</p><pre><code>newest\t        2021 to 2024\nrecent\t        2018 to 2020\nmid\t            2015 to 2017\nearly\t        2011 to 2014\nold             2005 to 2010</code></pre><p><strong>NSFW：</strong></p><p>These words help guide the results towards adult content, but generally do not generate adult content if rating words are not included.</p><p>Of course, you can also put it in negative prompts.</p><pre><code>safe\t            General\nsensitive\t        Sensitive\nnsfw\t            Questionable\nexplicit, nsfw\t    Explicit</code></pre><p><strong>quality：</strong></p><p>While this model can function without quality words, in practice, these words can still be used to adjust the output.</p><pre><code>masterpiece\t            &gt; 95%\nbest quality\t        &gt; ?\ngreat quality\t        &gt; ?\ngood quality\t        &gt; ?\nnormal quality\t        &gt; ?\nlow quality\t            &gt; ?\nworst quality\t        ≤ 10%</code></pre><p><strong>Resolution：</strong></p><p>You are free to use the vast majority of reasonable resolutions, whether it is the resolution used by SD1.5 at 512*768 or higher resolutions above 2048, each will have a different effect. However, using images that are too large or too small may cause the picture to break down or the character/background structure to become distorted.</p><p><strong>Tags：</strong></p><p>If you want to generate high-quality pictures, you can use negative prompts, such as:</p><pre><code>nsfw, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, artist name</code></pre><p>Negative tags can include common negative tags, but it is best not to assign too high of a weight to their content, for example (ugly:2.8).</p><p>Because of models merge, some labels in the original model that have not been fully trained may be lost, and some labels may need to have a weight of over 1.5 in order to be effective.</p><h3 id=\"resolution-z7ubsr43p\"><strong>Resolution：</strong></h3><p>A resolution greater than 1024×1024 is recommended, and hires fix is recommended if you want higher resolution or quality</p><p>Most of the generation parameters of the example graph are:</p><pre><code>euler_a | 20steps | no hires fix | CFG7</code></pre><pre><code>2048 x 2048     not recommended\n……\n1280 x 2048     \n1280 x 1536     \n960  x 1536     Recommended\n1024 x 1024\t    1:1   Square\n…… \n960  x 640                \n768  x 512      SD1.5\n……\n2048 x 512      ¿  Unable to guarantee the quality\n512  x 2048     ¿  Unable to guarantee the quality</code></pre><h2 id=\"disclaimer:-fpml81eib\"><strong>Disclaimer:</strong></h2><p><strong><span style=\"color:rgb(250, 82, 82)\">All images generated by the model are created by the users themselves, and the model author cannot control the images generated by the users. The model author will not be held responsible for any potential copyright infringement or unsafe images.</span></strong></p><h2 id=\"license:-bu0z358o8\"><strong>License:</strong></h2><p>Anything now uses the <a target=\"_blank\" rel=\"ugc\" href=\"https://freedevproject.org/faipl-1.0-sd/\"><strong><u>Fair AI Public License 1.0-SD</u></strong></a>, compatible with Stable Diffusion models.<strong>All versions of the models in the Anything series are open source using this protocol</strong>. Key points:</p><ul><li><p><strong>Modification Sharing:</strong> If you modify Anything, you must share both your changes and the original license.</p></li><li><p><strong>Source Code Accessibility:</strong> If your modified version is network-accessible, provide a way (like a download link) for others to get the source code. This applies to derived models too.</p></li><li><p><strong>Distribution Terms:</strong> Any distribution must be under this license or another with similar rules.</p></li><li><p><strong>Compliance:</strong> Non-compliance must be fixed within 30 days to avoid license termination, emphasizing transparency and adherence toopen-sourcevalues.</p></li></ul><h1 id=\"-0sz67drmd\"><strong>—————————————————</strong></h1><p><strong><span style=\"color:rgb(76, 110, 245)\">您所看到的是单独给日本和中国AI玩家的备注：</span></strong></p><p>①除非需要生成2048x2048以上的图或者遇到严重问题，否则请放弃高清修复。</p><p>②如果你感觉模型偏向某方面，请先检查提示词。一些提示词在之前使用的模型上可能无效，在这里可能有效。</p><p>③请不要用SD1.5的使用习惯来使用SDXL，因为两个模型本质上不同。如有必要，请使用简介中的质量词，而不是8k高清等。</p><p>④最好不要和NegativeXL一起使用，也不建议使用高权重的负面提示词，如(ugly:2)。</p><p>⑤想要一张好图片，请尽可能详细描述内容，而不要仅标注\"1girl, nsfw\"，这样无法得到好的图片。</p><p><strong><span style=\"color:rgb(76, 110, 245)\">あなたが見ているのは、日本と中国のAIプレイヤーへの単独の備考です：</span></strong></p><p>①2048x2048以上の画像を生成する必要があるか、深刻な問題が発生している場合を除き、高画質修復をやめてください。</p><p>②モデルが特定の側面に偏っている場合や他の問題がある場合は、ヒントワードを確認してください。一部のヒントワードは以前のモデルでは機能しないかもしれませんが、ここでは有効になる可能性があります。</p><p>③SD1.5の使用法ではなく、SDXLの使用法は異なるため、注意してください。必要な場合は、8kの高画質などではなく、以下に示す品質の言葉を使用してください。</p><p>④NegativeXLとの組み合わせは避けるべきであり、(ugly:2)のような大きなウェイトのネガティブなヒントワードの使用もおすすめしません。</p><p>⑤良い画像が必要な場合は、内容を可能な限り詳細に説明してください。単に「1girl, nsfw」というラベルを付けるだけでは良い画像が得られません。</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581154+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "36520",
    "prompt": "GhostMix\n<p><a rel=\"ugc\" href=\"https://civitai.com/models/312431/ghostxl\"><strong>My New SDXL Model (GhostXL) already release on Civitai, please check it out. I think it will give you a surprise !</strong></a></p><p>Any questions or corporations? Find me at <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/576hznSTS7\">Discord</a> or by Wechat: ghostinshell10. Thanks</p><p><strong>You can run GhostMix on the cloud at Mage &amp; SinkIn.ai:</strong></p><p><span style=\"color:rgb(219, 222, 225)\">My model is now supported to create a short-form animation with the new \"Animate\" feature on Mage!</span></p><p><span style=\"color:rgb(193, 194, 197)\">GhostMix V2 at: </span><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/model/ghostmix-v2\">https://www.mage.space/model/ghostmix-v2</a></p><p><span style=\"color:rgb(193, 194, 197)\">GhostXL at: </span><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/model/ghostxl_v10BakedVAE\">https://www.mage.space/model/ghostxl_v10BakedVAE</a></p><p>SinkIn.ai<span style=\"color:rgb(193, 194, 197)\"> GhostMix model at: </span><a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/DY5rYnx\">https://sinkin.ai/m/DY5rYnx</a></p><p></p><h2 id=\"important-matters\"><em><u>IMPORTANT MATTERS(重要事项)</u></em></h2><ol><li><p>I think compacity is the most important thing of a checkpoint, that's why I don't merge ANY LORA in GhostMix. Checkpoint solves the CAN DO problem and Lora solves the DO IT RIGHT problem. （我认为checkpoint最终要的是兼容性，所以我没有融任何lora进checkpoint，checkpoint应该解决的是做的到的问题，而lora解决的是做的对的问题）</p></li><li><p><strong>Highres-Fix is A Must! </strong>Highres-Fix: 2x, denoising:0.4-0.5 or 1.5x, denoising:0.5-0.65. (<strong>一定要做高清修复</strong>! 高清修复: 2倍, 重绘幅度:0.4-0.5 或 1.5倍, 重绘幅度:0.5-0.65)</p></li><li><p><strong>Make Sure you are in the right CLIP</strong> if you want to replicate my job, some themes are CLIP=1,while others are CLIP=2.Suggest download the image and put it into PNG info to check the setting <strong>(如果想要复现,确保CLIP值要对! </strong>CLIP1和CLIP2要对!建议把图下下来然后放到PNG信息里面去查设置<strong>)</strong></p></li><li><p><strong>Most Prompts in Previous Version of GhostMix can produce similiar result in New Version of GhostMix (之前用的大多数Prompts在新版本也可以生成相似的结果)</strong></p></li><li><p>Textual Inversion&amp;VAE: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4629/deep-negative-v1x\">ng_deepnegative_v1_75t </a>and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\">easynegative</a> ,don't use Bad-Hand V4 &amp; V5！（用 <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4629/deep-negative-v1x\">ng_deepnegative_v1_75t</a>和<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\">easynegative</a>,别用BadHandV4,V5)</p></li><li><p>Sampler Suggest : DPM++ series , Steps: 20-30, CFG:5-7(7 is best)（采样方法建议 DPM++系列 , 步数20-30, CFG:5-7(7最好) ）</p></li><li><p>Suggest resolution: 512,768! mechanical girl theme is very sensitive to the resolution, not suggest make the aspect ratio too low.(建议分辨率:512,768! 机械少女主题对分辨率设置非常敏感，不建议设太低的宽高比)</p></li></ol><p>If you want to support me, please buy me a coffee : <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/ghostshell\">https://ko-fi.com/ghostshell</a></p><p>国内支付宝、微信用户可以通过爱发电给我买杯咖啡：<a target=\"_blank\" rel=\"ugc\" href=\"https://afdian.net/a/ghostmix\">https://afdian.net/a/ghostmix</a></p><p></p><p>I create the <strong>world's first checkpoint review framework GhostReview,</strong> by using LAION Aesthetics, Clipscore, HPS, StyleLoss to measure ckpts quantitatively in Image Quality,Style Compatibility and LoRA Compatibility. If you want to see the detail, please check the article link below.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/1548/ghostreview-the-worlds-first-checkpoint-review-framework-by-ghostmix-creator\">https://civitai.com/articles/1548/ghostreview-the-worlds-first-checkpoint-review-framework-by-ghostmix-creator</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/drnighthan/GhostReview\"><u>GhostReview Github Project: https://github.com/drnighthan/GhostReview</u></a></p><p></p><h2 id=\"2023521-ghostmix-v20-fp16-pruned-ver-replaced\"><em>2023.5.21 GhostMix-V2.0 (fp16 pruned ver replaced)</em></h2><h3 id=\"update-detail\"><u>UPDATE DETAIL(中文更新说明在下面)</u></h3><p>Hello everyone, this is Ghost_Shell, the creator. The GhostMix-V2.0 significantly improves the realism of faces and also greatly increases the good image rate. In my tests at 512,768 resolution, the good image rate of the Prompts I used before was above 50%. It is more user-friendly. During making the GhostMix-V2.0, I adjusted 47 versions of the model and finally chose one of them.</p><p>大家好，这里是作者Ghost_Shell。这次GhostMix-V2.0大幅提升了脸的真实性，也大幅提升了良图率，在我测的512,768分辨率之下，之前用的Prompts良图率都在50%以上，对用户更加友好。这次在测试中一共调了47个版本的模型，最终选了一个。</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9ade01d7-6a5e-40e5-92cb-67f7c2c818c9/width=525/9ade01d7-6a5e-40e5-92cb-67f7c2c818c9.jpeg\" /></p><h3 id=\"other-words-i-want-to-say\"><u>Other Words I want to say(题外话):</u></h3><p>To be honest, this may be the last version of GhostMix.On one hand, it is really inefficient to use 3060ti to make models. In the past two weeks, I have almost no free time except for making models and testing them. On the other hand, I temporarily feel that this model is almost at its limit and the space for improvement is really not high. I hope you like it. If you like the model, I hope you can post your images to Civitai. <strong>Many of the prompts I tested for GhostMix-V2.0 are from your posts, which is really important for me to test the model. If you can give it a 5-star rating, that would be great.</strong> If you are willing to support my work, please click: <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/ghostshell\">https://ko-fi.com/ghostshell</a>. My goal is to buy a 4070 and work more efficiently on making models. Using a 3060ti to make models is really inefficient and it basically cannot be used to test high resolution images.</p><p>说实话，这可能是GhostMix的最后一个模型，一方面3060ti去做模型真的效率太低了…最近两个星期基本没有空闲时间，除了做模型，就是测模型。另外一方面，我暂时觉得这个模型近乎极限，能提升的空间确实不高了，希望大家喜欢。<strong>如果大家喜欢模型，希望大家能post自己的作品到Civitai，这次测试的很多Prompts就是从你们post里面来的，这对我测试模型真的很关键，如果能5星评价就更好。</strong>如果愿意支持我的工作，请点击：<a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/ghostshell。\">https://ko-fi.com/ghostshell。</a> 我的目标就希望能换一块4070，更高效的去做模型，3060ti真的测模型效率太低了，而且基本没法测更高分辨率的图片。</p><p></p><h2 id=\"202351-ghostmix-v12-fp16-version-uploaded\"><em>2023.5.1 GhostMix-V1.2 (fp16 version uploaded)</em></h2><h3 id=\"update-detail\"><u>UPDATE DETAIL(中文更新说明在下面)</u></h3><p><strong>THIS IS NOT A 3D MODEL! THIS IS NOT A 3D MODEL! THIS IS NOT A 3D MODEL!</strong></p><p><strong>If you like my model，please give me 5 Stars ,it will encourage me a lot. Thanks!</strong></p><p><strong>Color Problem ：Check VAE is kl-f8-anime2 ？颜色问题：查VAE是否为kl-f8-anime2？</strong></p><p>GhostMix V1.2 is an absolutely astonishing model, and I think it is the strongest 2.5D model in Civitai right now. I think a update of the model should improve the model’s compatibility, good image rate and image details given the main structure of 90% generated images doesn’t change. So I use layer combination to combine models layer by layer. And I got this model after 9 different versions of “the final version of GhostMix V1.2”,LOL.This version of GhostMix V1.2 is a balance in terms of compatibility, good image rate and image details, although sometimes using the same Promts of GhostMix V1.1, may comes up a different result.But this doesn’t happen too much.</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/057f494c-a5a7-4861-de03-259304c88e00/width=525/057f494c-a5a7-4861-de03-259304c88e00.jpeg\" /></p><p>PS: The first image of GhostMix V1.2 is a nod to Mamoru Oshii’s version of Ghost in Shell in 1995, and my name Ghost_Shell is also a nod to this movie.</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/896fd995-5423-4de4-fa6a-5ab31be74a00/width=525/896fd995-5423-4de4-fa6a-5ab31be74a00.jpeg\" /></p><h3 id=\"heading-397\"><u>中文更新说明</u></h3><p>GhostMix V1.2是绝对让你惊艳的模型，也是自己认为现在最强的2.5D模型。我认为模型的更新应该是基于现有的画面整体不大变的前提下，提高模型的成图率，兼容性和画面细节。所以我采用了分层融合，一共做了9个版本的“GhostMix V1.2最终版本”，最终得到了现在这个版本的GhostMix V1.2。这个版本的GhostMix V1.2在兼容性，成图率和画面细节表现比较平衡，虽然有时候会出现同样的Promts，出图改变的情况，但实测不多。</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/057f494c-a5a7-4861-de03-259304c88e00/width=525/057f494c-a5a7-4861-de03-259304c88e00.jpeg\" /></p><p>PS：GhostMixV1.2的头图是致敬1995押井守版Ghost in Shell 攻壳机动队的生成的，Ghost in Shell也是作者名字的由来。</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/896fd995-5423-4de4-fa6a-5ab31be74a00/width=525/896fd995-5423-4de4-fa6a-5ab31be74a00.jpeg\" /></p><p></p><h2 id=\"2023311-ghostmix-v10\"><em>2023.3.11 GhostMix-V1.0</em></h2><h3 id=\"introduction\"><u>Introduction(中文简介在下面)</u></h3><p>First of all , I want to thank all the people who use this Checkpoint. And this is my first Checkpoint.All the sample image can be reproduced. This Checkpoint works well on both SFW and NSFW.THE NSFW PART IS VERY GOOD!!!<br />I uploaded this Checkpoint yesterday and from yesterday to today , I am still trying all the possibility of this Checkpoint. So if you try the model and find some good promts , I hope you can upload it and share with me, it will help me for the next version of GhostMix, Thank you agian!</p><h3 id=\"recommend-some-promts\"><u>Recommend Some Promts:</u></h3><ol><li><p><strong>Fractal Art（highly recommend，awsome）</strong></p></li></ol><pre><code>(masterpiece, top quality, best quality, official art, beautiful and aesthetic:1.2), (1girl:1.3), (fractal art:1.3),</code></pre><ol><li><p><strong>Color Art</strong></p></li></ol><pre><code>(flat color:1.3),(colorful:1.3),(masterpiece:1.2), best quality, masterpiece, original, extremely detailed wallpaper, looking at viewer,1girl,solo,floating colorful water</code></pre><h3 id=\"vaeandtextual-inversion\"><u>VAE&amp;Textual Inversion:</u></h3><p>VAE: kl-f8-anime2 or vae-ft-mse-840000-ema-pruned(anime suggest: kl-f8-anime2)</p><p>Textual Inversion: ng_deepnegative_v1_75t, easynegative</p><p></p><h3 id=\"about-image-reproduction\"><u>About Image Reproduction:</u></h3><p>Some user said that they can not reproduce my result.Maybe the setting goes wrong.I just reproduce my cover image. If you want to reproduce my result, Checkpoint Model，Postive Promt，Negative Promt，Textual Inversion，Sampler Steps，Sampler，CFG，Resolution，Seed , ALL the things should be the SAME! Then be careful if you open controlnet or lora ,don't make them influnence your result.</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d644a081-4d69-441e-ea1c-81d6b1934800/width=525/d644a081-4d69-441e-ea1c-81d6b1934800.jpeg\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f7062462-6f14-4555-7176-0ec8fdb67600/width=525/f7062462-6f14-4555-7176-0ec8fdb67600.jpeg\" /></p><p></p><h2 id=\"heading-398\"><u>中文简介</u></h2><p>首先感谢每一个使用这个Checkpoint的人，这是我融的第一个Checkpoint。所有样图自测都可以复现。SFW和NSFW的图都挺漂亮的，NSFW的图非常棒。这个模型昨天上传到今天，我一直在尝试这个模型的可能性。希望使用这个Checkpoint的朋友们，如果你试了，觉得有不错Promts，欢迎上传图分享，让我也了解一下这个Checkpoint的可能性，也可以帮助我调下一个版本GhostMix，再次感谢。</p><h3 id=\"promts\"><u>推荐Promts:</u></h3><ol><li><p><strong>分型艺术（超级推荐，必出好图）</strong></p></li></ol><pre><code>(masterpiece, top quality, best quality, official art, beautiful and aesthetic:1.2), (1girl:1.3), (fractal art:1.3),</code></pre><ol><li><p><strong>色彩艺术</strong></p></li></ol><pre><code>(flat color:1.3),(colorful:1.3),(masterpiece:1.2), best quality, masterpiece, original, extremely detailed wallpaper, looking at viewer,1girl,solo,floating colorful water</code></pre><h3 id=\"vaeandtextual-inversion\"><u>VAE&amp;Textual Inversion:</u></h3><p>VAE:kl-f8-anime2或者vae-ft-mse-840000-ema-pruned(动画风建议kl-f8-anime2)</p><p>Textual Inversion:ng_deepnegative_v1_75t,easynegative</p><p></p><h3 id=\"heading-399\"><u>关于图片复现:</u></h3><p>有同学好像没法复现我的图，可能是设置有点问题，刚刚我才把头图给复现了。注意几个点：Checkpoint 模型，正向Promt，反向Promt，Textual Inversion，迭代步数，迭代方法，CFG，分辨率，随机种子都必须一模一样！然后复现的话，要把controlnet和lora关掉，怕影响复现。</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/978438b2-a581-4740-a0b5-1531a2c47300/width=525/978438b2-a581-4740-a0b5-1531a2c47300.jpeg\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/87b94620-4032-4ba5-1949-cb07e18cfa00/width=525/87b94620-4032-4ba5-1949-cb07e18cfa00.jpeg\" /></p><h1 id=\"heading-400\"></h1>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581169+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "439889",
    "prompt": "Prefect Pony XL\n<p>If you like my work, drop a 5 review and hit the heart icon. it's free and keeps me motivated</p><h2 id=\"all-my-models-are-officially-hosted-and-maintained-by-me-on-tensor.art-.-use-my-exclusive-and-public-model-for-free-on-tensor.art-eeq913jiq\"><span style=\"color:rgb(250, 176, 5)\">All my models are officially hosted and maintained by me on</span> <a target=\"_blank\" rel=\"ugc\" href=\"http://Tensor.art\">Tensor.art</a> . use my <span style=\"color:rgb(250, 82, 82)\">Exclusive</span> and <span style=\"color:rgb(64, 192, 87)\">public</span> model for free on <a target=\"_blank\" rel=\"ugc\" href=\"http://tensor.art\">tensor.art</a></h2><p></p><h3 id=\"v5.0-civitai-onsite-generation-enabled-:-040125-t75gquk9a\"><strong><span style=\"color:rgb(130, 201, 30)\">v5.0 civitai onsite generation enabled : 04/01/25</span></strong></h3><h3 id=\"v5.0-final-release-:-010125-6vfl76nb1\"><strong><span style=\"color:rgb(64, 192, 87)\">v5.0 final release : 01/01/25</span></strong></h3><p><strong><u>v5.0 pre relelase update : 25/12/24</u></strong></p><p><strong><u>Check </u></strong><a target=\"_blank\" rel=\"ugc\" href=\"http://tensor.art\"><strong><u>tensor.art</u></strong></a><strong><u> for V1,V2,V3 online generation support</u></strong></p><h3 id=\"you-can-run-prefect-pony-xl-and-use-its-api-on-sinkin-7t3mg6rbn\"><span style=\"color:rgb(250, 176, 5)\">You can run Prefect Pony XL and use its API on </span><a rel=\"ugc\" href=\"https://sinkin.ai/m/6zv9aDj\"><span style=\"color:#228be6\">SinkIn</span></a></h3><p><strong><em><span style=\"color:rgb(250, 82, 82)\">currently, only v5 and v4 are available for civitai generation.</span></em></strong><em><span style=\"color:rgb(250, 82, 82)\"><br />v3,v2,v1 are retired from civitai generation. check other version details for alternative on site generation service.<br /></span></em></p><p><br /><span style=\"color:rgb(250, 176, 5)\">WIP: Realistic</span></p><h3 id=\"v5-update-:-3dk13unaf\"><span style=\"color:rgb(76, 110, 245)\">V5 Update :</span></h3><p><span style=\"color:rgb(76, 110, 245)\">onsite generation : </span><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/815661199413897287\"><span style=\"color:rgb(76, 110, 245)\">https://tensor.art/models/815661199413897287</span></a></p><p><strong><u>pre-release : </u></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/810892802167877454\"><strong><u>https://tensor.art/models/810892802167877454</u></strong></a></p><ul><li><p><span style=\"color:rgb(76, 110, 245)\">Added trained Lora</span></p></li><li><p><span style=\"color:rgb(76, 110, 245)\">Cleaned style</span></p></li><li><p><span style=\"color:rgb(76, 110, 245)\">Baked in VAE</span></p></li><li><p><span style=\"color:rgb(76, 110, 245)\">Extra trained data of 15000 steps</span></p></li><li><p><span style=\"color:rgb(76, 110, 245)\">Better Lora support.</span></p><p></p></li></ul><h3 id=\"v4-update-:-zo4vtl05o\"><span style=\"color:rgb(190, 75, 219)\">V4 Update :</span></h3><ul><li><p>onsite generation : <a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/794513755405953653/Prefect-Pony-XL-v4\">https://tensor.art/models/794513755405953653/Prefect-Pony-XL-v4</a></p></li><li><p><span style=\"color:rgb(190, 75, 219)\">Added trained Lora</span></p></li><li><p><span style=\"color:rgb(190, 75, 219)\">Cleaned style</span></p></li><li><p><span style=\"color:rgb(190, 75, 219)\">Baked in VAE</span></p></li><li><p><span style=\"color:rgb(190, 75, 219)\">Extra trained data of 15000 steps</span></p></li><li><p><span style=\"color:rgb(190, 75, 219)\">Better Lora support.</span></p></li></ul><h3 id=\"v3-update-:-in42v0bc5\"><br /><strong><u><span style=\"color:rgb(64, 192, 87)\">V3 Update</span><span style=\"color:rgb(250, 176, 5)\"> :</span></u></strong></h3><ul><li><p>onsite generation <a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/772139385270444718\">https://tensor.art/models/772139385270444718</a></p></li><li><p><strong><u><span style=\"color:rgb(64, 192, 87)\">added some style to it</span></u></strong></p></li><li><p><strong><u><span style=\"color:rgb(64, 192, 87)\">should give better face and eyes</span></u></strong></p></li><li><p><strong><u><span style=\"color:rgb(64, 192, 87)\">better NSFW supports</span></u></strong></p></li><li><p><strong><u><span style=\"color:rgb(64, 192, 87)\">wide range of Lora support</span></u></strong></p></li></ul><h3 id=\"v1-lightning-:-ep418cndn\"><strong><u><span style=\"color:rgb(250, 176, 5)\">V1 lightning :</span></u></strong></h3><ul><li><p><strong><u>8-steps</u></strong></p></li><li><p><strong>DPM++ 2M</strong></p></li></ul><h3 id=\"v2-update:-zk16vgh71\"><strong><span style=\"color:rgb(250, 82, 82)\">V2 update:</span></strong></h3><ul><li><p>onsite generation <a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/754887012743423435\">https://tensor.art/models/754887012743423435</a></p></li><li><p><strong>has less style influence</strong></p></li><li><p><strong>can work with wide range of loras</strong></p></li><li><p><strong>better anatomy</strong></p></li><li><p><strong>better color</strong></p></li></ul><h3 id=\"v1-update:-46il4dpa5\"><strong><span style=\"color:rgb(253, 126, 20)\">V1 update:</span></strong></h3><ul><li><p><strong><span style=\"color:rgb(250, 82, 82)\">On site generation closed for v1 on civitai for limitation of civitai.</span></strong></p></li><li><p><strong><span style=\"color:rgb(250, 82, 82)\">try </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"http://tensor.art\"><strong><span style=\"color:rgb(250, 82, 82)\">tensor.art</span></strong></a><strong><span style=\"color:rgb(250, 82, 82)\"> if you want to use the online generation for v1</span></strong></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/724940954567461228/Prefect-Pony-XL-v1.0\">https://tensor.art/models/724940954567461228/Prefect-Pony-XL-v1.0</a></p></li></ul><p>If you like my work then drop a 5 review and hit the heart icon. it's free and keeps me motivated</p><h3 id=\"-wk7b1pwct\"></h3><p><strong><span style=\"color:rgb(64, 192, 87)\">Suggested settings:</span></strong></p><ul><li><p>I had CLIP skip 2 on every image</p></li><li><p>I had <em>ENSD</em>: 31337 all of them</p></li><li><p>All of them had <strong>highres.fix</strong> or img2img at higher resolution.</p></li><li><p>I <strong>don't use restore faces</strong></p></li><li><p><strong>I use afterdetailer for face details</strong></p></li><li><p><strong>Tiled diffusion for img2img upscaling and sometimes Noise Inversion for some more extra details.</strong></p></li><li><p><strong>4x-Ultrasharp upscaler</strong></p></li></ul><p>NOTE: if you find any prompt of the preview images look familiar it's because I've taken them from other model review images, Credits to the original authors. Thanks for the benchmark.</p><h3 id=\"commission-open-in-patreon.-tczr9qqzt\">Commission open in <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/hinokiart\">Patreon</a><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/goofyai\">.</a></h3><h3 id=\"get-early-access-and-exclusive-nsfw-lora-in-my-patreon-.-ec4b3afdy\"><span style=\"color:rgb(64, 192, 87)\">Get early access and Exclusive </span><span style=\"color:rgb(253, 126, 20)\">NSFW </span><span style=\"color:rgb(64, 192, 87)\">Lora in my </span><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/hinokiart\"><span style=\"color:rgb(250, 82, 82)\">Patreon</span></a><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/GoofyAi\"><span style=\"color:rgb(250, 82, 82)\"> </span><span style=\"color:rgb(146, 147, 149)\">.</span></a></h3><p><span style=\"color:rgb(253, 126, 20)\">Support my work by joining any one of them and get early access to all my upcoming loras and other perks such as fan requests and Discord role.</span></p><h3 id=\"join-my-discord-server-y8zexxmdn\">Join my <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/M8yAsU9ZhC\"><strong><u>Discord Server</u></strong></a></h3><p></p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581175+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "443821",
    "prompt": "CyberRealistic Pony\n<p><span style=\"color:rgb(250, 176, 5)\">Like what I build here? You’ll <em>love</em> the chaos behind the scenes - </span><a target=\"_new\" rel=\"ugc\" href=\"https://patreon.com/cyberdelia\"><span style=\"color:rgb(250, 176, 5)\"><u>Check my Patreon</u></span></a></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e727677f-17fd-4bbf-b4f2-c3f7bc15daeb/width=525/e727677f-17fd-4bbf-b4f2-c3f7bc15daeb.jpeg\" /><span style=\"color:rgb(230, 73, 128)\"><strong>You can run CyberRealistic Pony and use its API on SinkIn: </strong></span><a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/Z9jVny2\"><span style=\"color:rgb(230, 73, 128)\"><strong>https://sinkin.ai/m/Z9jVny2</strong></span></a><span style=\"color:rgb(230, 73, 128)\"><br /></span><span style=\"color:rgb(250, 82, 82)\">Give CyberRealistic Pony a try </span><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/892064490751798485/CyberRealistic-Pony-v12.7\"><span style=\"color:rgb(250, 82, 82)\"><u>here</u></span></a><span style=\"color:rgb(250, 82, 82)\">! Want unlimited access? Take a look at the one-time purchase for full use.</span></p><p>CyberRealistic Pony blends all the charm of Pony Diffusion with the striking realism of CyberRealistic. The vibe? You get everything from adorable to bold (sometimes both at once) with crazy-detailed textures, moody cinematic lighting, and a hint of AI flair.</p><hr /><p>🧠 <span style=\"color:rgb(21, 170, 191)\"><strong>How to Use It</strong></span></p><pre><code>Sampling method: DPM++ SDE Karras / DPM++ 2M Karras / Euler a\nSampling steps: 30+ Steps\nResolution: 896x1152 / 832x1216\nCFG: 5\nClip Skip: 2</code></pre><p></p><hr /><p>✅ <span style=\"color:rgb(21, 170, 191)\"><strong>Recommended Prompts</strong></span></p><pre><code>score_9, score_8_up, score_7_up, (SUBJECT), </code></pre><p><strong>Negative Prompt examples:</strong></p><pre><code>score_6, score_5, score_4, (worst quality:1.2), (low quality:1.2), (normal quality:1.2), lowres, bad anatomy, bad hands, signature, watermarks, ugly, imperfect eyes, skewed eyes, unnatural face, unnatural body, error, extra limb, missing limbs</code></pre><p>it's also possible to remove the normal pony tags:</p><pre><code>(SUBJECT), </code></pre><p><strong>Negative Prompt examples:</strong></p><pre><code>(worst quality:1.2), (low quality:1.2), (normal quality:1.2), lowres, bad anatomy, bad hands, signature, watermarks, ugly, imperfect eyes, skewed eyes, unnatural face, unnatural body, error, extra limb, missing limbs</code></pre><hr /><p>🛠 <span style=\"color:rgb(21, 170, 191)\"><strong>ADetailer Settings</strong></span></p><pre><code>Adetailer model: face_yolov9c.pt\nIf you only want the main face being refined set 'Mask only the top k largest' to 1.</code></pre><p></p><hr /><p>☕<span style=\"color:rgb(21, 170, 191)\"><strong> Support</strong></span><br />Enjoying the ride? [<a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/cyberdelia\">Buy me a coffee</a>] – but only if the Pony delivered something you <em>actually</em> like.<br /></p><hr /><p>⚠️ <span style=\"color:rgb(21, 170, 191)\"><strong>Disclaimer</strong></span><br />This model might generate sensitive content. Whatever you make with it is on you. Don’t do anything weird and try to blame the horse.<br /></p><hr /><p>🔗 <span style=\"color:rgb(21, 170, 191)\"><strong>Links</strong></span><br />Backup location: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/cyberdelia/CyberRealisticPony/tree/main\">huggingface</a></p><p></p><hr /><p>💡<span style=\"color:rgb(21, 170, 191)\"><strong> Need Better Prompts?</strong></span><br />This custom ChatGPT was made to whip up top-tier prompts just for this model:<br />🔗 [<a target=\"_blank\" rel=\"ugc\" href=\"https://chatgpt.com/g/g-6834133e3ab881918a91b3ec6b9eb01f-cyberrealistic-prompt-helper\">Try it now on ChatGPT</a>]</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581188+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "47274",
    "prompt": "XXMix_9realistic\n<p></p><ul><li><p>I found a new AI tool Shakker, a best image to image tool. You can try it via <a target=\"_blank\" rel=\"ugc\" href=\"https://www.shakker.ai\">https://www.shakker.ai</a> </p></li><li><p>You can run XXMix_9realistic on <a target=\"_blank\" rel=\"ugc\" href=\"http://sinkin.ai\">sinkin.ai</a>: <a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/Y99mNKb\">https://sinkin.ai/m/Y99mNKb</a></p></li></ul><p></p><ul><li><p>feel free to <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/zyx_xx\">buy me a coffee ☕</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/119860/xxmixunreal\">XXMixunreal：</a><span style=\"color:rgb(193, 194, 197)\">我的2.5D新模型，一个极具特色的模型，可以根据关键词进行变种，创造属于自己的风格化图片。A highly distinctive model that can generate variations based on keywords, creating personalized, stylized images.</span><br /></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/110810?modelVersionId=119495\"><strong>XXMix_Petrichor:</strong></a>这是我新的系列模型，比较偏网红图片质感一些，希望大家可以支持下载尝试一下</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/110810?modelVersionId=119495\"><strong>XXMix_Petrichor:</strong></a><span style=\"color:rgb(201, 209, 217)\">This is my new series of models, which are more focused on the aesthetic of internet celebrity images. I hope everyone can support and download them to give them a try</span></p></li></ul><p></p><p></p><p>可以尝试下这个高清修复的算法，我认为在某些图片里用这个放大算法的效果要更好，画面也更风格化一些，hf地址在下面，喜欢的朋友可以尝试一下。</p><p><span style=\"color:rgb(201, 209, 217)\">You can try this high-definition restoration algorithm. I believe that in some pictures, the effect of using this magnification algorithm is better, and the picture is more stylized. The link to the high-frequency (hf) is below, and those who are interested can give it a try.</span><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9ffa500f-72ca-4225-acbf-f04818546bf6/width=525/9ffa500f-72ca-4225-acbf-f04818546bf6.jpeg\" /></p><p>1x_NMKDDetoon_97500_G</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/utnah/esrgan/tree/main\">https://huggingface.co/utnah/esrgan/tree/main</a></p><p>------------------------------------------------------------------------------------------------------</p><p></p><p>v4.0</p><p>最近热情有所下降，喜欢图例的直接copy吧，没有特别的版本说明。</p><p>------------------------------------------------------------------------------------------------------</p><p></p><p>我认为修手最好的是<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/58390/detail-tweaker-lora-lora\"><strong>Detail Tweaker LoRA (细节调整LoRA)，其他都是垃圾0 0</strong></a></p><p>v3.0版本说明：</p><ul><li><p>图片信息里的XXMix_4_v2893模型就是v30版本，图片是在模型改名前生成的</p></li><li><p>1.很高兴向大家介绍XXMix_9系列的3.0版本。这个版本在泛用性和对LORA的支持上都有明显的加强，并且手部的表现要明显好于之前的版本。3.0版本是由v2.5、v2.6和<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/47919/xxmix4reupload\">XXMix_4</a>这三个版本Mix而来。生成的图片我尽量没有用任何Embedding模型，因为我发现有些Embedding模型比较隐晦，你不知道哪些Embedding模型起了作用哪些没起作用，从而不能还原图例。</p></li><li><p>2.如果你想还原图例，请先安装以下扩展：</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\"><u>Adetailer</u></a><u>:建议在生成图片时始终开启（如果你想90%以上还原图例，那么建议你在图片信息内查看adetailer是否已开启）。</u></p></li><li><p><u>注意:Adetailer需要下载一些模型</u><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Bingsu/adetailer/tree/main，这里是模型地址。模型存放路径：webui/models/adetailer。没有找到adetailer文件夹自己建一个即可。\"><u>https://huggingface.co/Bingsu/adetailer/tree/main，这里是模型地址。模型存放路径：webui/models/adetailer。没有找到adetailer文件夹自己建一个即可。</u></a></p></li><li><p><u>Adetailer视频教程，这里我就贴</u><a target=\"_blank\" rel=\"ugc\" href=\"https://space.bilibili.com/8095370\"><u>娜乌斯嘉的教程喽</u></a><a target=\"_blank\" rel=\"ugc\" href=\"https://www.bilibili.com/video/BV13s4y197cK/?spm_id_from=333.337.search-card.all.click&amp;vd_source=8c2a86ab53df9752cdd75679f58834a6\"><u>https://www.bilibili.com/video/BV13s4y197cK/?spm_id_from=333.337.search-card.all.click&amp;vd_source=8c2a86ab53df9752cdd75679f58834a6</u></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/mcmonkeyprojects/sd-dynamic-thresholding\"><u>CFG Scale Fix</u></a><u>:有需求的时候开启，会提高画面的质感。我用的默认数值7左右，如果是白天CFG数值可以稍微大一些，晚上数值要小一些。</u></p></li><li><p><u>（经过我的测试，在第二台电脑上没有办法100%还原图例，我现在还不知道是什么原因，有可能是CFG Scale Fix这个扩展的问题，也有可能是分块VAE的问题，不过基本上你可以还原到90%-95%左右，对画面的影响不是很大。）</u></p></li><li><p>3.对于生成图片，个人的小心得：如果你得到了一张非常喜欢的图片，但是手部或其他部位的问题很严重，如果你不想用局部重绘修改的话，那么建议你在固定好seed之后，微调CFG的数值（每次调整0.2-0.3这种幅度来尝试），这样你就有可能在保持原图的基础上得到一张完美的图片。</p></li><li><p>4.在这里，我还想分享一个我喜欢的后缀句子，它可以让画面的表现力更强。当然，你可以根据需要修改句子中的单词来微调画面风格。这些单词包括：<strong><em>fantasy, high contrast, ink strokes, explosions, over exposure, purple and red tone impression , abstract, ((watercolor painting by John Berkey and Jeremy Mann )) brush strokes, negative space,</em></strong></p></li><li><p>5.最后，如果你喜欢这次模型的更新，希望你可以把生成的好看图片分享出来。</p></li></ul><p>Version 3.0 Description:</p><ul><li><p>The XXMix_4_v2893 model in the image information is actually the v3.0 version, but the images were generated before the model was renamed.</p></li><li><p>Pleased to introduce the 3.0 version of the XXMix_9 series. This version has significantly improved in versatility and support for LORA, and the hand performance is significantly better than the previous versions. The 3.0 version is a mix of v2.5, v2.6, and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/47919/xxmix4reupload\">XXMix_4</a>. When generating images, I try not to use any Embedding models as much as possible because I have found that some Embedding models are more obscure, and you don't know which ones are working and which ones are not, which makes it difficult to restore the example.</p></li><li><p>If you want to restore the example, please install the following extensions first:</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\">Adetailer</a>: It is recommended to always enable it when generating images. If you want to restore the example by more than 90%, it is recommended to check whether Adetailer is enabled in the image information.</p></li><li><p>Note: Adetailer requires downloading some models from <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Bingsu/adetailer/tree/main\">https://huggingface.co/Bingsu/adetailer/tree/main</a>. Here is the model address. The model should be stored in the path: webui/models/adetailer. If you cannot find the adetailer folder, please create one yourself.</p></li><li><p>Adetailer Chinese Video Tutorial，这里我就贴<a target=\"_blank\" rel=\"ugc\" href=\"https://space.bilibili.com/8095370\"><strong>娜乌斯嘉的教程喽</strong></a><a target=\"_blank\" rel=\"ugc\" href=\"https://www.bilibili.com/video/BV13s4y197cK/?spm_id_from=333.337.search-card.all.click&amp;vd_source=8c2a86ab53df9752cdd75679f58834a6\">https://www.bilibili.com/video/BV13s4y197cK/?spm_id_from=333.337.search-card.all.click&amp;vd_source=8c2a86ab53df9752cdd75679f58834a6</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/mcmonkeyprojects/sd-dynamic-thresholding\">CFG Scale Fix</a>: Enable it when needed, it will improve the quality of the image. I use the default value of about 7. If it is daytime, the CFG value can be slightly larger, and at night, the value should be smaller. (After my test, I cannot restore the example 100% on the second computer. I still don't know the reason. It may be a problem with the CFG Scale Fix extension or the Tiled VAE. However, you can basically restore it to about 90%-95%, and the impact on the image is not significant.)</p></li><li><p>For generating images, here is my personal experience: If you get a picture that you really like, but there are serious problems with the hands or other parts, and you don't want to use local redraw to modify it, then it is recommended to adjust the CFG value slightly (0.2-0.3 range) after fixing the seed. This way, you may get a perfect picture while keeping the original image.</p></li><li><p>Here, I would like to share a suffix sentence that I like, which can make the image more expressive. Of course, you can modify the words in the sentence to fine-tune the image style. These words include: <strong><em>fantasy, high contrast, ink strokes, explosions, overexposure, purple and red tone impression, abstract, brush strokes ((watercolor painting by John Berkey and Jeremy Mann)), negative space.</em></strong></p></li><li><p>Finally, if you like the updates of this model, we hope you can share the beautiful images you generated.</p></li></ul><p>------------------------------------------------------------------------------------------------------</p><p>v26-fp16-no-ema update</p><p>------------------------------------------------------------------------------------------------------</p><p>v2.6版本说明:</p><p>这版算小更新，优化了脸型，手的问题有优化，不过主要还是抽卡。大问题下个版本解决。</p><p>Version 2.6 release notes:</p><p>This version is a minor update that optimizes the face and hand issues. However, the main focus is still on the gacha system. The major issues will be addressed in the next version.</p><p></p><p>------------------------------------------------------------------------------------------------------</p><p></p><p></p><p><strong><u>有人留言说模型基本不能用，麻烦新朋友看下自己的设置是否和图例的设置一样，除了全身图会有IMG2IMG放大的操作，其他图都是直出的。请一定先确定自己设置是否和图里一样哈！！！</u></strong></p><p>V2.5版本的光影效果表现更好，支持更多幻想内容，调整了基础脸型，场景方面的表现更好。</p><p>V2.5 version has better lighting effects and supports more fantasy content. The basic face shape has been adjusted, and the performance in scenes has been improved.</p><p>------------------------------------------------------------------------------------------------------</p><p><strong>适当调小(CFG Scale)的数值，可以得到与众不同的效果。</strong></p><p>V2版本说明:</p><p>1.更换了默认脸。</p><p>2.更好的光影表现。</p><p>3.融合了更多模型，后面还会继续迭代。</p><p>4.如果想得到更好的皮肤质感，那么生成图片的时候不要开启高清修复，而是将生成的图片传入图生图模式，启用<a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111\">Tiled Diffusion</a>，来进行放大，从而得到更真实的皮肤质感。</p><p>5.我会继续更新迭代这个大模型，希望能不断填充内容，让模型更具趣味性。</p><p>谢谢您的支持！</p><p>Version 2 Release Notes:</p><ol><li><p>Changed the default face.</p></li><li><p>Improved lighting and shadow effects.</p></li><li><p>Added more models and will continue to iterate in the future.</p></li><li><p>For better skin texture, do not enable Hires Fix when generating images. Instead, use the \"Tiled Diffusion\" mode to enlarge the generated image and achieve a more realistic skin texture.</p></li><li><p>I will continue to update and iterate on this large model, hoping to add more content and make it more interesting.</p></li></ol><p>Thank you for your support!</p><p>------------------------------------------------------------------------------------------------------</p><p>推荐参数</p><p>Recommended Parameters:</p><p>Sampler: DPM++ 2M Karras alt Karras or DPM++ SDE Karras</p><p>Steps: 20~40</p><p>Hires upscaler:4x-UltraSharp</p><p>Hires upscale: 2</p><p>Hires steps: 15</p><p>Denoising strength: 0.2~0.5</p><p>CFG scale: 6-8</p><p>clip skip 2</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581203+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "25494",
    "prompt": "Beautiful Realistic Asians\n<p>Im currently preparing and collecting dataset for SDXL, Its gonna be huge and a monumental task. I wanna thank everyone for supporting me so far, and for those that support the creation of SDXL BRA model. Thank you thank you thank you</p><p><a target=\"_blank\" rel=\"ugc\" href=\"http://Ko-fi.com/bankaiplease\">Ko-fi.com/bankaiplease</a></p><p>(Recommended)</p><p><span style=\"color:rgb(219, 222, 225)\">Mage provides unlimited generations for my model with amazing features. They also share their revenue per content generation with me! Go check it out here: </span><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/\">https://www.mage.space/</a></p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581206+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "12597",
    "prompt": "墨心 MoXin\n<h3><strong>《墨心》—— 昔涓子《琴心》，王孙《巧心》，心哉美矣，故用之焉。</strong></h3><p>本品由安吉吴仓石、兴化板桥先生、八大山人、山阴伯年等大师之大小写意作品辅以现代人物训练而成。辅以恰当之提示词，诵先贤尊号，襄古今并用之意，明雅俗共举之美。</p><p></p><h3><strong>《疏可走马》—— <em>字画疏处可以走马，密处不使透风。</em></strong></h3><p>这是一个和<strong>墨心</strong>搭配使用的构图Lora, 一旦使用并再最前前置提示词后，就会采用较大面积留白的构图风格。可以在版本处找到他</p><p></p><p></p><p>注意事项：<br />1.）CFG范围将会改变风格</p><ul><li><p>1~3 : 大小写意</p></li><li><p>3~7 : 逐渐工笔</p></li></ul><p>2.）推荐基础模型为ChilloutMix、国风3.2等</p><p>3.）《墨心》的推荐Lora权重为0.85以下</p><p>4.）《疏可走马》推荐Lora权重为0.7~1</p><p>====================================</p><p></p><p><strong>\"MoXin\"<br /><em>Xi Juanzi \"Qinxin\". Wangsun \"QiaoXin\", Xin zai mei yi, gu yong zhi yan.</em></strong></p><p>MoXin is a Lora trained from on Chinese painting Masters lived in Ming and Qing dynasties.</p><p><br />“<strong>Shukezouma”<em><br />Zi hua shu chu ke yi zou ma, mi chu bu shi tou feng.</em></strong><br />This is a Lora that major functions in Traditionla Chinese painting composition. Once it is used and preceded by \"shukezouma\" prompts in the very beginning, it adopts a composition style featuring a large area of negative space.</p><p></p><p>Tips:</p><p>1.) The result style will change within the following CFG ranges:</p><ul><li><p>1~3 : Xieyi Painting</p></li><li><p>3~7 : Gongbi Painting</p></li></ul><p>2.) It is recommended to use with ChilloutMix, GuoFeng3.2, etc.</p><p>3.) It is recommended to use \"MoXin\"'s Lora weight of 0.85 or lower.</p><p>4.) It is recommended to use \"Shukezouma\"'s Lora weight between 0.7~1</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581211+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "15003",
    "prompt": "CyberRealistic\n<p><span style=\"color:rgb(250, 176, 5)\">Like what I build here? You’ll <em>love</em> the chaos behind the scenes - </span><a target=\"_new\" rel=\"ugc\" href=\"https://patreon.com/cyberdelia\"><span style=\"color:rgb(250, 176, 5)\"><u>Check my Patreon</u></span></a></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/17febe49-5713-4d68-bb17-6789ae5675e7/width=525/17febe49-5713-4d68-bb17-6789ae5675e7.jpeg\" /><span style=\"color:rgb(250, 82, 82)\">Give CyberRealistc a try </span><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/878750700945827383/CyberRealistic-v9.0\"><span style=\"color:rgb(250, 82, 82)\"><u>here</u></span></a><span style=\"color:rgb(250, 82, 82)\">! Want unlimited access? Take a look at the one-time purchase for full use.</span></p><p>CyberRealistic is a flexible, easy-to-use photorealistic model built from nonstop testing, custom blends, and just the right amount of chaos. The backstory? It’s honestly a wild mashup of different checkpoints, but what really counts is what you get in the end: sharp, expressive, clean renders that just work.</p><p>It’s tuned for both textual inversion and LoRA, so it’s great for anyone from total beginners to hardcore prompt wizards. If you’re making portraits, messing around with new styles, or just want a model that steps aside and does its job, CyberRealistic won’t let you down.</p><hr /><p><span style=\"color:rgb(21, 170, 191)\"><strong>⚙️ Suggested Settings</strong></span></p><pre><code>Sampling method: DPM++ SDE Karras / DPM++ 2M Karras  \nVAE: is already Baked In\nSampling steps: 30 Steps\nResolution: 512x768\nCFG: 5\nUpscale: 2x\nUpscaler: 4x_NickelbackFS_72000_G\nDenoising strength: 0.3</code></pre><p></p><hr /><p><span style=\"color:rgb(21, 170, 191)\"><strong>🧠 Prompting</strong></span></p><p><strong>Negative prompt examples</strong></p><pre><code>lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry</code></pre><p></p><hr /><p><span style=\"color:rgb(21, 170, 191)\"><strong>💾 Backup &amp; Resources</strong></span><br />backup location: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/cyberdelia/CyberRealistic/tree/main\">huggingface</a></p><p></p><hr /><p><span style=\"color:rgb(21, 170, 191)\"><strong>☕ Support the Project</strong></span><br />If this model helped you hit your vision faster, cleaner, or just plain better — consider [<a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/cyberdelia\">buying me a coffee</a>]. It keeps the updates coming and the experiments wild.</p><p></p><hr /><p><span style=\"color:rgb(193, 194, 197)\">💡</span><span style=\"color:rgb(21, 170, 191)\"><strong> Need Better Prompts?</strong></span><br /><span style=\"color:rgb(193, 194, 197)\">This custom ChatGPT was made to top-tier prompts just for this model:</span><br /><span style=\"color:rgb(193, 194, 197)\">🔗 [</span><a target=\"_blank\" rel=\"ugc\" href=\"https://chatgpt.com/g/g-6834133e3ab881918a91b3ec6b9eb01f-cyberrealistic-prompt-helper\">Try it now on ChatGPT</a><span style=\"color:rgb(193, 194, 197)\">]</span></p><p></p><hr /><p><span style=\"color:rgb(21, 170, 191)\"><strong>⚠️ Friendly Warning</strong></span><br />This model can generate mature content. Use responsibly. Respect laws, platforms, and people.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581222+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "56519",
    "prompt": "negative_hand Negative Embedding \n<h2>negative_hand Negative Embedding</h2><h3>Problem with Negative Embedding's</h3><p>Currently, there are more and more negative embedding, while many are also very good and easy to use. However, almost all of them currently have a big problem... They change the main or initial artstyle of the used model. Best example would be my bad_prompt_version2 Negative Embedding. It helps enormously with the quality of an image, but drastically changes the artstyle of the model. That's not the point of it. For this reason, I have now trained my new Negative Embedding negative_hand!</p><p>An example of the issue:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/images/667829?modelVersionId=60938&amp;prioritizedUserIds=162020&amp;period=AllTime&amp;sort=Most%20Reactions&amp;limit=20\">Image Link</a></p><p></p><h3>So what is negative_hand?</h3><p>negative_hand is supposed to fix the said issue. That means it should improve the quality of the image, but without changing the initial artstyle of the model.</p><p>Pro:</p><ul><li><p>The artstyle of the model can be used without any problems and without possible artstyle changes.</p></li><li><p>The quality of the image and incorrect anatomy like hands are improved.</p></li></ul><p>Con:</p><ul><li><p>Since this embedding cannot drastically change the artstyle and composition of the image, not one hundred percent of any faulty anatomy can be improved.</p></li></ul><p></p><h3>Usage</h3><p>To use this embedding you have to download the file aswell as drop it into the \"\\stable-diffusion-webui\\embeddings\" folder.</p><p><strong>Please put the embedding in the negative prompt to get the right results!</strong></p><p>For special negative tags such as \"malformed sword\", you still need to add them yourself. The negative embedding is trained on a basic skeleton for the negative prompt, which should provide a high-resolution image as a result.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581225+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "618692",
    "prompt": "FLUX\n<p><span style=\"color:#e64980\">Please check out the</span> <a rel=\"ugc\" href=\"https://education.civitai.com/quickstart-guide-to-flux-1\">Quickstart Guide to Flux </a><span style=\"color:#e64980\">for all the info you need to get started!</span></p><p></p><p><code>FLUX.1 [dev]</code> is a 12 billion parameter rectified flow transformer capable of generating images from text descriptions. For more information, please read our <a target=\"_blank\" rel=\"ugc\" href=\"https://blackforestlabs.ai/announcing-black-forest-labs/\"><strong><u>blog post</u></strong></a>.</p><h1 id=\"key-features-325mmh6sm\">Key Features</h1><ol><li><p>Cutting-edge output quality, second only to our state-of-the-art model <code>FLUX.1 [pro]</code>.</p></li><li><p>Competitive prompt following, matching the performance of closed source alternatives .</p></li><li><p>Trained using guidance distillation, making <code>FLUX.1 [dev]</code> more efficient.</p></li><li><p>Open weights to drive new scientific research, and empower artists to develop innovative workflows.</p></li><li><p>Generated outputs can be used for personal, scientific, and commercial purposes as described in the <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/licence.md\"><strong><u>flux-1-dev-non-commercial-license</u></strong></a>.</p></li></ol><h1 id=\"usage-y9h8q18hm\">Usage</h1><p>We provide a reference implementation of <code>FLUX.1 [dev]</code>, as well as sampling code, in a dedicated <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/black-forest-labs/flux\"><strong><u>github repository</u></strong></a>. Developers and creatives looking to build on top of <code>FLUX.1 [dev]</code> are encouraged to use this as a starting point.<br /><br />Learn More Here: <br /><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/black-forest-labs/FLUX.1-dev\">https://huggingface.co/black-forest-labs/FLUX.1-dev</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581230+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "16014",
    "prompt": "Anime Lineart / Manga-like (线稿/線画/マンガ風/漫画风) Style\n<h2>Update information</h2><p></p><p>V3.0 updated. Fine-tuned LoRA to improve the effects of generating characters with complex body limbs and backgrounds. The overall styling is more toward manga style rather than simple lineart. A lower CFG scale can make lines thinner.</p><p></p><p>V3.0更新。对LoRA进行了微调，改善生成人物肢体和复杂背景的效果。整体更趋向漫画风而非纯线稿。低CFG scale可以让线条变细。</p><p></p><h2>Recommend settings</h2><p>Model: Anything V4.5</p><p>VAE: Orangemix (the same with NAI)</p><p>LoRA Strength: 1</p><p>Sampler: DPM++ 2M Karras</p><p>Sampling steps: 20</p><p>CFG: 7</p><p>Negative embedding: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\">EasyNegative</a>、<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16993/badhandv4-animeillustdiffusion\">badhandv4</a></p><p>Highres fix is also recommended.</p><p>Note: all the LoRA names used in sample images are my local name, you need to change them to your saved LoRA filename!</p><p>基模：Anything V4.5</p><p>VAE：Orangemix（同NAI）</p><p>LoRA强度：1</p><p>采样器：DPM++ 2M Karras</p><p>采样步数：20</p><p>CFG：7</p><p>负面embedding：<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\">EasyNegative</a>、<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16993/badhandv4-animeillustdiffusion\">badhandv4</a></p><p>推荐使用高清修复。</p><p>注意：样图中的LoRA名称是我本地文件名，要改成你保存的文件名！</p><p></p><h2>Difference</h2><p></p><p>Here's a comparision of V2.0 and V3.0 (locally called V3 and V4 on my machine - V2 on my machine is not published):</p><p>V2.0和V3.0的对比（在我的本地机器上命名为V3和V4——本地的V2我并未发布）：</p><p></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/38354d83-7523-4334-c3de-1a3a493e5a00/width=525/38354d83-7523-4334-c3de-1a3a493e5a00\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cc03ae1f-4391-4ff5-4850-d9478d78c600/width=525/cc03ae1f-4391-4ff5-4850-d9478d78c600\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/4c7eaa16-9f4d-4545-dc36-c2d3f43b9d00/width=525/4c7eaa16-9f4d-4545-dc36-c2d3f43b9d00\" /><p></p><p>Comparision of different CFG scale:</p><p>不同CFG scale对比：</p><p></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/845cf24a-c5c6-4ee0-a999-d7130ecb7e00/width=525/845cf24a-c5c6-4ee0-a999-d7130ecb7e00\" />",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581238+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "82098",
    "prompt": "Add More Details - Detail Enhancer / Tweaker (细节调整) LoRA\n<h2 id=\"heading-734\">Add More Details - Detail Enhancer / Tweaker</h2><p><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> 🅿️ or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> ☕</strong><br /></p><p>I've been using the (great) Detail Tweaker by CyberAIchemist for a while now, and I was really curious. I really just wanted to know if I was capable of doing something similar. </p><p>I had a lot of fun doing this, and I think it came out pretty great. I wil ldefinitely incorporate it in most of my work going forward. </p><p>You should use this <strong>between 0.5 and 1 weight</strong>, depending on your preference. You can go lower than 0.5 for a more subtle effect, of course.</p><p>I also found out that this gives some interesting results at negative weight, sometimes. See the examples to see what I mean. <br /></p><p><strong>How to use LoRA's in auto1111:</strong></p><ul><li><p>Update webui (use <code>git pull</code> <a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/embed/mn8fMF10XN4?start=31&amp;end=60\">like here</a> or redownload it)</p></li><li><p>Copy the file to <code>stable-diffusion-webui/models/lora</code></p></li><li><p>Select your LoRA like in <a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/watch?v=-bMeyXOZwN0\">this video</a></p></li><li><p><strong>Make sure to change the weight</strong> (by default it's <code>:1</code> which is usually too high)</p></li></ul>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581246+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "112902",
    "prompt": "DreamShaper XL\n<h1 id=\"heading-4\">DreamShaper XL - Now Turbo!</h1><h3 id=\"heading-134\"><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384/dreamshaper\">Also check out the 1.5 DreamShaper page</a></h3><p><strong>Check the version description below (bottom right) for more info and add a ❤️ to receive future updates.</strong><br /><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> 🅿️ to get exclusive tips and tutorials, or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> ☕</strong></p><p></p><h3 id=\"heading-135\">Join my <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/uAhsmDq7GC\">Discord Server</a></h3><p></p><p><strong><span style=\"color:rgb(64, 192, 87)\">Alpha2 is a bit old now. I suggest you switch to the Turbo or Lightning version.</span></strong><br /><strong>DreamShaper</strong> is a<em> general purpose </em>SD model that aims at doing everything well, photos, art, anime, manga. It's designed to go against other general purpose models and pipelines like Midjourney and DALL-E.</p><p></p><h2 id=\"heading-634\">\"It's Turbotime\"</h2><p><strong>Turbo </strong>version should be used at <u><span style=\"color:rgb(253, 126, 20)\">CFG scale 2</span></u> and with around <u><span style=\"color:rgb(253, 126, 20)\">4-8 sampling steps</span></u>. This should work only with <strong><u><span style=\"color:rgb(253, 126, 20)\">DPM++ SDE Karras</span></u></strong> (NOT 2M). You can use this with LCM sampler, but don't do it unless you need speed vs quality. <br /><strong><span style=\"color:rgb(130, 201, 30)\">Sampler comparison at 8 steps:</span></strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/951781\">https://civitai.com/posts/951781</a><br /><strong><span style=\"color:rgb(250, 82, 82)\">UPDATE: </span><span style=\"color:rgb(18, 184, 134)\">Lightning </span></strong>version targets <u><span style=\"color:rgb(253, 126, 20)\">3-6 sampling steps</span></u> at <u><span style=\"color:rgb(253, 126, 20)\">CFG scale 2</span></u> and should also work only with <strong><u><span style=\"color:rgb(253, 126, 20)\">DPM++ SDE Karras</span></u></strong>. Avoid going too far above 1024 in either direction for the 1st step.</p><p>No need to use refiner and this model itself can be used for highres fix and tiled upscaling. <br />Examples have been generated using Auto1111, but you can achieve similar results with this ComfyUI Workflow: <a target=\"_blank\" rel=\"ugc\" href=\"https://pastebin.com/79XN01xs\">https://pastebin.com/79XN01xs</a></p><p><strong>Basic style comparison: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/images/4427452\">https://civitai.com/images/4427452</a></p><p><strong>If you train on this, make sure to use <u><span style=\"color:rgb(253, 126, 20)\">DPM++ SDE</span></u> sampler and appropriate steps/cfg.</strong></p><p><strong>Keep in mind <span style=\"color:rgb(250, 82, 82)\">Turbo currently cannot be used commercially unless you get permission from StabilityAI.</span> </strong>Get a membership here: <a target=\"_blank\" rel=\"ugc\" href=\"https://stability.ai/membership\">https://stability.ai/membership</a></p><p>You can use the Turbo version (<strong>not Lightning</strong>) as a non-Turbo model with DPM++ <strong><u>2M</u> </strong>SDE Karras / Euler at cfg 6 and 20-40 steps. Here is a comparison I made with some of the best non-Turbo XL models (with regular settings and turbo settings): <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/1414848￼￼\">https://civitai.com/posts/1414848<br /></a>I have no idea why anyone would prefer 40 steps over 8, but you have the option.</p><p></p><div data-youtube-video><iframe width=\"640\" height=\"480\" allowfullscreen=\"true\" autoplay=\"false\" disablekbcontrols=\"false\" enableiframeapi=\"false\" endtime=\"0\" ivloadpolicy=\"0\" loop=\"false\" modestbranding=\"false\" origin playlist src=\"https://www.youtube.com/embed/l71ZCs7tUu8\" start=\"0\"></iframe></div><p></p><h2 id=\"heading-635\"><u>Old</u> description referring to <u>Alpha 2</u> and before</h2><p><strong>Finetuned over SDXL1.0.</strong><br />Even if this is still an alpha version, I think it's already much better compared to the first alpha based on xl0.9.<br />For the workflows you need Math plugins for comfy (or to reimplement some parts manually).<br />Basically I do the first gen with DreamShaperXL, then I upscale to 2x and finally a do a img2img steo with either DreamShaperXL itself, or a 1.5 model that i find suited, such as DreamShaper7 or AbsoluteReality.</p><p><strong>What does it do better than SDXL1.0?</strong></p><ul><li><p>No need for refiner. Just do highres fix (upscale+i2i)</p></li><li><p>Better looking people</p></li><li><p>Less blurry edges</p></li><li><p>75% better dragons 🐉</p></li><li><p>Better NSFW</p></li></ul><p></p><h3 id=\"heading-226\">Old DreamShaper XL 0.9 Alpha Description</h3><p>Finally got permission to share this. It's based on SDXL0.9, so it's just a training test. It definitely has room for improvement.</p><p>Workflow for this one is a bit more complicated than usual, as it's using AbsoluteReality or DreamShaper7 as \"refiner\" (meaning I'm generating with DreamShaperXL and then doing \"highres fix\" with AR or DS7). <br /><br />Results are quite nice for such an early stage. <br /><br />I might disable the comment section as I'm sure some people will judge this even if it's early stage. I also don't think this is on par with SD1.5 DreamShaper yet, but it's useless to pour resources into this as SDXL1.0 is about to be released. <br /><br />Have fun and make sure to add a <strong>❤️ </strong>to receive future updates.<br /><br /><s>Non commercial license is forced by Stability at the moment.</s></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581262+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "212532",
    "prompt": "All Disney Princess XL LoRA Model from Ralph Breaks the Internet\n<h1 id=\"heading-45\"><strong>All Disney Princess XL LoRA Model - Ralph Breaks the Internet</strong></h1><p>If You Like This Model, Give It a ❤️</p><p>This LoRA model is trained on screen capture images featuring beloved Disney princesses from the movie Ralph Breaks the Internet, including Rapunzel, Snow White, Ariel, Aurora, Belle, Cinderella, Elsa, Anna, Jasmine, Mulan, Merida, Tiana, Moana, and Pocahontas. It's designed to be an All-in-One Model for your creative endeavors.</p><p></p><p>Check out SD1.5 Version Here: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/202866/all-princesses-from-disneys-ralph-2-ralph-breaks-the-internet-or-all-in-one-lora-model\">https://civitai.com/models/202866/all-princesses-from-disneys-ralph-2-ralph-breaks-the-internet-or-all-in-one-lora-model</a></p><p></p><h2 id=\"heading-46\"><strong>Bonus Characters</strong></h2><p>Additionally, this model includes representations of other characters like Vanellope, Shank, Raya, Namaari, Asha, and Rapunzel with short hair. While these extras are included, the quality may vary.</p><p></p><h2 id=\"heading-47\"><strong>Quick Tips</strong></h2><ul><li><p><strong>Direct Name Usage</strong>: You can generate any princess by directly prompting their names, such as <code>Anna</code>, <code>Ariel</code>, <code>Aurora</code>, <code>Belle</code>, <code>Cinderella</code>, <code>Elsa</code>, <code>Asha</code>, <code>Jasmine</code>, <code>Merida</code>, <code>Moana</code>, <code>Mulan</code>, <code>Namaari</code>, <code>Pocahontas</code>, <code>Rapunzel</code>, <code>Raya</code>, <code>Shank</code>, <code>Snow White</code>, <code>Tiana</code>, <code>Vanellope</code>.</p><ul><li><p>More Character in v2 including: <code>Alice</code>, <code>Chel</code>,<code>Esmerada</code>, <code>Jane Porter</code>, <code>Kida</code>, <code>Megera</code>,<code>Mirabel Madrigal</code>, <code>Isabela Madrigal</code>, <code>Dolores Madrigal</code> and some secret character! </p></li></ul></li><li><p><strong>LoRA Scale</strong>: Optimal LoRA scales range between 0.6-0.7 for close-up character generation and 0.3-0.5 for full-body generation. Combining these scales using the ADetailer plugin can yield enhanced results. Ensure an adequate number of sampling steps for better output.</p></li><li><p><strong>Base Models</strong>: Although various base models can function, models with animation styles like DreamShaper or RealCartoon are preferred for optimal performance.</p></li></ul><p>Enjoy exploring the LoRA!</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581266+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "24149",
    "prompt": "Mistoon_Anime\n<p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b8f7dc5a-4261-44ec-9abc-2c1ca3c60c5e/width=525/b8f7dc5a-4261-44ec-9abc-2c1ca3c60c5e.jpeg\" /><strong>You can use this model on SeaArt </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.seaart.ai/models/detail/588bb5f910028a5c341822e4f5667e41\"><strong>here</strong></a><strong>.</strong></p><p>Mistoon_Anime is my blend of SD models that tries to achieve a more \"cartoony\" anime style with thick borders and brighter colors. The aim of this model is not to mimic a particular style, but to achieve an aestethic I like.</p><p>This merge has been created using a lot of different models. In the start I've used popular models (and also nieche ones), but now I'm mostly using my custom LoRAs to finetune the model in the way I like.</p><p>This model is oriented towards creating girls portraits, but the V2 and V3 is also capable of creating male characters in a convincing way.</p><p>If you plan to do some inpainting there is also an inpainting version available for you to download.</p><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b28baea5-472a-41d7-a5cc-542c4578cd39/width=525/b28baea5-472a-41d7-a5cc-542c4578cd39.jpeg\" />The idea behind Mistoon_Anime is to achieve the modern anime style while keeping it as colorful as possible. A lot of checkpoints available now are mostly based on anime illustrations oriented towards 2.5, but I prefer the bright 2d anime aesthetic.</p><p>It creates realistic and expressive characters with a \"cartoony\" twist. Unlike other anime models that tend to have muted or dark colors, Mistoon_Anime uses bright and vibrant colors to make the characters stand out.</p><p>This model can easily do both SFW and NSFW stuff (V1 has a bias towards NSFW keep that in mind).</p><p>Do you want a softer style? Try out: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/319650/mistoonxlcopper\">https://civitai.com/models/319650/mistoonxlcopper</a></p><h3 id=\"-kpu5h7kho\"></h3><h3 id=\"v1-ntfz8opos\"><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/20885ddf-b4d1-469e-9ae4-722b2bf0534a/width=525/20885ddf-b4d1-469e-9ae4-722b2bf0534a.jpeg\" />V1</h3><p>The v1 version is the original Mistoon_Anime that a lot of you already know. It's bright, cartoony and likes tight clothes 😂. If you've never used the original version I highly recommend to check out the gallery and see if it is for you. <strong>If you want to use the V1 you'll need a VAE, I highly suggest you to use </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/iZELX1/Grapefruit/resolve/main/Grapefruit.vae.pt\"><strong>this one</strong></a><strong>.</strong></p><p>If you want a more traditional anime style, you'll probably want the newest version.</p><p></p><h3 id=\"v2-vwxhsknep\">V2</h3><ul><li><p>Is WAY better at producing images depicting males</p></li><li><p>Has lower distortion at lower resolutions</p></li><li><p>Is way more detailed</p></li><li><p>Has better backgrounds consistency</p></li><li><p>Eyes are more detailed and consistent</p></li><li><p>Is incredibly detailed when working with close-ups or upper body portrait</p></li><li><p>Is better with NSFW than the previous version</p></li><li><p><strong>Works better with CLIP skip set to 2</strong></p></li><li><p><strong>Has already a VAE embedded.</strong></p></li></ul><p></p><h3 id=\"v3-0tl5idd1j\">V3</h3><ul><li><p>I've merged it back the original version of Mistoon_Anime to give it a more similar vibe to the original</p></li><li><p>I've merged it with Mistoon_Pearl to give it more flexibility and versatility</p></li><li><p>The model should now be able to create more interesting poses</p></li><li><p>The model has now an improved level of detail on both full body portraits and close-ups</p></li><li><p>The model should be capable of generating high quality 512x768 pictures (especially close-ups)</p></li><li><p><strong>Works better with CLIP set to 2</strong></p></li><li><p><strong>Has already a VAE embedded.</strong></p></li></ul><p></p><h3 id=\"pony-(alpha)-26hpwz8l5\">Pony (Alpha)</h3><p>After a long wait the alpha for the Mistoon Anime pony version is here! There are a few things you'll need to know:</p><ul><li><p>All my generations have been done with:</p><ul><li><p>UI: <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Panchovix/stable-diffusion-webui-reForge\">Panchovix/stable-diffusion-webui-reForge (</a><a target=\"_blank\" rel=\"ugc\" href=\"http://github.com\">github.com</a><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Panchovix/stable-diffusion-webui-reForge\">)</a></p></li><li><p>Sampler: Euler A</p></li><li><p>Scheduler: SGM Uniform</p></li><li><p>CFG: 2,5/3</p></li><li><p>Width/Height: 768x1152 -&gt; 1024x1536 -&gt; 1280x1920</p></li><li><p>Sampling Steps: 8</p></li></ul></li><li><p>My workflow is the same as usual:</p><ul><li><p>Generate a bunch of 768x1152 pictures</p></li><li><p>Choose the best one and send it to img2img</p></li><li><p>Run the same prompt but with higher resolution (1024x1536) and denoising set to 0.5</p></li><li><p>Take the best result and send it again to img2img</p></li><li><p>Run again with higher resolution (1280x1920) and denoising set to 0.2</p></li></ul></li><li><p>Right now, there are a few issues (and that's the reason I consider this to be an alpha):</p><ul><li><p>Sometimes the area around the eyes is distorted due to excessive training</p></li><li><p>Sometimes the colors are off, especially in areas hit by sunlight</p></li><li><p>It's not as flexible as the base pony model</p></li><li><p>It does not always maintain a consistent style</p></li></ul></li></ul><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3bd064dd-e9da-4b9a-8f69-fedbd240e9d1/width=525/3bd064dd-e9da-4b9a-8f69-fedbd240e9d1.jpeg\" />Learn more about how I create the examples here: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/3318\">From Noise to Illustrations: How I Generate AI Pictures with Stable Diffusion | Civitai</a></p><p>In the past few months I've had a lot of people asking me why their pictures are not as detailed or clean as mine. I've written a few articles about SD, but if you want to learn my exact workflow I highly recommend you to check out my latest one: <a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/p/6be78130eb9e\">My Workflow</a></p><p>If you want to test this (or other models), I have made an extension to help me create pictures using a variety of different tags. The previews images have been generated using my custom extension <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Inzaniak/sd-webui-ranbooru\">Ranbooru </a>which scrapes tags from random images on gelbooru, safebooru and rule34.</p><p>If you want to learn more about my workflow, check out the guides below.</p><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/900abc6f-a55f-4f93-8109-e03a7e96f427/width=525/900abc6f-a55f-4f93-8109-e03a7e96f427.jpeg\" />Learn how to create pictures like mine with my step-by-step tutorials:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/p/bd7dbcd5ce4b\">Beginner's Guide</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/p/35eacb3dc5f4\">Prompting</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/@inzaniak/stable-diffusion-ultimate-guide-pt-3-high-resolution-a4f5d7b60f38\">High Resolution</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/p/772ea69472c9\">Inpainting</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/@inzaniak/stable-diffusion-ultimate-guide-pt-5-controlnet-6f45e9614119\">ControlNet</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/p/6be78130eb9e\">My Workflow</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/p/e2b299a70421\">Tips and Tricks</a></p></li></ul><p>Other stuff here on CivitAI:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/3318/from-noise-to-illustrations-how-i-generate-ai-pictures-with-stable-diffusion\">Learn how I create my examples</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/3357/ranbooru-the-comprehensive-guide\">Learn how to master the Ranbooru Extension</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/3716\">Learn how to master the Workflow Extension</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/10480/my-workflow-invokeai\">2025 Workflow</a></p></li></ul><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/80a56b01-6eed-43ac-94fb-e73e96d76ca0/width=525/80a56b01-6eed-43ac-94fb-e73e96d76ca0.jpeg\" />I've got a lot of models here on CivitAI (and even more on Patreon), here's some of them:</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a357f034-3ab6-4585-8534-5ca2903ce490/width=525/a357f034-3ab6-4585-8534-5ca2903ce490.jpeg\" /></p><p>Initially I used to release every LoRA here on CivitAI, but after a while it became very time-consuming, so I started releasing only my favourite new LoRAs here on CivitAI while still releasing all the models <strong>for free</strong> on Patreon.</p><p>So, if you don't want to miss a release be sure to follow me on Patreon (for free you don't need to sub if you don't want to) here:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Inzaniak\">https://www.patreon.com/Inzaniak</a></p><p>If you want to check out my other models you'll find them here:</p><ul><li><p>Civitai: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Inzaniak\">Civitai | Share your models</a></p></li><li><p>Patreon (Free): <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Inzaniak?filters[tag]=public\">Inzaniak | Generative Art and Tech Blogging | Patreon</a></p></li><li><p>Patreon (All): <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Inzaniak?filters[tag]=lora\"><u>Inzaniak | Generative Art and Tech Blogging | Patreon</u></a></p><p></p><p></p></li></ul><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/336304e8-65f5-4070-a1b8-fe59b651cf7a/width=525/336304e8-65f5-4070-a1b8-fe59b651cf7a.jpeg\" />I've started developing custom models for myself a few months ago just to check out how SD worked, but in the last few months it has become a new hobby I like to practice in my free time. All my checkpoints and LoRAs will always be released for free on Patreon or CivitAI, but if you want to support my work and get early access to all my models feel free to check out my Patreon:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Inzaniak\">https://www.patreon.com/Inzaniak</a></p><p></p><p>If you want to support my work for <strong>free</strong>, you can also check out my music/art here:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://inzaniak.bandcamp.com/\">Bandcamp</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.deviantart.com/inzaniak\">DeviantArt</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.threads.net/@inzaniak_aiart\">Threads</a></p></li></ul><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/12bf0a72-1930-4f17-8ad9-7233a8ebd8de/width=525/12bf0a72-1930-4f17-8ad9-7233a8ebd8de.jpeg\" /></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581292+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "24779",
    "prompt": "Dark Sushi Mix 大颗寿司Mix\n<p>Recommend:</p><p>vae-ft-mse-840000-ema</p><p></p><p>use highres fix to improve quality.</p><p></p><p></p><p></p><p>打了一个月王国之泪后重操旧业。</p><p>新版本算是对2.5d的整合，保留整体二次元画风的同时肢体上比前几个版本要好，脸型也要更多样化一点。</p><p>但光影和线条上就和2.5D更像一些，我也纠结了很久究竟该放在哪边，最终还是放在这了。于是干脆起个2.25d的版本名吧，至于孰好孰坏就见仁见智了。</p><p><s>多少有点背离初衷了，一点都不暗了。想暗的话还是自己加noiseoffset吧</s></p><p></p><p>After playing Tears of the Kingdom for a month, I resumed my old work. The new version is an integration of 2.5d, which retains the overall anime style while being better than the previous versions on the limbs, but the light and shadow and lines are more like 2.5D, so i simply call it 2.25d version.</p><p></p><p></p><p></p><p></p><p>起名废玩烂梗系列，事后想想起的不错。</p><p>首先暗图效果比较好，dark合适，自己融的时候差不多也是寿司那样什么都塞点，dark 寿司没毛病。</p><p>光效比较好，能生成比较暗的图，正常亮度的图片也有不错的光影表现。</p><p>融了群友私模和一大堆我也记不住组成的以前的自融模</p><p>能确定包含的是自己之前的五仁<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/21409/five-nuts-mixed-mix\">Five Nuts Mixed 五仁月饼Mix | Stable Diffusion Checkpoint | Civitai </a>和<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/23905/unrule\">Unrule | Stable Diffusion Checkpoint | Civitai</a></p><p>以及群友的TmndMix ，绝对的杰作，推荐大家都去试试 <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/27259\">https://civitai.com/models/27259</a></p><p>darker版本里还加了noiseoffset的lora，生图要比brighter版本暗一些，光影表现上要强一点，但缺点就是正常生图也会比较暗。大家一般用brighter版再自己调用noiseoffset的lora也能达到类似效果。</p><p></p><p>Intro:</p><p>named from a dark soul's meme in Chinese community.</p><p></p><p>merged with my friend's pravite model and some other models merged by myself.</p><p>Including <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/21409/five-nuts-mixed-mix\">Five Nuts Mixed 五仁月饼Mix | Stable Diffusion Checkpoint | Civitai </a>,</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/23905/unrule\">Unrule | Stable Diffusion Checkpoint | Civitai</a></p><p>and my friend's TmndMix <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/27259\">https://civitai.com/models/27259</a> .it's definitely a masterpiece.</p><p>if you like dark sushi ,you should also try tmnd.</p><p>noiseoffset lora is merged into the darker version. So the imgs generated by the darker version will be darker ,and have better light and shadow performance. you can use brighter version and noiseoffset lora to get similar effect.</p><p></p><p></p><p></p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581297+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "23900",
    "prompt": "AnyLoRA - Checkpoint\n<h1 id=\"heading-232\">AnyLoRA</h1><p><strong>Add a ❤️ to receive future updates.</strong><br /><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> 🅿️ or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> ☕</strong></p><p><strong><span style=\"color:rgb(253, 126, 20)\">For LCM read the version description.</span></strong></p><p><strong>Available on the following websites with GPU acceleration:</strong></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/WLRRBnv\"><strong>Sinkin.ai</strong></a></p></li></ul><h2 id=\"heading-233\"><strong>Remember to use the <u>pruned</u> version when training</strong> (less vram needed).<br />Also this is mostly for training on anime, drawings and cartoon.</h2><p>I made this model to ensure my future LoRA training is compatible with newer models, plus to get a model with a style neutral enough to get accurate styles with any style LoRA. Training on this model is much more effective compared to NAI, so at the end you might want to adjust the weight or offset (I suspect that's because NAI is now much diluted in newer models). I usually find good results at 0.65 weigth that I later offset to 1 (very easy to do with ComfyUI).</p><p>This is good for inference (again, especially with styles) even if I made it mainly for training. It ended up being super good for generating pics and it's now my go-to anime model. It also eats very little vram.</p><p>Get the pruned versions for training, as they consume less VRAM. </p><p>Make sure you use CLIP skip 2 and booru style tags when training.</p><p>Remember to use a good vae when generating, or images wil look desaturated. Or just use the baked vae versions.</p><h2 id=\"heading-234\"></h2><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581305+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "300005",
    "prompt": "Incase Style [PonyXL]\n<p>Version Guide:</p><p>V1: Weakest style, but high compatibility, struggles with details at lower resolutions.</p><p>V2: Recommended for beginners - Good style, good compatibility, hard to mess up.</p><p>V3: Best style/colors, maybe reduced compatibility with some other loras.</p><p>Top tag counts:</p><pre><code>penis                153  (81%)\nfemale               144  (76%)\nbreasts              117  (62%)\nmale                 107  (56%)\ncum                  102  (54%)\nerection             96  (51%)\nnipples              91  (48%)\noral                 83  (44%)\n1girl                82  (43%)\nfellatio             75  (39%)\nstraight             72  (38%)\nareolae              64  (34%)\nsex                  60  (32%)\nballs                55  (29%)\ncum inside           55  (29%)\nnude                 54  (28%)\nlarge breasts        54  (28%)\nlipstick             54  (28%)\nlight-skinned male   53  (28%)\ncum in mouth         50  (26%)\nfutanari             49  (26%)\nhuman                48  (25%)\nblue eyes            46  (24%)\ndark skin            44  (23%)\npussy                41  (22%)\nblush                41  (22%)\npubic hair           41  (22%)\nopen mouth           40  (21%)\n1boy                 39  (21%)\nblack hair           38  (20%)\nsaliva               37  (19%)\nbig breasts          36  (19%)\npenetration          36  (19%)\ncum on face          36  (19%)\noriginal             35  (18%)\ntongue out           35  (18%)\nlight skin           33  (17%)\nlong hair            33  (17%)\nclothing             32  (17%)\nhandjob              31  (16%)\nfreckles             31  (16%)\npointy ears          31  (16%)\ntongue               31  (16%)\nglasses              30  (16%)\nthighhighs           30  (16%)\nintersex             30  (16%)\nvaginal penetration  30  (16%)\ncum on breasts       30  (16%)\ntesticles            30  (16%)\n2boys                29  (15%)\nblonde hair          29  (15%)\n1futa                28  (15%)\ntext                 27  (14%)\nspread legs          27  (14%)\nlight-skinned female 27  (14%)\nfacial               27  (14%)\ninterracial          26  (14%)\nred hair             26  (14%)\npiercing             26  (14%)\nanal                 26  (14%)\ndark-skinned male    26  (14%)\nfuta on female       25  (13%)\nearrings             25  (13%)\ngloves               25  (13%)\norange hair          25  (13%)\nmakeup               25  (13%)\nclothed              24  (13%)\nass                  23  (12%)\ncleavage             23  (12%)\ndickgirl             22  (12%)\n2girls               22  (12%)\nnipple piercing      22  (12%)\nanal sex             22  (12%)\nfemboy               22  (12%)\nlipstick on penis    22  (12%)\nhumanoid             22  (12%)\nhair                 22  (12%)\nlarge penis          21  (11%)\nbig penis            21  (11%)\nfemale focus         20  (11%)\nkneeling             20  (11%)\nelf                  19  (10%)\ndemon                19  (10%)\nmilf                 19  (10%)</code></pre>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581311+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "147759",
    "prompt": "Remacri\n<p>This upscaler is not mine, all the credit goes to: <a target=\"_blank\" rel=\"ugc\" href=\"https://openmodeldb.info/users/foolhardy\"><strong>FoolhardyVEVO</strong></a></p><p>Official WIKI page: <a target=\"_blank\" rel=\"ugc\" href=\"https://openmodeldb.info/models/4x-Remacri\"><strong>openmodeldb</strong></a></p><p>License of use it: <a target=\"_blank\" rel=\"ugc\" href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\"><strong>CC-BY-NC-SA-4.0</strong></a></p><p></p><p><strong>HOW TO INSTALL:</strong></p><p>Copy the file <code>4x_foolhardy_Remacri.safetensors</code> inside the folder: <code>stable-diffusion/models/ESRGAN</code> <span style=\"background-color:rgb(26, 27, 30);color:rgb(193, 194, 197);font-family:-apple-system, system-ui, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;;font-size:16px\">or </span><code>ComfyUI/models/upscale_models</code></p><p>Restart/Reload you Stable Diffusion instance</p><p>The upscaler should be visible for hi-res and extras tabs</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581315+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "10415",
    "prompt": "国风3 GuoFeng3\n<p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0f6b6abd-75c6-4a33-be22-2497f0efc937/width=525/0f6b6abd-75c6-4a33-be22-2497f0efc937.jpeg\" /></p><h3 id=\"ai\"><strong><u><span style=\"color:rgb(134, 142, 150)\">本人郑重声明：本模型禁止用于训练基于明星、公众人物肖像的风格模型训练，因为这会带来争议，对AI社区的发展造成不良的负面影响。</span></u></strong></h3><h3 id=\"heading-31\"><strong><u><span style=\"color:rgb(134, 142, 150)\">本模型注明：训练素材中不包含任何真人素材。</span></u></strong></h3><p></p><p><span style=\"color:rgb(130, 201, 30)\">国风偏写实版本推荐-Recommended Realistic Version of National Style：</span><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/77650/guofengrealmix\">https://civitai.com/models/77650/guofengrealmix</a></p><p><span style=\"color:rgb(250, 82, 82)\">基于SDXL1.0训练的国风4-National Style 4 Based on SDXL1.0 Training:</span><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/118009/4-guofeng4\"><span style=\"color:rgb(250, 82, 82)\">https://civitai.com/models/118009/4-guofeng4</span></a></p><p></p><p><strong>一些答疑</strong></p><p><strong><span style=\"color:rgb(193, 194, 197)\">TIP：国风2或国风3以及大版本下的小版本，都是独立存在，不同版本的画风，关键词，对应内容都会有相应区别，建议下载时可以根据效果图或者模型的独立介绍去下载。</span></strong></p><p><strong><span style=\"color:rgb(193, 194, 197)\">TIP2：国风2代与3代的区别：我对大版本的划分是训练质量不同(比如素材分辨率，训练设置所消耗的显存量，有时候也会和素材量有关)。</span></strong></p><p></p><p>===========</p><p></p><h2 id=\"update-history\"><strong><span style=\"color:rgb(230, 73, 128)\">更新历史 - Update History</span></strong></h2><p></p><p><span style=\"color:rgb(134, 142, 150)\">2023.6.29 增加了v3.4版本</span></p><p><span style=\"color:rgb(134, 142, 150)\">2023.4.05 增加了v3.3版本</span></p><p><span style=\"color:rgb(134, 142, 150)\">2023.3.02 增加了v3.2_light版本</span></p><p><span style=\"color:rgb(134, 142, 150)\">2023.2.27 增加了safetensors格式</span></p><p><span style=\"color:rgb(134, 142, 150)\">-</span></p><p><span style=\"color:rgb(134, 142, 150)\">2023.6.29 added v3.4 version</span></p><p><span style=\"color:rgb(134, 142, 150)\">2023.4.05 added v3.3 version</span></p><p><span style=\"color:rgb(134, 142, 150)\">2023.3.02 added v3.2_Light version</span></p><p><span style=\"color:rgb(134, 142, 150)\">2023.2.27 added safetensors format</span></p><p></p><p>===========</p><p></p><h2 id=\"model-introduction\"><strong><span style=\"color:rgb(230, 73, 128)\">模型介绍 - Model Introduction</span></strong></h2><p></p><p><span style=\"color:rgb(250, 82, 82)\">欢迎使用GuoFeng3模型 - 这是一个中国华丽古风风格模型，也可以说是一个古风游戏角色模型，具有2.5D的质感。</span></p><p><span style=\"color:rgb(253, 126, 20)\">GuoFeng3:原始模型</span></p><p><span style=\"color:rgb(253, 126, 20)\">GuoFeng3.1:对GuoFeng3人像进行了微调修复</span></p><p><span style=\"color:rgb(253, 126, 20)\">GuoFeng3.2:如果你不知道选择GuoFeng3还是GuoFeng2，可以直接使用此版本</span></p><p><span style=\"color:rgb(253, 126, 20)\">GuoFeng3.2_light:通过GuoFeng3.2融合了基于 Noise Offset 训练的Lora使得模型能够画出更漂亮的光影效果(Lora:epi_noiseoffset/Theovercomer8's Contrast Fix)</span></p><p><span style=\"color:rgb(253, 126, 20)\">GuoFeng3.3:此版本是基于3.2的一次较大的更新与改进，可以适配full body，即使你的tag不太好，模型也会对画面进行自动修改，不过因此模型出的脸会比较雷同。</span></p><p><span style=\"color:rgb(253, 126, 20)\">GuoFeng3.4:此版本重新进行了新的训练，适配全身图，同时内容上与前几个版本有较大不同。并调整了整体画风，降低了过拟合程度，使其能使用更多的lora对画面与内容进行调整。</span></p><p>其它个人模型：</p><p>同款模型画风的Lora版本：<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/11352/guofeng3lora\">https://civitai.com/models/11352/guofeng3lora</a></p><p>西幻模型：<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/10818/westmagic\">https://civitai.com/models/10818/westmagic</a></p><p>-</p><p><span style=\"color:rgb(34, 139, 230)\">Welcome to GuoFeng3 model - This is a Chinese gorgeous antique style model, which can also be said to be an antique game role model with a 2.5D texture.</span></p><p><span style=\"color:rgb(250, 176, 5)\">GuoFeng3: original model</span></p><p><span style=\"color:rgb(250, 176, 5)\">GuoFeng3.1: The portrait of GuoFeng3 has been fine-tuned and repaired</span></p><p><span style=\"color:rgb(250, 176, 5)\">GuoFeng3.2: If you don't know whether to choose GuoFeng3 or GuoFeng2, you can use this version directly</span></p><p><span style=\"color:rgb(250, 176, 5)\">GuoFeng3.2_Light: Through GuoFeng3.2, Lora based on Noise Offset training is integrated to enable the model to draw more beautiful light and shadow effects (Lora: epi_noiseoffset/Theovercolor8's Contrast Fix)</span></p><p><span style=\"color:rgb(250, 176, 5)\">GuoFeng3.3:This version is a major update and improvement based on 3.2, which can adapt to full bodies. Even if your tag is not very good, the model will automatically modify the screen, but therefore the faces produced by the model will be quite similar.</span></p><p><span style=\"color:rgb(250, 176, 5)\">GuoFeng3.4: This version has undergone new training to adapt to the full body image, and the content is significantly different from previous versions.At the same time, the overall painting style has been adjusted, reducing the degree of overfitting, allowing it to use more Lora to adjust the screen and content.</span></p><p>Lora version of the same model painting style:<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/11352/guofeng3lora\">https://civitai.com/models/11352/guofeng3lora</a></p><p>Western fantasy model:<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/10818/westmagic\">https://civitai.com/models/10818/westmagic</a></p><p></p><p>===========</p><p></p><h2 id=\"3lora-guofeng3dlclora\"><strong><span style=\"color:rgb(230, 73, 128)\">国风3可选Lora - GuoFeng3DLC(Lora)</span></strong></h2><p></p><p>1.梦 Dream (<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/44310/dream-based-on-guofeng3\">https://civitai.com/models/44310/dream-based-on-guofeng3</a>)</p><p>2.武墨 WuMo (<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/47728/wumo\">https://civitai.com/models/47728/wumo</a>)</p><p></p><p>===========</p><p></p><h2 id=\"recommended-settings\"><strong><span style=\"color:rgb(230, 73, 128)\">建议的设置 - Recommended settings</span></strong></h2><p></p><p>Sampling steps:<strong>30 or 50</strong></p><p>Sampler:<strong>DPM++ SDE Karras</strong></p><p>VAE<strong>:vae-ft-mse-840000 </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\">stabilityai/sd-vae-ft-mse-original at main (</a><a target=\"_blank\" rel=\"ugc\" href=\"http://huggingface.co\">huggingface.co</a>)</p><p>======</p><p><span style=\"color:rgb(250, 82, 82)\">如果你的出图全身图时出现脸部崩坏建议删除full body关键词或者使用脸部自动修复插件：</span></p><p><span style=\"color:rgb(250, 82, 82)\">国外源地址：</span><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/ototadana/sd-face-editor.git\">https://github.com/ototadana/sd-face-editor.git</a></p><p><span style=\"color:rgb(250, 82, 82)\">国内加速地址：</span><a target=\"_blank\" rel=\"ugc\" href=\"https://jihulab.com/xiaolxl_pub/sd-face-editor.git\">https://jihulab.com/xiaolxl_pub/sd-face-editor.git</a></p><p>-</p><p><span style=\"color:rgb(34, 139, 230)\">If you experience facial collapse during the full body image, it is recommended to delete the full body keyword or use the facial automatic repair plugin:</span></p><p><span style=\"color:rgb(34, 139, 230)\">Foreign source address:</span><span style=\"color:rgb(76, 110, 245)\"> </span><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/ototadana/sd-face-editor.git\">https://github.com/ototadana/sd-face-editor.git</a></p><p><span style=\"color:rgb(34, 139, 230)\">Domestic acceleration address: </span><a target=\"_blank\" rel=\"ugc\" href=\"https://jihulab.com/xiaolxl_pub/sd-face-editor.git\">https://jihulab.com/xiaolxl_pub/sd-face-editor.git</a></p><p>=====</p><p>关键词 - key word:</p><pre><code>best quality, masterpiece, highres, 1girl,china dress,Beautiful face</code></pre><p>负面词 - Negative words:</p><pre><code>NSFW, lowres,bad anatomy,bad hands, text, error, missing fingers,extra digit, fewer digits, cropped, worstquality, low quality, normal quality,jpegartifacts,signature, watermark, username,blurry,bad feet</code></pre><p>更好的负面词 - Better negative words:</p><pre><code>(((simple background))),monochrome ,lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, lowres, bad anatomy, bad hands, text, error, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, ugly,pregnant,vore,duplicate,morbid,mut ilated,tran nsexual, hermaphrodite,long neck,mutated hands,poorly drawn hands,poorly drawn face,mutation,deformed,blurry,bad anatomy,bad proportions,malformed limbs,extra limbs,cloned face,disfigured,gross proportions, (((missing arms))),(((missing legs))), (((extra arms))),(((extra legs))),pubic hair, plump,bad legs,error legs,username,blurry,bad feet</code></pre><p>如果想元素更丰富，可以添加下方关键词 - If you want to enrich the elements, you can add the following keywords</p><pre><code>Beautiful face,\nhair ornament, solo,looking at viewer,smile,closed mouth,lips\nchina dress,dress,hair ornament, necklace, jewelry, long hair, earrings, chinese clothes,\narchitecture,east asian architecture,building,outdoors,rooftop,city,cityscape</code></pre>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581330+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "30240",
    "prompt": "ToonYou\n<h1 id=\"toonyou-beta-3-is-up\">ToonYou - Beta 6 is up!</h1><p>Silly, stylish, and.. kind of cute? 😅</p><p>A bit of detail with a cartoony feel, it keeps getting better!</p><p>With your support, ToonYou has come this far, Thx!</p><h3 id=\"heading-18\">⬇Please read the information below🙏</h3><h3 id=\"heading-3326\">1️⃣Recommended Settings</h3><pre><code>- VAE is included starting with Alpha2 (840000)\n- Clip skip: 2\n- CFG scale: 8</code></pre><pre><code>- Sampler: DPM++ SDE Karras\n    Sampling Steps : 30+</code></pre><pre><code>- Upscaler (Hires. fix): R-ESRGAN 4x+ Anime6B\n    Hires steps: 14\n    Denoising strength: 0.35\n    Upscale by: 1.5+</code></pre><pre><code>- Default prompts  \n    Pos: (best quality, masterpiece), ... \n    Neg: (worst quality, low quality, letterboxed), ...</code></pre><h3 id=\"heading-3327\">2️⃣Using <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\">Adetailer</a></h3><pre><code>- Main UI &gt; Extensions &gt; Install from URL\n    This fixes problems with the character's eyes and face in most situations\n    The default usage is to simply enable it and leave it alone</code></pre><h3 id=\"heading-3328\">✅Now you're good to go!</h3><p>For more information, please continue below</p><p></p><h3 id=\"heading-3329\">ℹ️Why is my image different from yours?</h3><ul><li><p><strong>I can't give you any technical help, sorry</strong></p></li><li><p>Keep your prompts <strong>simple and correct</strong></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/DominikDoom/a1111-sd-webui-tagcomplete\"><strong>Tag auto complete extension</strong> </a>to find the appropriate tags</p></li><li><p>Tags like 'Realistic, 8k, ...' sometimes ruin an image</p><ul><li><p>Also These tags are often more useless than you might think</p></li><li><p>Neg Tags like 'mutated arms' are useless than you might think</p></li></ul></li><li><p><strong>Neg embedding</strong> can have a <strong>significant impact</strong> on the characteristics of a model</p><ul><li><p>These are not as perfect as you might think</p></li></ul></li></ul></li></ul><p></p><h3 id=\"heading-2458\">💝Contact &amp; Support</h3><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"mailto:ux.arihan@gmail.com\"><strong>ux.arihan@gmail.com</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/bradcatt\"><strong>A cup of coffee would be nice! 😉</strong></a></p></li></ul><p></p><h3 id=\"heading-3330\">⚠️Warning</h3><ul><li><p><strong>You are solely responsible for any legal liability resulting from unethical use of this model</strong></p></li></ul><ul><li><p><strong>Don't use my model as bait to drive people to your paid generation service without permission</strong></p></li><li><p><strong>For anything other than general personal use, please be sure to contact me</strong></p></li></ul>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581340+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "404154",
    "prompt": "WAI-ANI-NSFW-PONYXL\n<p>If you want to use more my checkpoint online generation, please visit here.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/u/762555264535746522\">https://tensor.art/u/762555264535746522</a></p><p></p><p></p><p><span style=\"color:rgb(193, 194, 197)\">You can run WAI-ANI-NSFW-PONYXL and use its API on SinkIn:</span></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/2zgReX9\"><span style=\"color:rgb(34, 139, 230)\">https://sinkin.ai/m/2zgReX9</span></a></p><p></p><hr /><h1 id=\"v14-released.-0dd7br8zl\"><span style=\"color:rgb(250, 82, 82)\">V14 released.</span></h1><p></p><p><strong><span style=\"color:#fab005\">Increased composition diversity and improved model accuracy now allow images to be generated with fewer steps.</span></strong></p><p></p><p></p><h2 id=\"recommended-setting-kqfs7j4n7\"><span style=\"color:rgb(64, 192, 87)\">Recommended Setting</span></h2><h3 id=\"steps:20-30-a2841j4w3\"><span style=\"color:rgb(250, 82, 82)\">Steps:20-30</span></h3><h3 id=\"cfg-scale:-5-7-hge3gwra1\"><span style=\"color:rgb(250, 82, 82)\">CFG scale: 5-7</span></h3><h3 id=\"sampler:-euler-adpm++-2m-karras-7gc2n7sm9\"><span style=\"color:rgb(250, 82, 82)\">Sampler: Euler a/DPM++ 2M Karras</span></h3><h3 id=\"adetailer-face_yolov8ns.pt-use-can-fix-eyes-9wc2h6jcw\"><strong><span style=\"color:rgb(250, 82, 82)\">ADetailer face_yolov8n/s.pt use can fix eyes</span></strong></h3><p></p><h3 id=\"for-the-example-images-qds2h65da\"><strong><span style=\"color:rgb(250, 176, 5)\">For the example images</span></strong></h3><p><span style=\"color:rgb(250, 176, 5)\">I used 1024x1360,</span></p><p><span style=\"color:rgb(250, 176, 5)\">generated directly without AD or hires fix.</span></p><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>worst quality,bad quality,jpeg artifacts, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark,</code></pre><p></p><p></p><hr /><h1 id=\"v13-released.-poprjihzr\"><span style=\"color:rgb(250, 82, 82)\">V13 released.</span></h1><p></p><ul><li><p><strong><span style=\"color:rgb(250, 176, 5)\">Increased body stability and accuracy.</span></strong></p></li><li><p><strong><span style=\"color:rgb(250, 176, 5)\">overall balance adjustment.</span></strong></p></li></ul><p></p><p></p><h2 id=\"recommended-setting-u0qh3zebz\"><span style=\"color:rgb(64, 192, 87)\">Recommended Setting</span></h2><h3 id=\"steps:-30-wv1nst4jf\"><span style=\"color:rgb(250, 82, 82)\">Steps: 30</span></h3><h3 id=\"cfg-scale:-7-ait3luw3w\"><span style=\"color:rgb(250, 82, 82)\">CFG scale: 7</span></h3><h3 id=\"sampler:-euler-adpm++-2m-karras-o6o23533p\"><span style=\"color:rgb(250, 82, 82)\">Sampler: Euler a/DPM++ 2M Karras</span></h3><h3 id=\"adetailer-face_yolov8ns.pt-use-can-fix-eyes-g62djd3n6\"><strong><span style=\"color:rgb(250, 82, 82)\">ADetailer face_yolov8n/s.pt use can fix eyes</span></strong></h3><p></p><h3 id=\"for-the-example-images-ai92tf9rz\"><strong><span style=\"color:rgb(250, 176, 5)\">For the example images</span></strong></h3><p><span style=\"color:rgb(250, 176, 5)\">I used 1024x1360,</span></p><p><span style=\"color:rgb(250, 176, 5)\">generated directly without AD or hires fix.</span></p><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>worst quality,bad quality,jpeg artifacts, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark,</code></pre><p></p><p></p><hr /><h1 id=\"v12-released.-rf2308ahd\"><span style=\"color:rgb(250, 82, 82)\">V12 released.</span></h1><p></p><ul><li><p><span style=\"color:rgb(250, 176, 5)\">Style adjustment, background adjustment, and increased stability.</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Added more compositions.</span></p></li></ul><p></p><p></p><h2 id=\"recommended-setting-vor7cury3\"><span style=\"color:rgb(64, 192, 87)\">Recommended Setting</span></h2><h3 id=\"steps:-30-forgzmpw8\"><span style=\"color:rgb(250, 82, 82)\">Steps: 30</span></h3><h3 id=\"cfg-scale:-7-lvvc2hvsl\"><span style=\"color:rgb(250, 82, 82)\">CFG scale: 7</span></h3><h3 id=\"sampler:-euler-adpm++-2m-karras-82o2n084x\"><span style=\"color:rgb(250, 82, 82)\">Sampler: Euler a/DPM++ 2M Karras</span></h3><h3 id=\"adetailer-face_yolov8ns.pt-use-can-fix-eyes-ptr9gwc6h\"><strong><span style=\"color:rgb(250, 82, 82)\">ADetailer face_yolov8n/s.pt use can fix eyes</span></strong></h3><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>score_6, score_5, score_4, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark,</code></pre><p></p><p></p><hr /><h1 id=\"v11-dmmzd6ilc\">v11</h1><h3 id=\"-r28kaeyl4\"></h3><h3 id=\"weight-adjustment-balancing-the-art-style-mdijozia6\"><strong><span style=\"color:rgb(190, 75, 219)\">Weight adjustment, balancing the art style</span></strong></h3><p></p><p><strong><span style=\"color:rgb(250, 176, 5)\">All example images(Except the cover) are generated at 1024x1360, without using AD and hires fix.</span></strong></p><p></p><h2 id=\"recommended-setting-0yvhg3h0r\"><span style=\"color:rgb(64, 192, 87)\">Recommended Setting</span></h2><p><strong><span style=\"color:rgb(250, 82, 82)\">Steps: 30</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">CFG scale: 7</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">Sampler: Euler a/DPM++ 2M Karras</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">ADetailer face_yolov8n/s.pt use can fix eyes</span></strong></p><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>worst quality,bad quality,jpeg artifacts, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark, </code></pre><hr /><p></p><p></p><h1 id=\"v10-2bajuxpz1\"><span style=\"color:rgb(250, 82, 82)\">V10</span></h1><ul><li><p><span style=\"color:rgb(250, 176, 5)\">Better Background</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Clothes details up</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Better mature female</span></p><p></p></li></ul><p></p><h2 id=\"recommended-setting-m1vaq9cng\"><span style=\"color:rgb(64, 192, 87)\">Recommended Setting</span></h2><p><strong><span style=\"color:rgb(250, 82, 82)\">Steps: 30</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">CFG scale: 7</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">Sampler: Euler a/DPM++ 2M Karras</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">ADetailer face_yolov8n/s.pt use can fix eyes</span></strong></p><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>worst quality,bad quality,jpeg artifacts, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark, </code></pre><p></p><p>++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</p><h2 id=\"v9-hyper12step-0k6r0qsl6\"><span style=\"color:rgb(64, 192, 87)\">V9 Hyper12step</span></h2><h3 id=\"please-refer-to-the-instructions-on-the-right-side-of-v9-hyper12step-for-usage.-9qp2vzfbk\"><span style=\"color:rgb(250, 176, 5)\">Please refer to the instructions on the right side of V9 Hyper12step for usage.</span></h3><h1 id=\"v9-released.-2m4qfkrww\"><span style=\"color:rgb(250, 82, 82)\">V9 released.</span></h1><h3 id=\"v8-greaterv9-vo47a7xib\"><span style=\"color:rgb(250, 176, 5)\">v8-&gt;v9</span></h3><ul><li><p>adjusted the facial data to make it more versatile, allowing for easier generation of faces across various ages.</p></li><li><p>added more NSFW materials.</p></li><li><p>attempted to reduce the generation of some unnecessary details.</p></li></ul><p></p><h2 id=\"-5iwvq1ujq\"></h2><h2 id=\"recommended-setting-vp04o1mlv\"><span style=\"color:rgb(64, 192, 87)\">Recommended Setting</span></h2><p><strong><span style=\"color:rgb(250, 82, 82)\">Steps: 30</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">CFG scale: 7</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">Sampler: Euler a/DPM++ 2M Karras</span></strong></p><p><strong><span style=\"color:rgb(250, 82, 82)\">ADetailer face_yolov8n/s.pt use can fix eyes</span></strong></p><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>worst quality,bad quality,jpeg artifacts, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark, </code></pre><p></p><p></p><p>__________________________________________________________________________________________________</p><p></p><p></p><p></p><h3 id=\"hyper12step-released.-5lioxxzfd\"><span style=\"color:rgb(250, 176, 5)\">hyper12step released.</span></h3><p><span style=\"color:rgb(250, 176, 5)\">about size</span></p><p><span style=\"color:rgb(250, 176, 5)\">Various combinations from 768x768 to 1360x1360 can produce good images.</span></p><p><span style=\"color:rgb(64, 192, 87)\">Recommended Setting</span></p><p><span style=\"color:rgb(250, 82, 82)\">Steps: </span><span style=\"color:rgb(250, 176, 5)\">12</span></p><p><span style=\"color:rgb(250, 82, 82)\">CFG scale: </span><span style=\"color:rgb(250, 176, 5)\">3.5</span></p><p><span style=\"color:rgb(250, 82, 82)\">Sampler: Euler a</span></p><p><span style=\"color:rgb(250, 82, 82)\">Not very necessary to use ADetailer correction</span></p><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>score_6, score_5, score_4, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark,</code></pre><p></p><h3 id=\"ps.the-example-images-use-a-size-of-896x1192.-no-ad-no-hires.-fix-soqzlyiuy\"><strong><span style=\"color:rgb(250, 82, 82)\">PS.The example images use a size of 896x1192. no AD no Hires. fix</span></strong></h3><p>__________________________________________________________________________________________________</p><h3 id=\"version-8-released.-cdrr4xcso\"><span style=\"color:rgb(250, 176, 5)\">Version 8 released.</span></h3><p><span style=\"color:rgb(250, 176, 5)\">v7-&gt;v8</span></p><ul><li><p><span style=\"color:rgb(250, 176, 5)\">Added some training related to camera angles and backgrounds.</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Added more NSFW materials for additional training.</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Added some training for special effects.</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Optimization of overall composition logic.</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Fixed some minor issues.</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">better eyes and hands.</span></p></li></ul><p></p><h3 id=\"recommended-setting-h3xiwnufc\"><span style=\"color:rgb(230, 73, 128)\">Recommended Setting</span></h3><h1 id=\"same-as-v7-9x5tr5gm8\"><span style=\"color:rgb(250, 176, 5)\">Same as v7</span></h1><p></p><p></p><p>__________________________________________________________________________________________________</p><p></p><h3 id=\"version-7-9yvvvzl0o\"><span style=\"color:rgb(121, 80, 242)\">Version 7</span></h3><p><span style=\"color:rgb(121, 80, 242)\">v6-&gt;v7</span></p><ul><li><p><span style=\"color:rgb(121, 80, 242)\">Fixed the issue where images appeared entirely covered with snowflakes.</span></p></li><li><p><span style=\"color:rgb(121, 80, 242)\">Revised the composition logic to be more suitable for general scenarios.</span></p></li><li><p><span style=\"color:rgb(121, 80, 242)\">Added new assets for backgrounds, mature women, and clothing.</span></p></li><li><p><span style=\"color:rgb(121, 80, 242)\">Ensured consistency with the previous model and further fixed the issue of blurry eyes in medium and long shots.</span></p></li><li><p><span style=\"color:rgb(121, 80, 242)\">Fixed some minor issues.</span></p></li></ul><p></p><h1 id=\"v7-recommended-setting-x2ap9wrt8\"><span style=\"color:rgb(64, 192, 87)\">V7 Recommended Setting</span></h1><h3 id=\"steps:-30-k55h036h4\"><span style=\"color:rgb(250, 82, 82)\">Steps: 30</span></h3><h3 id=\"cfg-scale:-7-1aw715qhk\"><span style=\"color:rgb(250, 82, 82)\">CFG scale: 7</span></h3><h3 id=\"sampler:-euler-adpm++-2m-karras-xt48l5suu\"><span style=\"color:rgb(250, 82, 82)\">Sampler: Euler a/DPM++ 2M Karras</span></h3><h3 id=\"adetailer-face_yolov8ns.pt-use-can-fix-eyes-4ej2ph4rr\"><strong><span style=\"color:rgb(250, 82, 82)\">ADetailer face_yolov8n/s.pt use can fix eyes</span></strong></h3><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>score_6, score_5, score_4, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark,</code></pre><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p>________________________________________________________________________________________________</p><p><span style=\"color:rgb(250, 82, 82)\">Regarding the 8step model, it is a lightweight model that can generate images in as few as 8 steps. However, the quality and text comprehension will be relatively lower. If speed is not a major concern for you, it is recommended to continue using version 6.0.</span></p><p></p><h3 id=\"8-step-setting-qw3s638uu\"><span style=\"color:rgb(230, 73, 128)\">8 STEP Setting</span></h3><p>Steps: 8-12</p><p>CFG scale: 3</p><p>Sampler: Euler a</p><p><strong>ADetailer face_yolov8n/s.pt use can fix eyes</strong></p><p>Positive Prompt and Negative Prompt same 6.0</p><p>__________________________________________________________________________________________________</p><h3 id=\"6.0-t5dizlz1j\"><span style=\"color:rgb(34, 139, 230)\">6.0</span></h3><h3 id=\"v5-greaterv6-change-point-pemeolnrq\"><span style=\"color:rgb(34, 139, 230)\">v5-&gt;v6 Change point</span></h3><ul><li><p><span style=\"color:rgb(34, 139, 230)\">Better Background</span></p></li><li><p><span style=\"color:rgb(34, 139, 230)\">better eyes</span></p></li><li><p><span style=\"color:rgb(34, 139, 230)\">fix vae</span></p></li></ul><p></p><h1 id=\"recommended-setting-yqn47j4s2\"><span style=\"color:rgb(64, 192, 87)\">Recommended Setting</span></h1><h3 id=\"steps:-30-vj1c8s575\">Steps: 30</h3><h3 id=\"cfg-scale:-7-7rxotcvfk\">CFG scale: 7</h3><h3 id=\"sampler:-euler-adpm++-2m-karras(better-eyes)-pu6yrkipe\">Sampler: Euler a/<span style=\"color:rgb(250, 82, 82)\">DPM++ 2M Karras(better eyes)</span></h3><h3 id=\"adetailer-face_yolov8ns.pt-use-can-fix-eyes-39l0e6jub\"><strong>ADetailer face_yolov8n/s.pt use can fix eyes</strong></h3><p></p><p>Positive Prompt</p><p></p><pre><code>score_9, score_8_up, score_7_up,source_anime,BREAK</code></pre><p></p><p>Negative Prompt</p><p></p><pre><code>score_6, score_5, score_4, source_cartoon, \n3d, (censor),monochrome,blurry, lowres,watermark,</code></pre><p></p><p></p><h3 id=\"you-can-view-the-supported-art-styles-from-https:civitai.comarticles5715-vbflweqoa\"><span style=\"color:rgb(250, 82, 82)\">You can view the Supported art styles from </span><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/5715\"><span style=\"color:rgb(34, 139, 230)\">https://civitai.com/articles/5715</span></a></h3><h3 id=\"thank-you-deepdark_fantasy514-for-providing-the-test.-1wfpzltwt\"><span style=\"color:rgb(250, 82, 82)\">Thank you, DeepDark_Fantasy514, for providing the test.</span></h3><h3 id=\"-y8h3kh9k3\"></h3><p></p><p><span style=\"color:rgb(250, 176, 5)\">v4-&gt;v5 Change point</span></p><ul><li><p><span style=\"color:rgb(250, 176, 5)\">Better Background</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Clothes details up</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Add some mature female</span></p></li><li><p><span style=\"color:rgb(250, 176, 5)\">Little better hands and eyes</span></p><p></p><p></p></li></ul><p>Recommended Setting</p><ul><li><p>Steps: 30</p></li><li><p>CFG scale: 7</p></li><li><p>Sampler: Euler a</p></li><li><p><strong>ADetailer face_yolov8n/s.pt use can fix eyes</strong></p></li></ul><p></p><p>Positive Prompt</p><pre><code>score_9, score_8_up, score_7_up,</code></pre><p>Negative Prompt (<strong>THX for <span style=\"color:rgb(193, 194, 197)\">snipsnapsnipsnap recommend </span></strong>)</p><ul><li><p>Base:score_6, score_5, score_4, source_cartoon</p></li><li><p>Optional: source_furry, source_pony <strong><span style=\"color:rgb(250, 82, 82)\">can bleaches skin</span></strong></p></li><li><p>else: 3d, (censor),monochrome,blurry, lowres,watermark,</p></li></ul><p>I often use it now</p><p>[score_6, score_5, score_4, source_cartoon,</p><p>3d, (censor),monochrome,blurry, lowres,watermark, ]</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581352+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "14171",
    "prompt": "Cute_girl_mix4\n<p>work with Chilloutmix, can generate natural, cute, girls.</p><p>Mix from chinese tiktok influencers, not any specific real person.</p><p></p><p>The third example used my other lora <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/15271\"><strong>20D.</strong></a></p><p></p><p>&lt;lora:cuteGirlMix4_v10:<strong>(<u>recommend0.4-0.7 here)</u></strong>&gt;,</p><p><strong>Trigger Word is '<u>mix4</u>' .</strong></p><p></p><p><strong>hope to receive your works!!!</strong></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581355+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "16993",
    "prompt": "badhandv4\n<h1 id=\"heading-1238\"><strong>介绍（Chinese Version）</strong></h1><h2 id=\"heading-1239\"><strong>简介</strong></h2><p>此文本嵌入（text embedding）为 <strong><span style=\"color:#fa5252\">负面文本嵌入</span></strong>。它能够在对画风影响较小的前提下改善AI生成图片的手部细节。如果它让你的模型表现得比以前更糟，请勿使用它。您可与其他负面文本嵌入一同使用。虽然它是为 AnimeIllustDiffusion 模型设计的，但您也可以在其他模型上使用。</p><p>它<strong>似乎</strong>在较高的 CFG Scale 下（&gt;=11）表现得更好。</p><p></p><h2 id=\"heading-1240\"><strong>如何使用</strong></h2><p><strong>对于 AUTOMATIC1111 WebUI 用户</strong></p><ol><li><p>下载模型文件 <a target=\"_blank\" rel=\"ugc\" href=\"http://badhandv4.pt\">badhandv4.pt</a>；</p></li><li><p>将模型文件放置于您 Stable Diffusion WebUI 目录下的 \"embeddings\" 文件夹内；</p></li><li><p>打开 WebUI，在负面提示词框内填入 “badhandv4” 以触发效果。</p></li></ol><p></p><p><strong>对于 ComfuUI 用户</strong></p><ol><li><p>下载模型文件 <a target=\"_blank\" rel=\"ugc\" href=\"http://badhandv4.pt\">badhandv4.pt</a>；</p></li><li><p>将模型文件放置于您 ComfyUI 目录下的 \"models/embeddings\" 文件夹内；</p></li><li><p>打开 ComfyUI，在 <strong>负面提示词框内 </strong>填入 “embedding:badhandv4” 以触发效果。</p></li></ol><p></p><h2 id=\"heading-1241\"><strong>SDXL 版本</strong></h2><p>我将 badhandv4 移植到了 SDXL 格式的 embedding 上。下载地址参见：</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/144327/negative-embeddings-aidxl-series-models\">Negative Embeddings - AIDXL Series Models - v0.4 | Stable Diffusion Embedding | Civitai</a></p><p></p><h1 id=\"heading-1242\"><strong>Introduction</strong> (英文版本)</h1><h2 id=\"heading-13\"><strong>Introduction</strong></h2><p>This text embedding is a <strong><span style=\"color:#fa5252\">negative text embedding</span></strong>. It can improve the hand details of AI-generated images with less impact on the style of painting. If it makes your model behave worse than before, please do not use it. You can use it with other negative text embeddings.</p><p>Although it was designed for AnimeIllustDiffusion model, you can use it on other models as well.</p><p>It performs better with higher CFG scale (&gt;=11).</p><p></p><h2 id=\"heading-1244\"><strong>Quick Start</strong></h2><p><strong>For AUTOMATIC1111 WebUI User</strong></p><ol><li><p>Download model file <a target=\"_blank\" rel=\"ugc\" href=\"http://badhandv4.pt\">badhandv4.pt</a>;</p></li><li><p>Move the model file to the \"embeddings\" folder in your Stable Diffusion WebUI directory;</p></li><li><p>Lanuch WebUI. Enter \"badhandv4\" into the <strong>negative prompt</strong> box to trigger its effect.</p></li></ol><p></p><p><strong>For ComfyUI User</strong></p><ol><li><p>Download model file <a target=\"_blank\" rel=\"ugc\" href=\"http://badhandv4.pt\">badhandv4.pt</a>;</p></li><li><p>Move the model file to the \"models/embeddings\" folder in your ComfyUI directory;</p></li><li><p>Lanuch ComfyUI. Enter \"embedding:badhandv4\" into the negative prompt box to trigger its effect.</p></li></ol><p></p><h2 id=\"heading-1245\"><strong>SDXL version</strong></h2><p>I converted badhandv4 to SDXL format embedding.<span style=\"color:rgb(60, 64, 67)\"> </span>For downloading, see:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/144327/negative-embeddings-aidxl-series-models\">Negative Embeddings - AIDXL Series Models - v0.4 | Stable Diffusion Embedding | Civitai</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581360+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "10028",
    "prompt": "NeverEnding Dream (NED)\n<h2>NeverEnding Dream (a.k.a. NED)</h2><h3><strong>This is a dream that you will never want to wake up from</strong></h3><p><strong>Add a ❤️ to receive future updates. This took much time and effort, please be supportive </strong>🫂<br /><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> 🅿️ or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> ☕</strong></p><p><strong>V1.22 update: </strong>thanks to Bokus for some of the preview images and the tests.</p><p><strong>Available on the following websites with GPU acceleration:</strong></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/\"><strong>Mage.space</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"http://Sinkin.ai\"><strong>Sinkin.ai</strong></a></p></li><li><p><a rel=\"ugc\" href=\"https://randomseed.co/model/59\"><strong>RandomSeed</strong></a></p></li></ul><p></p><p>It has been a while since I made a model. I've been making LoRA's non stop for the last month, but I felt like I needed something. A big problem with <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384\">DreamShaper</a> is that it wasn't much compatibles with the LoRA's I was making. So I wanted to create a model that was \"artistic\" like DreamShaper but also able to use my LoRA's and booru tags for generating images. Plus I wanted this to be able to make <strong>good </strong>anime stuff out of the box, without needing an additional LoRA.</p><p>After a lot of tests and also fine tuning (plus LoRA merges) here is my newest model.</p><p>It came out a bit more realistic then I wanted, but I won't complain.</p><p><strong>What is this model great at?</strong></p><ul><li><p>Generating cosplay images</p></li><li><p>Generating anime pictures</p></li><li><p>Work accurately with character LoRA</p></li><li><p>Generating good looking people</p></li><li><p>Generating realistic animals</p></li><li><p>Generating images using booru-like tags</p></li></ul><p><strong>What is this model not too good at?</strong></p><ul><li><p>Generating pictures from complex sentences</p></li><li><p>Making fantasy/sci-fi paintings</p></li></ul><p>So this basically complements <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384\">DreamShaper</a>, and it also doesn't include Dreamlike in the mix.</p><p></p><p>I hope you'll enjoy it!</p><p></p><p><strong>Some tips:</strong></p><ul><li><p>Use CLIP skip 2.</p></li><li><p>Select \"auto\" as vae if you're using the baked vae version.</p></li><li><p>Use highres fix or img2img to upscale the images after you get a preview. See the examples generation data for settings suggestions, I've tested various techniques.</p></li><li><p>If you're making images where the subject is far, remember you can inpaint eyes and faces selecting \"only masked\".</p></li><li><p>Stable Diffusion is great, have fun with it!</p></li></ul><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581378+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "260267",
    "prompt": "Animagine XL V3.1\n<p><strong>Animagine XL 3.1 </strong>is an update in the Animagine XL V3 series, enhancing the previous version, Animagine XL 3.0. This open-source, anime-themed text-to-image model has been improved for generating anime-style images with higher quality. It includes a broader range of characters from well-known anime series, an optimized dataset, and new aesthetic tags for better image creation. Built on Stable Diffusion XL, Animagine XL 3.1 aims to be a valuable resource for anime fans, artists, and content creators by producing accurate and detailed representations of anime characters.</p><h2 id=\"heading-2230\">Model Details</h2><ul><li><p><strong>Developed by</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/cagliostrolab\"><strong><u>Cagliostro Research Lab</u></strong></a></p></li><li><p><strong>In collaboration with</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"http://SeaArt.ai\"><strong><u>SeaArt.ai</u></strong></a></p></li><li><p><strong>Model type</strong>: Diffusion-based text-to-image generative model</p></li><li><p><strong>Model Description</strong>: Animagine XL 3.1 generates high-quality anime images from textual prompts. It boasts enhanced hand anatomy, improved concept understanding, and advanced prompt interpretation.</p></li><li><p><strong>License</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://freedevproject.org/faipl-1.0-sd/\"><strong><u>Fair AI Public License 1.0-SD</u></strong></a></p></li><li><p><strong>Fine-tuned from</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/cagliostrolab/animagine-xl-3.0\"><strong><u>Animagine XL 3.0</u></strong></a></p></li></ul><p></p><h2 id=\"heading-2231\"><strong>Usage Guidelines</strong></h2><h3 id=\"heading-2232\">Tag Ordering</h3><p>For optimal results, it's recommended to follow the structured prompt template because we train the model like this:</p><pre><code>1girl/1boy, character name, from what series, everything else in any order.\n</code></pre><h2 id=\"heading-2233\">Special Tags</h2><p>Animagine XL 3.1 utilizes special tags to steer the result toward quality, rating, creation date and aesthetic. While the model can generate images without these tags, using them can help achieve better results.</p><h3 id=\"heading-2234\">Quality Modifiers</h3><p>Quality tags now consider both scores and post ratings to ensure a balanced quality distribution. We've refined labels for greater clarity, such as changing 'high quality' to 'great quality'.</p><pre><code>\nQuality Modifier\tScore Criterion\nmasterpiece\t        &gt; 95%\nbest quality\t        &gt; 85% &amp; ≤ 95%\ngreat quality\t        &gt; 75% &amp; ≤ 85%\ngood quality\t        &gt; 50% &amp; ≤ 75%\nnormal quality\t        &gt; 25% &amp; ≤ 50%\nlow quality\t        &gt; 10% &amp; ≤ 25%\nworst quality\t        ≤ 10%</code></pre><h3 id=\"heading-2235\">Rating Modifiers</h3><p>We've also streamlined our rating tags for simplicity and clarity, aiming to establish global rules that can be applied across different models. For example, the tag 'rating: general' is now simply 'general', and 'rating: sensitive' has been condensed to 'sensitive'.</p><pre><code>\nRating Modifier\t    Rating Criterion\nsafe\t            General\nsensitive\t    Sensitive\nnsfw\t            Questionable\nexplicit, nsfw\t    Explicit</code></pre><h3 id=\"heading-2236\">Year Modifier</h3><p>We've also redefined the year range to steer results towards specific modern or vintage anime art styles more accurately. This update simplifies the range, focusing on relevance to current and past eras.</p><pre><code>\nYear Tag\tYear Range\nnewest\t        2021 to 2024\nrecent\t        2018 to 2020\nmid\t        2015 to 2017\nearly\t        2011 to 2014\noldest\t        2005 to 2010</code></pre><h3 id=\"heading-2237\">Aesthetic Tags</h3><p>We've enhanced our tagging system with aesthetic tags to refine content categorization based on visual appeal. These tags are derived from evaluations made by a specialized ViT (Vision Transformer) image classification model, specifically trained on anime data. For this purpose, we utilized the model <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/shadowlilac/aesthetic-shadow-v2\"><strong><u>shadowlilac/aesthetic-shadow-v2</u></strong></a>, which assesses the aesthetic value of content before it undergoes training. This ensures that each piece of content is not only relevant and accurate but also visually appealing.</p><pre><code>\nAesthetic Tag\t       Score Range\nvery aesthetic\t       &gt; 0.71\naesthetic\t       &gt; 0.45 &amp; &lt; 0.71\ndispleasing\t       &gt; 0.27 &amp; &lt; 0.45\nvery displeasing       ≤ 0.27</code></pre><h2 id=\"heading-2238\">Recommended settings</h2><p>To guide the model towards generating high-aesthetic images, use negative prompts like:</p><pre><code>nsfw, lowres, (bad), text, error, fewer, extra, missing, worst quality, jpeg artifacts, low quality, watermark, unfinished, displeasing, oldest, early, chromatic aberration, signature, extra digits, artistic error, username, scan, [abstract]\n</code></pre><p>For higher quality outcomes, prepend prompts with:</p><pre><code>masterpiece, best quality, very aesthetic, absurdres\n</code></pre><p>it’s recommended to use a lower classifier-free guidance (CFG Scale) of around 5-7, sampling steps below 30, and to use Euler Ancestral (Euler a) as a sampler.</p><h3 id=\"heading-2239\">Multi Aspect Resolution</h3><p>This model supports generating images at the following dimensions:</p><pre><code>Dimensions\tAspect Ratio\n1024 x 1024\t1:1 Square\n1152 x 896\t9:7\n896 x 1152\t7:9\n1216 x 832\t19:13\n832 x 1216\t13:19\n1344 x 768\t7:4 Horizontal\n768 x 1344\t4:7 Vertical\n1536 x 640\t12:5 Horizontal\n640 x 1536\t5:12 Vertical</code></pre><h3 id=\"heading-2240\"><strong>Acknowledgements</strong></h3><p>The development and release of Animagine XL 3.1 would not have been possible without the invaluable contributions and support from the following individuals and organizations:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"http://SeaArt.ai\"><strong><u>SeaArt.ai</u></strong></a>: Our collaboration partner and sponsor.</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/shadowlilac\"><strong><u>Shadow Lilac</u></strong></a>: For providing the aesthetic classification model, <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/shadowlilac/aesthetic-shadow-v2\"><strong><u>aesthetic-shadow-v2</u></strong></a>.</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/derrian-distro\"><strong><u>Derrian Distro</u></strong></a>: For their custom learning rate scheduler, adapted from <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/derrian-distro/LoRA_Easy_Training_Scripts/blob/main/custom_scheduler/LoraEasyCustomOptimizer/CustomOptimizers.py\"><strong><u>LoRA Easy Training Scripts</u></strong></a>.</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/kohya-ss\"><strong><u>Kohya SS</u></strong></a>: For their comprehensive training scripts.</p></li><li><p><strong>Cagliostrolab Collaborators</strong>: For their dedication to model training, project management, and data curation.</p></li><li><p><strong>Early Testers</strong>: For their valuable feedback and quality assurance efforts.</p></li><li><p><strong>NovelAI</strong>: For their innovative approach to aesthetic tagging, which served as an inspiration for our implementation.</p></li></ul><p>Thank you all for your support and expertise in pushing the boundaries of anime-style image generation.</p><p></p><h2 id=\"heading-2241\"><strong>Limitations</strong></h2><p>While Animagine XL 3.1 represents a significant advancement in anime-style image generation, it is important to acknowledge its limitations:</p><ol><li><p><strong>Anime-Focused</strong>: This model is specifically designed for generating anime-style images and is not suitable for creating realistic photos.</p></li><li><p><strong>Prompt Complexity</strong>: This model may not be suitable for users who expect high-quality results from short or simple prompts. The training focus was on concept understanding rather than aesthetic refinement, which may require more detailed and specific prompts to achieve the desired output.</p></li><li><p><strong>Prompt Format</strong>: Animagine XL 3.1 is optimized for Danbooru-style tags rather than natural language prompts. For best results, users are encouraged to format their prompts using the appropriate tags and syntax.</p></li><li><p><strong>Anatomy and Hand Rendering</strong>: Despite the improvements made in anatomy and hand rendering, there may still be instances where the model produces suboptimal results in these areas.</p></li><li><p><strong>Dataset Size</strong>: The dataset used for training Animagine XL 3.1 consists of approximately 870,000 images. When combined with the previous iteration's dataset (1.2 million), the total training data amounts to around 2.1 million images. While substantial, this dataset size may still be considered limited in scope for an \"ultimate\" anime model.</p></li><li><p><strong>NSFW Content</strong>: Animagine XL 3.1 has been designed to generate more balanced NSFW content. However, it is important to note that the model may still produce NSFW results, even if not explicitly prompted.</p></li></ol><p>By acknowledging these limitations, we aim to provide transparency and set realistic expectations for users of Animagine XL 3.1. Despite these constraints, we believe that the model represents a significant step forward in anime-style image generation and offers a powerful tool for artists, designers, and enthusiasts alike.</p><h2 id=\"heading-2242\">License</h2><p>Based on Animagine XL 3.0, Animagine XL 3.1 falls under <a target=\"_blank\" rel=\"ugc\" href=\"https://freedevproject.org/faipl-1.0-sd/\"><strong><u>Fair AI Public License 1.0-SD</u></strong></a> license, which is compatible with Stable Diffusion models’ license. Key points:</p><ol><li><p><strong>Modification Sharing:</strong> If you modify Animagine XL 3.1, you must share both your changes and the original license.</p></li><li><p><strong>Source Code Accessibility:</strong> If your modified version is network-accessible, provide a way (like a download link) for others to get the source code. This applies to derived models too.</p></li><li><p><strong>Distribution Terms:</strong> Any distribution must be under this license or another with similar rules.</p></li><li><p><strong>Compliance:</strong> Non-compliance must be fixed within 30 days to avoid license termination, emphasizing transparency and adherence to open-source values.</p></li></ol><p>The choice of this license aims to keep Animagine XL 3.1 open and modifiable, aligning with open source community spirit. It protects contributors and users, encouraging a collaborative, ethical open-source community. This ensures the model not only benefits from communal input but also respects open-source development freedoms.<br /><br />Finally Cagliostro Lab Server open to public <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/cqh9tZgbGc\"><strong><u>https://discord.gg/cqh9tZgbGc</u></strong></a></p><p>Feel free to join our discord server.<br />If you want to donate or buy us a coffee you can donate <a rel=\"ugc\" href=\"https://ko-fi.com/linaqruf\"><strong><u>Here</u></strong></a></p><p>Thank you very much ^_^</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581393+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "5414",
    "prompt": "Pastel-Mix [Stylized Anime Model]\n<p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/pastel-mix\">Huggingface repository goes here.</a><br /><br />Interested in supporting me? <a target=\"_blank\" rel=\"ugc\" href=\"https://www.buymeacoffee.com/andite\">Buy me a coffee.</a><br /><br />A stylized anime model. This model is made with the thought of imitating pastel-like art while introducing the potential of merging LORAs into a model altogether to create a fantastic mix.</p><h2><strong>Guide</strong></h2><p>For the settings or parameters, I recommend using these settings.</p><p></p><pre><code>Sampler: DPM++ 2M Karras\n\nSteps: 20\n\nCFG Scale: 7\n\nHires. Fix: On\n\nUpscaler: Latent (MUST!)\n\nHires Steps: 20\n\nDenoising Strength: 0.\n</code></pre><p>I prefer using 0.6 since it's the sweet spot of this model. If you can find a better setting for this model, then good for you lol.</p><p>Latent upscaler is the best setting for me since it retains or enhances the pastel style. Other upscalers like Lanczos or Anime6B tends to smoothen them out, removing the pastel-like brushwork.</p><p>Please use the <strong>VAE</strong> that I uploaded in this repository. It is from the <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/tree/main/vae\"><strong><u>Waifu Diffusion</u></strong></a> team. Credits to <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei\"><strong><u>haru</u></strong></a> for letting me rename and upload it.</p><h2><strong>Tip (Optional)</strong></h2><p>Putting mksks style in the beginning of the prompt can further influence the pastel-like style and make the output better. It is optional though, so it's up to you. You don't really need it.</p><p></p><p>Recipe for the mix can be found inside the HF repository.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581397+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "81458",
    "prompt": "AbsoluteReality\n<h1 id=\"heading-6674\">AbsoluteReality</h1><h2 id=\"heading-6675\">That feeling after you wake up from a dream</h2><p><strong>Add a ❤️ to receive future updates. This took much time and effort, please be supportive </strong>🫂<br /><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> 🅿️ or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> ☕</strong></p><p></p><p><strong><span style=\"color:rgb(253, 126, 20)\">For LCM read the version description.</span></strong><br /><br /><strong>Additional ecamples for V1.6: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/353121\">https://civitai.com/posts/353121</a><br /><strong>Additional examples for V1</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/259634\">https://civitai.com/posts/259634</a><br /><strong>Amazing gallery by qf22:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/260939\">https://civitai.com/posts/260939</a><br />Quick face alteration examples using celebrity names and mixing them: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/274268\">https://civitai.com/posts/274268</a></p><h3 id=\"heading-91\">Available on <a target=\"_blank\" rel=\"ugc\" href=\"http://sinkin.ai\"><strong>sinkin.ai</strong></a><strong>, </strong><a target=\"_blank\" rel=\"ugc\" href=\"http://Mage.space\"><strong>Mage.space</strong></a><strong> and many other services</strong></h3><h3 id=\"heading-6676\">Suggestions</h3><ul><li><p>Use between 4.5 and 10 CFG Scale and between 25 and 30 Steps with DPM++ SDE Karras. Worse samplers might need more steps.</p></li><li><p><strong>To reproduce my results you MIGHT have to change these settings:</strong></p><ul><li><p><strong>Set \"Do not make DPM++ SDE deterministic across different batch sizes.\" (mostly for v1 examples)</strong></p></li><li><p><strong>Set the ETA Noise Seed Delta (ENSD) to 31337</strong></p></li><li><p><strong>Set CLIP Skip to 2</strong></p></li><li><p><strong>DISABLE face restore. It's terrible, never use it</strong></p></li></ul></li><li><p>Use simple prompts<strong>.</strong> Complex prompts might make less realistic pictures because of CLIP bleeding. More complex prompts does not mean better results. Keep it simple.</p></li><li><p>Use <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\">ADetailer</a> to enhance faces. Basically every <strong>solo </strong>portrait I made uses it. You can get my settings by clicking on \"copy generation data\". <strong>I suggest you use denoising under 0.3 to avoid getting always the same face.</strong></p></li><li><p>Use <strong>BadDream </strong>and <strong>UnrealisticDream </strong>negative embeddings (<code>BadDream, (UnrealisticDream:1.2)</code>). Add weight to UnrealisticDream between 1.2 and 1.5. <strong>Do not use FastNegative or EasyNegative if you aim at realism</strong>. However, they're good for artworks.</p></li><li><p><strong>Use Highres.fix</strong> with the following settings: <code>Denoising strength: 0.45, Hires steps: 20, Hires upscaler: 8x_NMKD-Superscale_150000_G</code> and as much upscale as you can (my gpu only handles up to x1.8 at 512x768 base resolution, but you can go higher). If you don't have <code>8x_NMKD-Superscale_150000_G</code> you can probably use another GAN, but it should be easy to find on Google. You can also try Latent with a denoise higher than 0.6, but the result will be harder to control.</p></li><li><p>Try to condition faces by prompting for eye colors, hairstyles, hair color, ethnicity and so on. Even celebrity names do work. This model is pretty good at not making a single face if you play with the context.</p></li><li><p>If the pic is too clean, try to add some ISO noise. Even as a post processing with external tools it will trick the brain enough to make you think \"damn, this is a real photo.</p></li><li><p>If you feel the grounded nature of this model is limiting your imagination, try generating on DS6 and then do img2img with this one to bump up the realism.</p></li></ul><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/images/986207?period=AllTime&amp;periodMode=published&amp;sort=Newest&amp;view=categories&amp;modelVersionId=86437&amp;modelId=81458&amp;postId=259728\">Pruned vs full comparison (not highres fixed)</a></p><h3 id=\"heading-6677\"><br />Brief story of this model</h3><p>While working on <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384/dreamshaper\">DreamShaper 6</a> I made many other models and a crap ton of tests. Some of them were strange mixes with photorealistic models I had previously made, plus new ones and some ISO noise LoRA I made. When I tested the various release candidates of DS6 for photography prompts, this came out on top. While mostly on the losing side with regards to range, flexibility and LoRA compatibility compared to what became DS6, I noticed this was pretty good at recreating photos with very simple and minimalistic prompts. So, why not, I gave it some love and kept working on it, just in time for its initial release.</p><p></p><h3 id=\"heading-6710\">Difference with DreamShaper</h3><p>Long story short, DS aims at art, this aims at realism. They might overlap a bit, but they have different objectives and different things they're good at. DreamShaper is total freedom and can basically do everything at a high level. This does about one thing and does it extremely well. This still uses DreamShaper as base, so it's capable of doing art to a lesser degree.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581411+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "139562",
    "prompt": "RealVisXL V5.0\n<p><strong><span style=\"color:rgb(21, 170, 191)\">Check my exclusive models on Mage: </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/4371756b27bf52e7a1146dc6fe2d969c\"><strong><span style=\"color:rgb(230, 73, 128)\">ParagonXL</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/df67a9f27f19629a98cb0fb619d1949a\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/d8db06ae964310acb4e090eec03984df\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL Lightning</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/541da1e10976ab82976a5cacc770a413\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL V2</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/a56d2680c464ef25b8c66df126b3f706\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL Pony</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/b0ab6733c3be2408c93523d57a605371\"><strong><span style=\"color:rgb(230, 73, 128)\">NovaXL Pony Lightning</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/e3b01cd493ed86ed8e4708751b1c9165\"><strong><span style=\"color:rgb(230, 73, 128)\">RealDreamXL</span></strong></a><strong> / </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/ef062fc389c3f8723002428290c1158c\"><strong><span style=\"color:rgb(230, 73, 128)\">RealDreamXL Lightning</span></strong></a></p><p><strong><span style=\"color:rgb(250, 82, 82)\">If you are using Hires.Fix with V5 Lightning, then use my recommended settings for Hires.Fix (3 Sampling Steps, Denoising strength: 0.5 and CFG Scale 1.0 - 2.0) or other settings you find better for you.</span></strong></p><p><strong><span style=\"color:rgb(0, 255, 111)\">Use Turbo models with DPM++ SDE Karras sampler, 4-10 steps and CFG Scale 1-2.5</span></strong></p><p><strong><span style=\"color:rgb(0, 255, 111)\">Use Lightning models with DPM++ SDE Karras / DPM++ SDE sampler, 4-6 steps and CFG Scale 1-2</span></strong></p><p><strong>Please pay attention to the model file name, the part of the name after the underscore is the true version of the model.</strong></p><p><strong>The model is already available on</strong> <a target=\"_blank\" rel=\"ugc\" href=\"http://Mage.Space\"><strong><u><span style=\"color:rgb(253, 126, 20)\">Mage.Space</span></u></strong></a><strong> (main sponsor)</strong></p><p><strong><span style=\"color:rgb(193, 194, 197)\">You can also support me directly on</span></strong><span style=\"color:rgb(193, 194, 197)\"> </span><a target=\"_blank\" rel=\"ugc\" href=\"https://boosty.to/sg_161222\"><strong><u><span style=\"color:rgb(250, 176, 5)\">Boosty</span></u></strong></a><span style=\"color:rgb(193, 194, 197)\">.</span></p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/collections/SG161222/realvisxl-sdxl-656daeb4adba74cd5ea2ef44\"><strong><u><span style=\"color:rgb(253, 126, 20)\">RealVisXL Hugging Face Full Collection</span></u></strong></a></p><p></p><p><strong>The model is aimed at photorealism. Can produce sfw and nsfw images of decent quality.</strong></p><p><span style=\"color:rgb(44, 45, 46)\">ᅠ</span></p><p><strong><u>Recommended Negative Prompt:</u></strong></p><p>(worst quality, low quality, illustration, 3d, 2d, painting, cartoons, sketch), open mouth</p><p><strong>or another negative prompt</strong></p><p><span style=\"color:rgb(44, 45, 46)\">ᅠ</span></p><p><strong><u>Recommended Generation Parameters:</u></strong><br /><strong>Sampling Method:</strong> <span style=\"color:rgb(179, 188, 201)\">DPM++ SDE Karras (30+ Sampling Steps) or DPM++ 2M Karras (50+ Sampling Steps)</span></p><p><span style=\"color:rgb(44, 45, 46)\">ᅠ</span></p><p><strong><u>Hires Fix Parameters:</u></strong></p><p><strong>Upscaler: </strong><span style=\"color:rgb(179, 188, 201)\">4x-NMKD-Superscale-SP_178000_G / 4x-UltraSharp upscaler / or another</span></p><p><strong>Denoising strength: </strong>0.1-0.3</p><p><strong>Upscale by: </strong>1.1-1.5</p><p><span style=\"color:rgb(44, 45, 46)\">ᅠ</span></p><p><strong><u>Optional Parameters:</u></strong></p><p><strong>ENSD: </strong>31337</p><p><span style=\"color:rgb(44, 45, 46)\">ᅠ</span></p><p><strong><u>This model is:</u></strong></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8ac18d6c-3ba5-43bb-a965-b7aeff47fde0/width=525/8ac18d6c-3ba5-43bb-a965-b7aeff47fde0.jpeg\" /></p><p><span style=\"color:rgb(44, 45, 46)\">ᅠ</span></p><p><strong>Huge thanks to the creators of these great models that were used in the merge.</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/112902/dreamshaper-xl10\"><strong>DreamShaper XL1.0</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Lykon\"><strong>Lykon</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/133005/juggernaut-xl\"><strong>Juggernaut XL</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/KandooAI\"><strong>KandooAI</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/118114/sdvn6-realxl\"><strong>SDVN6-RealXL</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/StableDiffusionVN\"><strong>StableDiffusionVN</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/119202/talmendoxl-sdxl-uncensored-full-model\"><strong>TalmendoXL - SDXL Uncensored Full Model</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/talmendo\"><strong>talmendo</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5273/wyvernmix-15-and-xl\"><strong>WyvernMix (1.5 &amp; XL)</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/wier\"><strong>wier</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/122822/crystal-clear-xl\"><strong>Crystal Clear XL</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/WarAnakin\"><strong>WarAnakin</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/125703?modelVersionId=144229\"><strong>ProtoVision XL</strong></a><strong> and </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/122606?modelVersionId=169718\"><strong>DynaVision XL</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/socalguitarist\"><strong>socalguitarist</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/131843/cinemax-alpha-or-sdxl-or-cinema-or-filmic-or-nsfw\"><strong>Cinemax Alpha | SDXL | Cinema | Filmic | NSFW</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/viakole\"><strong>viakole</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/243445?modelVersionId=274687\"><strong>Imperfect portrait</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/MakeThemComeAliveAIArt\"><strong>MakeThemComeAliveAIArt</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/194768?modelVersionId=335740\"><strong>Jib Mix Realistic XL</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/J1B\"><strong>J1B</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/43977/leosams-helloworld-xl?modelVersionId=338512\"><strong>LEOSAM's HelloWorld XL</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/LEOSAM\"><strong>LEOSAM</strong></a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581422+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "43977",
    "prompt": "LEOSAM's HelloWorld XL\n<p>🖥️Welcome to try out the open-source <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/jiayev/GPT4V-Image-Captioner\"><strong><u>GPT4V-Image-Captioner</u></strong></a>, developed by my friend and me. It offers a one-click installation and comes integrated with multiple features including image pre-compression, image tagging, and tag statistics. Recently, we also launched the <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/SleeeepyZhou/sd-webui-GPT4V-Image-Captioner\"><strong><u>webui plugin version</u></strong></a> of this tool, everyone is welcome to use it!</p><p>🌍<span style=\"color:rgba(255, 255, 255, 0.8)\">欢迎加入</span>QQ群\"兔狲·AIGC梦工北厂\"，群号 ：<span style=\"color:rgb(250, 176, 5)\">780132897</span> ；\"兔狲·AIGC梦工南厂\"，群号 ：<span style=\"color:rgb(250, 176, 5)\">835297318</span>（入群答案：兔狲）。<span style=\"color:rgba(255, 255, 255, 0.8)\">Telegram群聊“兔狲的SDXL百老汇”，链接：</span><a target=\"_blank\" rel=\"ugc\" href=\"https://t.me/+KkflmfLTAdwzMzI1\"><span style=\"color:rgb(250, 176, 5)\">https://t.me/+KkflmfLTAdwzMzI1</span></a></p><p></p><h3 id=\"helloworld-7.0-update-june-13-2024-lgbhpvueb\"><strong>📖HelloWorld 7.0 Update - June 13, 2024</strong></h3><p><strong><u>One-sentence update summary: </u></strong>HelloWorld 7.0 is an iteratively optimized version, with the best body performance in the entire series, and further enhanced concept scope and detail richness.</p><p>Update details:</p><ol><li><p>By adding negative training images, strengthening pose training, and optimizing the clip model, the accuracy of the model's limbs and hands has been improved compared to previous versions. The recommended negative prompt words are: \"bad hand, bad anatomy, worst quality, ai generated images, low quality, average quality\".</p></li><li><p>Extracted the fine-tuned LoRA from the<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/SPO-Diffusion-Models/SPO-SDXL_4k-p_10ep\"> official SPO model</a> and incorporated it into HelloWorld 7.0. SPO is a further improvement of the DPO method. The SPO base model is used for better performance than the DPO XL base model and the original SDXL base model. The SPO LoRA can enhance image details &amp; contrast and beautify images. Thanks to the technical team behind SPO.</p></li><li><p>Continued to expand the concept scope of the training set, but optimized and streamlined the training set (large training set fine-tuning is too expensive, and H800 is difficult to rent recently, can't afford the local training time). The current total training set is 20,821 images. The training set resolution distribution is as follows, and it is recommended to use several resolutions with a larger number of images for output:</p><pre><code>(832, 1248) - Count: 7128\n(896, 1152) - Count: 6250\n(1248, 832) - Count: 2402\n(1024, 1024) - Count: 1639\n(1360, 768) - Count: 928\n(1152, 896) - Count: 870\n(768, 1360) - Count: 432\n(960, 1088) - Count: 506\n(992, 1056) - Count: 162\n(1088, 960) - Count: 140\n(704, 1472) - Count: 120\n(1056, 992) - Count: 122\n(1472, 704) - Count: 115\n(1632, 640) - Count: 75\n(640, 1632) - Count: 12</code></pre></li><li><p>Used GPT4O to re-label all datasets. This time, a structured labeling method was used, with the specific structure being: \"one-sentence summary description + multiple image element tags + inspired by XXX + aesthetic quality description words\", where the aesthetic quality description words are divided into five levels: worst quality, low quality, average quality, best quality, and masterpiece. A typical labeling example is as follows:</p><pre><code>conceptual art featuring a human hand wrapped in red and beige ribbons, isolated against a plain, light background, realistic style, minimalist color scheme, smooth textures, elongated and surreal aesthetic, inspired by salvador dalí's surrealist works, masterpiece</code></pre></li></ol><p>The \"High-Frequency Tagging Word List\" and the \"High-Frequency Art Style List\" involved in the Inspired by XXX for the HelloWorld 7.0 version will only be provided to commercial licensing users. Partners who have purchased Helloworld XL series model authorization in the past, please contact me if there are any omissions to get it for free.</p><p>Players can refer to the <a target=\"_blank\" rel=\"ugc\" href=\"https://picturesque-soup-93d.notion.site/LEOSAM-HelloWorld-6-0-Top-250-High-Frequency-Tagging-Word-List-1be4971bafb84c22a231ee2f6da29cc1\">High-Frequency Tagging Word List of HelloWorld 6.0</a>. In addition, I have also provided 150+ high-quality HelloWorld 7.0 example images in the gallery, which can be used as a reference for everyone's output. Model making is not easy, thank you players for your understanding and tolerance!</p><p></p><h3 id=\"helloworld-6.0-update-april-20-2024-ru0h3cl08\"><strong>📖</strong>HelloWorld 6.0 Update - April 20, 2024</h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://picturesque-soup-93d.notion.site/LEOSAM-HelloWorld-6-0-Top-250-High-Frequency-Tagging-Word-List-1be4971bafb84c22a231ee2f6da29cc1?pvs=4\"><strong><u>LEOSAM HelloWorld 6.0 Top 250 High-Frequency Tagging Word List</u></strong></a></p><p>Thank you for your patience. I have been job hunting recently, which caused some delays in the HelloWorld updates. Here are the main updates in version 6.0:</p><ul><li><p>HelloWorld 6.0 is an iterative improvement based on version 5.0. Based on my own testing, the realism effect is not significantly different from version 5.0. The main advantage of version 6.0 lies in its broader coverage of concepts in the training set. According to feedback, enhancements have been made in various themes including surrealism, boudoir, group photos, masks, origami, 3D renders, cars, dragons, and maternity photography. Some examples are provided in the illustrations.</p></li><li><p>HelloWorld 6.0 intentionally includes some low-quality images in the training to enhance the model's response to negative prompts. It is recommended to use the following terms in negative prompts: \"low quality, jpeg artifacts, blurry, poorly drawn, ugly, worst quality\".</p></li><li><p>The main body of the HelloWorld 6.0 training set employs GPT4v tagging. For images that GPT4v cannot tag, cogVQA guided by blip2-opt-6.7b is used for tagging. The tagging language style of these multimodal models differs significantly from the traditional WD1.4 tagger. To facilitate more accurate triggering of different concepts in the training set, I have compiled the top 250 high-frequency tagging words from the HelloWorld 6.0 training set. You can view these high-frequency words in<a target=\"_blank\" rel=\"ugc\" href=\"https://www.notion.so/LEOSAM-HelloWorld-6-0-Top-250-High-Frequency-Tagging-Word-List-1be4971bafb84c22a231ee2f6da29cc1\"> this document</a>.</p></li></ul><p>Finally, although SD3 is about to be released, I will still update to HelloWorld XL 7.0, hoping to achieve greater enhancements in version 7.0!</p><p></p><h3 id=\"2024.2.22-introducing-&quot;hw5.0_euler_a_lightning&quot;-3k0ze75dh\"><strong>📖</strong><u>2024.2.22 Introducing </u>\"HW5.0_Euler_a_Lightning\"</h3><p>This model is a run-accelerated version of the HelloWorld SDXL base model, incorporating both <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/ByteDance/SDXL-Lightning/tree/main\">SDXL-Lightning</a> technologies. <strong>Equipped with the Eular a sampler and CFG 1, it is capable of generating images in 6-8 steps, which is three times faster than the original SDXL version</strong>. Moreover, upon comparison, <strong>its imaging results are superior to those of LCM or Turbo versions</strong>.</p><p>The recommended parameters for generating images with this model are:</p><p><strong>Sampler</strong>: Eular a (Important! The model is specifically adapted to Eular a, other samplers may not yield as good results)</p><p><strong>CFG scale</strong>: 1</p><p><strong>Sampling steps</strong>: 8 steps (6~8 steps are acceptable)</p><p><strong>Hires algorithm</strong>: ESRGAN 4x / 8x_NMKD-Faces_160000_G</p><p><strong>Hires Upscale factor</strong>: 1.5x</p><p><strong>Hires steps</strong>: 8 steps</p><p><strong>Hires Denoising strength</strong>: 0.3</p><h3 id=\"2024.2.11-introducing-&quot;helloworld-5.0-gpt4v&quot;-3xc4ya3hl\"><strong>📖</strong><u>2024.2.11 Introducing \"HelloWorld 5.0 GPT4V\"</u></h3><p>HelloWorld 5.0 is the most substantial update in the history of the HelloWorld series, tagged with GPT-4v, and has undergone significant fine-tuning in fields such as science fiction, animals, architecture, and illustration.</p><p>Comparative tests show improvements in this version include:</p><p>1. More varied and dynamic character poses and image compositions, creating visually engaging pictures;</p><p>2. The film dataset has been extensively trained. While the film texture was weak from versions 2.0 to 4.0, many fans missed the leogirl style of version 1.0. Therefore, this update has specifically strengthened the film texture without compromising other photographic qualities. The film texture can be triggered by phrases such as <strong><span style=\"color:rgb(250, 176, 5)\">film grain texture</span></strong> and <strong><span style=\"color:rgb(250, 176, 5)\">analog photography aesthetic</span></strong>;</p><p>3. Enhanced expressiveness in themes like science fiction, thriller, and animals, with mechas and other subjects having a more designed feel. Animals like snow leopard, red panda, giant panda, tiger, the Pallas's cat, and domestic cats and dogs are more lifelike;</p><p>4. Thanks to GPT tagging, prompt adherence and conceptual accuracy have been further improved.</p><p>However, the drawbacks of this version include:</p><p>1. As this is a substantial fine-tuning update, the error rate for limbs and such may slightly increase, a normal phenomenon when moving out of a comfort zone into new areas of relative optimization. Previous versions underwent extensive limb testing for improvements, while the new version had limited time for such enhancements. Nevertheless, the accuracy of limbs in this version is at least higher than in version 1.0, and I will continue to make improvements in future updates.</p><p>2. Due to the reinforced film texture, even though GPT tagging is as accurate as possible, there can be an unavoidable default warm tone in images. However, you can use prompts like <strong>studio light</strong> or <strong>sharp focus</strong> to produce high-definition studio-quality images, and with proper use of prompts, the output can have better skin tones and visual appeal than previous versions.</p><p>3. This version includes more full-body character images to enhance the full-body effect, so the model may produce wider scenes than before if no specific character composition is directed. Currently, the facial details in 1024 resolution full-body shots might be less sharp compared to half-body or close-up shots. However, this can be improved by adetailer and a 1.5x Hires. fix at 0.3 intensity, or by using prompts like specifying composition to avoid generating full-body images.</p><p>4. Since a small number of high-quality illustration datasets have been added, there is a chance that prompts related to animated styles will produce animated images. If this concerns you, please adjust your prompts accordingly.</p><p>These are the main updates for this version. Training the SDXL base model is challenging, and when the training set approaches ten thousand images, the cost for tagging and training for each model exceeds 300 USD. I welcome everyone to use the model and appreciate any feedback you can provide! If you find this model satisfactory, I would be immensely grateful if you could help spread the word about it.</p><h3 id=\"2024.1.31-introducing-&quot;helloworld-4.0&quot;-kw58jshiy\"><strong>📖</strong><u>2024.1.31 Introducing \"HelloWorld 4.0\"</u></h3><p>HelloWorld4.0 is a progressive transitional version from tagging with blip+clip to tagging with GPT4V. I initially trained a pure GPT4V tagging model, and then merged it with a large proportion of the HelloWorld3.2 version and 0.05 proportion of Juggernaut XL (to adjust the skin tone). The new version has shown improvements in prompt compliance and concept coverage compared to the 3.2 version.</p><p>The new GPT4V tagging training set has doubled from the 4000 images of the helloworld3 series to 8000 images, covering not only portraits but also animals, architecture, nature, food, illustrations, and more. However, the pure GPT4V version encountered an overfitting problem, which is preliminarily attributed to the doubling of the number of training images. One of the next steps in iterative optimization is to find out how to include as many non-portrait concepts as possible while ensuring sufficient training of portraits. At this stage, a fusion of the new and old versions has been used for fine-tuning to ensure a smooth transition between versions, so the expanded concept set and the advantages brought by GPT4V tagging are not very perceptible at the moment. These advantages will become increasingly apparent in the subsequent generations 5 and 6 of the model.</p><h3 id=\"2024.1.5-introducing-&quot;helloworld-3.2&quot;-rhw3t9si5\"><strong>📖</strong><u>2024.1.5 Introducing \"HelloWorld 3.2\"</u></h3><p><span style=\"color:rgb(193, 194, 197)\">Version 3.2 is an iteration optimized with </span><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/qqingzheng/AI-Self-Training-DPO-SDXL/tree/main\">DPO</a><span style=\"color:rgb(193, 194, 197)\"> technology, and compared to version 3.0, there are optimizations in skin tone and limb accuracy, but the improvements are not significant. That's why this version is marked as 3.2 rather than being labeled as 4.0.</span></p><h3 id=\"2023.12.15-introducing-&quot;helloworld-3.0&quot;-6xkr3cgn7\"><strong>📖</strong><u>2023.12.15 Introducing \"HelloWorld 3.0\"</u></h3><ol><li><p>The new version has expanded the training set, enhancing the model's ability to express in different artistic styles, including science fiction and art.</p></li><li><p>It has integrated a self-made quality enhancement LoCon (created using slider technology), to improve image texture and alleviate issues of distortion in fingers and limbs.</p></li></ol><h3 id=\"2023.11.17-introducing-&quot;helloworld-2.0&quot;-bb85dqdsy\"><strong>📖</strong><u>2023.11.17 Introducing \"HelloWorld 2.0\"</u></h3><p>Thank you all for your patience. After overcoming various challenges, the HelloWorld 2.0 version is finally ready to be presented to you all in a state that I'm satisfied with. The main differences between HelloWorld 2.0 and 1.0 are as follows:</p><ol><li><p>HelloWorld 2.0 no longer requires trigger words, and the results are comparable in quality to version 1.0 with trigger words.. The trigger word 'leogirl' in 1.0 was highly associated with East Asians. After the cancellation of the trigger words, while words like '1girl' will still likely generate East Asian portraits when race is not specified, you can now specify the race by using keywords like nationality, skin color, etc. For example, the trigger effects for words like 'Chinese', 'Russian', 'Iranian', 'Jamaican', 'Kenyan', 'dark-skinned', 'pale-skinned', etc., are listed below.</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/be3e96e6-33bd-40a1-9770-0e4a216c965f/width=525/be3e96e6-33bd-40a1-9770-0e4a216c965f.jpeg\" /></p><p>You can also get different styles of characters by writing the names of people from different countries and genders in the prompt, such as Han Meimei (China), Sophie Martin (France), Priya Patel (India), Fatima Al-Hassan (Arab), Wanjiru Mwangi (Kenya). The above prompts are just examples, there are many available prompts and ways to play, and you're welcome to explore and share them by yourself.</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/da4d543c-df00-4ae1-8663-dc54a28c2ed5/width=525/da4d543c-df00-4ae1-8663-dc54a28c2ed5.jpeg\" /></p></li><li><p>HelloWorld 2.0 has balanced the quality/color and offers more style options. The 1.0 version, when used with 'leogirl', would likely produce images with a strong film texture. HelloWorld 2.0 is no longer tied to a film texture and can be customized with some quality-related prompts. Some prompts that have been tested and work well include:</p><p>high-end fashion photoshoot, product introduction photo, popular Korean makeup, aegyo sal, Sharp High-Quality Photo, studio light, medium format photo, Mamiya photography, analog film, Medium Portrait with Soft Light, real-life image, refined editorial photograph, raw photo, real photo, Scanned Photo, film still</p><p>The color effects of these prompts are as follows:</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6c2b58b8-e34c-4292-9237-311d8ddc48db/width=525/6c2b58b8-e34c-4292-9237-311d8ddc48db.jpeg\" /></p></li><li><p>The training set for HelloWorld 2.0 significantly increased the proportion of full-body photos to improve the effects of SDXL in generating full-body and distant view portraits. Although it has improved compared to version 1.0, it is still strongly recommended to use 'adetailer' in the process of generating full-body photos. Also, for users with enough video memory (24g), it is recommended to perform 1.5x high-resolution repair on the image, which can significantly improve facial details.</p></li></ol><p></p><h3 id=\"2023.8.29-introducing-&quot;helloworld&quot;-sdxl-base-model-kaxnezy2g\"><strong>📖</strong><u>2023.8.29 Introducing \"HelloWorld\" SDXL Base Model</u></h3><p><strong><u>Special reminder</u>: <span style=\"color:rgb(34, 139, 230)\">When using the HelloWorld 1.0 model, please remember to add the trigger word \"leogirl\".</span></strong></p><p>Distinct from SD1.5 base model “MoonFilm”, “HelloWorld” is a brand new realistic SDXL base model series, . In order to allow more users to discover HelloWorld, I have retained the original Moonfilm's model link. It can be perceived as a spiritual continuation of Moonfilm on the SDXL new platform, but HelloWorld aims to achieve more than just the pursuit of realism and film-like quality in portraits. Thanks to the far superior amount of information and text understanding capabilities of SDXL compared to SD1.5, HelloWorld is a base model that seeks to realistically depict all things, or in other words, I hope to gradually build a virtual photography world using HelloWorld.</p><p>The realistic base model of SD1.5 has developed to a quite mature stage, and it is unlikely to have a significant performance improvement. Unless there is a breakthrough technology for SD1.5 platform, the Moonfilm &amp; MoonMix series will basically stop updating. I will devote my main energy to the development of the HelloWorld SDXL large model. The 1.0 version is now available for download, and the 2.0 version is being developed urgently and is expected to be updated in early September.</p><p>As a brand new SDXL model, there are three differences between HelloWorld and traditional SD1.5 models:</p><ol><li><p>Unlike SD1.5 base models, which typically do not include trigger words, please remember to use the trigger word \"<strong><span style=\"color:rgb(34, 139, 230)\">leogirl</span></strong>\" when using HelloWorld 1.0. This ensures that the SDXL model triggers the training set effect more stably.</p></li><li><p>The HelloWorld model supports direct output at a resolution of 1024*1024 pixels, eliminating the need for high-resolution magnification. The quality of close-up portrait directly output is not inferior to the SD1.5 version, but there are still flaws when outputting distant portraits directly. Therefore, it is suggested to use <strong><span style=\"color:rgb(34, 139, 230)\">ADetailer</span></strong> plugin, which can effectively correct the problems of distant faces.</p></li><li><p>SDXL now allows for easier output using <strong><span style=\"color:rgb(34, 139, 230)\">simple natural language prompts</span></strong>. It is recommended to try more natural language prompts, which will result in better outcomes when outputting AI realistic photos.</p></li></ol><p>After multiple rounds of testing, the suggested drawing parameter settings are:</p><ul><li><p>Steps ≥ 25</p></li><li><p>Sampler: DPM++ 2M Karras</p></li><li><p>CFG scale: 10</p></li><li><p>Size ≥ 1024x1024</p></li><li><p>ADetailer: open</p></li></ul><p>Everyone is welcome to try HelloWorld and provide plenty of feedback. Your valuable opinions are very important for the next step of model improvement!</p><p></p><h3 id=\"copyright-statement:-zwepllh9o\"><strong>Copyright Statement:</strong></h3><p>The HelloWorld series of models (hereinafter \"the Model\") has been crafted by myself (hereinafter \"the Owner\") with the assistance of the LiblibAI platform. Republishing the Model on platforms excluding LiblibAI and Civitai is unauthorized by the Owner.</p><p>The Owner permits the use of images generated by the Model for non-commercial educational or informative purposes at no cost, on the condition that:</p><p>- Users adhere to applicable laws and do not violate the rights of the Model or any third-party.</p><p>- Attribution for the images must be clearly stated as \"created by LEOSAM's HelloWorld base model\".</p><p>For any form of commercial utilization, a prior commercial license agreement with the Owner is required. For inquiries related to commercial licensing and model personalization, please reach out to the Owner via the contact information available on the Owner's homepage.</p><p>The development and free distribution of the SDXL model represent significant endeavors. The Owner pledges ongoing complimentary updates to the HelloWorld model for individual enthusiasts as a token of appreciation for the community's contributions to open-source development. Collaborative commercial engagements are vital for the Model's advancement and refinement. The Owner appreciates every user for their understanding and support.</p><p>Unauthorized use may breach applicable laws and carry legal repercussions. The Owner retains exclusive rights to interpret this statement, which is governed by prevailing laws and regulations.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581463+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "8730",
    "prompt": "Hipoly 3D Model LoRA\n<p><strong><u>(日本語は後半にあります)</u></strong></p><p></p><h2>High-poly 3D Model LoRA</h2><p>This is a LoRA trained on high-polygon 3D model images.</p><p>It can provide clean, high-resolution skin and hair materials, as well as detailed clothing elements.</p><p></p><p>For those interested, I have compiled the technical insights gained during the training of ver.2 in the following article.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://note.com/takumi__ncr/n/n21016c358ea5\">https://note.com/takumi__ncr/n/n21016c358ea5</a></p><p></p><h2>Changes in 2.0</h2><ul><li><p>Increased the number of training images</p></li><li><p>Increased the training resolution (ver.1: 768, ver.2: 896)</p></li><li><p>Revised the tagging</p><ul><li><p>Removed the trigger word as well</p></li></ul></li><li><p>Reviewed the training parameters</p></li></ul><p></p><h2>Improvements in 2.0</h2><ul><li><p>It can reproduce a more 3D-like texture and stereoscopi effect than ver.1</p></li><li><p>LoRA can be applied without a trigger word</p></li><li><p>The style can be controlled using <code>3d</code> and <code>realistic</code> tags</p><ul><li><p>When added to Positive Prompt, it enhances the 3D feel</p></li><li><p>When added to Negative Prompt, it adds details such as clothing while maintaining the model's art style</p></li></ul></li><li><p>The issue of eroding the model's art style with tags such as <code>intricate</code>, <code>detailed</code> has been alleviated</p></li></ul><p></p><h2>Additional information</h2><p>The effect of LoRA was confirmed using the following my custom merged models:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/38606/alstroemeria-mix\">Alstroemeria Mix</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/38619/bougainvillea-mix\">Bougainvillea Mix</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/38636/chrysanthemum-mix\">Chrysanthemum Mix</a></p></li></ul><p></p><p></p><p></p><h2>High-poly 3D Model LoRA</h2><p>ハイポリゴン 3D モデル画像を学習した LoRA です。</p><p>3D らしいクリーンで高精細な肌・髪の質感や、衣服のディテールを与えることができます。</p><p></p><p>ver.2 の学習時に得られた技術的知見をまとめましたので、興味がある方は次の記事をご覧ください。</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://note.com/takumi__ncr/n/n2fb9d265ffa9\">https://note.com/takumi__ncr/n/n2fb9d265ffa9</a></p><p></p><h2>2.0 での変更点</h2><ul><li><p>教師画像を増やしました</p></li><li><p>学習解像度を向上しました (ver.1: 768, ver.2: 896)</p></li><li><p>タグ付けを見直しました</p><ul><li><p>トリガーワードも削除しました</p></li></ul></li><li><p>学習パラメータを見直しました</p></li></ul><p></p><h2>2.0 での改善点</h2><ul><li><p>ver.1 よりも 3D らしいテクスチャ感、奥行き感が再現できます</p></li><li><p>トリガーワードなしで LoRA を適用することが可能です</p></li><li><p><code>3d</code>, <code>realistic</code> タグを使用することで絵柄のコントロールが可能です</p><ul><li><p>Positive Prompt に入れた場合、より 3D 感を強化します</p></li><li><p>Negative Prompt に入れた場合、モデルの絵柄を保ちつつ、衣装などのディテールを追加することができます</p></li></ul></li><li><p><code>intricate</code>, <code>detailed</code> などのタグによってモデルの絵柄を侵食してしまう問題が緩和されました</p></li></ul><p></p><h2>その他</h2><p>LoRA の動作確認は以下の自作マージモデルを使用して行いました。</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/38606/alstroemeria-mix\">Alstroemeria Mix</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/38619/bougainvillea-mix\">Bougainvillea Mix</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/38636/chrysanthemum-mix\">Chrysanthemum Mix</a></p></li></ul>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:47.581470+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  }
]