[
  {
    "id": "24350",
    "prompt": "PerfectDeliberate\n<p>Missed this weeks auction :/ will be back next week! My bad<br />I try to pin images that stand out / i personally like every 1-3 weeks<br />Join the Discord for questions / sharing pictures :) : <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/gcJqAKQ5Af\">https://discord.gg/gcJqAKQ5Af</a><br /><br /><strong>üõ†Ô∏è Recommended Settings:</strong></p><ul><li><p><strong>Resolution:</strong><br />best results with <code>832x1216</code> //<code>960x1440</code>// <code>1024x1024</code> // <code>1024x1536</code></p></li><li><p><strong>CFG Scale:</strong><br /><code>5‚Äì8</code></p></li><li><p><strong>Sampling Method:</strong><br /><code>Euler a</code> or <code>DPM++ 2M Karras</code></p></li><li><p><strong>Steps:</strong><br /><code>20‚Äì50</code> <br /></p></li></ul><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.831789+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "4514",
    "prompt": "Pure Eros Face\n<p>This embedding will generate <strong>good-looking girl faces</strong>, close concept of <strong><u>kpop idols or Instagram girls</u></strong>. For <strong>SD1.5</strong> based models.</p><p></p><p><em>what means \"Pure Eros\"?</em></p><p><em>&gt; Pure Eros is a simple translation of the Chinese word \"</em><strong><em>Á∫ØÊ¨≤</em></strong><em>\", which is a popular memes in the Chinese internet, the english words close to the semantics of this word are \"ulzzang face\", \"korean idol face\", so obviously this embedding will be close to the Asian aesthetic.ü§ó</em></p><p></p><p><strong>Recommended config:</strong></p><p>1. prompt</p><ul><li><p><strong>[:(detailed face:1.2):0.2]</strong>: When drawing high-quality faces, do not use the \"detail face\" tag at 0 steps, otherwise it may lead to deviation from the original semantics of embedding</p></li><li><p><strong>shiny eyes, looking at viewer</strong>: If your generated faces often close their eyes, adding \"shiny eyes, looking at viewer\" will open them instantly</p></li></ul><p>2. negative prompt:</p><ul><li><p><strong>long hair</strong>: add it to fix some errors caused by training data bias...(<em>although it does not always affect the output, my experiments found that it seems that the length of the hair in a certain scene will affect the quality of the clothes. In short, the relationship is very subtle, you can try to control the length of the hair to change the outfit quality)</em></p></li><li><p><strong>full body</strong>: Most of the data set is close-up, so it doesn't perform well on the \"full body\" scene, <em>I'm trying to fix it in the next version</em></p></li><li><p><strong>disabled body</strong>: If a deformed body structure is produced, please add it</p></li><li><p><strong>DeepNegative</strong>: A negative embedding I released can be used with PureErosFace very well, it is recommended to try</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4629/deep-negative-v1x\">https://civitai.com/models/4629/deep-negative-v1x</a></p></li></ul><p></p><p></p><p><strong>Recommended model:</strong></p><p>It is best to use a model with a realistic style. If it is an anime-style model, it may output a mask-like face.</p><p></p><p><strong>1. LOFI</strong></p><p>merged model I released, works fine with this embedding</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9052/lofi\">https://civitai.com/models/9052/lofi</a></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8e1c68da-4e15-49bf-0090-25a89a438800/width=525\" /><p></p><p>examples <a target=\"_blank\" rel=\"ugc\" href=\"https://imgur.com/a/nFRE1Z4.jpg\">https://imgur.com/a/nFRE1Z4.jpg</a></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/29349082-39d2-45bf-4221-b49134ba3000/width=525\" /><p></p><p>2. <strong>izumi</strong></p><p>Most of my example images are generated by izumi:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1364/izumi\">https://civitai.com/models/1364/izumi</a></p><p></p><p>examples and test: <a target=\"_blank\" rel=\"ugc\" href=\"https://imgur.com/ZirqVWK.jpg\">https://imgur.com/ZirqVWK.jpg</a></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9c53760b-fce1-4c3a-0339-d7f393e0d800/width=525\" /><p></p><p>3. <strong>F222</strong></p><p>Also produced a good-looking face, although I only experimented with a few, but they all look good for work</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1188/f222\">https://civitai.com/models/1188/f222</a></p><p></p><p>examples and test: <a target=\"_blank\" rel=\"ugc\" href=\"https://imgur.com/ixyVXTP.jpg\">https://imgur.com/ixyVXTP.jpg</a></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/711d2fde-6c76-4702-b392-23f79d1ebe00/width=525\" /><p></p><p>4. <strong>HassanBlend</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1173/hassanblend-1512-and-previous-versions\">https://civitai.com/models/1173/hassanblend-1512-and-previous-versions</a></p><p></p><p>examples and test: <a target=\"_blank\" rel=\"ugc\" href=\"https://imgur.com/no066sF.jpg\">https://imgur.com/no066sF.jpg</a></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/885d0191-ba9f-4001-7693-6e56ff3adc00/width=525\" /><p></p><p></p><h3 id=\"heading-93\">Backup</h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/lenML/PureErosFace_V1/tree/main\">https://huggingface.co/lenML/PureErosFace_V1/tree/main</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.831846+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "833294",
    "prompt": "NoobAI-XL (NAI-XL)\n<h1 id=\"model-introduction\"><strong>Model Introduction</strong></h1><p>This image generation model, based on Laxhar/noobai-XL_v1.0, leverages full Danbooru and e621 datasets with native tags and natural language captioning.</p><p>Implemented as a v-prediction model (distinct from eps-prediction), it requires specific parameter configurations - detailed in following sections.</p><p>Special thanks to my teammate euge for the coding work, and we're grateful for the technical support from many helpful community members.</p><h1 id=\"important-notice\">‚ö†Ô∏è IMPORTANT NOTICE ‚ö†Ô∏è</h1><h2 id=\"this-model-works-different-from-eps-models!\"><strong>THIS MODEL WORKS DIFFERENT FROM EPS MODELS!</strong></h2><h2 id=\"please-read-the-guide-carefully!\"><strong>PLEASE READ THE GUIDE CAREFULLY!</strong></h2><h2 id=\"model-details\">Model Details</h2><ul><li><p><strong>Developed by</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Laxhar\"><strong><u>Laxhar Lab</u></strong></a></p></li><li><p><strong>Model Type</strong>: Diffusion-based text-to-image generative model</p></li><li><p><strong>Fine-tuned from</strong>: Laxhar/noobai-XL_v1.0</p></li><li><p><strong>Sponsored by from</strong>:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://cloud.lanyun.net/\"><strong><u>Lanyun Cloud</u></strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.seaart.ai/\"><strong><u>Civitai &amp; Seaart</u></strong></a></p></li><li><p><strong>Collaborative testing</strong>:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"www.liblib.art\"><strong><u>LiblibAI</u></strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.nieta.ai/\"><strong><u>Nieta</u></strong></a></p></li></ul><hr /><h1 id=\"how-to-use-the-model.\">How to Use the Model.</h1><h2 id=\"guidebook-for-noobai-xl:\">Guidebook for NoobAI XL:</h2><p>ENG:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/8962\">https://civitai.com/articles/8962</a></p><p>CHS:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://fcnk27d6mpa5.feishu.cn/wiki/S8Z4wy7fSiePNRksiBXcyrUenOh\">https://fcnk27d6mpa5.feishu.cn/wiki/S8Z4wy7fSiePNRksiBXcyrUenOh</a></p><p></p><h2 id=\"recommended-lora-list-for-noobai-xl:\">Recommended LoRa List for NoobAI XL:</h2><p><a target=\"_blank\" rel=\"ugc\" href=\"https://fcnk27d6mpa5.feishu.cn/wiki/IBVGwvVGViazLYkMgVEcvbklnge\">https://fcnk27d6mpa5.feishu.cn/wiki/IBVGwvVGViazLYkMgVEcvbklnge</a></p><p></p><h2 id=\"method-i:-reforge\">Method I: <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Panchovix/stable-diffusion-webui-reForge/\"><strong><u>reForge</u></strong></a></h2><ol><li><p>(If you haven't installed reForge) Install reForge by following the instructions in the repository;</p></li><li><p>Launch WebUI and use the model as usual!</p></li></ol><h2 id=\"method-ii:-comfyui\">Method II: <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/comfyanonymous/ComfyUI\"><strong><u>ComfyUI</u></strong></a></h2><p>SAMLPLE with NODES</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Laxhar/noobai-XL-Vpred-0.5/blob/main/comfy_ui_workflow_sample.png\"><strong><u>comfy_ui_workflow_sample</u></strong></a></p><h2 id=\"method-iii:-webui\">Method III: <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui\"><strong><u>WebUI</u></strong></a></h2><p>Note that dev branch is not stable and <strong>may contain bugs</strong>.</p><p>1. (If you haven't installed WebUI) Install WebUI by following the instructions in the repository. For simp</p><p>2.Switch to <code>dev</code> branch:</p><pre><code>git switch dev\n</code></pre><p>3. Pull latest updates:</p><pre><code>git pull\n</code></pre><p>4. Launch WebUI and use the model as usual!</p><h2 id=\"method-iv:-diffusers\">Method IV: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/docs/diffusers/en/index\"><strong><u>Diffusers</u></strong></a></h2><pre><code>import torch\nfrom diffusers import StableDiffusionXLPipeline\nfrom diffusers import EulerDiscreteScheduler\n\nckpt_path = \"/path/to/model.safetensors\"\npipe = StableDiffusionXLPipeline.from_single_file(\n    ckpt_path,\n    use_safetensors=True,\n    torch_dtype=torch.float16,\n)\nscheduler_args = {\"prediction_type\": \"v_prediction\", \"rescale_betas_zero_snr\": True}\npipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, **scheduler_args)\npipe.enable_xformers_memory_efficient_attention()\npipe = pipe.to(\"cuda\")\n\nprompt = \"\"\"masterpiece, best quality,artist:john_kafka,artist:nixeu,artist:quasarcake, chromatic aberration, film grain, horror \\(theme\\), limited palette, x-shaped pupils, high contrast, color contrast, cold colors, arlecchino \\(genshin impact\\), black theme,  gritty, graphite \\(medium\\)\"\"\"\nnegative_prompt = \"nsfw, worst quality, old, early, low quality, lowres, signature, username, logo, bad hands, mutated hands, mammal, anthro, furry, ambiguous form, feral, semi-anthro\"\n\nimage = pipe(\n    prompt=prompt,\n    negative_prompt=negative_prompt,\n    width=832,\n    height=1216,\n    num_inference_steps=28,\n    guidance_scale=5,\n    generator=torch.Generator().manual_seed(42),\n).images[0]\n\nimage.save(\"output.png\")\n</code></pre><p><strong>Note</strong>: Please make sure Git is installed and environment is properly configured on your machine.</p><hr /><h1 id=\"recommended-settings\">Recommended Settings</h1><h2 id=\"parameters\">Parameters</h2><ul><li><p>CFG: 4 ~ 5</p></li><li><p>Steps: 28 ~ 35</p></li><li><p>Sampling Method: <strong>Euler</strong> (‚ö†Ô∏è Other samplers will not work properly)</p></li><li><p>Resolution: Total area around 1024x1024. Best to choose from: 768x1344, <strong>832x1216</strong>, 896x1152, 1024x1024, 1152x896, 1216x832, 1344x768</p></li></ul><h2 id=\"prompts\">Prompts</h2><ul><li><p>Prompt Prefix:</p></li></ul><pre><code>masterpiece, best quality, newest, absurdres, highres, safe,\n</code></pre><ul><li><p>Negative Prompt:</p></li></ul><pre><code>nsfw, worst quality, old, early, low quality, lowres, signature, username, logo, bad hands, mutated hands, mammal, anthro, furry, ambiguous form, feral, semi-anthro\n</code></pre><h1 id=\"usage-guidelines\">Usage Guidelines</h1><h2 id=\"caption\">Caption</h2><pre><code>&lt;1girl/1boy/1other/...&gt;, &lt;character&gt;, &lt;series&gt;, &lt;artists&gt;, &lt;special tags&gt;, &lt;general tags&gt;, &lt;other tags&gt;\n</code></pre><h2 id=\"quality-tags\">Quality Tags</h2><p>For quality tags, we evaluated image popularity through the following process:</p><ul><li><p>Data normalization based on various sources and ratings.</p></li><li><p>Application of time-based decay coefficients according to date recency.</p></li><li><p>Ranking of images within the entire dataset based on this processing.</p></li></ul><p>Our ultimate goal is to ensure that quality tags effectively track user preferences in recent years.</p><p><strong>Percentile RangeQuality Tags</strong>&gt; 95thmasterpiece&gt; 85th, &lt;= 95thbest quality&gt; 60th, &lt;= 85thgood quality&gt; 30th, &lt;= 60thnormal quality&lt;= 30thworst quality</p><h2 id=\"aesthetic-tags\">Aesthetic Tags</h2><p><strong>TagDescription</strong>very awaTop 5% of images in terms of aesthetic score by <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Eugeoter/waifu-scorer-v4-beta\"><strong><u>waifu-scorer</u></strong></a>worst aestheticAll the bottom 5% of images in terms of aesthetic score by <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Eugeoter/waifu-scorer-v4-beta\"><strong><u>waifu-scorer</u></strong></a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/shadowlilac/aesthetic-shadow-v2\"><strong><u>aesthetic-shadow-v2</u></strong></a>......</p><h2 id=\"date-tags\">Date Tags</h2><p>There are two types of date tags: <strong>year tags</strong> and <strong>period tags</strong>. For year tags, use <code>year xxxx</code> format, i.e., <code>year 2021</code>. For period tags, please refer to the following table:</p><p><strong>Year RangePeriod tag</strong>2005-2010old2011-2014early2014-2017mid2018-2020recent2021-2024newest</p><h2 id=\"dataset\">Dataset</h2><ul><li><p>The latest Danbooru images up to the training date (approximately before 2024-10-23)</p></li><li><p>E621 images <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/datasets/NebulaeWis/e621-2024-webp-4Mpixel\"><strong><u>e621-2024-webp-4Mpixel</u></strong></a> dataset on Hugging Face</p></li></ul><p><strong>Communication</strong></p><ul><li><p><strong>QQ Groups:</strong></p><ul><li><p>427280545</p></li><li><p>677964513</p></li><li><p>852429527</p></li><li><p>914818692</p></li><li><p>635772191</p></li><li><p>870086562</p></li></ul></li><li><p><strong>Discord:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.com/invite/DKnFjKEEvH\"><strong><u>Laxhar Dream Lab SDXL NOOB</u></strong></a></p></li></ul><p><strong>How to train a LoRA on v-pred SDXL model</strong></p><p>A tutorial is intended for LoRA trainers based on sd-scripts.</p><p>article link: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/8723\"><strong><u>https://civitai.com/articles/8723</u></strong></a></p><p><strong>Utility Tool</strong></p><p>Laxhar Lab is training a dedicated ControlNet model for NoobXL, and the models are being released progressively. So far, the normal, depth, and canny have been released.</p><p>Model link: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/929685\"><strong><u>https://civitai.com/models/929685</u></strong></a></p><h1 id=\"model-license\">Model License</h1><p>This model's license inherits from <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/OnomaAIResearch/Illustrious-xl-early-release-v0\"><strong><u>https://huggingface.co/OnomaAIResearch/Illustrious-xl-early-release-v0</u></strong></a> fair-ai-public-license-1.0-sd and adds the following terms. Any use of this model and its variants is bound by this license.</p><h2 id=\"i.-usage-restrictions\">I. Usage Restrictions</h2><ul><li><p>Prohibited use for harmful, malicious, or illegal activities, including but not limited to harassment, threats, and spreading misinformation.</p></li><li><p>Prohibited generation of unethical or offensive content.</p></li><li><p>Prohibited violation of laws and regulations in the user's jurisdiction.</p></li></ul><h2 id=\"ii.-commercial-prohibition\">II. Commercial Prohibition</h2><p>We prohibit any form of commercialization, including but not limited to monetization or commercial use of the model, derivative models, or model-generated products.</p><h2 id=\"iii.-open-source-community\">III. Open Source Community</h2><p>To foster a thriving open-source community,users MUST comply with the following requirements:</p><ul><li><p>Open source derivative models, merged models, LoRAs, and products based on the above models.</p></li><li><p>Share work details such as synthesis formulas, prompts, and workflows.</p></li><li><p>Follow the fair-ai-public-license to ensure derivative works remain open source.</p></li></ul><h2 id=\"iv.-disclaimer\">IV. Disclaimer</h2><p>Generated models may produce unexpected or harmful outputs. Users must assume all risks and potential consequences of usage.</p><h1 id=\"participants-and-contributors\">Participants and Contributors</h1><h2 id=\"participants\">Participants</h2><ul><li><p><strong>L_A_X:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/L_A_X\"><strong><u>Civitai</u></strong></a> | <a target=\"_blank\" rel=\"ugc\" href=\"http://Liblib.art\"><strong><u>Liblib.art</u></strong></a> | <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/LAXMAYDAY\"><strong><u>Huggingface</u></strong></a></p></li><li><p><strong>li_li:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/li_li\"><strong><u>Civitai</u></strong></a> | <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/heziiiii\"><strong><u>Huggingface</u></strong></a></p></li><li><p><strong>nebulae:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/kitarz\"><strong><u>Civitai</u></strong></a> | <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/NebulaeWis\"><strong><u>Huggingface</u></strong></a></p></li><li><p><strong>Chenkin:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Chenkin\"><strong><u>Civitai</u></strong></a> | <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/windsingai\"><strong><u>Huggingface</u></strong></a></p></li><li><p><strong>Euge:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Euge_\"><strong><u>Civitai</u></strong></a> | <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Eugeoter\"><strong><u>Huggingface</u></strong></a> | <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Eugeoter\"><strong><u>Github</u></strong></a></p></li></ul><h2 id=\"contributors\">Contributors</h2><ul><li><p><strong>Narugo1992</strong>: Thanks to <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/narugo1992\"><strong><u>narugo1992</u></strong></a> and the <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/deepghs\"><strong><u>deepghs</u></strong></a> team for open-sourcing various training sets, image processing tools, and models.</p></li><li><p><strong>Mikubill</strong>: Thanks to <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Mikubill\"><strong><u>Mikubill</u></strong></a> for the <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Mikubill/naifu\"><strong><u>Naifu</u></strong></a> trainer.</p></li><li><p><strong>Onommai</strong>: Thanks to <a target=\"_blank\" rel=\"ugc\" href=\"https://onomaai.com/\"><strong><u>OnommAI</u></strong></a> for open-sourcing a powerful base model.</p></li><li><p><strong>V-Prediction</strong>: Thanks to the following individuals for their detailed instructions and experiments.</p><ul><li><p>adsfssdf</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/bluvoll\"><strong><u>bluvoll</u></strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/bvhari\"><strong><u>bvhari</u></strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/catboxanon\"><strong><u>catboxanon</u></strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/parsee-mizuhashi\"><strong><u>parsee-mizuhashi</u></strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/very-aesthetic\"><strong><u>very-aesthetic</u></strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/momoura\"><strong><u>momoura</u></strong></a></p></li><li><p>madmanfourohfour</p></li></ul></li><li><p><strong>Community</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/aria1th261\"><strong><u>aria1th261</u></strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/neggles/neurosis\"><strong><u>neggles</u></strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/sdtana\"><strong><u>sdtana</u></strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/chewing\"><strong><u>chewing</u></strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/irldoggo\"><strong><u>irldoggo</u></strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/reoe\"><strong><u>reoe</u></strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/kblueleaf\"><strong><u>kblueleaf</u></strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Yidhar\"><strong><u>Yidhar</u></strong></a>, ageless, ÁôΩÁé≤ÂèØ, Creeper, KaerMorh, ÂêüÊ∏∏ËØó‰∫∫, SeASnAkE, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/zwh20081\"><strong><u>zwh20081</u></strong></a>, Wenaka‚Åß~Âñµ, Á®ÄÈáåÂìóÂï¶, Âπ∏Ëøê‰∫åÂâØ, Êò®Êó•„ÅÆÁ¥Ñ, 445, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/EBIX\"><strong><u>EBIX</u></strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/goyishsoyish\"><strong><u>Sopp</u></strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Y_X\"><strong><u>Y_X</u></strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Minthybasis\"><strong><u>Minthybasis</u></strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Rakosz\"><strong><u>Rakosz</u></strong></a>, Â≠§Ëæ∞NULL, Ê±§‰∫∫ÁÉÇ, Ê≤ÖÊúàÂºØÂàÄ,David, Âπ¥Á≥ïÁâπÂ∑•ÈòüÔºå</p></li></ul><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.831869+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "3036",
    "prompt": "CharTurner - Character Turnaround helper for 1.5 AND 2.1!\n<h1>CharTurner</h1><p>Edit: <strong>controlNet</strong> works <strong>great </strong>with this. Charturner keeps the outfit consistent, controlNet openPose keeps the turns under control. </p><p><strong>Three versions,</strong> scroll down to pick the right one for you.</p><p>If you're unsure of what version you are running, it's <em>probably</em> 1.5, as it is more popular, but 2.1 is newer and gaining ground fast.</p><p><strong>Version 2, for 2.0 and 2.1 models<br />Version 2, for 1.5 models<br />Version 1, for 1.5 models</strong></p><p>BONUS: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7252/charturnerbeta-lora-experimental\">Experimental </a>LORA released<br />used at your own risk. :D (mixes well tho)</p><p>Hey there! I'm a working artist, and I loathe doing character turnarounds, I find it the least fun part of character design. I've been working on an embedding that helps with this process, and, though it's not where I want it to be, I was encouraged to release it under the <a target=\"_blank\" rel=\"ugc\" href=\"https://en.wikipedia.org/wiki/Minimum_viable_product\"><u>MVP</u></a> principle.</p><p>I'm also working on a few more character embeddings, including a head turn around and an expression sheet. They're still way too raw to release tho.</p><p>Is there some type of embedding that would be useful for you? Let me know, i'm having fun making tools to fix all the stuff I hate doing by hand.</p><p>v1 is still a little bit... fiddly.</p><ul><li><p>Sampler: I use DPM++ 2m Karras or DDIM most often.</p></li><li><p>Highres. fix ON for best results</p></li><li><p>landscape orientation will get you more 'turns'; square images tend toward just front and back.</p></li><li><p>I like <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2540/elldreths-stolendreams-mix\"><u>https://civitai.com/models/2540/elldreths-stolendreams-mix</u></a> to make characters in.</p></li><li><p>I use an embedding trained on my own art (smoose) that I will release if people want it? But it's an aesthetic thing, just my own vibe.</p></li><li><p>I didn't really test this in any of the waifu/NAI type models, as I don't usually use them. Looks like it works but it probably has its own special dance.</p></li></ul><p>Things I'm working on for v2: EDIT: <strong>V2 out, see below! (also v2 2.1)</strong></p><ul><li><p>It fights you on style sometimes. I'm adding more various types of art styles to the dataset to combat this. -<strong> V2 has much better styles</strong></p></li><li><p>Open front coats and such tend to be open 'back' on the back view. Adding more types of clothing to the dataset to combat this. - <strong>Still has this problem</strong></p></li><li><p>Tends toward white and 'fit' characters, which isn't useful. Adding more diversity in body and skin tone to the dataset to combat this. - <strong>v2 Much more body and racial diversity added to the set, easier to get different results.</strong></p></li></ul><p>Helps create multiple full body views of a character. The intention is to get at least a front and back, and ideally, a front, 3/4, profile, 1/4 and back versions, in the same outfit.</p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.831882+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "166609",
    "prompt": "Realism By Stable Yogi (Pony)\n<p><span style=\"color:rgb(250, 176, 5)\"><strong>Pro Version of Realism Pony V4-V5-V6 now Available on</strong></span><span style=\"color:rgb(34, 139, 230)\"><strong> </strong></span><a target=\"_blank\" rel=\"ugc\" href=\"https://brandulate.com/\"><span style=\"color:rgb(34, 139, 230)\"><strong>My Patreon</strong></span></a></p><p><strong>Onsite generations are available on these models:</strong><br />üëâ <strong>Realism_By_Stable_Yogi V3:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/166609?modelVersionId=992946\">https://civitai.com/models/166609?modelVersionId=992946</a></p><p></p><p><br />To keep this model available for Image generation on Civitai, please place your bids here and I‚Äôll make it available for onsite generation:<br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/auctions/featured-checkpoints\">https://civitai.com/auctions/featured-checkpoints</a></p><p></p><p><span style=\"color:rgb(250, 82, 82)\"><strong>Join me on</strong></span><span style=\"color:rgb(134, 142, 150)\"><strong> </strong></span><a target=\"_blank\" rel=\"ugc\" href=\"https://brandulate.com/\"><span style=\"color:rgb(34, 139, 230)\"><strong>Patreon</strong></span></a><span style=\"color:rgb(134, 142, 150)\"><strong> </strong></span><span style=\"color:rgb(250, 82, 82)\"><strong>for exclusive perks and early access to unique resources.</strong></span></p><p><span style=\"color:rgb(250, 82, 82)\"><strong>To discuss custom LoRa's or models, feel free to connect on</strong></span><span style=\"color:rgb(134, 142, 150)\"><strong> </strong></span><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/FAgfAeMqys\"><span style=\"color:rgb(34, 139, 230)\"><strong>Discord.</strong></span></a></p><ul><li><p>üëç <strong>Like this model</strong> to keep me motivated and inspired to create more!</p></li><li><p>üí¨ <strong>Drop a comment</strong> and let me know what you'd love to see next.</p></li><li><p>üåü <strong>Review this model</strong> to help me improve and make even better creations.</p></li><li><p>üîî <strong>Hit that notification bell</strong> to stay updated with my latest models and updates!</p></li></ul><h3 id=\"important-usage-tips\"><span style=\"color:rgb(250, 176, 5)\"><strong>Important Usage Tips</strong></span></h3><ul><li><p>Add <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/177792?modelVersionId=775151\"><strong>Stable_Yogis_PDXL_Positives</strong></a> at the <strong>beginning of your prompt section</strong>.</p></li><li><p>Add <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/177792?modelVersionId=772342\"><strong>Stable_Yogis_PDXL_Negatives-neg</strong></a> at the <strong>beginning of your negative prompt section</strong>.</p></li></ul><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.831895+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "9139",
    "prompt": "„ÄêCheckpoint„ÄëYesMix\n<h3 id=\"2024716-update-s0rntex3v\">2024/7/16 update</h3><p>The version 5.0 is retrained using the same dataset as <a rel=\"ugc\" href=\"https://civitai.com/models/316783/yesmix-xl\"><strong>YesMix XL</strong></a>, and the syntax used is the same as <a rel=\"ugc\" href=\"https://civitai.com/models/316783/yesmix-xl\"><strong>YesMix XL</strong></a>.</p><p><strong>5.0 version recommended syntax:</strong></p><p><code>major content e.g. 1girl/1boy, key feature tags, rating tags e.g. general/safe/explicit, quality tags e.g. masterpiece, best quality</code></p><h3 id=\"2024113-udpate-uw8j3zr8q\">2024/1/13 udpate</h3><p>Upload 4.0 version. Add new trained contents filtered using anime aesthetic predictor. Slightly optimize realistic female face.</p><h3 id=\"20231014-udpate-vhmded85j\">2023/10/14 udpate</h3><p>Upload 3.5 version. Using 'Add Difference' method to add some training content in 1.6 version Yesmix (original). Try to balance realistic and anime effects and make the female characters more beautiful and natural.</p><p></p><p><strong><span style=\"color:rgb(250, 82, 82)\">3.5 version now is available in </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/648984346268663030\"><strong><span style=\"color:rgb(34, 139, 230)\">tensor.art</span></strong></a></p><p></p><h2 id=\"usage-for-3.5-version-ap0rupxsp\">Usage for 3.5 version</h2><ul><li><p><strong>For child:</strong> Control the weight of <code>cute</code> to adjust age of characters.</p></li><li><p><strong>For sister/mature female/„Åä„Å≠„Åà: </strong>Control the weight of <code>mature female</code> to adjust characteristic of characters.</p></li><li><p><strong>For realistic/anime: </strong>Control the weight of <code>realistic</code> to adjust effect.</p></li></ul><p></p><p><strong><span style=\"color:rgb(250, 82, 82)\">To prevent loss of prior knowledge, the</span><span style=\"color:rgba(0, 0, 0, 0.85)\"> </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/p1atdev/LECO\"><strong><u><span style=\"color:rgb(34, 139, 230)\">LECO</span></u></strong></a><strong><span style=\"color:rgba(0, 0, 0, 0.85)\"> </span><span style=\"color:rgb(250, 82, 82)\">method is not used in this version to erase negative tags.</span></strong></p><p></p><h3 id=\"2023105-udpate-umnon71ik\">2023/10/5 udpate</h3><p>Upload 3.0 version. The 3.0 version has the following important updates compared to previous versions:</p><p></p><ul><li><p>Support for <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/blob/main/vae/kl-f8-anime2.ckpt\"><strong><u>kl-f8-anime2 VAE</u></strong></a> and no longer support for NAI's VAE.</p></li></ul><p></p><ul><li><p>The 3.0 version is merged by a base model trained with about 7000 images randomly selected in a dataset that contains more than 10000 images. The base model will be continuously updated with the dataset updates.</p></li></ul><p></p><ul><li><p>Use <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/p1atdev/LECO\"><strong><u>LECO</u></strong></a> method to enhance the positive tags and weaken the negative tags in the model, so that good results can be obtained without inputting numerous negative tags.</p><ul><li><p>The positive tags involved in training are:</p><p><code>masterpiece, best quality, extremely delicate and beautiful, highres, original</code></p></li><li><p>The negative tags involved in training are:</p><p><code>lowres, ugly, worst quality, low quality, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, jpeg artifacts, signature, watermark, username, blurry, bad feet, poorly drawn hands, poorly drawn face, mutation, deformed, extra fingers, extra limbs, missing limbs, extra legs, extra arms, malformed limbs, long neck, extra feet</code></p></li></ul></li></ul><p></p><p>The 3.0 version is currently well compatible with other anime LORAs. It can be used in conjunction with <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/71961?modelVersionId=94057\"><strong><u>FastNegativeV2</u></strong></a> to achieve the best results.</p><p></p><h3 id=\"2023613-update-4q0q9il55\">2023/6/13 update</h3><p>Upload 2.0 version. Building upon previous versions, I further balanced the generation effects of realistic and anime images, attempting to make both more natural and harmonious. <strong>As of now, I remain uncertain whether this version's generation results outperform those of previous versions.¬†</strong>Currently, this version works quite well with other LoRA models (see preview images).¬†<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/71961/fast-negative-embedding-fastnegativev2\"><strong>FastNegativeV2</strong></a> <strong>embedding is highly recommended, which can further enhance the clarity of generated images and make them look sharper. NAI's VAE had been baked in this version, so unless necessary, no need to load other VAEs. In addition, this model is not recommended as base model for training other LoRA models.</strong></p><h3 id=\"2023319-update-tls1wvm7w\">2023/3/19 update</h3><p>Upload original version of 1.6 Yesmix. No LoRA models are merged in this version.</p><h3 id=\"2023314-update-5dce6llke\">2023/3/14 update</h3><p>Adjust merging proportion to fix hands. Merge following new LoRAs to enhance effect:</p><ol><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/12597/moxin\"><strong>Moxin </strong></a>by simhuang to enhance face and style.</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8217/fashion-girl\"><strong>Fashion Girl</strong></a> by me to enhance face.</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16667/akiryos-mai\"><strong>Akiryo's Mai</strong></a> by me to slightly finetune face, body shape and skin texture.</p></li></ol><p>Thus, when this model and the above LoRA are used to generate images, the weight of these LoRAs should be lowered appropriately.</p><p><strong>For convenience, the preview images are generated using only tags without any extra modules (e.g. embedding, LoRA, Hypernetwork) and functions (e.g. hires fix). The NAI's VAE had been baked in this model, so there is no need to load any additional VAEs.</strong></p><h3 id=\"2023216-upate-y01xmzcst\">2023/2/16 upate</h3><p>Adjust the merging ratios to fix deformed limbs.</p><h1 id=\"introduction-y6t2c20vu\">Introduction</h1><p>This model is originated an idea of creating a model that can precisely generate anime nsfw images. For this reason, I fine-tuned the NAI model with more than 10k nsfw images. Unfortunately, it's overcooked. To reduce this bad effect, I have to merge this model with the following models:</p><ol><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1173/hassanblend-1512-and-previous-versions\"><strong>Hassanblend</strong></a> by sdhassan (0.15)</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5706/anyhentai\"><strong>Anyhentai</strong></a> by asdpro123 (0.1)</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4451/abyssorangemix2-hardcore\"><strong>AbyssOrangeMix2 - Hardcore</strong></a> by Havoc (0.15)</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/syaimu/7th_Layer\"><strong>7th-anime-v3</strong></a> by syaimu (0.2)</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3850/kenshi\"><strong>Kenshi</strong></a> by Luna (0.15)</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2583/grapefruit-hentai-model\"><strong>Grapefruit</strong></a> by Ikena (0.1)</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7154/colorbombmix\"><strong>ColorbombMix</strong></a> by mocker (0.1)</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4468/counterfeit-v25\"><strong>Counterfeit v2.5</strong></a> by rqdwdw (0.1)</p></li></ol><p>Then this checkpoint was born after above merging, which is a very coincidental work. The name of this model is still unknown to me. Therefore it's named as \"YesMix\". <strong>The NAI's VAE had been baked in this model, so there is no need to load any additional VAEs.</strong> Thanks to the excellent models provided by the above authors. <strong>Btw, all of the preview images are generated using this model without any extra modules such as LORA and embedding.</strong></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.831914+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "33208",
    "prompt": "LEOSAM's FilmGirl Ultra ËÉ∂ÁâáÈ£é\n<p>üåç<span style=\"color:rgba(255, 255, 255, 0.8)\">Ê¨¢ËøéÂä†ÂÖ•</span>QQÁæ§\"ÂÖîÁã≤¬∑AIGCÊ¢¶Â∑•ÂåóÂéÇ\"ÔºåÁæ§Âè∑ Ôºö<span style=\"color:rgb(250, 176, 5)\">780132897</span> Ôºõ\"ÂÖîÁã≤¬∑AIGCÊ¢¶Â∑•ÂçóÂéÇ\"ÔºåÁæ§Âè∑ Ôºö<span style=\"color:rgb(250, 176, 5)\">835297318</span>ÔºàÂÖ•Áæ§Á≠îÊ°àÔºöÂÖîÁã≤Ôºâ„ÄÇ<span style=\"color:rgba(255, 255, 255, 0.8)\">TelegramÁæ§ËÅä‚ÄúÂÖîÁã≤ÁöÑSDXLÁôæËÄÅÊ±á‚ÄùÔºåÈìæÊé•Ôºö</span><a target=\"_blank\" rel=\"ugc\" href=\"https://t.me/+KkflmfLTAdwzMzI1\"><span style=\"color:rgb(250, 176, 5)\">https://t.me/+KkflmfLTAdwzMzI1</span></a></p><p></p><p><span style=\"color:rgb(255, 255, 255)\">üö®</span><strong><span style=\"color:rgb(193, 194, 197)\">Recommended parameters for </span>FilmGirl UltraÔºö</strong></p><p><strong>Clip skip</strong>:1</p><p><strong>CFG scale</strong>: 9</p><p><strong>Direct output image resolution: </strong>~500,000 pixels (640x768)</p><p></p><h3 id=\"2023524-introducing-the-velvia-version-lora-model\"><u>2024.2.29 Introducing \"FilmGirl Ultra\",Say goodbye to the AI face of SD1.5</u></h3><p>On February 24th last year, I completed the first version of FilmGirl LoRA. This LoRA was my first model to achieve a high download volume and marks the beginning of my dream in AI. Since the launch of SDXL, I have devoted a great deal of effort to improving the <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/43977/leosams-helloworld-xl\">HelloWorld</a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/219791/leosam-aiart-sdxl\">AIArt</a> XL models. It has also been 8 months since the FilmGirl series was last updated.</p><p>In fact, whether it's FilmGirl, or the subsequent <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/52652/leosams-instant-photo-polaroid-lora-and-loha\">Polaroid LoRA</a> or Helloworld XL, I have always been pursuing the ultimate in photorealism. Now a whole year has passed, and to commemorate the first anniversary, I have decided to release a model that elevates the photorealism of SD1.5 to new heights. The LoRA model is no longer sufficient for this mission; <strong><span style=\"color:rgb(250, 176, 5)\">the new FilmGirl Ultra is an SD1.5 base model.</span></strong></p><p>To completely break away from the homogenization of SD1.5 photorealistic models and the issue of AI faces, <strong><span style=\"color:rgb(250, 176, 5)\">FilmGirl Ultra didn't choose basilmix, chilloutmix, or their descendants as the training base model, but instead selected the newly released SPIN-Diffusion by UCLA.</span></strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/UCLA-AGI/SPIN-Diffusion-iter3\">SPIN-Diffusion</a> is a Self-Play Fine-Tune SD1.5 base model using the winner images of the pickapic_v2 dataset, which outperforms the SD1.5 original base model and SD1.5 DPO base model, and its prompt alignment performance is far superior to heavily fine-tuned and merged base models like Chilloutmix.</p><p>The training set for FilmGirl Ultra comes from HelloWorld XL. In fact, the first version of HelloWorld XL also used the training set from the last version of FilmGirl LoRA. Throughout this year, I have been meticulously accumulating and selecting this training set, which now totals ~10,000 images. The training process for FilmGirl Ultra utilized multiple labeling methods, including <strong><span style=\"color:rgb(250, 176, 5)\">GPT4V natural language captions, GPT4V tag-style captions, and Blip+Clip captions</span></strong>. To ensure that the model is compatible with the commonly used prompts \"1girl\", \"best quality\", and \"masterpiece\", these terms were also appropriately added to some images (but you can still accurately trigger the effect of a little girl with \"little girl/child girl\"). The reason for using multiple sets of labels is to maximize the likelihood of triggering the desired effect. As part of the FilmGirl tradition, <strong><span style=\"color:rgb(250, 176, 5)\">the film style has been given special attention, and you can trigger this style with the prompt \"film grain analog photography\"</span></strong>.</p><p>This model underwent a total of 7 training phases, with different batch sizes, optimizers, learning rates, and training set ratios used in each phase to achieve the current effect. If anyone is interested in fine-tuning SPIN-Diffusion, I recommend that your total training iterations should exceed 50,000 steps; in fact, I trained for about 100,000 steps with batch sizes ranging from 40 to 64.</p><p><strong><span style=\"color:rgb(250, 176, 5)\">The photorealistic effect of FilmGirl Ultra exceeded my expectations and is now close to the image quality of SDXL</span></strong>. Below is a comparison of this model with <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4201?modelVersionId=245598\">Realistic Vision v6</a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/132632?modelVersionId=363565\">epiCPhotoGasm</a>, the former being the currently highest downloaded base model on Civitai, and the latter being the most photorealistic SD1.5 base model in my opinion for a long time. I pay tribute to these two excellent base models and their creators.</p><pre><code>close-up couple's portrait,African young woman and man,clear skin face,looking at camera,fashion photography,simple background\nNegative prompt: watermark,anime,cartoon,open mouth</code></pre><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/4d5f46c6-a768-445f-8156-66de4c89e5d7/width=525/4d5f46c6-a768-445f-8156-66de4c89e5d7.jpeg\" /></p><pre><code>close-up couple's portrait,African little girl and boy,clear skin face,looking at camera,fashion photography,simple background,\nNegative prompt: watermark,anime,cartoon,open mouth,</code></pre><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/19d2365d-0adb-4d70-9548-545025efbde3/width=525/19d2365d-0adb-4d70-9548-545025efbde3.jpeg\" /></p><p>Thanks to GPT4V captions and the SPIN-Diffusion base model, <strong><span style=\"color:rgb(250, 176, 5)\">the model's prompt alignment performance is excellent</span></strong>. Below are some xy plot tests for different concepts.</p><p><strong>Ethnic test</strong></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/22188c36-be35-4f32-9b18-f1030ac0ffc4/width=525/22188c36-be35-4f32-9b18-f1030ac0ffc4.jpeg\" /></p><p><strong>Body shape test</strong></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5a3c6f79-6d29-4f92-9f4b-bef5ab249934/width=525/5a3c6f79-6d29-4f92-9f4b-bef5ab249934.jpeg\" /></p><p><strong>Skin color test</strong></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/090201f3-459b-4874-8af3-759f78792805/width=525/090201f3-459b-4874-8af3-759f78792805.jpeg\" /></p><p><strong>Age test</strong></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9c0754b2-0d68-4e61-a194-e6165f9d24ac/width=525/9c0754b2-0d68-4e61-a194-e6165f9d24ac.jpeg\" /></p><p><strong>Animal test</strong></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a3260141-4774-4dfe-99dc-26d36a771d30/width=525/a3260141-4774-4dfe-99dc-26d36a771d30.jpeg\" /></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/51cd5bf8-af30-46ef-9b6b-68245c252c88/width=525/51cd5bf8-af30-46ef-9b6b-68245c252c88.jpeg\" /></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0a862279-3ded-479a-bbb1-c9d821ad6a60/width=525/0a862279-3ded-479a-bbb1-c9d821ad6a60.jpeg\" /></p><p>However, FilmGirl Ultra doesn't lead in all dimensions. After all, it started from a new point and gave up on the continuous optimization and refinement of the community's 1.5 base models over the past year. Through extensive testing and comparison, I found that <strong><span style=\"color:rgb(250, 176, 5)\">this base model has a higher rate of limb errors than the community's mature realistic models</span></strong>. Also, due to a lack of anime-related content in the training set, <strong><span style=\"color:rgb(250, 176, 5)\">the output is not good when your prompts involve related tags of ACGN</span></strong>. It is recommended to avoid using words like \"digital art\", \"anime\", \"cartoon\", etc. These two issues are the main current shortcomings of FilmGirl Ultra.</p><p>FilmGirl Ultra is an annual summary of my first year on my AI journey, a gift to those AI enthusiasts who have supported me. The open-source community has brought me many friends, memories, joy, and knowledge. I also hope to contribute a bit back to the community. I welcome everyone to base your model training or merge it with FilmGirl Ultra.<strong><span style=\"color:rgb(250, 176, 5)\"> If you find this model helpful in improving your own model, please mention it in the model description. I hope that FilmGirl Ultra and SPIN-Diffusion will become more widely known and used.</span></strong></p><p>FilmGirl Ultra will continue to be updated, and I wish everyone happy usage!</p><p>Hope we can continue to progress with AI, and meet here again this time next year!</p><p></p><p>ÂéªÂπ¥ÁöÑ2Êúà24Êó•ÔºåÊàëÂÆåÊàê‰∫ÜÁ¨¨‰∏ÄÁâàFilmGirl LoRAÂà∂‰Ωú„ÄÇËøô‰∏™LoRAÊòØÊàëÁöÑÈ¶ñ‰∏™È´ò‰∏ãËΩΩÈáèÊ®°ÂûãÔºåÊòØÊàëÁöÑAI‰πãÊ¢¶ÁöÑÂºÄÂßã„ÄÇËá™‰ªéSDXLÊé®Âá∫ÂêéÔºåÊàëÂ∞ÜÂ§ßÈáèÁ≤æÂäõÊäïÂÖ•Âà∞HelloWorldÂíåAIArt‰∏§‰∏™XLÂ§ßÊ®°ÂûãÁöÑÊîπËøõ‰∏≠„ÄÇFilmGirlËøô‰∏™Á≥ªÂàó‰πüÂ∑≤Áªè8‰∏™ÊúàÊ≤°ÊúâÊõ¥Êñ∞‰∫Ü„ÄÇ</p><p>ÂÖ∂ÂÆû‰∏çÁÆ°ÊòØFilmGirlÔºåËøòÊòØÂêéÊù•ÁöÑÊãçÁ´ãÂæóLoRA„ÄÅHelloworld XLÔºåÊàë‰∏ÄÁõ¥ÈÉΩÂú®ËøΩÊ±ÇÊûÅËá¥ÁöÑÂÜôÂÆûÊÑü„ÄÇÂ¶Ç‰ªäÂ∑≤Êï¥Êï¥‰∏ÄÂπ¥ËøáÂéªÔºå‰Ωú‰∏∫‰∏ÄÂë®Âπ¥Á∫™ÂøµÔºåÊàëÂÜ≥ÂÆöÊé®Âá∫‰∏Ä‰∏™ÂèØ‰ª•Â∞ÜSD1.5ÁöÑÂÜôÂÆûÊÑüÊä¨ÂçáËá≥Êñ∞È´òÂ∫¶ÁöÑÊ®°ÂûãÔºåLoRAÊ®°ÂûãÂ∑≤‰∏çË∂≥‰ª•ÊâøËΩΩËøô‰∏™‰ΩøÂëΩÔºåÊñ∞ÁöÑFilmGirl UltraÊòØ‰∏Ä‰∏™SD1.5Â§ßÊ®°Âûã„ÄÇ</p><p>‰∏∫‰∫ÜÂΩªÂ∫ïÊëÜËÑ±SD1.5ÂÜôÂÆûÊÑüÂ§ßÊ®°ÂûãÁöÑÂêåË¥®ÂåñÂíåAIËÑ∏ÈóÆÈ¢òÔºåFilmGirl UltraÊ≤°ÊúâÈÄâÊã©basilmix„ÄÅchilloutmixÂèäÂÖ∂Â≠êÂ≠êÂ≠ôÂ≠ô‰ª¨‰Ωú‰∏∫ËÆ≠ÁªÉÂ∫ïÊ®°ÔºåËÄåÊòØÈÄâÊã©‰∫ÜUCLAÊúÄÊñ∞ÂèëÂ∏ÉÁöÑSPIN-Diffusion„ÄÇSPIN-DiffusionÊòØ‰∏Ä‰∏™‰ΩøÁî® pickapic_v2 Êï∞ÊçÆÈõÜËÉúËÄÖÂõæÂÉèËøõË°åËá™ÊàëÂØπÂºàÂæÆË∞ÉÁöÑSD1.5Â∫ïÊ®°ÔºåÂÖ∂Ë°®Áé∞‰ºò‰∫éSD1.5ÂéüÂßãÂ∫ïÊ®°‰ª•ÂèäDPOÂ∫ïÊ®°ÔºåÂêåÊó∂ÊèêÁ§∫ËØçÂØπÈΩêÊÄßËÉΩËøúÂ•Ω‰∫éChilloutmixÁ≠âÁªèËøáÂ§ßÈáèÂæÆË∞É‰∏éËûçÂêàÁöÑÂ∫ïÊ®°„ÄÇ</p><p>FilmGirl UltraÁöÑËÆ≠ÁªÉÈõÜÊù•Ëá™HelloWorld XL„ÄÇÂÆûÈôÖ‰∏äHelloWorld XLÁöÑÁ¨¨‰∏ÄÁâàÊâÄ‰ΩøÁî®ÁöÑËÆ≠ÁªÉÈõÜ‰πüÊù•Ëá™ÊúÄÂêé‰∏ÄÁâàFilmGirl LoRA„ÄÇËøô‰∏ÄÂπ¥ÊàëÈÉΩÂú®Á≤æÁõäÊ±ÇÁ≤æÂú∞ÁßØÁ¥ØÂíåÁ≠õÈÄâËØ•ËÆ≠ÁªÉÈõÜÔºåÂ¶Ç‰ªäÊï¥‰∏™ËÆ≠ÁªÉÈõÜÊï∞ÈáèÂ∑≤ËææÂà∞1‰∏áÂº†„ÄÇFilmGirl UltraÁöÑÊï¥‰∏™ËÆ≠ÁªÉËøáÁ®ã‰ΩøÁî®‰∫ÜÂ§öÁßçÊâìÊ†áÊñπÊ≥ïÔºåÂåÖÊã¨GPT4VËá™ÁÑ∂ËØ≠Ë®Äcaption„ÄÅGPT4V Ê†áÁ≠æÂºècaption„ÄÅBlip+Clip caption„ÄÇÂêåÊó∂‰∏∫‰∫Ü‰ΩøÂæóËØ•Ê®°ÂûãÂèØ‰ª•ÂÖºÂÆπÂ§ßÂÆ∂Ë∂ÖÂ∏∏Áî®ÁöÑ1girl„ÄÅbest quality„ÄÅmasterpiece‰∏â‰∏™ËØçÔºå‰πüÈÄÇÂΩìÂú∞Âú®ÈÉ®ÂàÜÂõæÂÉè‰∏≠Ê∑ªÂä†‰∫ÜËøô‰∏â‰∏™ËØçÔºà‰ΩÜÊÇ®‰ªçÂèØ‰ª•ÈÄöËøáchild girl/girlËøô‰∏§‰∏™ËØçÂáÜÁ°ÆËß¶ÂèëÂ∞èÂ•≥Â≠©ÊïàÊûúÔºâ„ÄÇ‰πãÊâÄ‰ª•‰ΩøÁî®Â§öÂ•óÊâìÊ†áÔºåÊòØ‰∏∫‰∫Ü‰ΩøËÆ≠ÁªÉÈõÜÁöÑÊïàÊûúÂèØ‰ª•Â∞ΩÂèØËÉΩÈ´òÊ¶ÇÁéáÂú∞Ëß¶Âèë„ÄÇÂêåÊó∂‰Ωú‰∏∫FilmGirlÁöÑ‰º†ÁªüÔºåËÉ∂ÁâáÈ£éÊ†ºË¢´ÈáçÁÇπÂÖ≥Ê≥®ÔºåÊÇ®ÂèØ‰ª•ÈÄöËøáfilm grain analog photographyÊù•Ëß¶ÂèëËØ•È£éÊ†º„ÄÇ</p><p>Êú¨Ê®°ÂûãËøõË°å‰∫ÜÂÖ±7Èò∂ÊÆµÁöÑËÆ≠ÁªÉÔºå‰∏çÂêåÈò∂ÊÆµÈÄâÁî®‰∫Ü‰∏çÂêåÁöÑbatch size„ÄÅ‰ºòÂåñÂô®„ÄÅÂ≠¶‰π†Áéá‰ª•ÂèäËÆ≠ÁªÉÈõÜÊØî‰æãÔºåÊñπÊâçËææÂà∞‰∫ÜÁõÆÂâçÁöÑÊïàÊûú„ÄÇÂ¶ÇÊûúÊúâÊúãÂèãÂêåÊ†∑ÂØπÂæÆË∞ÉSPIN-DiffusionÊÑüÂÖ¥Ë∂£ÔºåÊàëÂª∫ËÆÆÊÇ®ÁöÑÊÄª‰ΩìËÆ≠ÁªÉËø≠‰ª£Ê≠•Êï∞Â∫îÂú®5‰∏áÊ≠•‰ª•‰∏äÔºåÂÆûÈôÖ‰∏äÊàë‰ª•batch size 40~64ÔºåÂÖ±ËÆ≠ÁªÉ‰∫ÜÁ∫¶10‰∏áÊ≠•„ÄÇ</p><p>FilmGirl UltraÁöÑÂÜôÂÆûÊïàÊûúË∂ÖÂá∫‰∫ÜÊàëÁöÑÈ¢ÑÊñôÔºåÂ∑≤Áªè‰∏éSDXLÁöÑÂõæÂÉèÊïàÊûúÊé•Ëøë„ÄÇ‰∏äÂõæ‰∏≠ÂàóÂá∫‰∫ÜËØ•Ê®°Âûã‰∏éRealistic Vision v6‰ª•ÂèäepiCPhotoGasmÁöÑÂØπÊØîÔºåÂâçËÄÖÊòØÁõÆÂâçCÁ´ô‰∏ãËΩΩÈáèÊúÄÈ´òÁöÑ1.5Â∫ïÊ®°ÔºåÂêéËÄÖÊòØÊàëÂøÉÁõÆ‰∏≠ÈïøÊúü‰ª•Êù•ÊúÄ‰∏∫ÂÜôÂÆûÁöÑ1.5Â∫ïÊ®°ÔºåÂêëËøô‰∏§‰∏™‰ºòÁßÄÂ∫ïÊ®°‰ª•ÂèäÂÖ∂ËÉåÂêéÁöÑ‰ΩúËÄÖËá¥Êï¨„ÄÇ</p><p>ÂêåÊó∂ÂæóÁõä‰∫éGPT4VÊâìÊ†á‰ª•ÂèäSPIN-DiffusionÂ∫ïÊ®°ÔºåËØ•Ê®°ÂûãÁöÑÊèêÁ§∫ËØçÂØπÈΩêÊÄßËÉΩ‰ºòÂºÇ„ÄÇ</p><p>‰ΩÜFilmGirl Ultra‰πüÂπ∂ÈùûÂú®ÊâÄÊúâÁª¥Â∫¶ÈÉΩÂÖ®Èù¢È¢ÜÂÖà„ÄÇÂÆÉÊØïÁ´üÊòØ‰ªé‰∏Ä‰∏™ÂÖ®Êñ∞Ëµ∑ÁÇπÂá∫ÂèëÂà∂‰ΩúÔºåÊîæÂºÉ‰∫ÜÁ§æÂå∫‰∏ÄÂπ¥Â§öÊù•ÂØπ1.5Â∫ïÊ®°ÁöÑ‰∏çÊñ≠Ë∞É‰ºòÊâìÁ£®ÂÜÖÂÆπÔºåÁªèËøáÊàëÁöÑÂ§ßÈáèÊµãËØïÂØπÊØîÔºåËØ•Â∫ïÊ®°ÁöÑËÇ¢‰ΩìÈîôËØØÁéáË¶ÅÈ´ò‰∫éÁ§æÂå∫ÊàêÁÜüÁöÑÂÜôÂÆûÊ®°Âûã„ÄÇÂêåÊó∂Áî±‰∫éËÆ≠ÁªÉÈõÜÁº∫‰πè‰∫åÊ¨°ÂÖÉÂÜÖÂÆπÔºåÂΩì‰Ω†ÁöÑÊèêÁ§∫ËØç‰∏≠Ê∂âÂèä‰∫åÊ¨°ÂÖÉÁõ∏ÂÖ≥tagÊó∂ÔºåÂá∫ÂõæÊïàÊûú‰∏ç‰Ω≥„ÄÇÂª∫ËÆÆÂ§ßÂÆ∂ÈÅøÂÖç‰ΩøÁî®digital art„ÄÅanime„ÄÅcartoonÁ≠âËØç„ÄÇËøô‰∏§‰∏™ÈóÆÈ¢òÊòØFilmGirl UltraÁõÆÂâçÊúÄ‰∏ªË¶ÅÁöÑ‰∏§‰∏™Áº∫Èô∑„ÄÇ</p><p>FilmGirl UltraÊòØÊàëAI‰πãÊóÖÁ¨¨‰∏ÄÂπ¥ÁöÑÂπ¥ÁªàÊÄªÁªìÔºåÊòØÊàëÈÄÅÁªôÊîØÊåÅÊàëÁöÑAIÂêåÂ•Ω‰ª¨ÁöÑÁ§ºÁâ©„ÄÇÂºÄÊ∫êÁ§æÂå∫‰∏∫ÊàëÂ∏¶Êù•‰∫ÜËØ∏Â§öÊúãÂèã„ÄÅÂõûÂøÜ„ÄÅÂø´‰πê‰ª•ÂèäÁü•ËØÜÔºåÊàë‰πüÂ∏åÊúõÂõûÈ¶àÁ§æÂå∫ÂÅöÂá∫Ëá™Â∑±ÁöÑ‰∏ÄÁÇπÁÇπË¥°ÁåÆ„ÄÇÂ∏åÊúõ‰∏äËø∞ÁöÑÊ®°ÂûãÂà∂‰ΩúÊÄªÁªìËÉΩ‰∏∫Â§ßÂÆ∂Â∏¶Êù•‰∏Ä‰∫õÂ∏ÆÂä©ÔºåÂêåÊó∂‰πüÊ¨¢ËøéÂ§ßÂÆ∂Âü∫‰∫éFilmGirl UltraËøõË°å‰Ω†ÁöÑÊ®°ÂûãËÆ≠ÁªÉÊàñËûçÂêà„ÄÇÊú¨Ê®°Âûã‰∏éÂÖ∂ËÆ≠ÁªÉÂ∫ïÊ®°SPIN-Diffusion‰∏ÄÊ†∑ÔºåËØ∑Â§ßÂÆ∂ÈÅµÂæ™<a target=\"_blank\" rel=\"ugc\" href=\"https://choosealicense.com/licenses/apache-2.0/\">Apache-2.0</a>ËÆ∏ÂèØËØÅ‰ΩøÁî®ÔºåÂê¶ÂàôÂ∞ÜË¢´ËøΩË¥£„ÄÇÂ¶ÇÊûúÊÇ®ËßâÁùÄËøô‰∏™Ê®°ÂûãÊúâÂ∏ÆÂä©ÊÇ®ËÆ©Ëá™Â∑±ÁöÑÊ®°ÂûãÂèòÂæóÊõ¥Â•ΩÔºåËØ∑Âú®Ê®°ÂûãËØ¥Êòé‰∏≠ÊèêÂèä‰∏ãÂÆÉÔºåÂ∏åÊúõFilmGirl Ultra‰ª•ÂèäSPIN-DiffusionËÉΩË¢´Êõ¥Â§ö‰∫∫‰∫ÜËß£Âíå‰ΩøÁî®„ÄÇ</p><p>FilmGirl UltraÂêéÁª≠Ëøò‰ºöÊåÅÁª≠Êõ¥Êñ∞ÔºåÁ•ùÂ§ßÂÆ∂‰ΩøÁî®ÊÑâÂø´ÔºÅ</p><p>Â∏åÊúõÊàë‰ª¨ËÉΩÈöèAI‰∏ÄËµ∑‰∏çÊñ≠ËøõÊ≠•ÔºåÊòéÂπ¥Ê≠§Êó∂Ôºå‰ªçËÉΩÂú®Ê≠§Áõ∏ÈÅáÔºÅ</p><p></p><p><strong><u>ÁâàÊùÉÂ£∞ÊòéÔºö</u></strong></p><p>FilmGirl UltraÁ≥ªÂàóÊ®°ÂûãÔºà‰ª•‰∏ãÁÆÄÁß∞‚ÄúÊú¨Ê®°Âûã‚ÄùÔºâÊòØÁî±ÊàëÔºà‰ª•‰∏ãÁÆÄÁß∞‚ÄúÊâÄÊúâËÄÖ‚ÄùÔºâÂü∫‰∫éSPIN-DiffusionÂºÄÂèëÁöÑSD1.5Â§ßÊ®°Âûã„ÄÇ</p><p>ÊâÄÊúâËÄÖÊéàÊùÉ‰∏™‰∫∫ÊàñÊú∫ÊûÑÂèØÂÖçË¥π‰ΩøÁî®Êú¨Ê®°ÂûãÊâÄÁîüÊàêÁöÑÂõæÂÉèÁî®‰∫éÈùûÂïÜ‰∏öÊÄßË¥®ÁöÑÊïôËÇ≤Êàñ‰ø°ÊÅØ‰º†Êí≠ÁõÆÁöÑÔºåÂπ∂‰∏îÔºö</p><p>- ÈÅµÂÆàÁõ∏ÂÖ≥Ê≥ïÂæãËßÑÂÆöÔºå‰∏ç‰æµÁäØÊú¨Ê®°ÂûãÊàñ‰ªª‰ΩïÁ¨¨‰∏âÊñπÁöÑÂêàÊ≥ïÊùÉÁõä„ÄÇ</p><p>- Âú®‰ΩøÁî®ÂõæÂÉèÊó∂ÈúÄÊ≥®ÊòéÂõæÂÉèÊù•Ê∫ê‰∏∫‚ÄúÁî±LEOSAM's FilmGirl UltraÂ§ßÊ®°ÂûãÁîüÊàê‚Äù„ÄÇ</p><p>ÂØπ‰∫éÂïÜ‰∏öÁõÆÁöÑÁöÑ‰ΩøÁî®ÔºåÂøÖÈ°ªÂÖà‰∏éÊâÄÊúâËÄÖÁ≠æÁΩ≤ÂïÜÁî®ÊéàÊùÉÂçèËÆÆ„ÄÇÊúâÂÖ≥ÂïÜ‰∏öÊéàÊùÉÂíåÊ®°ÂûãÂÆöÂà∂‰∫ãÂÆúÔºåËØ∑ÈÄöËøáÊâÄÊúâËÄÖÂú®CivitaiÂπ≥Âè∞ÁöÑ‰∏ªÈ°µ‰ø°ÊÅØËÅîÁ≥ª„ÄÇ</p><p>ÊâÄÊúâËÄÖÂ∞ÜÊåÅÁª≠‰∏∫‰∏™‰∫∫Áé©ÂÆ∂ÂÖçË¥πÊèê‰æõFilmGirl UltraÊ®°ÂûãÁöÑÊõ¥Êñ∞Ôºå‰ª•Ê≠§Ë°®ËææÂØπÁ§æÂå∫ÂºÄÊ∫êË¥°ÁåÆËÄÖÁöÑÊîØÊåÅÂíåÊÑüË∞¢„ÄÇÂïÜ‰∏öÁî®Êà∑ÁöÑÊúâÂÅøÂêà‰ΩúÊòØÊé®Âä®Êú¨Ê®°ÂûãÂºÄÂèëÂíåÊåÅÁª≠ÊîπËøõÁöÑÈáçË¶ÅÂä®Âäõ„ÄÇÊÑüË∞¢ÊØè‰∏Ä‰ΩçÁî®Êà∑ÁöÑÁêÜËß£‰∏éÊîØÊåÅ„ÄÇ</p><p>ËØ∑Ê≥®ÊÑèÔºå‰ªª‰ΩïÊú™ÁªèÊéàÊùÉÁöÑ‰ΩøÁî®Ë°å‰∏∫ÈÉΩÂèØËÉΩËøùÂèçÁõ∏ÂÖ≥Ê≥ïÂæãËßÑÂÆöÔºåÂπ∂ÂèØËÉΩÊâøÊãÖÊ≥ïÂæãË¥£‰ªª„ÄÇÊú¨Â£∞ÊòéÁöÑÊúÄÁªàËß£ÈáäÊùÉÂΩíÊâÄÊúâËÄÖÊâÄÊúâÔºåÂπ∂ÂèóÁõ∏ÂÖ≥Ê≥ïÂæãÊ≥ïËßÑÁöÑÁ∫¶Êùü„ÄÇ</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.831951+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "101055",
    "prompt": "SD XL\n<p>Originally <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0\">Posted to Hugging Face</a> and shared here with permission from Stability AI.</p><p></p><p><strong><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d8bce8ee-d0c4-4834-8aab-1ee886eb3e12/width=525/d8bce8ee-d0c4-4834-8aab-1ee886eb3e12.jpeg\" /></strong></p><p>SDXL consists of a two-step pipeline for latent diffusion: First, we use a base model to generate latents of the desired output size. In the second step, we use a specialized high-resolution model and apply a technique called SDEdit (<a target=\"_blank\" rel=\"ugc\" href=\"https://arxiv.org/abs/2108.01073\"><strong><u>https://arxiv.org/abs/2108.01073</u></strong></a>, also known as \"img2img\") to the latents generated in the first step, using the same prompt.</p><p></p><h3 id=\"heading-29\">Model Description</h3><ul><li><p><strong>Developed by:</strong> Stability AI</p></li><li><p><strong>Model type:</strong> Diffusion-based text-to-image generative model</p></li><li><p><strong>Model Description:</strong> This is a model that can be used to generate and modify images based on text prompts. It is a <a target=\"_blank\" rel=\"ugc\" href=\"https://arxiv.org/abs/2112.10752\"><strong><u>Latent Diffusion Model</u></strong></a> that uses two fixed, pretrained text encoders (<a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/mlfoundations/open_clip\"><strong><u>OpenCLIP-ViT/G</u></strong></a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/openai/CLIP/tree/main\"><strong><u>CLIP-ViT/L</u></strong></a>).</p></li><li><p><strong>Resources for more information:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Stability-AI/generative-models\"><strong><u>GitHub Repository</u></strong></a>.</p><p></p></li></ul><h3 id=\"heading-30\">Model Sources</h3><ul><li><p><strong>Repository:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Stability-AI/generative-models\"><strong><u>https://github.com/Stability-AI/generative-models</u></strong></a></p></li><li><p><strong>Demo [optional]:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://clipdrop.co/stable-diffusion\"><strong><u>https://clipdrop.co/stable-diffusion</u></strong></a></p><p></p></li></ul><h2 id=\"heading-88\"><strong>Uses</strong></h2><h3 id=\"heading-89\">Direct Use</h3><p>The model is intended for research purposes only. Possible research areas and tasks include</p><ul><li><p>Generation of artworks and use in design and other artistic processes.</p></li><li><p>Applications in educational or creative tools.</p></li><li><p>Research on generative models.</p></li><li><p>Safe deployment of models which have the potential to generate harmful content.</p></li><li><p>Probing and understanding the limitations and biases of generative models.</p></li></ul><p>Excluded uses are described below.</p><p></p><h3 id=\"heading-90\">Out-of-Scope Use</h3><p>The model was not trained to be factual or true representations of people or events, and therefore using the model to generate such content is out-of-scope for the abilities of this model.</p><p></p><h2 id=\"heading-91\">Limitations and Bias</h2><h3 id=\"heading-92\">Limitations</h3><ul><li><p>The model does not achieve perfect photorealism</p></li><li><p>The model cannot render legible text</p></li><li><p>The model struggles with more difficult tasks which involve compositionality, such as rendering an image corresponding to ‚ÄúA red cube on top of a blue sphere‚Äù</p></li><li><p>Faces and people in general may not be generated properly.</p></li><li><p>The autoencoding part of the model is lossy.</p></li></ul><h3 id=\"heading-93\">Bias</h3><p>While the capabilities of image generation models are impressive, they can also reinforce or exacerbate social biases.</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7ba2e0d0-01db-48cf-abd5-a7449e400ea8/width=525/7ba2e0d0-01db-48cf-abd5-a7449e400ea8.jpeg\" /></p><p>The chart above evaluates user preference for SDXL (with and without refinement) over Stable Diffusion 1.5 and 2.1. The SDXL base model performs significantly better than the previous variants, and the model combined with the refinement module achieves the best overall performance.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.831962+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "11772",
    "prompt": "veryBadImageNegative\n<h1>v1.3</h1><p>veryBadImageNegative_v1.3‰ΩøÁî®‰∫ÜÊñ∞ÁöÑËÆ≠ÁªÉÂõæÈõÜÔºåÂú®AOM3Âíå<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7813/viewer-mixv13\">viewer-mix_v1.7</a>‰∏≠‰ΩøÁî®Êó∂Ë°®Áé∞ËæÉÂ•Ω„ÄÇ</p><p>veryBadImageNegative_v1.3 uses a new training atlas and performs well when used in AOM3 and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7813/viewer-mixv13\">viewer-mix_v1.7</a>.</p><p></p><h1>v1.2</h1><p>veryBadImageNegativeÊòØ‰ΩøÁî®<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7813/viewer-mixv13\">viewer-mix_v1.3</a>ÁîüÊàêÁöÑÁâπÊÆäÂõæÈõÜËÆ≠ÁªÉËÄåÊù•ÁöÑË¥üÈù¢ÂµåÂÖ•„ÄÇ</p><p>ÊâÄ‰ª•veryBadImageNegativeÊòØ<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7813/viewer-mixv13\">viewer-mix_v1.3</a>ÁöÑ‰∏ìÁî®Ë¥üÈù¢ÂµåÂÖ•„ÄÇ</p><p>ÊàñËÆ∏Âú®ÂÖ∂‰ªñÁöÑÊâ©Êï£Ê®°Âûã‰∏≠‰πüÊúâ‰∏çÈîôÁöÑÊïàÊûúÔºå‰ΩÜÁº∫‰πèÈ™åËØÅ„ÄÇ</p><p>veryBadImageNegative is a negative embedding trained from the special atlas generated by <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7813/viewer-mixv13\">viewer-mix_v1.3</a>.</p><p>So veryBadImageNegative is the dedicated negative embedding of <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7813/viewer-mixv13\">viewer-mix_v1.3</a>.</p><p>It may also have a good effect in other diffusion models, but it lacks verification.</p><p></p><p>ÂÖ≥‰∫év1.2Ôºö</p><p>Â¢ûÂº∫ÂõæÂÉèÁöÑË¥®ÈáèÔºåÂâäÂº±‰∫ÜÈ£éÊ†º„ÄÇ</p><p>Âú®‰ΩøÁî®v1.2ÁâàÊú¨Êó∂ÔºåÂèØ‰ª•Èôç‰Ωé‰∏Ä‰∫õÊùÉÈáç‰ª•Ëé∑ÂæóÊõ¥Â•ΩÁöÑÁÅµÊ¥ªÊÄß„ÄÇ</p><p>‰æãÂ¶ÇÔºö(veryBadImageNegative_v1.2-6400:0.9)</p><p>About v1.2:</p><p>Enhance image quality and weaken style.</p><p>When using v1.2, you can reduce some weights to obtain better flexibility.</p><p>For example: (veryBadImageNegative_v1.2-6400:0.9)</p><p></p><p>ÂÖ≥‰∫év1.0‰∏év1.1ÁöÑÂ∑ÆÂºÇÔºö</p><p>Âá†‰πéÊ≤°ÊúâÂ∑ÆÂà´Ôºå‰ªÖÁî®‰∫éËÆ≠ÁªÉÁöÑÂõæÈõÜÂú®ÁîüÊàêÂèÇÊï∞Êúâ‰∏Ä‰∫õÂæÆÂ¶ôÁöÑÂ∑ÆÂà´„ÄÇ</p><p>ÂÖ≥‰∫é1600~6400ÁöÑÂ∑ÆÂºÇÔºö</p><p>Êï∞Â≠ó‰ª£Ë°®‰∫ÜËÆ≠ÁªÉÊ≠•Êï∞ÔºåÁêÜËÆ∫‰∏äÊ≠•Êï∞Ë∂äÂ§öÊïàÊûúË∂äÂ•Ω„ÄÇ</p><p>About the difference between v1.0 and v1.1:</p><p>There is almost no difference. The atlas used for training only has some subtle differences in the generation parameters.</p><p>About the difference between 1600 ~ 6400:</p><p>The number represents the number of training steps. In theory, the more steps, the better the effect.</p><p></p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.831970+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "88132",
    "prompt": "LEOSAM's Clothing +/-  Adjuster  Ë°£Áâ©Â¢û/Âáè  LoRA\n<p>üñ•Ô∏èWelcome to try out the open-source <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/jiayev/GPT4V-Image-Captioner\"><strong><u>GPT4V-Image-Captioner</u></strong></a>, developed by my friend and me. It offers a one-click installation and comes integrated with multiple features including image pre-compression, image tagging, and tag statistics. Recently, we also launched the <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/SleeeepyZhou/sd-webui-GPT4V-Image-Captioner\"><strong><u>webui plugin version</u></strong></a> of this tool, everyone is welcome to use it!</p><p></p><p>üåç<span style=\"color:rgba(255, 255, 255, 0.8)\">Ê¨¢ËøéÂä†ÂÖ•</span>QQÁæ§\"ÂÖîÁã≤¬∑AIGCÊ¢¶Â∑•ÂåóÂéÇ\"ÔºåÁæ§Âè∑ Ôºö<span style=\"color:rgb(250, 176, 5)\">780132897</span> Ôºõ\"ÂÖîÁã≤¬∑AIGCÊ¢¶Â∑•ÂçóÂéÇ\"ÔºåÁæ§Âè∑ Ôºö<span style=\"color:rgb(250, 176, 5)\">835297318</span>ÔºàÂÖ•Áæ§Á≠îÊ°àÔºöÂÖîÁã≤Ôºâ„ÄÇ<span style=\"color:rgba(255, 255, 255, 0.8)\">TelegramÁæ§ËÅä‚ÄúÂÖîÁã≤ÁöÑSDXLÁôæËÄÅÊ±á‚ÄùÔºåÈìæÊé•Ôºö</span><a target=\"_blank\" rel=\"ugc\" href=\"https://t.me/+KkflmfLTAdwzMzI1\"><span style=\"color:rgb(250, 176, 5)\">https://t.me/+KkflmfLTAdwzMzI1</span></a></p><p></p><p><strong>üìñËøôÊòØ‰∏Ä‰∏™Ë∞ÉËäÇÊâÄÁªòÂà∂ÂØπË±°Ë°£Áâ©Â§öÂ∞ëÁöÑÂäüËÉΩÊÄßLoRA„ÄÇÈÄöËøáÂ∞ÜLoRAÊùÉÈáç‰ªé1.0Ë∞ÉËäÇËá≥+1.0ÔºåÂèØ‰ª•ÂÆûÁé∞ÁªòÂà∂ÂØπË±°Ë°£Áâ©ÁöÑÈÄêÊ≠•Â¢ûÂä†„ÄÇ</strong></p><p><strong>This is a functional LoRA for adjusting the amount of clothing on the drawn objects. By adjusting the LoRA weight from -1.0 to 1.0, a gradual reduction of the clothing on the drawn objects can be achieved.</strong></p><p></p><p><strong><u>Â¶Ç‰ΩïÂà∂‰Ωú‰∏éÂ∞ÅÈù¢Á§∫ÊÑèÂõæÁ±ª‰ººÁöÑgifÔºö</u></strong></p><p>SD ÊñáÁîüÂõæÁïåÈù¢‰∏ãÊñπ\"ËÑöÊú¨\"ÁöÑ \"XYZ plot\" ÈáåÊúâ‰∏™‚ÄúÊèêÁ§∫ËØçÊêúÁ¥¢/ÊõøÊç¢‚ÄùÁöÑÈÄâÈ°π„ÄÇÂèØ‰ª•‰ΩøÁî®Ëøô‰∏™ÂäüËÉΩÔºå‰ª•Âõ∫ÂÆöÈó¥Èöî‰ªé-1 Âà∞ 1ÔºåÊîπÂèòloraÊ®°Âûã‰ΩøÁî®ÊùÉÈáç„ÄÇÁÑ∂ÂêéSDÂ∞±ÂèØ‰ª•‰æùÊ¨°Âêå‰∏ÄÊèêÁ§∫ËØç‰∏ã„ÄÅloraÊùÉÈáçÊ∏êÂèòÁöÑ‰∏ÄÁ≥ªÂàóÂõæÂÉè„ÄÇÂæóÂà∞Ëøô‰∫õÂõæÂÉèÂêéÔºåÂèØ‰ΩøÁî®ffmpegÂ∑•ÂÖ∑ÂåÖÊàñËÄÖÂÖ∂‰ªñ gif Âà∂‰ΩúÂ∑•ÂÖ∑ÔºåÂ∞ÜËøô‰∫õÂõæÂÉèÂà∂‰ΩúÊàê gif Âä®Âõæ„ÄÇ</p><p>Âª∫ËÆÆ‰ΩøÁî®controlnet‰∏≠ÁöÑopenposeÂäüËÉΩÊù•Âõ∫ÂÆö‰∫∫Áâ©ÂßøÊÄÅ„ÄÇÂ¶ÇÊûú‰Ω†ÊÉ≥Ëøõ‰∏ÄÊ≠•Âõ∫ÂÆöËÉåÊôØÔºåÂàôÈúÄË¶Å‰ΩøÁî®inpaintÂäüËÉΩ„ÄÇ</p><p></p><p><strong><u>How to create a gif similar to the cover gif:</u></strong></p><p>In the \"XYZ plot\" under the \"Script\" section of the SD interface, there is an option for \"Prompt S/R (Prompt search/replacement)\". You can use this feature to change the weighting of the Lora model at fixed intervals from -1 to 1. SD can then generate a series of images with the same Prompt and gradually changing Lora weights. After obtaining these images, you can use the FFmpeg toolkit or other GIF creation tools to create animated GIFs from these images.</p><p>It is recommended to use the 'OpenPose' feature in ControlNet to fix the character's pose. If you want to further fix the background, you will need to use the 'Inpaint' feature.\"</p><p></p><p><strong><u>Â¶Ç‰ΩïÂà∂‰Ωú‰∏é‚ÄúClothing +/- Adjuster‚ÄùÁ±ª‰ººÁöÑLoRAÔºö</u></strong></p><p>Êú¨Ê®°ÂûãÂèóÈùíÈæôÂ§ß‰Ω¨Âú®<a target=\"_blank\" rel=\"ugc\" href=\"https://www.bilibili.com/video/BV11m4y147WQ/?spm_id_from=333.337.search-card.all.click&amp;vd_source=98fa411a98cd1aa45fe8235bb8207969\">Ê≠§ËßÜÈ¢ë</a>‰∏≠ÊâÄ‰ªãÁªçÁöÑÁ¨¨‰∏ÄÁßçÊñπÊ≥ï‚ÄúÂ§çÂç∞Â≠¶‰π†Ê≥ï‚ÄùÂêØÂèë„ÄÇÊàëËøõË°å‰∫Ü‰∏Ä‰∫õÊîπËøõ‰ª•ÂÆûÁé∞Â§öÂº†ÂõæÊÉÖÂÜµ‰∏ãÁöÑÊâπÈáèËÆ≠ÁªÉ„ÄÇÂÖ∑‰ΩìÁöÑÊ≠•È™§Â¶Ç‰∏ãÔºö</p><p>Ê≠•È™§‰∏ÄÔºöÊåëÈÄâNÁªÑ‰∏çÂêå‰∫∫Áâ©ÁöÑÁä∂ÊÄÅA‰∏éÁä∂ÊÄÅBÂØπÊØîÂõæÁâáÔºåÂπ∂ÂΩ¢ÊàêÁä∂ÊÄÅAÂõæÂÉèËÆ≠ÁªÉÈõÜ‰∏éÁä∂ÊÄÅBÂõæÂÉèËÆ≠ÁªÉÈõÜ„ÄÇ‰øùËØÅÁõ∏Âêå‰∫∫Áâ©ÁöÑÁä∂ÊÄÅA‰∏éÁä∂ÊÄÅB‰∏§Âº†ÂõæÁâáÁöÑÊñá‰ª∂ÂêçÁõ∏Âêå„ÄÇ</p><p>Ê≠•È™§‰∫åÔºöÂØπÁä∂ÊÄÅAËÆ≠ÁªÉÈõÜÊ∑ªÂä†txtÊ†áÁ≠æÔºåÊØè‰∏™ÂõæÁâáÂè™Êâì‰∏Ä‰∏™ÂèØ‰ª•Âå∫ÂàÜ‰∏çÂêå‰∫∫Áâ©ÁöÑÁâπÊÆäËØçÊ±áÊ†áÁ≠æ„ÄÇÊØîÂ¶ÇÊúâ10‰∏™‰∫∫Áâ©ÔºåÈÇ£Â∞±ÁªôÊØè‰∏™‰∫∫Áâ©‰ªéjinitaimei1Ëá≥jinitaimei10ÂàÜÈÖçÂêÑËá™ÁöÑÊ†áÁ≠æ„ÄÇÁÑ∂ÂêéÂ∞ÜÁä∂ÊÄÅAËÆ≠ÁªÉÈõÜÁöÑÊâÄÊúâÊ†áÁ≠æÂ§çÂà∂Á≤òË¥¥ËøõÁä∂ÊÄÅBÂõæÂÉèËÆ≠ÁªÉÈõÜ‰∏≠„ÄÇ</p><p>Ê≠•È™§‰∏âÔºöÈÄâÊã©‰∏éËÆ≠ÁªÉÈõÜÁîªÈ£éÁõ∏ËøëÁöÑÂ∫ïÊ®°CÔºå‰ΩøÁî®Áä∂ÊÄÅAÂõæÂÉèËÆ≠ÁªÉÈõÜËøõË°åLoraËÆ≠ÁªÉÁõ¥Ëá≥Ê®°ÂûãËøáÊãüÂêàÔºåËæìÂÖ•‰∫∫Áâ©NÁöÑÂØπÂ∫îÊ†áÁ≠æÂêéÔºåÂè™ËÉΩÁîüÊàê‰∫∫Áâ©NÁöÑÁä∂ÊÄÅAÁÖßÁâá„ÄÇ</p><p>Ê≠•È™§ÂõõÔºöÂ∞ÜËÆ≠ÁªÉÂæóÂà∞ÁöÑËøáÊãüÂêàLoRAÊ®°Âûã‰ª•1.0ÁöÑÊØî‰æãËûçÂêàËøõÂ∫ïÊ®°C‰∏≠ÔºàÊõ¥Êñ∞ÔºöÁªèËøõ‰∏ÄÊ≠•ÊµãËØïÔºåÂãæÈÄâ‰∏äsame to strengthÊïàÊûú‰ºöÊõ¥Â•ΩÔºâÔºåÁÑ∂ÂêéÁî®Áä∂ÊÄÅBÂõæÂÉèËÆ≠ÁªÉÈõÜÂü∫‰∫éÊñ∞Â∫ïÊ®°ËøõË°åLoraËÆ≠ÁªÉ„ÄÇËØ•ËÆ≠ÁªÉËøáÁ®ã‰∏ç‰∏ÄÂÆöË¶ÅËÆ≠ÁªÉËá≥‰∏•ÈáçËøáÊãüÂêàÔºåÂèØ‰ª•ÈÄâÊã©LoRAËøáÁ®ãÊñá‰ª∂ËøõË°åAIÁªòÂõæÊµãËØïÔºåÂè™Ë¶ÅËÉΩÈÄöËøáË∞ÉËäÇÊùÉÈáçÔºåÂÆûÁé∞Áä∂ÊÄÅAËá≥Áä∂ÊÄÅBÁöÑËøáÊ∏°Âç≥ÂèØ„ÄÇÔºàÊõ¥Êñ∞ÔºöÁªèËøõ‰∏ÄÊ≠•ÊµãËØïÔºåÁîúËúúÁÇπÂ§ßÊ¶ÇÂú®ÊØèÂº†ÂõæÁâá400Âú®800Ê≠•ËåÉÂõ¥ÂÜÖÔºâ</p><p>Ê≠•È™§‰∫îÔºöÂ¶ÇÊûúËÆ≠ÁªÉÁöÑLoRAÊâÄÊ∂âÂèäÂú∫ÊôØËæÉÂ§çÊùÇÔºåÂú®È´òÊùÉÈáç‰∏ã‰ºöÂá∫Áé∞ËøáÊãüÂêàÁöÑÊÉÖÂÜµ„ÄÇÊúâ‰∏§ÁßçÊîπËâØÁöÑÂª∫ËÆÆÔºö‰∏ÄÊòØËøõË°åLoRAÂàÜÂ±ÇË∞ÉËäÇÔºåÈôç‰ΩéLoRA‰∏≠‰∏éA/BÁä∂ÊÄÅÂàáÊç¢Êó†ÂÖ≥ÁöÑÂ±ÇÊï∞ÁöÑÊùÉÈáçÔºõ‰∫åÊòØÂéãÁº©LoRAÁöÑÁª¥Â∫¶ÔºåÊØîÂ¶Ç‰ªé64ÂéãÁº©Ëá≥4„ÄÇ</p><p></p><p><strong><u>How to make a LoRA similar to \"Clothing +/- Adjuster\":</u></strong></p><p>This model is inspired by the first method \"Copy Learning\" introduced by Qinglong in <a target=\"_blank\" rel=\"ugc\" href=\"https://www.bilibili.com/video/BV11m4y147WQ/?spm_id_from=333.337.search-card.all.click&amp;vd_source=98fa411a98cd1aa45fe8235bb8207969\">this video</a>. I made some improvements to implement batch training in the case of multiple images. The specific steps are as follows:</p><p>Step 1: Select N groups of comparison images of different characters in State A and State B. Put them into the State A image training set and the State B image training set, respectively. Please ensure that the file names of the two images of State A and State B for the same character are the same.</p><p>Step 2: Add txt labels to the State A training set, with each image receiving only one unique word label that distinguishes different characters. For example, if there are 10 characters, assign each character a label from jinitaimei1 to jinitaimei10. Then copy and paste all labels from the State A training set into the State B image training set.</p><p>Step 3: Choose a base model C with a similar style to the training set. Use the State A image training set for Lora training until the model overfits.</p><p>Step 4: Merge the overfitted LoRA model obtained from training into the base model C at a ratio of 1.0 (Update: After further testing, it will be better to choose same to strength). Then, use the State B image training set for Lora training based on the new base model. This training process does not necessarily need to be trained until severe overfitting occurs; you can choose the LoRA process file for AI drawing tests, as long as the transition from State A to State B can be achieved by adjusting the weight. (Update: 400ÔΩû800 steps for single pic)</p><p>Step 5: If the LoRA training involves complex scenes, overfitting may occur at high weights. There are two suggested improvements: one is to perform layer-by-layer adjustment of LoRA, reducing the weights of layers unrelated to the A/B state switch; the other is to compress the dimensions of LoRA, such as from 64 to 4.</p><p></p><p></p><p>Èô§‰∫ÜËøô‰∏™LoRA‰πãÂ§ñÔºåÊàëÁöÑ‰ΩúÂìÅËøòÂåÖÊã¨Ôºö</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/33208/filmgirl-film-grain-lora-and-loha\"><strong>FilmGirl/ËÉ∂ÁâáÈ£é</strong></a><strong> </strong>Lora<strong>Ê®°ÂûãÔºöÂ¶ÇÊûú‰Ω†ÊÉ≥Â¢ûÂä†‰Ω†ÊâÄÁªòÂà∂‰∫∫Áâ©ÁöÑÁúüÂÆûÊÑüÔºåËøô‰∏™LoraÂ∞±ÊòØÁõÆÂâçÊúÄ‰Ω≥ÁöÑÈÄâÊã©„ÄÇ</strong></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/43977/moonfilm\"><strong>MoonFilm</strong></a><strong> </strong>CheckPointÊ®°Âûã<strong>ÔºöÂèØËÉΩÊòØÊï¥‰∏™civitai‰∏äÁöÆËÇ§ÁúüÂÆûÊÑüTop5ÁöÑÂÜôÂÆûÊ®°Âûã„ÄÇ</strong></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/33194/pallass-catmanul-lora\"><strong>Pallas's cat/ÂÖîÁã≤</strong></a><strong> </strong>LoRA<strong>Ê®°ÂûãÔºöÂÖîÁã≤ÊòØËøô‰∏™‰∏ñÁïåÊúÄÊúâË∂£ÁöÑÁå´ÁßëÂä®Áâ©ÔºåËØ∑Â∞Ü‰Ω†ÁöÑGPUÁÆóÂäõÁåÆÁªôÂèØÁà±ÁöÑÁå´Áå´„ÄÇ</strong></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/52652/instant-photo-polaroid-loha-and-lora\"><strong>ÊãçÁ´ãÂæó/Polaroid</strong></a><strong> </strong>Lora<strong>Ê®°ÂûãÔºö‰∏Ä‰∏™ÂÆûÁé∞ÊãçÁ´ãÂæóÁÖßÁâáË¥®ÊÑüÁöÑLoRAÔºåÁõÆÂâçËøòÂú®Ëøõ‰∏ÄÊ≠•ÊîπËøõ‰∏≠„ÄÇ</strong></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/51484/eva-neon-genesis-evangelion-lora\"><strong>EVA„ÄéÊñ∞‰∏ñÁ∫™„Ç®„É¥„Ç°„É≥„Ç≤„É™„Ç™„É≥„Äè</strong></a>LoRA<strong>Ê®°ÂûãÔºö</strong><span style=\"color:rgb(193, 194, 197)\">ÂèØ‰ª•ÁîüÊàêÁ±ªEVAÈ£éÊ†ºÊ≥õÁî®‰∫∫ÂûãÂÜ≥ÊàòÂÖµÂô®ÁöÑLoRAÔºåÈÄÇÈÖçEVA 00„ÄÅEVA 01„ÄÅEVA 02„ÄÅEVA 08ÂõõÊ¨æÊú∫Âûã„ÄÇ</span></p></li></ul><p>In addition to this LoRA, my works also include:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/33208/filmgirl-film-grain-lora-and-loha\"><strong>FilmGirl Film Style Lora</strong></a> Model: If you want to increase the realism of the characters you draw, this Lora is currently the best choice.</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/43977/moonfilm\"><strong>MoonFilm CheckPoint</strong></a> Model: Possibly one of the top 5 most realistic skin models on Civitai.</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/33194/pallass-catmanul-lora\"><strong>Pallas's Cat LoRA</strong></a> Model: Pallas's cat is the most interesting feline in the world. Please dedicate your GPU power to these adorable cats.</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/52652/instant-photo-polaroid-loha-and-lora\"><strong>Polaroid Lora</strong></a> Model: A LoRA that achieves the texture of Polaroid photos, currently undergoing further improvements.</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/51484/eva-neon-genesis-evangelion-lora\"><strong>EVA \"Neon Genesis Evangelion\" LoRA</strong></a> Model: A LoRA that generates EVA-style general-purpose humanoid combat weapons, compatible with EVA 00, EVA 01, EVA 02, and EVA 08 models.</p></li></ul><p></p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.831991+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "153568",
    "prompt": "Real Dream\n<p>Note: In order for the model to be available in the generator, it needs to be in a good position in the CivitAi auction system every week. I need your help to keep the model in the auction. I always try to keep it in a good position, if you want to donate Buzz directly so that I can bid on it in the auction, that is also an option.</p><p></p><p>On my Patreon, I make beta versions of models in development available for download. Almost every week, a new model is released. Most of them are available for free users; there is a $1 plan that allows you to use the vast majority of models in development and a $5 plan that gives you access to more advanced models.</p><p></p><h3 id=\"real-dream-website-(faster-download-and-all-flux-quantizations)\"><a target=\"_blank\" rel=\"ugc\" href=\"https://sites.google.com/view/realdream-ai/\">Real Dream Website (Faster download and all Flux Quantizations)</a></h3><p></p><h2 id=\"new-patreon\"><a target=\"_blank\" rel=\"ugc\" href=\"https://patreon.com/RealDreamSoftware?utm_medium=unknown&amp;utm_source=join_link&amp;utm_campaign=creatorshare_creator&amp;utm_content=copyLink\">NEW Patreon</a></h2><p></p><p><strong>Available at TensorArt:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/764428935426615833\">https://tensor.art/models/764428935426615833</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.segmind.com/models/sdxl1.0-realdream-pony-v9\">Available as an API service on Segmind</a></p><p></p><p><strong>Stable Diffusion prompt generator AI Tool Bot: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://hf.co/chat/assistant/65c5622d649836a37deb39f6\">https://hf.co/chat/assistant/65c5622d649836a37deb39f6</a></p><p></p><h3 id=\"recomendations:\">Recomendations:</h3><p><br />Default SD 1.5: Use the \"DPM++ SDE Karras\" or \"<span style=\"color:rgb(193, 194, 197)\">DPM++ 2M Karras\"</span> sampler with only 20 steps for better quality. \"DPM++ SDE Karras\" has better quality but is slow.</p><p>Default SD 1.5: Use the CFG scale between 5 and 9. CFG scale at 5 is recommended. Stable Diffusion default value is 7.</p><p>SD 1.5: Resolution between 512 and 768 using \"Hires. Fix\" or other form of upscaling. The 600x600 resolution is the one that has worked best.</p><p><strong>SD 1.5 LCM:</strong> Use the \"Euler a\" or \"<span style=\"color:rgb(193, 194, 197)\">LCM\"</span> sampler with only 8 steps for better quality.</p><p><strong>SD 1.5 LCM AND SDXL Lightning:</strong> Use the CFG scale between 1 and 2. CFG scale at 2 is recommended.</p><p>Pony SDXL: Use the \"Euler a\" or \"DPM++ SDE Karras\" sampler with 20-30 steps for better quality.</p><p>Flux 1 Dev: Use the \"Euler\" sampler, \"simple\" scheduler, distilled cfg 3,5 and 20 steps.</p><p>If you use <strong>\"</strong>Hires. Fix\", use \"Upscale by\" with the value 1.5 with denoising at 0.6.</p><p></p><h3 id=\"tips-for-a-better-prompt:\">Tips for a better prompt:</h3><p></p><p>Use (word) for larger weight and [word] for smaller weight and (word:0.5) to set the weight manually.</p><p></p><h3 id=\"recomendations-for-improvement-on-performance-(stable-diffusion-web-ui):\">Recomendations for improvement on performance (Stable Diffusion Web UI):</h3><p></p><p>Use Token Merging Ratio 0.5 on optimization settings.</p><p>If you have a GPU with low VRAM, use --medvram or --lowvram on command line arguments (webui-user.bat on Windows).</p><p>Enable fp8 in the latest versions of Web UI to save a lot of ram. It can speed up SDXL a lot depending on how much ram and vram you have.</p><p></p><p>If you are having a lot of trouble running SDXL in the Web UI. Try using Fooocus</p><p></p><p>Extensions I recommend: Controlnet, Booru tag autocompletion, CivitAI Browser+,Ultimate SD Upscale,Lobe Theme</p><p></p><p></p><p>Recommended negative prompts to improve human images: amputee, deformed body, long neck, extra fingers, bad body proportions, mutated hands, mutilated, mutation, ugly, fused fingers, malformed limbs, extra heads, disfigured,</p><p></p><p>I would like to thank the following projects that were important to the community and helped improve Stable Diffusion to achieve greater levels of realism:</p><ul><li><p>Realistic Vision</p></li><li><p>RealVisXL</p></li><li><p>epiCRealism</p></li><li><p>QGO</p></li><li><p>ICBINP</p></li><li><p>Analog Madness</p></li><li><p>majicMIX realistic</p></li><li><p>CyberRealistic</p></li><li><p>Juggernaut</p></li><li><p>LCM Lora</p></li><li><p>SDXL Lightning</p></li><li><p>Pony Realism</p></li></ul><p></p><p>Special thanks to other projects from anime and artistic models:</p><ul><li><p>Pony Diffusion</p></li><li><p>AutismMix SDXL</p></li><li><p>T-ponynai3</p></li><li><p>Prefect Pony XL</p><p></p></li></ul><p>The use of Real Dream models in API services, depending on me, is allowed as long as it follows the ethical use rules at the end of the description.</p><p></p><p>This model is capable of generating very realistic images that can confuse people's critical sense, please <strong>do not use it irresponsibly</strong>, harming ordinary people or public figures. Also avoid its use in electoral campaigns, promoting or damaging the image of candidates. Although the field of artificial intelligence is poorly regulated, its improper use can cause legal penalties even in countries with little regulation in the area. Be very careful to not commit crimes in your country and not to promote injustices against innocent people. <strong>I do not authorize the use of this model for Lora training using the face of real people without authorization from the biological owner</strong>. I do not authorize the use of images generated by this model for scam applications and the dissemination of false information. If the image is not included in the cases of unauthorized use but for some reason may cause confusion among the public and may end up being considered true, causing some form of misinformation, place a notice that the image is generated by AI.</p><p></p><p>During the fine-tuning of AI models, I only use synthetic images that do not infringe any copyright, personal image rights, or laws. The models are merges of open models from different sources and may contain diluted data remnants in the neural network. I am not responsible for possible data remnants since they are diluted, and it is not humanly possible to track the existence and origin of this diluted data.</p><p></p><p><span style=\"color:rgb(201, 211, 227)\">I do not allow the upload of any of my models on Tensor Art. I only do not allow it there because the policy of duplicate models on Tensor Art prevents me from uploading again if someone has already done it.</span></p><p></p><p>I have enabled to automatically hide all NSFW posts for several reasons that are not worth listing. I hope you have patience and understand.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832003+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "8030",
    "prompt": "Analog Madness - Realistic model\n<h1 id=\"check-my-exclusive-model-on-mage:-pony-madness-i80q3e6pz\"><strong><span style=\"color:rgb(34, 139, 230)\">Check my exclusive model on Mage</span><span style=\"color:rgb(250, 82, 82)\">: </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/b6ae8b91db7249b8842d79100679c2b1\"><strong><span style=\"color:rgb(64, 192, 87)\">Pony Madness</span></strong></a></h1><h2 id=\"or-try-mage-for-free-and-unlimited!!-less-q2ra2zq0w\"><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/df1d72c555d148418a9fba8fad87d6b6\"><strong><span style=\"color:rgb(250, 176, 5)\">Or try Mage for free and Unlimited!!</span> &lt;---</strong></a></h2><p></p><p></p><p></p><h2 id=\"thanks-for-using-analog-madness-jwj1b8nsf\">Thanks for using Analog Madness,</h2><h2 id=\"if-you-like-my-models-please-buy-me-a-coffee-z8yx1tk00\">if you like my models, please <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/cornmeisternl\">buy me a coffee ‚ù§Ô∏è</a></h2><p></p><h1 id=\"check-out-my-new-model-cartoon-madness-!!!-jcwzwgicq\"><span style=\"color:rgb(64, 192, 87)\">Check out my new model, </span><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/222844\"><span style=\"color:rgb(64, 192, 87)\">Cartoon Madness </span></a><span style=\"color:rgb(64, 192, 87)\">!!!</span></h1><p>MANY thanks to <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Noneyabiz\">Noneyabiz</a> for creating an inpaint version for AMv6!!!!!</p><p></p><p>[v6.0 update 2023-09-12]</p><p>Another update, probably the last SD update.</p><p>have fun with it! :)</p><p></p><p><span style=\"color:rgb(250, 82, 82)\">[v5.0 update]</span></p><p><span style=\"color:rgb(250, 82, 82)\">All images do contain meta data, but Civitai isn't showing them.</span></p><p><span style=\"color:rgb(250, 82, 82)\">Just save the image as a .jpg, and import in automatic1111 (PNG Info)</span></p><p></p><p>Check out my other model! <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/48694/chronos\">Chronos</a><br /></p><p>About Analog Madness</p><p>A very versatile model, the more powerfull prompts you give, the better results.</p><p>Capable of creating both NSFW and SFW images but also great scenery,<br />both in landscape and portrait.</p><p></p><p>Example prompt:</p><p><em>hyper realistic gopro action photo of a beautiful 20yo Dutch girl with small breasts (looking at camera:1.3), windy, wearing old trashy worn torn out clothes, in a themepark, analog style, masterpiece, exposed breasts</em></p><p>negative prompt: <br /><em>3d max, grotesque, desaturated</em></p><p><br />tnx to Hoblin for this negative prompt!</p><p>Euler a, 25 to 35 steps, CFG7</p><p></p><p><strong>Disclaimer:</strong><br /><strong>All characters on my images are 18+. No likeness to real people intended. No pixels were hurt during the production of this images.</strong></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832033+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "22922",
    "prompt": "Lyriel\n<p><strong><span style=\"color:rgb(250, 82, 82)\">The creator of this resource has been found to be manipulating their reviews and the reviews of others.</span></strong><span style=\"color:rgb(250, 82, 82)\"><br /></span><strong><span style=\"color:rgb(250, 82, 82)\">As such they have been banned from the platform and their </span><s><span style=\"color:rgb(250, 82, 82)\">resource delisted </span></s></strong><br /><strong><span style=\"color:rgb(250, 82, 82)\">By popular demand, we've brought back the resource availability to download.</span><s><span style=\"color:rgb(250, 82, 82)\"> but locked discussion and further reviews from being posted.</span></s><span style=\"color:rgb(250, 82, 82)\"> </span></strong><br /><strong><u><span style=\"color:rgb(250, 82, 82)\">We've opened the images back up by popular demand, as a lot of users want to see the metadata for images. However, to ensure this resource does not receive an unfair advantage from its false reviews, we've excluded all reviews and comments on the resource. This ensures it has a fresh start. </span></u></strong><br /><br />Hello, the model was created as an artistic style, the model can do almost anything, the main thing is to follow the promt, hands and eyes looks good for the most cases</p><p>Model Information:</p><p>This model is generally designed for portraits and full-length anime style photos. Fantastic landscapes are quite decent. And it doesn't require kilometer-long queries to get a high-quality result.</p><p>Recommend: DPM++2M Karras, Clip skip 2 Sampler, Steps: 25-35+</p><p></p><p>This model would not have come out without XpucT's help, which made <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4823/deliberate\"><strong>Deliberate</strong></a></p><p>If you have the desire and means to support future models, here you go:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://wallet.advcash.com/ru/login\">Advanced Cash</a> - U 1281 8592 6885 , E 8642 3924 9315 , R 1339 7462 2915</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://payeer.com/ru/\">PEYEER</a> - P1075963156</p><p>I hope you like it, thanks for the feedback</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832046+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "94809",
    "prompt": "RealCartoon3D\n<h3 id=\"checkout-my-mage.space-exclusive-model:-realcartoon-mage-pscvtc8d9\"><em>Checkout my Mage.Space Exclusive model: </em><a rel=\"ugc\" href=\"https://www.mage.space/play/370647b21770751ed173c9a34761ddd1\"><em><span style=\"color:#fa5252\">RealCartoon - Mage</span></em></a></h3><p><strong><em>You can also run this model<span style=\"color:rgb(219, 222, 225)\"> on </span></em></strong><a target=\"_blank\" rel=\"ugc\" href=\"http://sinkin.ai\"><strong><em><span style=\"color:rgb(219, 222, 225)\">sinkin.ai</span></em></strong></a><strong><em><span style=\"color:rgb(219, 222, 225)\"> and </span></em></strong><a target=\"_blank\" rel=\"ugc\" href=\"http://mage.space\"><strong><em><span style=\"color:rgb(219, 222, 225)\">mage.space</span></em></strong></a><strong><em><span style=\"color:rgb(219, 222, 225)\">:</span></em></strong></p><ol><li><p><a target=\"_blank\" rel=\"ugc\" href=\"http://www.Mage.space\"><strong><em>www.Mage.space</em></strong></a><strong><em> really helps:</em></strong></p><ol><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/d6ec9d76c61c51e88c8d7ebedfed4870\">V11 - https://www.mage.space/play/d6ec9d76c61c51e88c8d7ebedfed4870</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/0d8c0275c138d22f316d6fe75ee17040\">V14 - https://www.mage.space/play/0d8c0275c138d22f316d6fe75ee17040</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/e4b5b5108f3d42d501c6a25b95fdb784\">V15 - https://www.mage.space/play/e4b5b5108f3d42d501c6a25b95fdb784</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/3179aa44ab27ae1b37345ebdd6f8b8de\">V17 - https://www.mage.space/play/3179aa44ab27ae1b37345ebdd6f8b8de</a></p></li></ol></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.shakker.ai/userpage/76e974968502489794d7d7938e6dda54/publish\">https://www.shakker.ai/userpage/76e974968502489794d7d7938e6dda54/publish</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/gLv9zeq\"><strong><em>https://sinkin.ai/m/gLv9zeq</em></strong></a></p></li></ol><p><strong><em>Want to send some support? </em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/7whitefire7\"><strong><em>(send some at Ko-fi)</em></strong></a></p><h2 id=\"scroll-down-for-some-prompt-recommendations-x4toem79f\"><strong>Scroll down for some prompt recommendations</strong></h2><p><strong>If you want to add some age to a subject, I tested Age Slider and it did well: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/128417/age-slider\"><strong>Age Slider</strong></a></p><p><strong>Also recommend </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808?modelVersionId=9208\"><strong><span style=\"color:rgb(34, 139, 230)\">easynegative</span></strong></a><strong><span style=\"color:rgb(34, 139, 230)\">, </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16993?modelVersionId=20068\"><strong><span style=\"color:rgb(34, 139, 230)\">badhandv4</span></strong></a><span style=\"color:rgb(64, 192, 87)\"> </span><strong>in the negative prompt</strong></p><h2 id=\"the-history:-js1nkwfyt\"><em>The History:</em></h2><p><em>RealCartoon3D was my first model uploaded. I was still learning this stuff, but wanted to create a checkpoint to do what I wanted it to do when prompted with a look I enjoyed. Some goals for the checkpoint (updated as time went on):</em></p><ul><li><p><em>1. Variety in humans (I.E. African, European, Asian, etc). I did not want it just producing the same look I saw everywhere.</em></p></li><li><p><em>2. Produce a cartoon look with a realistic touch</em></p></li><li><p><em>3. Do well with LoRAs. (because this is where the customization really happens)</em></p></li></ul><p><em>The mission was/is to attempt to get this checkpoint to a point where it will do well on first attempt or second attempt with prompts (my computer is just a gaming laptop that gets really hot when doing things like this lol...already kill the battery once).</em></p><p><em>I have learned a lot in the process and even started other checkpoints (RealCartoon-Anime, Realistic, Pixar, and 2.5D) to give a more focused variation. This checkpoint is the basis for all of them and gets a merge in from time to time to them. This one though will always be my main one though....even though that PIXAR one has a really nice look :P</em></p><p><em>I hope you all enjoy it! </em><strong><em>Please review and share your images</em></strong><em>. I very much appreciate the support with the downloads and feedback </em><strong><em>(THANK YOU ALL)</em></strong><em>. Never thought it would get this much attention.</em></p><p></p><h2 id=\"the-creation-process:-ey9dsuk2v\">The Creation Process:</h2><p><br />The starting checkpoints for merging were a couple of top ones during May of 2023 (<strong>The checkpoints do/did not have restrictions on checkpoint mergers</strong>). I also baked in the VAE <strong><em>(</em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors\"><strong><em>vae-ft-mse-840000-ema-pruned</em></strong></a><strong><em>)</em></strong>. I tried ClearVAE (which does some nice results, but it would mess up from time to time (which may have been my computer). I did not want this issue to fall to anyone that downloaded this model, so I did not use that VAE. Sadly, I did not have the resources to train from scratch; but found that many people would just train off these top checkpoints anyway. As time moved on, I would try to find checkpoints that had a look or cool backdrop (or odd result sometimes) that would help the overall look <strong>(again avoiding those that had restrictions with merging, as I do not want to mess up anyone's work or get lost in licensing)</strong>. One issue that would always seem to show up was hands being messed up. They just did not come out right (as many checkpoints seemed to have a problem with in SD 1.5); but as I kept moving forward in merging, the hands seemed to get better. I would then look for LoRas to influence the look and style. These LoRas were not to take over the checkpoint but help mold it per say. As I wanted the user to have control of this. Since that is the point of LoRas.</p><p>Overall, this checkpoint moved up in versions quickly as it got figured out. Eventually it started to really go where I wanted with Version 3.0, 3.1, and then of course Version 4 (slowing down a bit in the updates as well). I still like the older versions; and these older versions are what influenced the other RealCartoon checkpoints. As the look for this primary one got figured out.</p><p></p><h2 id=\"prompt-settings:-a95zr9a0p\">Prompt Settings:</h2><p>(These settings are for <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui\">A1111 )</a>:</p><p>The below image is the top settings I recommend. I do not use a VAE normally as</p><p><strong><em>(</em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors\"><strong><em>vae-ft-mse-840000-ema-pruned</em></strong></a><strong><em>) </em></strong>is baked in.</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/49089e68-ffb2-44fc-a415-fb587d13f013/width=525/49089e68-ffb2-44fc-a415-fb587d13f013.jpeg\" /></p><p>Below are the normal settings I do run when generating most of my images.</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/706895f3-8900-4f92-9c29-88d1d1b524fd/width=525/706895f3-8900-4f92-9c29-88d1d1b524fd.jpeg\" /></p><p>Some variation of course happens depending on the desired outcome (I.E. Landscape). I also like to make <strong><em>portrait 512 by 904</em></strong> as well. <em>I only run batches when I am checking checkpoints or looking for that perfect image. This is normally set to 1</em></p><p></p><p>Sampling method I primarily use is Euler a, but <span style=\"color:rgb(64, 192, 87)\">DPM++ SDE Karra</span><span style=\"color:rgb(193, 194, 197)\"> and </span><span style=\"color:rgb(64, 192, 87)\">DPM++ 2M Karras</span><span style=\"color:rgb(193, 194, 197)\"> do well as well.</span></p><p><span style=\"color:rgb(193, 194, 197)\">A newer version of the Euler sampler (Advanced Euler by licyk) - </span><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/licyk/advanced_euler_sampler_extension\"><span style=\"color:rgb(34, 139, 230)\">https://github.com/licyk/advanced_euler_sampler_extension</span></a></p><ul><li><p>This one does better on hands</p></li><li><p>Normally produces images faster</p></li></ul><p></p><p>Upscaler is either <span style=\"color:rgb(64, 192, 87)\">R-ESRGAN 4x+</span> or <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/116225/4x-ultrasharp\"><span style=\"color:rgb(34, 139, 230)\">4k-UltraSharp</span></a> for most of my images.</p><p><strong><em><span style=\"color:rgb(250, 82, 82)\">The Upscale settings will vary depending on your computer.</span></em></strong></p><p></p><p>Would <em>run </em><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\"><em>ADetailer</em></a><em> if subject is in the distance as SD1.5 can sometimes fail at faces with distance people. Be careful if you have blurred subjects in backgrounds; as this can start \"enhancing them\" and thus mess with the overall look.</em></p><p></p><p><strong>If you are having problems running A1111 you can change the \"webui-user.bat\" settings to help (by right clicking and opening in notepad):</strong></p><ul><li><p>set COMMANDLINE_ARGS= --xformers</p></li></ul><p><strong>If you do not have xformers or cannot install it, put the following instead:</strong></p><ul><li><p>set COMMANDLINE_ARGS= --disable-model-loading-ram-optimization --opt-sdp-no-mem-attention</p></li></ul><p><strong><em>To install xformers: </em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://aipromptshome.com/fix-no-module-xformers-stable-diffusion-automatic-1111/\"><strong><em>how to install xformers</em></strong></a></p><p></p><h2 id=\"prompt-recommendations:-ely891uk0\">Prompt Recommendations:</h2><p>When it comes to prompts that is really up to you. Here is some advice:</p><ol><li><p>Please be careful on the strength you add to LoRas as this can affect the overall look with the checkpoint. Stronger does not always mean better. I normally run 0.4 - 1 strengths depending on the LoRa.</p></li><li><p>What is first in your prompt has higher priority.</p></li><li><p>Having parathesis increases a priority, but having everything in them is almost as good as typing without them.</p></li><li><p>Subtle changes in a prompt (to include punctuation) can change the image</p></li><li><p>The seed helps in producing similar images with similar software and settings. It does not guarantee the same image as even a difference in software (I.E. ComfyUI) or hardware can affect it.</p></li><li><p>If you want a more cartoon look (at least with this checkpoint) use the following near the front of the prompt: Anime, Cartoon, painted, or comic. This does not guarantee a look depending on the version; but it will lean more that way. This also works for Realistic looks (Realistic, real, etc).</p></li><li><p>If you want Safe for work or not nudity to show up then make sure you put the following in your negative prompt: nude, nudity, naked, NSFW, nipples. Of course if you have this in your actual prompt then it will more then likely do it.</p></li><li><p>The following is what I normally run in a negative prompt (you can click on easynagative or badhandv4 to get the files):</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808?modelVersionId=9208\"><span style=\"color:rgb(64, 192, 87)\">easynegative</span></a><span style=\"color:rgb(64, 192, 87)\">,(</span><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16993?modelVersionId=20068\"><span style=\"color:rgb(64, 192, 87)\">badhandv4</span></a><span style=\"color:rgb(64, 192, 87)\">),(bad quality:1.3),(worst quality:1.3),watermark,(blurry),5-funny-looking-fingers</span></p><p>NOTE: Badhandv4 is an embedding. So goes in the embedding folder of A1111</p><p></p></li></ol><h2 id=\"why-so-many-versions:-770m18pja\">Why So Many Versions:</h2><p>Because I wanted to share all the results that I felt reached a desired outcome. Allowed me to have fun, and I saw that many enjoyed them. Which motivated me to keep trying. Again, thank you.</p><p>__________________________________________________________________________________________________</p><h3 id=\"license-and-use-hdl5ocj0o\">License &amp; Use</h3><p>This model is open access and available to all, with a¬†CreativeML OpenRAIL-M¬†license further specifying rights and usage.</p><ul><li><p>1. You can't use the model to deliberately produce nor share illegal or harmful outputs or content.</p></li><li><p>2. The authors claims no rights on the outputs you generate, you are free to use them and are accountable for their use which must not go against the provisions set in the license.</p></li><li><p>3. You may re-distribute the weights. If you do, please be aware you have to include the same use restrictions as the ones in the license and share a copy of the modified CreativeML OpenRAIL-M to all your users (please read the license entirely and carefully).</p><p></p><p>Please read the full license here¬†Stable Diffusion</p></li></ul><h3 id=\"use-restrictions:-2j286dzru\">Use Restrictions:</h3><p>You agree not to use the Model or Derivatives of the Model:</p><p>- In any way that violates any applicable national, federal, state, local or international law or regulation</p><p>- For the purpose of exploiting, harming or attempting to exploit or harm minors in any way</p><p>- To generate or disseminate verifiably false information and/or content with the purpose of harming others</p><p>- To generate or disseminate personal identifiable information that can be used to harm an individual</p><p>- To defame, disparage or otherwise harass others</p><p>- For fully automated decision making that adversely impacts an individual‚Äôs legal rights or otherwise creates or modifies a binding, enforceable obligation</p><p>- For any use intended to or which has the effect of discriminating against or harming individuals or groups based on online or offline social behavior or known or predicted personal or personality characteristics</p><p>- To exploit any of the vulnerabilities of a specific group of persons based on their age, social, physical or mental characteristics, in order to materially distort the behavior of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm</p><p>- For any use intended to or which has the effect of discriminating against individuals or groups based on legally protected characteristics or categories</p><p>- To provide medical advice and medical results interpretation</p><p>- To generate or disseminate information for the purpose to be used for administration of justice, law enforcement, immigration or asylum processes, such as predicting an individual will commit fraud/crime commitment (e.g. by text profiling, drawing causal relationships between assertions made in documents, indiscriminate and arbitrarily-targeted use).</p><h3 id=\"terms-of-use:-jibakfj6v\">Terms of use:</h3><p>- You are solely responsible for any legal liability resulting from unethical use of this model(s)</p><p>- If you use any of these models for merging, please state what steps you took to do so and clearly indicate where modifications have been made.</p><h3 id=\"note:-jn5whtc1d\">Note:</h3><p>If you see any conflicts or corrections to be made, please let me know.</p><h2 id=\"-113pu8dd9\"></h2>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832068+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "888231",
    "prompt": "Vixon's Pony Styles - gothic neon\n<p>Please avoid using too many LoRA's as that can mess up your image!</p><p>remember to leave hearts and reviews &lt;3</p><p>~ Vixon's recipe for potato pancakes ~</p><p>Ingredients</p><p>1 medium onion, peeled</p><p>4 large Idaho or russet potatoes, peeled</p><p>2 large eggs</p><p>2 Tbsp. all-purpose flour</p><p>Kosher salt and black pepper</p><p>6 Tbsp. vegetable oil</p><p>6 Tbsp. unsalted butter</p><p>Applesauce and/or sour cream, for serving</p><p>Instructions</p><p>Preheat oven to 200¬∞F. Place 2 nonstick baking sheets in oven.</p><p>Using box grater or food processor fitted with grating disc, coarsely grate onion and place in colander set in sink. Coarsely grate potatoes, add to colander, and set aside to drain.</p><p>Lightly beat eggs in a large bowl, then whisk in flour.</p><p>Press potatoes and onion to extract as much liquid as possible, then add to egg/flour mixture. Season with salt and freshly ground black pepper. Using wooden spoon or hands, mix well, but do not overwork.</p><p>Heat 1 Tbsp. oil and 1 Tbsp. butter in a heavy-bottomed large skillet over medium-high heat, until hot but not smoking. Drop 4 scant ¬º-cup portions of potato mixture into pan and flatten with spatula to form four 3-inch pancakes.</p><p>Fry until bottoms are golden-brown, 4 to 5 minutes, then turn over and fry until golden-brown and crisp, an additional 4 to 5 minutes. Transfer to paper towels to drain; season immediately with salt and pepper. Keep warm on baking sheets in oven while making remaining pancakes.</p><p>Using paper towels, carefully wipe out pan. Add 1 Tbsp. oil and 1 Tbsp. butter and fry 4 more pancakes. Repeat with remaining batter, wiping out pan and adding 1 Tbsp. oil and 1 Tbsp. butter before each batch.</p><p>Serve pancakes hot with applesauce and/or sour cream.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832073+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "132632",
    "prompt": "epiCPhotoGasm\n<h2 id=\"heading-2443\">Welcome to epiCPhotoGasm</h2><p>This Model is highly tuned for Photorealism with the tiniest amount of exessive prompting needed to shine.<br /><strong><span style=\"color:rgb(230, 73, 128)\">All Showcase images are generated without Negatives</span></strong> (V1) to show what is possible on the bare prompt.</p><h3 id=\"heading-2444\">Whats special?</h3><p>The model has highly knowledge of what a photo is, so if u promt u can avoid using photo. If the prompt tends to be fantasy like the model will turn away from photo and u have to tweak by prompting and/or negatives.</p><p><em>The model can do various ethnicities well, so try them out.</em><br /><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/84911669-d40e-42bf-8138-c3cd268e8252/width=525/84911669-d40e-42bf-8138-c3cd268e8252.jpeg\" /></p><p><em>Age is also well trained and known by the model, so try them out too.</em><br /><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0f33117e-6b4f-4a70-9ce4-f4fd0f9ff096/width=525/0f33117e-6b4f-4a70-9ce4-f4fd0f9ff096.jpeg\" /><br /><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/53da0005-d7c0-4868-bb15-d671d69b5bc3/width=525/53da0005-d7c0-4868-bb15-d671d69b5bc3.jpeg\" /></p><h3 id=\"heading-2445\">How to use</h3><ul><li><p><strong><span style=\"color:rgb(64, 192, 87)\">use simple prompts</span></strong> without \"fake\" enhancers like \"masterpiece, photorealistic, 4k, 8k, super realistic, realism\" etc.</p></li><li><p><strong><span style=\"color:rgb(250, 82, 82)\">don't use a ton of negative embeddings</span></strong>, focus on few tokens or single embeddings</p></li><li><p>you can still use atmospheric enhances like \"cinematic, dark, moody light\" etc.</p></li><li><p>start sampling at 20 Steps</p></li><li><p><span style=\"color:rgb(193, 194, 197)\">no extra noise-offset needed</span></p></li></ul><h3 id=\"heading-2446\">Additional Ressources</h3><p>Style Negatives: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/132719?modelVersionId=145996\">colorful Photo</a> | <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/132719?modelVersionId=145994\">soft Photo</a></p><h3 id=\"heading-87\">Useful Extensions</h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\">!After Detailer</a> | <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Mikubill/sd-webui-controlnet\">ControlNet</a> | <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/ArtVentureX/sd-webui-agent-scheduler\">Agent Scheduler</a> | <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Coyote-A/ultimate-upscale-for-automatic1111\">Ultimate SD Upscale</a></p><p></p><p>‚≠ê Feel free to leave Reviews and Samples - and always have fun creating ‚ù§</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832081+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "11866",
    "prompt": "MeinaPastel\n<p><strong>MeinaPastel </strong>aims to make illustrations with a <strong>2d feeling</strong> to like <strong>pastel</strong> <strong>or colorful</strong> images!<br /><span style=\"color:rgb(193, 194, 197)\">I have a </span><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/F6yeQtEQ98\">discord</a><span style=\"color:rgb(193, 194, 197)\"> where you can </span><strong>share images</strong><span style=\"color:rgb(193, 194, 197)\">, </span><strong>discuss prompt</strong><span style=\"color:rgb(193, 194, 197)\"> and </span><strong>ask for help</strong><span style=\"color:rgb(193, 194, 197)\">. </span><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/F6yeQtEQ98\">https://discord.gg/meinaverse</a><br /><span style=\"color:rgb(193, 194, 197)\">ÊàëÊúâ‰∏™ÂèØ‰ª•ËÆ©‰Ω†ÂàÜ‰∫´ÂõæÁâáÂíåÂèÇ‰∏éËÆ®ËÆ∫‰∏éËØ¢ÈóÆÈóÆÈ¢òÁöÑdiscordÁæ§„ÄÇ</span><br /><br /><span style=\"color:rgb(193, 194, 197)\">I also have a </span><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/meina\"><strong>ko-fi</strong></a><span style=\"color:rgb(193, 194, 197)\"> and </span><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/MeinaMix\"><strong>Patreon</strong></a><span style=\"color:rgb(193, 194, 197)\"> page where you can support me or buy me a coffee &lt;3 , </span><strong>it will be very much appreciated: </strong><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/meina\"><strong>https://ko-fi.com/meina</strong></a><strong> and </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/MeinaMix\"><strong>https://www.patreon.com/MeinaMix</strong></a><br /><br /><strong>MeinaPastel is officially hosted for online generation in:</strong><br />- <a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/373589820c033becad9b826a2ed88f71\">Mage.space</a> ( with animate feature )<br />-<strong> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.seaart.ai/models/detail/a45181396ce22f9bf2efec5661014fc5\">SeaArt</a><br />---------------------------------------------<br /><strong>Recommendations:</strong><br /><strong>Sampler:</strong> DPM++ 2M Karras/SDE Karras/euler a: 20 to 40 steps.<br /><strong>Resolutions:</strong> 512x768, 512x1024 for Portrait!<br /><strong>Resolutions: </strong>768x512, 1024x512, 1536x512 for Landscape!<br /><strong>CFG Scale:</strong> 4 to 11.<br /><strong>Hires.fix:</strong> R-ESRGAN 4x+Anime6b, with 15 steps at 0.4 denoising.<br /><strong>V6(Pastel) Hires.fix:</strong> Latent (Nearest-exact) with 10 to 15 steps at 0.55 denoising.<br /><strong>Clip Skip:</strong> 2.<br /><strong>Negatives:</strong> '(worst quality, low quality:1.4), monochrome, zombie, (interlocked fingers)'<br />---------------------------------------------</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832086+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "795765",
    "prompt": "Illustrious-XL\n<p><strong>Illustrious XL: A Powerful Model for Illustration</strong></p><p>Illustrious XL is an advanced Stable Diffusion XL (SD XL)-based model, developed by <a target=\"_blank\" rel=\"ugc\" href=\"https://onomaai.com/\">OnomaAI</a> Research, optimized specifically for illustration and animation tasks. It is built upon the <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/KBlueLeaf/kohaku-xl-beta5\">Kohaku XL-Beta - Revision 5</a> checkpoint, leveraging its robust foundation to deliver high-quality generative capabilities.</p><p>The full technical specifications for Illustrious XL are available in <a target=\"_blank\" rel=\"ugc\" href=\"https://arxiv.org/abs/2409.19946\">https://arxiv.org/abs/2409.19946</a>. For detailed information and updates, please refer to our <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/OnomaAIResearch/Illustrious-xl-early-release-v0/\">official release page</a>.</p><p>As an open-source project, Illustrious XL is designed to drive innovation and support the open-source community. We encourage collaboration, knowledge sharing, and transparency around its use, aiming to foster creative advancements in technology and content creation.</p><p>While the model is open for all to use, we urge users to uphold the spirit of openness. Using the model for closed-source or proprietary monetization purposes contradicts the ethos of this project.</p><p></p><p>Illustrious XL has been developed with resources provided by OnomaAI, and we hope that the community respects this by promoting open collaboration.</p><p></p><p>//09-26 - Fixed main thumbnail being wrongly uploaded</p><p></p><p>// The sentences were kindly cleaned up by gpt4o.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832090+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "8217",
    "prompt": "„ÄêCharacter / Art Style„ÄëFashion Girl\n<h3 id=\"heading-22\">2024/2/22 update</h3><p><span style=\"color:rgb(193, 194, 197)\">Upload Lycoris version. Remove SDXL version temporarily from the archives, and a new page will be created for the SDXL version to facilitate management.</span></p><h3 id=\"heading-99\">2023/7/30 experimental update</h3><p>Upload sdxl version trained using <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0\"><strong>sdxl v1.0 base model</strong></a>. <strong>Running SDXL on webui requires at least 8GB of CUDA memory.</strong> <strong>Currently, the generating quality of this version is lower than 6.0 anime version.</strong></p><h3 id=\"heading-22\">2023/7/30 update</h3><p>Update dataset. <strong>Remove trigger tag, so there is no need to input trigger tag when generating images using the latest version.</strong> Retrain the model using new craft.</p><h3 id=\"heading-971\">2023/6/4 update</h3><p>Clean up the old versions and retain the versions with good generated results.</p><h3 id=\"heading-972\">2023/5/11 update</h3><p>Update dataset. <strong>Adjust trigger tag to 'fashi-girl'.</strong></p><h3 id=\"heading-973\"><strong><u>BTW, make sure set this option in 'Stable Diffusion' settings to 'CPU' to successfully regenerate the preview images with the same seed.</u></strong></h3><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c1e77cab-093f-44e5-803b-1afcf2d42df4/width=525/c1e77cab-093f-44e5-803b-1afcf2d42df4.jpeg\" /></p><h3 id=\"heading-974\">2023/4/20 update</h3><p>Update dataset. Slightly optimize body shape. Try to make the face more alluring. <strong>v5.4 version is conventional LoRA model.</strong></p><h3 id=\"heading-975\">2023/4/12 update</h3><p><strong>Upload Lycoris version (v5.3).</strong> Remove hyper-realistic images in dataset that may cause bad results. Try to make face more natural and beautiful.</p><h3 id=\"heading-976\">2023/3/29 update</h3><p>Due to the instability of Lycoris caused by sensitivity to learning rate settings, <strong>the updated model (5.2 version) is still conventional LoRA model. </strong>Use images published by some users as dataset to train the model.<strong> </strong>Fix the compatibility problem of non-NAI-based checkpoints. Now arbitrary anime model with NAI's VAE or kl-f8-anime2 VAE can also generate good results using this LoRA, theoretically. This version is a bit overfitted that will be fixed next time.</p><h3 id=\"heading-977\">2023/3/24 Experimental Update</h3><p>New model is trained using <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/KohakuBlueleaf/LyCORIS\"><strong>Lycoris</strong></a> method <strong>(all versions before 5.1 version are conventional LoRA model)</strong>, <strong>pls install this </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/KohakuBlueleaf/a1111-sd-webui-locon\"><strong>extension</strong></a><strong> to use this new model in webui.</strong> <strong>Adjust trigger tag to 'fashi-g'</strong>. If some problem occur during generating pls use old version.</p><h3 id=\"heading-978\">2023/3/8 update</h3><p>Update dataset and model. Decide to upload 5-epoch version whose color saturation is a bit better than higher-epoch version after careful consideration. Adjust rank to 128 to keep perfect face. The trigger tag is unchanged. <strong>The preview images are generated using latest version of </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9139/yesmix\"><strong>YesMix</strong></a><strong> and </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\"><strong>EasyNegative</strong></a><strong> embedding.</strong></p><h3 id=\"heading-979\">2023/3/3 update</h3><p>Reduce loss to ~0.11 using Lion optimizer. <strong>Btw, if you use Hires. fix, 0.55~0.6 weights of Denoising should be enough, otherwise the face may be slightly deformed. Btw, the preview images are generated using latest version of </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9139/yesmix\"><strong>YesMix</strong></a><strong> and </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\"><strong>EasyNegative</strong></a><strong> embedding.</strong></p><h3 id=\"heading-980\">2023/2/28 update</h3><p>Update dataset and model. Add trigger tag <strong>'fashi-girl'</strong> to improve generating probability. Adjust rank to 32 to balance file size and quality.</p><h3 id=\"heading-981\">2023/2/24 update</h3><p>Prune tags to make the description more accurate.</p><h3 id=\"heading-982\">2023/2/23 update</h3><p>Merge previous LORA model that is easy to generate nice images to slightly improve color saturation and optimize face. Adjust rank to 32 to balance file size and quality. <strong>The preview images of new version are generated using latest version of </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9139/yesmix\"><strong>YesMix</strong></a><strong>.</strong></p><h3 id=\"heading-983\">2023/2/21 update</h3><p>Adjust dataset to fix bad philtrum. Reduce training epochs to fix deformed limbs. <strong>The preview images of new version are generated using latest version of </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9139/yesmix\"><strong>YesMix</strong></a><strong>.</strong></p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b41cac39-371a-46bc-de1e-0d308b29b500/width=525\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/37b4b98a-f3d1-401a-d470-50a602297300/width=525\" /></p><h3 id=\"heading-984\">2023/2/20 update</h3><p>Update and balance dataset to remain the images of mature female that fit personal aesthetics. New version of LORA model is trained using Lion optimizer discovered by Google Brain that is purportedly better than Adam(w). <strong>The preview images of new version are generated using latest version of </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9139/yesmix\"><strong>YesMix</strong></a><strong>.</strong></p><h3 id=\"heading-985\">2023/2/18 update</h3><p>Update dataset and model. <strong>The preview images of new version are generated using latest version of </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9139/yesmix\"><strong>YesMix</strong></a><strong>.</strong></p><h3 id=\"heading-986\">2023/2/16 update</h3><p>Clean the dataset to remove the images of unattractive characters. Use offset noise to improve ability to generate lighter/darker images. <strong>The preview images are generated using latest version of </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9139/yesmix\"><strong>YesMix</strong></a><strong>.</strong></p><h3 id=\"heading-987\">2023/2/14 update</h3><p>Dataset is updated, so model is updated. Reduce the model file size to 1MB. The generating quality is unchanged.</p><h1 id=\"heading-988\">Introduction</h1><p>This is an experimental LORA model trained with about 100 images of fashionable girls that fit personal aesthetics. Therefore, this model is named as \"Fashion Girl\". <strong>Due to the small-scale dataset that are composed of realistic/photorealistic images, some output images will remain anime style.</strong> The 784mb VAEs (NAI, Orangemix, Anything, Counterfeit) are recommended. 0.6~0.8 weights should be enough. This model will be continuously updated as the dataset is updated.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832101+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "8124",
    "prompt": "A-Zovya RPG Artist Tools\n<p><em>Update April 28th Added version V4 pruned model.</em><br /><br />A model with professional RPG industry artists in mind. Those working in video games, board and tabletop games as well as concept art and book covers should get good use from this model. The new version, V4, packs in more training for creatures and RPG subjects including a more illustrative style.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/34192/ultra-sharp-high-contrast-tutorial-vaeandupscaler\"><strong>Detailed tutorial on how I get the results in the preview images.</strong></a><br />Check here if you're having trouble getting the same results. Initial generation size and VAE usage is key.</p><p></p><p>You can prompt any style you need with these models, but the default aesthetic is listed for each of the models in this handy list.</p><p><br /><u>Different models available, check the blue tabs above the images up top:</u></p><p><u>Stable Diffusion 1.5 (512) versions:</u></p><ul><li><p><strong><u>V4 inpaint</u></strong> <em>Inpainting version of V4 that's good for outpainting.</em></p></li><li><p><strong><u>V4+VAE</u></strong> <em>Same as V4 but with the added convenience of having a preset VAE baked in so you don't need to select that each time. Saves on vram usage and possible NaN errors. Speeds up workflow if that's the VAE you're going to use anyway.</em></p></li><li><p><strong><u>V4</u></strong> <em>New aesthetic added to make it a bit more illustrative. More training for better coherency for all things RPG.</em></p></li><li><p><strong><u>V3+VAE</u></strong> <em>Same as V3 but with the added convenience of having a preset VAE baked in so you don't need to select that each time. Saves on vram usage and possible NaN errors. Speeds up workflow if that's the VAE you're going to use anyway.</em></p></li><li><p><strong><u>V3</u></strong> <em>Stronger painterly style. High contrast and sharpness. Even more RPG knowledge.</em></p></li><li><p><strong><u>V3 inpaint</u></strong> <em>Inpainting version of V3 that's good for outpainting.</em></p></li><li><p><strong><u>V2</u></strong> <em>Stronger painterly style. High contrast and sharpness. More RPG knowledge.</em></p></li><li><p><strong><u>V2 offset</u></strong> <em>Noise Offset added making more contrast and bringing the model back to photoreal.</em></p></li><li><p><strong><u>V2 Art</u></strong> <em>Trained model. Very artsy. Strongest painterly style. Less details and bigger brush strokes to mimic digital painting style pre-AI.</em></p></li><li><p><strong><u>V2 inpaint</u></strong> <em>Inpainting version of V2 that's good for outpainting.</em></p></li><li><p><strong><u>V1</u></strong> <em>Smoother renders with least painterly effect.</em></p></li><li><p><strong><u>V1 inpaint</u></strong> <em>Inpainting version of V1 that's good for outpainting.</em></p></li></ul><p><br /><u>Stable Diffusion 2.1 (768) versions:</u></p><ul><li><p><strong><u>SD 2.1 768 V1</u></strong> <em>Strong painterly style, very coherent with hands and objects. Higher native resolution and detail. Not good for nudity.</em></p></li></ul><p></p><p><em>Not as effective, but here's the LoRA if you like to use that instead:</em><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8951/a-to-zovya-rpg-artists-tools-lora\"><strong>A to Zovya RPG Artist's Tools LoRA</strong></a><br /><br /><span style=\"color:rgb(64, 192, 87)\">Do you have requests? I've been putting in many more hours lately with this. That's my problem, not yours. But if you'd like to tip me, buy me a beer. Beer encourages me to ignore work and make AI models instead. Tip and make a request. I'll give it a shot if I can.</span> <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/zovya\">Here at Ko-Fi</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832110+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "25995",
    "prompt": "blindbox/Â§ßÊ¶ÇÊòØÁõ≤Áõí\n<h1>BlindBox Artstyle</h1><p>Êõ¥Êñ∞‰∫ÜV3ÁâàÊú¨ÔºåË∞ÉÊï¥‰∫ÜÁúºÁùõÔºå‰øóËØùËØ¥ÁúºÁùõÊòØÂøÉÁÅµÁöÑÁ™óÂè£„ÄÇ‰ΩÜÊòØÁõÆÂâçËøòÊòØÂÆûÈ™åÊÄßË¥®ÁöÑÔºå‰ªéÁ®≥ÂÆöÊÄß‰∏äËøòÊòØÊé®Ëçêv1_mixÁâàÊú¨„ÄÇ</p><p>Â¶ÇÊûú‰Ω†ÂñúÊ¨¢ÊàëÁöÑ‰ΩúÂìÅÔºåÂèØ‰ª•ÁÇπ‰∏™LikeÔºåÊàñËÄÖËØ∑Êàë <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/samecorners\">ÂñùÊùØÂíñÂï°</a>„ÄÇ</p><p>Áà±Êù•Ëá™Áì∑Âô®„ÄÇ</p><p>[Êú∫ÁøªËã±ËØ≠]</p><p>Updated v3 version, adjusted the eyes, as the saying goes, the eyes are the windows to the soul. But it is still experimental, from the stability or recommended v1_mix version.</p><p>If you like my work, you can click \"Like\" or <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/samecorners\">buy me a coffee</a>.</p><p>Love from China.</p><p></p><h2>blindbox_v1_mix üëç</h2><ul><li><p>Add the prompt <strong>full body,chibi,</strong></p></li><li><p>weigh : 1</p></li><li><p>checkpoint : <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7371/rev-animated\">RevAnimated</a> or other you like</p></li><li><p></p></li></ul><p>mix PVC material, is good.</p><p>üññ<strong>I would appreciate it if you could share with me the results of your use.</strong></p><p></p><h2>blindbox v1</h2><ul><li><p>Add the prompt <strong>full body,chibi,</strong></p></li><li><p>Recommeneded weigh : 1</p></li><li><p>checkpoint : <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7371/rev-animated\">RevAnimated</a></p></li><li><p></p></li></ul><p>Other checkpoint may produce fantastic results, try it yourself.</p><p>Can be used with other LoRA.</p><p></p><p></p><h2>blindbox v2</h2><ul><li><p>Reduces the probability of a big head (maybe)</p></li><li><p>Lowered network_dim value, smaller file size</p></li><li><p>More Chibi, Less blindbox</p></li><li><p></p></li></ul><p>v1 version has good blindbox artstyle</p><p></p><h2>blindbox v3</h2><ul><li><p>Ë∞ÉÊï¥ÁúºÈÉ®ÁªÜËäÇ</p></li></ul><p></p><p>„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº„Éº</p><p></p><p>Áõ≤ÁõíÈ£éÊ†ºÁöÑLoRAÔºå‰∏ÄÂºÄÂßãÊòØËøô‰πàÊÉ≥ÁöÑ„ÄÇ</p><p><strong>v1ÁâàÊú¨ </strong>ËøòÊòØÊØîËæÉÁõ≤ÁõíÁöÑ„ÄÇ</p><p>Â¢ûÂä†‰∫ÜPVCÁöÑË¥®ÊÑüÔºåÊõ¥Êñ∞‰∫Üv1_mixÔºåÊïàÊûúÂæà‰∏çÈîôÔºåÂª∫ËÆÆ‰ΩøÁî®üëç</p><p>Â¢ûÂä†ÂÖ≥ÈîÆËØç<strong>chibi, full body,</strong></p><p>ÂáèÂ∞ëË¥üÈù¢ÊèèËø∞‰ºöÂ•Ω‰∏ÄÁÇπÔºå‰πüÂèØËá™Ë°åÂ∞ùËØï„ÄÇ</p><p><strong>ÁªèËøáÊµãËØïÔºåÂ¶ÇÊûúË¶ÅÂíåÂà´ÁöÑLoRA‰∏ÄËµ∑‰ΩøÁî®ÔºåËøòÊòØÊääÈÇ£‰∫õË¥üÈù¢ÂÖ≥ÈîÆËØçÂä†‰∏äÂêß</strong>üòÖ</p><p>Êé®Ëçê‰ΩøÁî®<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7371/rev-animated\">RevAnimated</a>Ê®°Âûã„ÄÇ</p><p>Ë∑ü‰∏Ä‰∫õËßíËâ≤LoRA‰πüÊúâÊØîËæÉÂ•ΩÁöÑÁõ∏ÊÄß„ÄÇ</p><p></p><p><strong>v2ÁâàÊú¨</strong>ÂáèÂ∞ë‰∫ÜÂ§ßÂ§¥ÁöÑÊ¶ÇÁéáÔºåÊõ¥ÂÅèÂêë‰∫åÂ§¥Ë∫´„ÄÇ</p><p>ÈÄÇÂêà‰∏Ä‰∫õÂä®Êº´ÁîªÈ£é‰∫ÜÔºå‰πüËÆ∏„ÄÇ</p><p></p><p>ÊúâÈóÆÈ¢òÂèØ‰ª•ÂéªBÁ´ôÈóÆÔºåÂ¶ÇÊûúÊàëËÉΩËß£ÂÜ≥ÁöÑËØùüòÑ</p><p>Âßë‰∏îÊîæ‰∏ä‰∏Ä‰∏™Ê≤°‰∫∫Ê∞îÁöÑËßÜÈ¢ë</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.bilibili.com/video/BV1Ah411G7Zs/\">https://www.bilibili.com/video/BV1Ah411G7Zs/</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832140+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "71961",
    "prompt": "Fast Negative Embedding (+ FastNegativeV2)\n<h1 id=\"heading-94\">Fast Negative Embedding</h1><p><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> üÖøÔ∏è or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> ‚òï</strong><br /></p><p>Token mix of my usual negative embedding. This way it's faster to use and easier to reproduce.</p><p>I'm also working on a much stronger one that doesn't preserve styles but it's good on base models without style loras applied. I plan to upload it during the next week, so be sure to leave a ‚ù§Ô∏è to be notified of future updates.</p><p><s>This is very much a </s><strong><s>work in progress</s></strong><s>, but since I'm already using it in examples, I thought I should upload it.</s></p><p>It should keep styles on all my style loras. If not please tell me in the comments. <br />Additionally, if you find this too overpowering, use it with weight, like <code>(FastNegativeEmbedding:0.9)</code>.</p><p><strong>Update: </strong>added <code>FastNegativeV2</code>. It shouldn't be necessary to lower the weight.</p><p></p><p>Of course, don't use this in the positive prompt.<br />This includes Nerf's <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/56519/negativehand-negative-embedding\">Negative Hand</a> embedding.</p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832164+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "8484",
    "prompt": "Yae Miko | Realistic Genshin LORA\n<p>Realistic Yae Miko from Genshin Impact. All samples generate with <strong>Ulzzang-6500</strong>\" embeddings, \"<strong>vae-ft-mse-840000\" </strong>VAE.</p><p><em>For everyone: I am not using the official lora loader, so you should use the</em><strong><em> additional-network </em></strong><em>webui plugin to use my lora setting.</em><br />Recommended weights for txt2img - 0.45-0.75, higher weights may cause bad face generate.</p><ul><li><p><strong><em>Update 23/3/1: </em>I believe it's illegal if you made any works/Loras/Embeddings that using actual person‚Äòs face without admission.</strong></p></li></ul><ul><li><p>Update 23/2/23: Shogun is here. <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/11896/raiden-shogun-or-realistic-genshin\">Raiden Shogun | Realistic Genshin | Stable Diffusion LORA | Civitai</a></p></li><li><p>Update 23/2/17: The new <strong>Mixed version</strong> using new dataset, I think it work better with other lora or different sd model now. <em>(Recommended weights for txt2img in this version - 0.65-0.85)</em></p></li></ul><p><strong>The Standard version</strong> working better only 1 lora model, will not missing characteristics, but sometimes will overfitting.</p><p><strong>The Full version</strong> use bigger dataset and working better with other face lora model, but missing some of characteristics.</p><p><em>Thank you for downloading!<br />Please leave a image with comment if you like it, I would love to see.</em></p><p><strong>If you see anyone selling images that generated by this model on pixiv or other platform please message me on twitter.</strong></p><p>(Perfroms better when prompt includes 'yae_sakura' :] )</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832181+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "1224788",
    "prompt": "Prefect illustrious XL\n<p>If you like my work, drop a 5 review and hit the heart icon. it's free and keeps me motivated</p><h3 id=\"060625-:-v2.0p-released-bkjt4p8s6\"><strong><span style=\"color:#fab005\">06/06/25 : v2.0p released </span></strong></h3><p>Main focus of 2.0b is cleaning the style influence of v1.5</p><p></p><h3 id=\"19022025-:-on-site-generation-added-4thawzg9o\"><strong><span style=\"color:rgb(250, 82, 82)\">19/02/2025 : On-site Generation added</span></strong></h3><p></p><h3 id=\"patreon-account.-do-check-it-out-squg8oeep\"><a target=\"_blank\" rel=\"ugc\" href=\"https://patreon.com/goofy_ai\">Patreon </a>account. do check it out</h3><p><span style=\"color:rgb(130, 201, 30)\">I post my upcoming concepts and nsfw lora early on my patreon</span></p><h3 id=\"if-you-want-commission-dm-me-on-discord.-8k1y8f1q5\">If you want commission dm me on <a target=\"_blank\" rel=\"ugc\" href=\"https://discordapp.com/users/292013661902471170\">Discord</a>.</h3><h3 id=\"get-early-access-to-my-upcoming-nsfw-lora-in-my-patreon-.-brptmajnl\"><span style=\"color:rgb(64, 192, 87)\">Get early access to my upcoming </span><span style=\"color:rgb(253, 126, 20)\">NSFW </span><span style=\"color:rgb(64, 192, 87)\">Lora in my </span><a target=\"_blank\" rel=\"ugc\" href=\"https://patreon.com/hinokiart\"><span style=\"color:rgb(250, 82, 82)\">Patreon </span></a><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/GoofyAi\"><span style=\"color:rgb(146, 147, 149)\">.</span></a></h3><p><span style=\"color:rgb(253, 126, 20)\">Support my work by joining any one of them and get early access to all my upcoming loras and other perks such as fan requests and Discord role.</span></p><p></p><p><strong><span style=\"color:rgb(64, 192, 87)\">Suggested settings:</span></strong></p><ul><li><p>I had CLIP skip 1 on every image</p></li><li><p><strong>Samplers : Eular A, DPM++ 2M</strong></p></li><li><p><strong>CFG : 5-6</strong></p></li><li><p>I had <em>ENSD</em>: 31337 all of them</p></li><li><p>All of them had <strong>highres.fix</strong> or img2img at higher resolution.</p></li><li><p>I <strong>don't use restore faces</strong></p></li><li><p><strong>I use Adetailer for face details</strong></p></li><li><p><strong>4x-Ultrasharp upscaler</strong></p></li><li><p><strong>positive: masterpiece,best quality,amazing quality,absurdres,</strong></p></li><li><p><strong>negative: bad quality,worst quality,worst detail,sketch,censored,watermark, signature, artist name</strong></p></li></ul><h3 id=\"join-my-discord-server-1gzxuqhi5\">Join my <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/M8yAsU9ZhC\"><strong><u>Discord Server</u></strong></a></h3>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832208+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "200255",
    "prompt": "Hands XL + SD 1.5 + FLUX.1-dev + Pony + Illustrious\n<p><strong>Update</strong>: <u>Please if you see any of my models somewhere else report or let me know! Thnx</u></p><p><u>Please read version info</u> (about this version)</p><p>Update: Added <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/411088?notOwner=true\">perfection</a> style model (Hands + Feet + all in one)</p><p>Update: Added <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/421162/detailed-style-xl-hand-focus-all-in-one-detailed-perfection-style-extension?modelVersionId=469308\">Detailed </a>style (Hand focus + all in one)</p><p>Update: Added <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/200255?modelVersionId=486156\">SD 1.5</a> Model</p><p>Update: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/200255?modelVersionId=1356581\">Pony </a>version added! (<u>Please read version info. before using it</u>)</p><p>Update: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/200255?modelVersionId=2212079\">Illustrious</a> version added.</p><p>Update: added <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/200255?modelVersionId=1620163\">gun focus</a> (weapon focus) F1D model.</p><p>Trained on base model xl 1.0 + FLUX.1-dev + Pony + Illustrious</p><p>Feel free to check <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/200251/feet?modelVersionId=225347\">feet model</a> as well.</p><p>In addition to <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/697832/archery-style-flux1-dev\">Archery</a> style.</p><p><span style=\"color:rgb(250, 176, 5)\"><strong><u>Feedback and ratings are much appreciated.</u></strong></span></p><p><u>Other models to check:</u></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/562884/skin-tone-cinematic-photography-style-xl-human-skin-color?modelVersionId=691175\">Skin Tone (Cinematic Photography) Style XL (Human skin color)</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/580857/realistic-skin-texture-style-xl-detailed-skin?modelVersionId=691191\">Realistic Skin Texture style XL (Detailed Skin)</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/541620/facial-expressions-detailed-emotions-style-xl?modelVersionId=603774\">Facial Expressions (detailed emotions) style XL</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/623398/perfect-eyes-variaty-of-sclera-xl?modelVersionId=696927\">Perfect Eyes (Variaty of sclera) XL</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832226+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "7241",
    "prompt": "MIX-Pro-V4\n<h2>Anime Style Mergemodel</h2><p></p><ul><li><p>All sample images using highrexfix + ddetailer</p></li><li><p>Put the upscaler in the your \"ESRGAN\" folder</p><p></p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/dddetailer\">ddetailer</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://mega.nz/folder/qZRBmaIY#nIG8KyWFcGNTuMX_XNbJ_g/file/vRYVhaDA\">4x-UltraSharp.pth</a></p></li></ul><p></p><p></p><h3><strong>&lt;Parameters&gt;</strong></h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/GIMG/AIChan_Model/tree/main/Blend/MIX-Pro/V4/Parameters\">https://huggingface.co/GIMG/AIChan_Model/tree/main/Blend/MIX-Pro/V4/Parameters</a></p><p></p><p></p><p></p><h3><strong>&lt;Source&gt;</strong></h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/mikapikazo-diffusion/blob/main/mikapikazo-40000.ckpt\">https://huggingface.co/andite/mikapikazo-diffusion/blob/main/mikapikazo-40000.ckpt</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/cutesexyrobutts-diffusion/blob/main/csrb-diffusion.ckpt\">https://huggingface.co/andite/cutesexyrobutts-diffusion/blob/main/csrb-diffusion.ckpt</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/piromizu-diffusion/blob/main/piromizu-20000.ckpt\">https://huggingface.co/andite/piromizu-diffusion/blob/main/piromizu-20000.ckpt</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/yohan-diffusion/blob/main/yohan-diffusion.safetensors\">https://huggingface.co/andite/yohan-diffusion/blob/main/yohan-diffusion.safetensors</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nuigurumi/basil_mix/blob/main/Basil%20mix.safetensors\">https://huggingface.co/nuigurumi/basil_mix/blob/main/Basil%20mix.safetensors</a></p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/22607/loconlora-airconditioner-style\">https://civitai.com/models/22607/loconlora-airconditioner-style</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/14393/thick-coat-cg-style\">https://civitai.com/models/14393/thick-coat-cg-style</a></p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/closertodeath/mouseymix/blob/main/mouseymix.safetensors\">https://huggingface.co/closertodeath/mouseymix/blob/main/mouseymix.safetensors</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/pastel-mix/blob/main/pastelmix-fp16.safetensors\">https://huggingface.co/andite/pastel-mix/blob/main/pastelmix-fp16.safetensors</a></p><p></p><p></p><h3>&lt;My models&gt;</h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/GIMG/AIChan_Model/tree/main\">https://huggingface.co/GIMG/AIChan_Model/tree/main</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/14206/mix-pro-v45colorbox\">https://civitai.com/models/14206/mix-pro-v45colorbox</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832238+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "107842",
    "prompt": "AniVerse\n<h2 id=\"!!!-uploadingsharing-my-models-outside-civitai-is-stricly-prohibited*-!!!-b2g14hwss\"><strong><span style=\"color:rgb(250, 82, 82)\">!!! UPLOADING/SHARING MY MODELS OUTSIDE CIVITAI IS STRICLY PROHIBITED*</span></strong> <strong><span style=\"color:rgb(250, 82, 82)\">!!!</span></strong></h2><hr /><p>Check my <strong><u><span style=\"color:rgb(250, 82, 82)\">EXCLUSIVE</span></u></strong> models on <a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/u/aOLZe8jJNONrQadNcgm354ugzPD3\">Mage.Space</a>: <a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/05d04289a2142f35a9cd6d486a9c50d7\"><strong>AniMage PXL</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/8c08b7556d0342d397b60d10d8dc446e\"><strong>AniReal PXL</strong></a><strong><span style=\"color:rgb(34, 139, 230)\"> </span><span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span><span style=\"color:rgb(34, 139, 230)\"> </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/319e16adef75450cbadc4105c5c0babf\"><strong><span style=\"color:rgb(34, 139, 230)\">Lucid Dream</span></strong></a><strong><span style=\"color:rgb(34, 139, 230)\"> </span><span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span><span style=\"color:rgb(34, 139, 230)\"> </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/04f8ba407b28bcd490642337c78c085a\"><strong>AniMage<span style=\"color:rgb(34, 139, 230)\"> </span>SD1.5 </strong></a><strong><span style=\"color:rgb(250, 82, 82)\">‚Ä¢ </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/2f1eb43493644bdcbba5d837f2e7d83b\"><strong>Realistic Portrait</strong></a><br /><strong>SDXL - Pony</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/7f1e1dc38ca541a190665638f5eac0a5\"><strong>AniVerse PXL</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/c52ad2e5dc64445989432a3babda7455\"><strong>AniMerge PXL</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/5f0620e7941346e5ba609b1d6818b905\"><strong>AniToon PXL</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢ </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/ffa9c347274e487a82c39940e4e4c1ce\"><strong>AniMics PXL</strong></a><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/7084c020ad695014147d24cbc1d0b0ce\"><strong> </strong></a><strong><span style=\"color:rgb(250, 82, 82)\">‚Ä¢ </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/a3cb9984f6a63fa3d9579508e8045527\"><strong>AniVerse XL</strong></a><br /><strong>SD1.5</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/20a658c9b57e5916dc352793ccaa50db\"><strong>AniVerse</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/c2b74fd272d4b8ff87a3af9344424409\"><strong>AniThing</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/8d75a4725b8b45e5bc9c42a3dd6b0041\"><strong>AniMerge</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/2e7ecf8dc586a31d04411007af7c910c\"><strong>AniMesh</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/704df2ffe3ec24b1ff581d5048d562c9\"><strong>AniToon</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/1400dae0ecf2a5e3fcbec059de4a8e1f\"><strong>AniMics</strong></a></p><hr /><p>Also in Collaboration with <a target=\"_blank\" rel=\"ugc\" href=\"https://www.shakker.ai/userpage/751b8d22818d4996992184cb0dc11d32\"><strong>Shakker.ai</strong></a></p><hr /><p>This model is <u><span style=\"color:rgb(250, 82, 82)\">free for </span></u><strong><u><span style=\"color:rgb(250, 82, 82)\">personal</span> <span style=\"color:rgb(250, 82, 82)\">use</span></u><em><span style=\"color:rgb(250, 82, 82)\"> </span></em></strong>and free for <strong><span style=\"color:rgb(250, 82, 82)\">personal</span></strong><span style=\"color:rgb(250, 82, 82)\"> merging(</span>*<span style=\"color:rgb(250, 82, 82)\">)</span>.<br />For <strong><u><span style=\"color:rgb(250, 82, 82)\">commercial use</span></u></strong>, please be sure to <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/samael1976\"><strong>contact me </strong></a>(Ko-fi) or by email: <strong>samuele[dot]bonzio[at]gmail[dot]com</strong></p><hr /><h3 id=\"read-the-info-below-to-get-the-high-quality-images-(click-on-show-more)-0ub2foj80\">‚¨áRead the <span style=\"color:rgb(250, 82, 82)\">info below</span> to get the <span style=\"color:rgb(250, 82, 82)\">high quality images </span>(<em>click on show more</em>)‚¨á</h3><hr /><h2 id=\"aniverse-is-just-the-beginning!-dupa776f3\"><strong><span style=\"color:rgb(253, 126, 20)\">Aniverse - is just the beginning!</span></strong></h2><p>This is a long shot project, I‚Äôd like to implement something new at every update!</p><p></p><p>The name is a merge of the two words: Animation and Universe (and a word pun: Any+Universe -&gt; Anyverse -&gt; Aniverse)</p><hr /><p>-&gt; If you are satisfied using my model, press on ‚ù§Ô∏è to follow the progress and consider leaving me ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê on model review, it's really important to me!</p><p>Thank you in advance üôá</p><p>And remember to publish your creations using this model! I‚Äôd really love to see what your imagination can do!</p><hr /><h2 id=\"recommended-settings:-xlwb1rait\"><strong><u><span style=\"color:rgb(250, 82, 82)\">Recommended Settings:</span></u></strong></h2><ul><li><p><strong>Excessive negative prompt can makes your creations worse, so follow my suggestions below!</strong></p></li><li><p><strong>Before applying a LoRA to produce your favorite character, try it without first. You might be surprised what this model can do!</strong></p></li></ul><hr /><h2 id=\"a1111-my-settings:-62mu44pnf\"><strong><u><span style=\"color:rgb(250, 82, 82)\">A1111 my settings:</span></u></strong></h2><p></p><p><strong>I run <u><span style=\"color:rgb(250, 82, 82)\">my Home PC</span></u> A1111 with this setting:</strong></p><ul><li><p>set COMMANDLINE_ARGS= --xformers</p></li></ul><p></p><p><strong>if you can't install xFormers (read below) use my <u><span style=\"color:rgb(250, 82, 82)\">Google Colab Setting</span></u>:</strong></p><p></p><ul><li><p>set COMMANDLINE_ARGS= --disable-model-loading-ram-optimization --opt-sdp-no-mem-attention</p></li></ul><p></p><p><strong>My A1111 Version:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/a0af2852b67859b427b662789d0b42f592e78dec\"><strong>v1.6.0-RC-28-ga0af2852</strong></a> ‚ÄÄ‚Ä¢‚ÄÄ python: 3.10.6 ‚ÄÄ‚Ä¢‚ÄÄ torch: 2.0.1+cu118 ‚ÄÄ‚Ä¢‚ÄÄ xformers: 0.0.20 ‚ÄÄ‚Ä¢‚ÄÄ gradio: 3.41.2</p><p></p><p><strong><span style=\"color:rgb(250, 82, 82)\">If you want activate xformers optimization like </span><u><span style=\"color:rgb(250, 82, 82)\">my Home PC</span></u><span style=\"color:rgb(250, 82, 82)\"> </span>(</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://aipromptshome.com/fix-no-module-xformers-stable-diffusion-automatic-1111/\"><strong>How to install xFormers</strong></a><strong>)<span style=\"color:rgb(250, 82, 82)\">:</span></strong></p><ul><li><p>In A1111 click in \"<strong><em>Setting Tab</em></strong>\"</p></li><li><p>In the left coloumn, click in \"<strong><em>Optimization</em></strong>\"</p></li><li><p>in: \"<strong><em>Cross attention optimization</em></strong>\" select: \"<strong><em>xformers</em></strong>\"</p></li><li><p>Press in \"<strong><em>Apply Settings</em></strong>\"</p></li><li><p>Reboot your Stable Diffusion</p></li></ul><p></p><p><strong><span style=\"color:rgb(250, 82, 82)\">If you can't install xFormers use SDP-ATTENTION, like </span><u><span style=\"color:rgb(250, 82, 82)\">my Google Colab</span></u><span style=\"color:rgb(250, 82, 82)\">:</span></strong></p><ul><li><p>In A1111 click in \"<strong><em>Setting Tab</em></strong>\"</p></li><li><p>In the left coloumn, click in \"<strong><em>Optimization</em></strong>\"</p></li><li><p>in: \"<strong><em>Cross attention optimization</em></strong>\" select: \"<strong>sdp-no-mem - scaled dot product without memory efficient attention</strong>\"</p></li><li><p>Press in \"<strong><em>Apply Settings</em></strong>\"</p></li><li><p>Reboot your Stable Diffusion</p></li></ul><p></p><p><strong><span style=\"color:rgb(250, 82, 82)\">How to emulate the nvidia GPU follow this steps</span></strong>:</p><ul><li><p>In A1111 click in \"<strong><em>Setting Tab</em></strong>\"</p></li><li><p>In the left coloumn, click in \"<strong><em>Show all pages</em></strong>\"</p></li><li><p>Search \"<strong><em>Random number generator source</em></strong>\"</p></li><li><p>Select the voice: \"<strong><em>NV</em></strong>\"</p></li><li><p>Press in \"<strong><em>Apply Settings</em></strong>\"</p></li><li><p>Reboot your Stable Diffusion</p></li></ul><p></p><p><strong><span style=\"color:rgb(250, 82, 82)\">If you use my models, install the </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\"><strong><span style=\"color:rgb(34, 139, 230)\">ADetailer</span></strong></a><strong><span style=\"color:rgb(250, 82, 82)\"> extension for your A1111.</span></strong></p><p>Navigate to the \"<strong>Extensions</strong>\" tab within Stable Diffusion.</p><ul><li><p>Go to the \"<strong>Install from URL</strong>\" subsection.</p></li><li><p>Paste the following URL: <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\">https://github.com/Bing-su/adetailer</a></p></li><li><p>Click on the \"<strong>Install</strong>\" button to install the extension</p></li><li><p>Reboot your Stable Diffusion</p></li></ul><p><br /><strong><span style=\"color:rgb(250, 82, 82)\">How to install Euler Smea Dyn and Euler Max Sampler:</span></strong></p><ul><li><p>In A1111 click in \"<strong><em>Extensions Tab</em></strong>\"</p></li><li><p>click in \"<strong><em>Install from URL</em></strong>\"</p></li><li><p>Under \"<span style=\"color:rgb(229, 231, 235)\">URL for extension's git repository</span>\" put this link: <strong>https://github.com/licyk/advanced_euler_sampler_extension</strong></p></li><li><p>Once installed click in: \"<strong><em>Installed\" </em></strong>Tab</p></li><li><p>Click in \"<strong><em>Apply and quit</em></strong>\"</p></li><li><p>Reboot your Stable Diffusion</p></li><li><p>Now at the end of the list of the sampler, you have the new sampler.</p></li></ul><p></p><p><strong><span style=\"color:rgb(250, 82, 82)\">How to use ADetailer with Euler Smea Dyn and Euler Max Sampler:</span></strong></p><ul><li><p>In A1111 click in \"<strong><em>txt2img</em></strong>\" tab</p></li><li><p>Expand and click in \"<strong>enable ADetailer</strong>\"</p></li><li><p>Scroll down and expand \"<strong>inpaint</strong>\" section</p></li><li><p>Click and turn on \"<strong>Use separate Sampler</strong>\"</p></li><li><p>Now select: \"DPM++ 2M Karras\" (or your favourite sampler)</p></li></ul><p></p><hr /><ul><li><p><strong>VAE:</strong>¬†VAE is included (but usually I still use the<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors\">¬†<strong>840000 ema pruned</strong></a>)</p></li><li><p><strong>Clip skip:</strong>¬†2</p></li><li><p><strong>Upscaler:</strong>¬†<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/116225?modelVersionId=125843\"><strong>4x-Ultrasharp</strong></a> or <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/141491?modelVersionId=156841\"><strong>4X NMKD Superscale</strong></a></p></li></ul><hr /><ul><li><p><strong>Sampling method: </strong>DPM++ 2M SDE Karras</p></li><li><p><strong>Width: </strong>576 (o 768)</p></li><li><p><strong>Height: </strong>1024</p></li><li><p><strong>CFG Scale:</strong> 3 -&gt; <strong>Steps</strong>: 15<br /><strong>CFG Scale:</strong> 4 -&gt; <strong>Steps:</strong> 20<br /><strong>CFG Scale:</strong> 5 -&gt; <strong>Steps:</strong> 25<br /><strong>CFG Scale:</strong> 6 -&gt; <strong>Steps:</strong> 30</p><p>...and so on...</p></li></ul><hr /><p><strong>MY FAVORITE PROMPT:</strong></p><ul><li><p>(masterpiece, best quality, highres:1.2), (photorealistic:1.2), (intricate and beautiful:1.2), (detailed light:1.2), (colorful, dynamic angle), RAW photo, upper body shot, fashion photography, <strong><em>YOUR PROMPT</em></strong>, (highres textures), dynamic pose, bokeh, soft light passing through hair, (abstract background:1.3), (sharp), exposure blend, bokeh, (hdr:1.4), high contrast, (cinematic), (muted colors, dim colors, soothing tones:1.3), morbid</p><hr /><p><strong>NEGATIVE PROMPT:</strong></p></li><li><p>(worst quality, low quality), negative_hand-neg, bad-hands-5, naked, nude, braless, cross, sepia, black&amp;white, B&amp;W, painting, drawing, illustration</p></li></ul><hr /><p><strong>YOU CAN ALSO USE THESE NEGATIVE EMBEDDINGS:</strong></p><ul><li><p><strong>1)</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808?modelVersionId=9536\"><strong>Easy Negative</strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/56519/negativehand-negative-embedding\"><strong>negative_hand-neg</strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/116230/bad-hands-5\"><strong>bad-hands-5</strong></a></p></li><li><p><strong>2)</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Xynon/models/blob/main/experimentals/TI/bad-image-v2-39000.pt\"><strong>Bad-Images-39000</strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/56519/negativehand-negative-embedding\"><strong>negative_hand-neg</strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/116230/bad-hands-5\"><strong>bad-hands-5</strong></a></p></li><li><p><strong>3)</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4629/deep-negative-v1x\"><strong>ng_deepnegative_v1_75t</strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/116230/bad-hands-5\"><strong>bad-hands-5</strong></a></p></li><li><p><strong>4)</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/71961?modelVersionId=94057\"><strong>FastNegativeV2</strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/56519/negativehand-negative-embedding\"><strong>negative_hand-neg</strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/116230/bad-hands-5\"><strong>bad-hands-5</strong></a></p></li><li><p><strong>5)</strong> For <strong>MEN images</strong>: girl, woman, female, tits, <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Xynon/models/blob/main/experimentals/TI/bad-image-v2-39000.pt\"><strong>BadImage_v2-39000</strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/56519/negativehand-negative-embedding\"><strong>negative_hand-neg</strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/116230/bad-hands-5\"><strong>bad-hands 5</strong></a></p></li></ul><hr /><h3 id=\"hires.fix-setting:-lkm82qk8c\"><u><span style=\"color:rgb(250, 82, 82)\">HiRes.Fix Setting:</span></u></h3><p>I don't use Hi.Res fix because:</p><p>1) in my computer don't work</p><p>2) my models don't need it. Use txt2image, aderailer and the suggested upscaler in the resources tab.</p><p>If you still want use it, this is the setting sent me by¬†<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/MarkWar\"><strong>MarkWar</strong></a>¬†(follow him to see his creations ‚ù§Ô∏è).</p><p><strong>Hires upscale:</strong> 1.5</p><p><strong>Hires steps:</strong> 20~30</p><p><strong>Hires upscaler:</strong> R-ESRGAN 4x + Anime6B,</p><p><strong>Denoising strength:</strong> 0.4</p><p><strong>Adetailer:</strong>¬†<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Bingsu/adetailer/blob/main/face_yolov8n.pt\">face_yolov8n</a></p><p><strong>How to install and use adetailer:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\">Click Here</a></p><hr /><h3 id=\"inpainting-setting:-y5yepmlr4\"><u><span style=\"color:rgb(250, 82, 82)\">Inpainting Setting:</span></u></h3><p>When you see that I used Inpainting on my images, I only modify the face (Hires Fix on my old PC doesn't work and got stuck). This is my setting:</p><ul><li><p>Click in the tab¬†img2img,¬†than click on¬†inpaint -&gt;</p></li><li><p>Paint the face¬†(only the face, neck, ears...) and after that set:</p></li><li><p>Inpaint masked</p></li><li><p>Only masked</p></li><li><p>Only masked padding, pixels:¬†12</p></li><li><p>Sampling steps:¬†50</p></li><li><p>Set:¬†Only masked</p></li><li><p>Batch Size:¬†8<br />in the Positive Prompt write:¬†(ultra realistic, best quality, masterpiece, perfect face)</p></li><li><p>Than click on¬†<em>GENERATE</em></p></li></ul><hr /><h3 id=\"controlnet-and-prompt-guide-video-tutorial:-kapv3wqv5\"><u><span style=\"color:rgb(250, 82, 82)\">ControlNet &amp; Prompt guide video tutorial:</span></u></h3><p>Thanx to: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/tejasbale01\"><strong>tejasbale01</strong></a><strong> - </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/@spidey-ai\"><strong>Spidey Ai Art Tutorial</strong></a><span style=\"color:rgb(241, 241, 241)\"> (follow him in youtube)</span></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/watch?v=X95IVzPa_bU\"><strong>Animesh Full V1.5 + Controlnet | Prompt Guide |</strong></a></p><hr /><p>Do you like my work?</p><p>If you want you can help me to buy a new PC for Stable Diffusion!<br />‚ù§Ô∏è <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/samael1976\">You can buy me a <strong>(Espresso... I'm italian)</strong> coffee or a beer </a>‚ù§Ô∏è</p><p>This is the list of hardware if you are courius:¬†<a target=\"_blank\" rel=\"ugc\" href=\"https://www.amazon.it/hz/wishlist/ls/2FYKOW9MQY6A?ref_=list_d_wl_lfu_nav_10\">Amazon Wishlist</a></p><hr /><p>I must¬†thank you¬†<a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/@OlivioSarikas\"><strong>Olivio Sarikas</strong>¬†</a>and¬†<a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/@SECourses\"><strong>SECourses</strong></a>¬†for their video tutorials! (I'd really love to see a your video using my model¬†‚ù§Ô∏è¬†)</p><hr /><h3 id=\"you-are-solely-responsible-for-any-legal-liability-resulting-from-unethical-use-of-this-model-fhxvkg85a\"><strong>You are solely responsible for any legal liability resulting from unethical use of this model</strong></h3><p></p><ul><li><p><em>(*) </em><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/MarkWar\"><strong>MarkWar</strong></a>¬†<em>is authorized by me to do anything with my models.</em></p><p></p></li><li><p><em>(**) Why did I set such stringent rules? Because I'm tired of seeing sites like Pixai (and many others) that get rich on the backs of the model creators without giving anything in return.</em></p><p></p></li><li><p><em>(***) Low Rank Adaptation models (LoRAs) and Checkpoints created by me.</em></p><p><em>As per Creative ML OpenRAIL-M license section III, derivative content(i.e. LoRA, Checkpoints, mixes and other derivative content) is free to modify license for further distribution. In that case such is provided by licensing on each single model on </em><a target=\"_blank\" rel=\"ugc\" href=\"http://Civitai.com\"><em>Civitai.com</em></a><em>. All models produced by me are prohibiting hosting, reposting, reuploading or otherwise utilisation of my models on other sites that provide generation service without a my explicit authorization.</em><br /></p></li><li><p><em>(****)According to Italian law (I'm Italian):</em></p><p><em>The law on copyright (</em><a target=\"_blank\" rel=\"ugc\" href=\"http://www.normattiva.it/uri-res/N2Ls?urn:nir:stato:legge:1941-04-22;633!vig=\"><em>law 22 April 1941, n. 633</em></a><em>, and subsequent amendments, most recently that provided for by the legislative decree of </em><a target=\"_blank\" rel=\"ugc\" href=\"http://www.normattiva.it/uri-res/N2Ls?urn:nir:stato:decreto.legge:2017-10-16;148!vig=\"><em>16 October 2017 n.148</em></a><em>) provides for the protection of \"intellectual works of a creative nature\", which belong to literature, music, figurative arts, architecture, theater and cinema, whatever their mode or form of expression.</em></p><p><em>Subsequent changes, linked to the evolution of new information technologies, have extended the scope of protection to photographic works, computer programs, databases and industrial design creations.</em></p><p><em>Copyright is acquired automatically when a work is defined as an intellectual creation.</em></p><p><em>Also valid for the US: </em><a target=\"_blank\" rel=\"ugc\" href=\"https://ufficiobrevetti.it/copyright/copyright-usa/\"><em>https:// ufficiobrevetti.it/copyright/copyright-usa/</em></a></p><p></p><p><em>All my Stable Diffusion models in Civitai (as per my approval) are covered by copyright.</em></p></li></ul>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832294+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "13090",
    "prompt": "Gacha splash LORA\n<p>The training dataset is 100% generated by NovelAI. No real artwork is used.</p><h3 id=\"heading-16\">Checkout my Alter version, which uses real artwork: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/85859/gacha-splash-alter\">https://civitai.com/models/85859/gacha-splash-alter</a></h3><p></p><hr /><p></p><p>3.0 version is released. I rebuilt the entire training set for this version.</p><p>Notes:</p><ol><li><p>Use hires fix + SD upscale or MultiDiffusion to get better face details.</p></li><li><p>Try adding <strong>wood, stone</strong> in negative prompt if you see too many woods, stones, structures. You may also emphasize it. For example, the bottle keeps getting transformed into structures till I add <strong>wood, stone</strong>.</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0f22fd23-ec7b-412e-3510-b2eb1b939300/width=525/0f22fd23-ec7b-412e-3510-b2eb1b939300\" /></p></li></ol><p></p><p>A 2.0 version is released:</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d581a9e1-feba-4e9e-5e5b-77a9620aa100/width=525/d581a9e1-feba-4e9e-5e5b-77a9620aa100\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c769bab0-33fa-41b8-a078-aa74960e7e00/width=525/c769bab0-33fa-41b8-a078-aa74960e7e00\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f0923741-80ed-47d6-a907-c735d8870700/width=525/f0923741-80ed-47d6-a907-c735d8870700\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8c61993b-b369-4db3-ca80-5cb1f97b5e00/width=525/8c61993b-b369-4db3-ca80-5cb1f97b5e00\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/29bbb4b7-c376-46dc-0707-160f2c748800/width=525/29bbb4b7-c376-46dc-0707-160f2c748800\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a1a6e79c-fc71-4d6d-e97a-c8ce76800c00/width=525/a1a6e79c-fc71-4d6d-e97a-c8ce76800c00\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f8ee28bb-46df-4a8b-509a-09a307409300/width=525/f8ee28bb-46df-4a8b-509a-09a307409300\" /></p><p></p><p>A gacha splash style lora. Make sure you start with the following template and add your background prompts.</p><p>[(white background:1.5)::5], isometric <strong>OR </strong>hexagon , 1 girl, mid shot, full body, &lt;add your background prompts here&gt;</p><p>Suggested resolution: 640X640 with hires fix. You may modify your prompt and resolution after successfully getting the effect.</p><p></p><p>I trained two different versions with different learning rate and scheduler.</p><p>Gacha Splash Fantasy fits more in abstract backgrounds.</p><p>Gacha Splash is intentionally trained to be slightly overfit. It fits greatly for architectures.</p><p>See compares from sample images</p><p></p><p>Notes:</p><p>1. If your characters are always wearing jackets/half off jackets, try adding \"off shoulder\" in negative prompt. You may further add \"jackets\"/ \"bare shoulders\" if the issue persists.</p><p>2. Similar as the jacket issue, if you find any elements that are always being generated, try adding them into negative prompt first. The training dataset is well tagged. Therefore AI should be able to remove these elements.</p><p></p><p>Prompts like hexagon and isometric help to shape the gacha splash effect. There are some alternative choices.</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/fce99058-b1b4-4c11-2d73-a2f6d2cfef00/width=525/fce99058-b1b4-4c11-2d73-a2f6d2cfef00\" /></p><p></p><p></p><p></p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3d0c31d6-d02f-4f4f-c0e8-81eabac72d00/width=525/3d0c31d6-d02f-4f4f-c0e8-81eabac72d00\" /></p><p></p><p></p><p></p><p></p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8405dea0-5eb3-4a0a-33ac-4d9a6b17dd00/width=525/8405dea0-5eb3-4a0a-33ac-4d9a6b17dd00\" /></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832310+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "11177",
    "prompt": "Anime Tarot Card Art Style LoRA (Â°îÁΩóÁâå/„Çø„É≠„ÉÉ„Éà„Ç´„Éº„Éâ)\n<p>Trained on Phantom Star illustrations.</p><p>V3.1 updated. Improve consistency. Support for more varied backgrounds (use <code>{} background</code> to set). </p><p>V3.1 Êõ¥Êñ∞ÔºåÊèêÈ´òÁ®≥ÂÆöÊÄß„ÄÇÊîØÊåÅÊõ¥Â§öÂÖÉÁöÑËÉåÊôØÔºà‰ΩøÁî®<code>{} background</code>Êù•ËÆæÁΩÆÔºâ„ÄÇ</p><p>All examples are generated with Anything V4.5 &amp; orange-mix VAE. Recommend strength: 0.8~1.</p><p>ÊâÄÊúâÊ†∑ÂõæÂùá‰ΩøÁî®Anything V4.5 &amp; orangeminx VAEÁîüÊàê„ÄÇÊé®ËçêÂº∫Â∫¶Ôºö0.8~1„ÄÇ</p><p>Recommend negative embeddings: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\">EasyNegative</a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16993/badhandv4-animeillustdiffusion\">badhandv4</a>.</p><p>Êé®ËçêË¥üÈù¢embeddingÔºö<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\">EasyNegative</a>„ÄÅ<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16993/badhandv4-animeillustdiffusion\">badhandv4</a>„ÄÇ</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832322+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "332646",
    "prompt": "Pony PDXL Negative Embeddings\n<p><span style=\"color:rgb(130, 201, 30)\">No need to use score this, and score that. Just use the embeddings instead.</span></p><h3 id=\"new-v3-versions-only-need-the-one-positive-embedding!.-gpr27v3ec\"><span style=\"color:rgb(190, 75, 219)\">New V3 versions only need the one positive embedding!.</span></h3><p>A set of quality enhancing embeddings for Pony SDXL, and other Pony-Adjacent models. You can mix and match any of the embeddings that you feel you need. They don't duplicate each other, so feel free to use as many together as needed.</p><p><strong><span style=\"color:rgb(64, 192, 87)\">High Quality V3 (zPDXL3):</span></strong><span style=\"color:rgb(64, 192, 87)\"> gives higher quality results and removes annoying censoring.</span></p><p><strong><span style=\"color:rgb(64, 192, 87)\">XXX Rating:</span></strong><span style=\"color:rgb(64, 192, 87)\"> tells the Pony model of your choice to allow NSFW content.</span></p><p><strong><span style=\"color:rgb(64, 192, 87)\">PG Rating: </span></strong><span style=\"color:rgb(64, 192, 87)\">tells the Pony model of your choice to try and remove NSFW content for safe images.</span></p><p><strong><span style=\"color:rgb(64, 192, 87)\">Photo Real:</span></strong><span style=\"color:rgb(64, 192, 87)\"> tells the Pony model of your choice to use realistic or near realistic renders instead of cartoon or anime.</span></p><p><strong><span style=\"color:#fa5252\">High Quality V2 (old):</span></strong><span style=\"color:#fa5252\"> designed to give higher quality results and remove censoring.</span></p><h2 id=\"doesn't-work-with-non-pony-models.-check-your-model.-4jrzjoc49\"><span style=\"color:rgb(230, 73, 128)\">Doesn't work with non-Pony models. Check your model.</span></h2><p>Recommend using both positive and negative embeddings together at strength 1.0 to 2.0. If you can't use both, the Positive version should be take priority.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832336+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "35960",
    "prompt": "Flat-2D Animerge\n<h2 id=\"heading-705\">Description</h2><p>(for best results, read the full description - usage guide below)</p><p>This is a merge of some random anime based and cartoon based models to achieve a somewhat cartoony anime style, more similar to what you would actually see in anime as opposed to the more common hyper-detailed anime models.</p><p>Versions 3, 4, and 4.5 include some custom training to further enhance the style. More details available in \"About this Version\" on the sidebar. Most positive prompts for the v3 sample images were randomly generated.</p><p></p><h2 id=\"heading-706\">Usage Guide</h2><ul><li><p><strong>(highly recommended)</strong> Use a negative embedding for best results</p><ul><li><p>I use verybadimagenegative_v1.3 (all examples use this)</p></li><li><p>verybadimagenegative_v1.3</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/11772/verybadimagenegative\">https://civitai.com/models/11772/verybadimagenegative</a></p></li></ul></li><li><p>Place the downloaded file into the \"embeddings\" folder of the SD WebUI</p></li><li><p>In the negative prompt, paste \"verybadimagenegative_v1.3\"</p></li></ul></li><li><p><strong>(highly recommended)</strong> Upscaling at 2x (or more) is important to getting a good result. I would recommend the following settings:</p><ul><li><p>Denoising strength of 0.45</p></li><li><p>Use the \"R-ESRGAN 4x+ Anime6B\" upscaler for a flatter look, or use \"Latent\" for a bit more detail</p></li><li><p>Leave hires steps at default of 0 (equal to your generation steps)</p></li></ul></li><li><p><strong>(highly recommended) </strong>Use DPM++2M Karas as the sampler. Other samplers can yield odd artifacts, though your mileage may vary depending on your specific setup.</p></li><li><p><strong>(only for version 3 and below) </strong>Use the dynamic thresholding plugin (all example images do with cfg scale 10 mimic 7): <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/mcmonkeyprojects/sd-dynamic-thresholding\">https://github.com/mcmonkeyprojects/sd-dynamic-thresholding</a></p><ul><li><p>Set the CFG scale to 10.0</p></li><li><p>Click the checkbox \"Enable Dynamic Thresholding (CFG Scale Fix)\"</p></li><li><p>Set the Mimic CFG Scale to 7</p></li><li><p>If you don't want to use this plugin, then set the config scale to 5 or 6</p></li></ul></li><li><p>This model is very easy to prompt, and does not require a ton of prompt engineering to get good results. The following format will yield decent results:</p><ul><li><p>Prompt:</p><ul><li><p>(best-quality:0.8), perfect anime illustration, &lt;normal description of the image, e.g. a woman running in tokyo at night, a flaming meteor, etc.&gt;</p></li></ul></li><li><p>Negative:</p><ul><li><p>(worst quality:0.8), verybadimagenegative_v1.3, (surreal:0.8), (modernism:0.8), (art deco:0.8), (art nouveau:0.8)</p></li></ul></li></ul></li><li><p>The model is capable of NSFW</p></li></ul>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832348+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "926443",
    "prompt": "NTR MIX | illustrious-XL | Noob-XL\n<h3 id=\"this-model-is-recommended-for-use-with-comfyui-zrlme5qw4\"><strong>This model is recommended for use with Comfyui</strong></h3><h3 id=\"compatibility-with-reforge-is-not-guaranteed.-tp5e3byt8\"><strong>compatibility with Reforge is not guaranteed.</strong></h3><p></p><h2 id=\"recommend-setting-(ntr-mix-xiii)-9ohu36deo\"><strong><span style=\"color:oklch(0.93 0.003 106.451)\">RECOMMEND setting (NTR MIX Xiii)</span></strong></h2><pre><code>{your Prompt}\n\nmasterpiece, best quality, amazing quality, very aesthetic, absurdres,  newest, \n\nyou can add tag scenery, (volumetric lighting), To make the background more distinctive.</code></pre><pre><code>Use dpm ++ 2m sgm uniform or karras (Sometimes euler is okay...?)\nStep 25, cfg 5 (can up to 5.8 by looking at the situation)\nIf you not use LoRA, author tags, etc., up the step to 28 </code></pre><p></p><p></p><p></p><p></p><p></p><p></p><h2 id=\"extream-(very-scenery)-setting-(ntr-mix-xii)-vpdgo642j\"><strong><span style=\"color:oklch(0.93 0.003 106.451)\">EXTREAM (very scenery) setting (NTR MIX Xii)</span></strong></h2><pre><code>masterpiece, best quality, amazing quality, very aesthetic, absurdres,  newest, (scenery, volumetric lighting),\n\n{your Prompt}\n\nmasterpiece, best quality, amazing quality, very aesthetic, absurdres,  newest, (scenery, volumetric lighting)</code></pre><pre><code>Use dpm ++ 2m karras or sgm uniform\nStep 28, cfg 5.8 (can take it down to 5 by looking at the situation)</code></pre><p></p><h2 id=\"soft-(char-only-simple-background)-setting-(ntr-mix-xii)-m0br7l9cj\"><strong><span style=\"color:oklch(0.93 0.003 106.451)\">SOFT (char only, simple background) setting (NTR MIX Xii)</span></strong></h2><p><span style=\"color:oklch(0.93 0.003 106.451)\">Quality tags (please put </span><strong><span style=\"color:oklch(0.93 0.003 106.451)\">Bottom </span></strong><span style=\"color:oklch(0.93 0.003 106.451)\">of the tag)</span></p><pre><code>{your Prompt}\n\nmasterpiece, best quality, amazing quality, very aesthetic, absurdres,  newest,</code></pre><pre><code>Use dpm ++ 2m beta or karras or sgm uniform\nStep 20, cfg 5 (up to 5.8 by looking at the situation)</code></pre><p></p><p></p><p></p><p></p><h2 id=\"extream-(very-scenery)-setting-(ntr-mix-xi)-a4oqbcvgn\"><strong><span style=\"color:oklch(0.93 0.003 106.451)\">EXTREAM (very scenery) setting (NTR MIX Xi)</span></strong></h2><pre><code>Use dpm ++ 2m SDE (recommend SGM UNIFORM or Karras or BETA, choose your own!)\nStep 28, cfg 5.8 (can take it down to 5.5 by looking at the situation)</code></pre><p>this need Two Quality tags, bottom and top (refers to the beginning and end of the prompt.)</p><p><span style=\"color:oklch(0.93 0.003 106.451)\">Quality tags (please put </span><strong><span style=\"color:oklch(0.93 0.003 106.451)\">Bottom and Top </span></strong><span style=\"color:oklch(0.93 0.003 106.451)\">of the tag)</span></p><pre><code>masterpiece, best quality, amazing quality, very aesthetic, absurdres,  newest, (scenery, volumetric lighting),\n\n{your Prompt}\n\nmasterpiece, best quality, amazing quality, very aesthetic, absurdres,  newest, (scenery, volumetric lighting)</code></pre><p></p><h2 id=\"soft-(char-only-simple-background)-setting-(ntr-mix-xi)-6wddfiibn\"><strong><span style=\"color:oklch(0.93 0.003 106.451)\">SOFT (char only, simple background) setting (NTR MIX Xi)</span></strong></h2><pre><code>Use dpm ++ 2m karras\nStep 28, cfg 5.8 (can take it down to 5 by looking at the situation)</code></pre><p><span style=\"color:oklch(0.93 0.003 106.451)\">Quality tags (please put </span><strong><span style=\"color:oklch(0.93 0.003 106.451)\">Bottom </span></strong><span style=\"color:oklch(0.93 0.003 106.451)\">of the tag)</span></p><pre><code>masterpiece, best quality, amazing quality, very aesthetic, absurdres,  newest, volumetric lighting\n\n{your Prompt}\n\nmasterpiece, best quality, amazing quality, very aesthetic, absurdres,  newest, volumetric lighting</code></pre><p></p><p>Negative Tags (all setting)</p><p></p><pre><code>lowres, (worst quality, bad quality:1.2), bad anatomy, sketch, jpeg artifacts, signature, watermark, old, oldest, censored, bar_censor, (pregnant), chibi, loli, simple background, </code></pre><p></p><p></p><p></p><p></p><p><span style=\"color:oklch(0.93 0.003 106.451)\">Recommendation setting (under NTR MIX 777)</span></p><p></p><pre><code>Use dpm ++ 2m Karras (in i2i, use BETA and cfg 5)\nStep 28, cfg 7</code></pre><p></p><p><span style=\"color:oklch(0.93 0.003 106.451)\">Quality tags (please put </span><strong><span style=\"color:oklch(0.93 0.003 106.451)\">Bottom </span></strong><span style=\"color:oklch(0.93 0.003 106.451)\">of the tag)</span></p><pre><code>masterpiece, best quality, amazing quality, very aesthetic, absurdres,  </code></pre><p><span style=\"color:oklch(0.93 0.003 106.451)\">Negative tags</span></p><pre><code>lowres, (worst quality, bad quality:1.2), bad anatomy, sketch, jpeg artifacts, signature, watermark, old, oldest, censored, bar_censor, (pregnant), chibi, loli, simple background, conjoined, futanari, </code></pre><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832363+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "6925",
    "prompt": "RealDosMix\n<p>!!pruned fp16 replaced with no ema. The change in quality is less than 1 percent, and we went from 7 GB to 2 GB.<br /></p><p>See example picture for prompt.There are recurring quality prompts.</p><p>vae-ft-mse-840000-ema-pruned or kl f8 amime2</p><p>img2img SD upscale method: scale 20-25, denoising 0.2-0.3 After selecting SD Upscale at the bottom, tile overlap 64, scale factor2</p><p>caution! Sampler must be DPM++SDE karras.</p><p>clip skip 2</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/blob/main/vae-ft-mse-840000-ema-pruned.ckpt\">https://huggingface.co/stabilityai/sd-vae-ft-mse-original/blob/main/vae-ft-mse-840000-ema-pruned.ckpt</a> <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/AIARTCHAN/aichan_blend/tree/main/vae\">https://huggingface.co/AIARTCHAN/aichan_blend/tree/main/vae</a> Apply VAE. You will get better color results.</p><p>We recommend hiring and upscaling only the pictures whose faces are damaged from being far away.</p><p></p><p>As it is a semi-realistic model, we do not recommend inappropriate exposure.</p><p></p><p>There are other dos series as well.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6250/dosmix\">https://civitai.com/models/6250/dosmix</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6437/anidosmix\">https://civitai.com/models/6437/anidosmix</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8437/ddosmix\">https://civitai.com/models/8437/ddosmix</a></p><pre><code></code></pre><p><br /></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832393+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "27259",
    "prompt": "TMND-Mix\n<h1 id=\"heading-51\"><strong>Suggestion/Âª∫ËÆÆ</strong>:</h1><h3 id=\"heading-52\">Step 1/Á¨¨1Ê≠•: txt2img/ÊñáÁîüÂõæ:</h3><h3 id=\"heading-14\"><strong><span style=\"color:rgb(250, 82, 82)\">Negative prompt: (worst quality:2), (low quality:2), (normal quality:2)</span></strong></h3><p><span style=\"color:var(--block-title-text-color)\">Sampling steps/Ëø≠‰ª£Ê≠•Êï∞: 40-50</span></p><p>Hires. fix/È´òÂàÜËæ®Áéá‰øÆÂ§ç: On/ÂºÄ</p><p>Upscaler/ÊîæÂ§ßÁÆóÊ≥ï: R-ESRGAN 4x+ or <span style=\"color:rgb(31, 41, 55)\">4x-UltraSharp</span></p><p>Hires steps/È´òÂàÜËø≠‰ª£Ê≠•Êï∞: 20</p><p>Denoising strength/ÈáçÁªòÂπÖÂ∫¶: 0.2-0.4</p><h3 id=\"heading-53\">Step 2/Á¨¨2Ê≠•: Send to img2img/&gt;&gt; ÂõæÁîüÂõæ:</h3><p>Resize mode/Áº©ÊîæÊ®°Âºè: Just resize/‰ªÖË∞ÉÊï¥Â§ßÂ∞è</p><p>Denoising strength/ÈáçÁªòÂπÖÂ∫¶: 0.2-0.25</p><p>Script/ËÑöÊú¨: SD upscale/‰ΩøÁî®SDÊîæÂ§ß(Upscaler/ÊîæÂ§ßÁÆóÊ≥ï:R-ESRGAN 4x+ or <span style=\"color:rgb(31, 41, 55)\">4x-UltraSharp</span>)</p><p></p><h1 id=\"heading-54\"><strong>ËØ∑ÂãøÂïÜÁî®</strong></h1>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832409+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "13941",
    "prompt": "epi_noiseoffset\n<p><strong>UPDATE: v2-pynoise released, read the Version changes/notes</strong></p><p>LORA based on the <a target=\"_blank\" rel=\"ugc\" href=\"https://www.crosslabs.org//blog/diffusion-with-offset-noise\">Noise Offset post</a> for better contrast and darker images.</p><p></p><p>Weighting depends often on Sampler, kept it in the low-middle range (Maybe i will put up a stronger one).</p><p>Custom weighting is needed sometimes.</p><p>Works better if u use good keywords like: <code>dark studio, rim lighting, two tone lighting, dimly lit, low key</code> etc.</p><p></p><p>Didn't like the color saturation and image compositions from the <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8765/theovercomer8s-contrast-fix-sd15sd21-768\">theovercomer8sContrastFix_sd15</a> so i made this one.</p><p></p><p>UPDATE: v2 is slightly stronger in the whole composition</p><p>Update 2: added safetensor file</p><p></p><p><strong><em>Quick Comparsion</em></strong></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/af07d184-3f37-40bb-526e-a6cf9d41bf00/width=525/af07d184-3f37-40bb-526e-a6cf9d41bf00\" />",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832419+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "28169",
    "prompt": "CuteYukiMix(ÁâπÂåñÂèØÁà±È£éÊ†ºadorable styleÔºâ\n<h3 id=\"heading-9\"><strong><span style=\"color:#fa5252\">Ê†πÊçÆÂª∫ËÆÆÔºåËØ•ÁâàÂü∫‰∫éspecialchapterÁâàÊú¨ÊîπÈÄ†ÔºåÂú®È¢úËâ≤ÂíåËÇ¢‰ΩìÊñπÈù¢ÂùáÊúâ‰∏çÈîôÁöÑÊîπÂñÑÔºåËØ≠ÊÑèÊñπÈù¢Ë°®Áé∞ËâØÂ•Ω„ÄÇ</span></strong></h3><p><strong><em><span style=\"color:#e64980\">Based on the advice, this version is a transformation based on the special chapter version, showing significant improvements in both color and body language, while also performing well in conveying meaning.</span></em></strong></p><h3 id=\"heading-11\"><strong><span style=\"color:rgb(130, 201, 30)\">ÂÖ≥‰∫éÊñ∞ÁâàÊú¨ÁªòÂõæÂèÇÊï∞ÔºåÂª∫ËÆÆÁõ¥Êé•Â§çÂà∂ÊàëÂ±ïÁ§∫‰æãÂõæÁöÑÂèÇÊï∞„ÄÇËøôÊ¨°ÁâàÊú¨Êõ¥Êñ∞‰æùÊóßÊòØÂÖ≥‰∫éÊ∑∑ÂêàÁöÑnaiv3ÁîªÈ£éÔºå‰ª•ÂèäÂåÖÂê´‰∫ÜCuteyukimixÂâç‰ª£ÁâàÊú¨ÁöÑ‰ΩìÂûãÁ≠âÂà∂‰ΩúÁöÑÈ£éÊ†ºÊ®°ÂûãÔºåÁªô‰∏Ä‰ΩçÂ•ΩÂèãÂà∂‰ΩúÁöÑÁâπÊÆäÁâàÊú¨„ÄÇÊÄª‰ΩìÈ£éÊ†ºËøòÊòØÊØîËæÉËÆ®ÂñúÔºå‰ΩÜÊòØÁ®≥ÂÆöÊÄßËøòÂ≠òÂú®‰∏Ä‰∫õÊ¨†Áº∫ÔºåÂπ∂‰∏î‰ºò‰∫éÂâç‰ª£Â∞èÁâàÊú¨ÂêçÁß∞Â≠òÂú®‰∫âËÆÆÔºåËøô‰∏™ÁâàÊú¨ÊàëÂ∞±Â∞ÜÂÖ∂Ëµ∑Âêç‰∏∫Ëá™Â∑±ÁöÑÊòµÁß∞„ÄÇÂêéÁª≠Êàë‰ºöÂ∞Ü‰∏ä‰∏™ÁâàÊú¨‰∏éËøô‰∏™ÁâàÊú¨ÁöÑÊ®°Âûã‰ªéÂêÑ‰∏™ÊñπÈù¢ÊåÅÁª≠ËøõË°å‰ºòÂåñÔºåÂ§ßÂÆ∂ÂèØ‰ª•ÊúüÂæÖ‰∏Ä‰∏ã</span></strong></h3><h3 id=\"heading-11\"><strong><em><span style=\"color:rgb(121, 80, 242)\">Regarding the parameters for the new version of the drawing, I suggest directly copying the parameters shown in my example image.This update continues to focus on the hybrid Naiv3 art style, incorporating Cuteyukimix's predecessor's body shapes, crafted in a style tailored for a specific friend. Overall, the style remains quite appealing, yet stability still lacks in some areas, and there's controversy over the name in comparison to the previous minor versions. I've decided to name this version after my own nickname. Moving forward, I'll continuously optimize both this and the previous version's models in various aspects. Stay tuned for further improvements!</span></em></strong></h3><h3 id=\"heading-5\"><strong><span style=\"color:rgb(250, 176, 5)\">ÂèàÊòØËÆ∏‰πÖ‰∏çËßÅÔºÅ‰∏çÁü•ÈÅìÂ§ßÂÆ∂ËøôÊÆµÊó∂Èó¥ËøáÂæóÂ¶Ç‰ΩïÔºüÊÉ≥ÂøÖÂêÑ‰ΩçÊúãÂèãÂ∑≤ÁªèÂê¨ËØ¥NaiV3ÁâàÊú¨Â†ÇÂ†ÇÁôªÂú∫ÔºåÂú®ËøôÊÆµÊó∂Èó¥‰πüÂºïËµ∑‰∫Ü‰∏çÂ∞èÁöÑÊ≥¢ÊæúÔºåÂú®ÁªèËøáÂá†ËΩÆÁöÑ‰ΩìÈ™å‰ª•ÂêéÔºåÊÑüËßâÂÆÉÊòØÈùûÂ∏∏ÊúâË∂£‰∏î‰ºòÁßÄÁöÑÊ®°Âûã„ÄÇÊ≠§Ê¨°Êõ¥Êñ∞CuteyukimixÁâàÊú¨ÁÆóÊòØÁï™Â§ñ‰∏≠ÁöÑÁï™Â§ñÔºåÊòØÊàëÂú®Â∞ùËØï‰∫ÜÊúãÂèãÊ∑∑ÂêàÁöÑNaiV3ÁâàÊú¨ÁîªÈ£éÂêéÔºåËø∑‰∏ä‰∫ÜËØ•ÁîªÈ£éÁöÑÁ¨îËß¶‰∏éËâ≤ÂΩ©ÔºåÊÉ≥ÊûÅÂäõÊääÂÆÉÂ∏¶Âà∞1.5Ê®°ÂûãÔºåËÄå‰∫ßÁîüÁöÑËØ•ÁâàÊú¨„ÄÇËØ•ÁâàÊú¨Ê®°Âûã‰Ωú‰∏∫Âàù‰ª£ÁöÑÊµãËØïÁâàÊú¨ÔºåËøòÂ≠òÂú®‰∏Ä‰∫õÈóÆÈ¢òÔºå‰æãÂ¶Ç‰∫ÆÂ∫¶ÂÅèÈ´òÔºåÈ•±ÂíåÂ∫¶È´òÔºå‰ª•Âèä‰∏Ä‰∫õÊâãÈÉ®ÁªÜËäÇÈóÆÈ¢òÁ≠âÁ≠âÔºåÊé•‰∏ãÊù•Êàë‰πü‰ºöÊÉ≥ÂäûÊ≥ïÊåÅÁª≠ÂØπÂÆÉËøõË°åÊîπËøõÔºå‰∏çËøáÂÆÉÊòØ‰∏ÄÊ¨°ÈùûÂ∏∏ÊúâË∂£‰∏îÊúâÊÑè‰πâÁöÑÂ∞ùËØïÔºåÁ°ÆÂÆûÂ∞ÜÊàëÂñúÊ¨¢ÁöÑÁîªÈ£éÂ∏¶Âà∞‰∫Ü1.5Ê®°Âûã‰∏äÔºå‰πüËÆ©ÊàëÁúãÂà∞‰∫Ü1.5Ê®°ÂûãÊõ¥Â§öÁöÑÊΩúÂäõ„ÄÇÊúÄÂêéÁ•ùÊÑøÂ§ßÂÆ∂Áé©ÁöÑÂºÄÂøÉÔºÅ</span></strong></h3><p><strong><em><span style=\"color:rgb(130, 201, 30)\">Long time no see! I hope everyone has been doing well during this period. You've probably heard about the grand entrance of the NaiV3 version, which has caused quite a stir. After several rounds of exploration, I find it to be a fascinating and outstanding model. The Cuteyukimix version, introduced in this update, is like a special edition. After experimenting with a friend's hybrid NaiV3 version art style, I became captivated by its brushstrokes and colors. I was eager to bring this style to the 1.5 model, giving rise to this version. As a preliminary test version, it does have some issues like high brightness, saturation, and minor hand details. I'll continue working on improving it, but it's a fun and intentional experiment. It successfully translates the art style I love onto the 1.5 model, revealing even more potential. Lastly, I wish everyone a joyful experience with it!</span></em></strong></p><h3 id=\"heading-30\"><strong><span style=\"color:rgb(21, 170, 191)\">ËÆ∏‰πÖ‰∏çËßÅÔºÅËøôÊÆµÊó∂Èó¥Âøô‰∫éÁîüÊ¥ªÂÖ∂‰ªñ‰∫ãÊÉÖÔºå‰πüÊòØÊäΩÂá∫Á©∫Èó≤ËÉΩÂõûÊù•ÁªßÁª≠Á†îÁ©∂ÂñúÊ¨¢ÁöÑÊ®°ÂûãÔºåÊõ¥Êñ∞‰ΩúÂìÅ„ÄÇÊñ∞ÁâàÊú¨Ê®°ÂûãÊòØÂü∫‰∫éNeochapter3ËøõË°å‰∫ÜÊîπÂä®ÔºåÂØπclipÂÅö‰∫ÜÊØîËæÉÂ§ßÁöÑË∞ÉÊï¥ÔºåËØ≠‰πâË°®Áé∞ËÉΩÂäõÂæóÂà∞‰∫ÜÂä†Âº∫ÔºåÂπ∂‰∏îÂØπÊúâ‰∫õÊ≥õÁôΩÁöÑ‰ΩéÂØπÊØîÂ∫¶ËøõË°å‰∫Ü‰∏ÄÂÆöÊîπÂñÑÔºåÂπ∂‰∏î‰ΩøËÑ∏ÂûãÊõ¥Êé•ËøëMidchapterÁâàÊú¨ÁöÑÂúÜÂúÜËÑ∏ÔºåÊõ¥Âä†ÂèØÁà±ÔºåÂØπÁâπÊÆä‰ΩìÂûãÁöÑË°®Áé∞ËÉΩÂäõ‰πüÊõ¥Âä†Êé•ËøëMidchapterÁ≥ªÂàó„ÄÇ</span></strong></h3><p><strong><em><span style=\"color:rgb(18, 184, 134)\">Long time no see! During this period, I've been busy with other aspects of life but managed to find some time to continue my research on the models I love and update my work. The new version of the model has been modified based on Neochapter3, with significant adjustments made to CLIP, enhancing its semantic expressive ability. Additionally, improvements have been made to certain washed-out low contrast areas, making the facial features closer to the round face of the Midchapter version, which is even cuter. The model's ability to represent special body types is also more akin to the Midchapter series.</span></em></strong></p><h3 id=\"heading-204\"><span style=\"color:rgb(64, 192, 87)\">midchapter3Âú®2ÁöÑÂü∫Á°Ä‰∏äÊâ©ÂÖÖ‰ΩìÂûãËåÉÂõ¥ÔºåËôΩÁÑ∂‰æùÊóßÂ±û‰∫éÁâπÂåñÊ®°ÂûãÔºå‰ΩÜÊÄª‰ΩìÊõ¥ÂÅèÂêë‰∫éÂØπÊèêÁ§∫ËØçÊúâÊõ¥Â•ΩÁöÑÁÅµÊïèÂ∫¶ÔºåËÉΩËææÂà∞ÁöÑ‰∏äÈôêÊõ¥È´òÔºåÂ∏∏ÊÄÅÂåñÊØîËµ∑‰πãÂâç‰∏§‰∏™ÁâàÊú¨Âº±ÂåñÔºå‰æùÊóßÂª∫ËÆÆ‰ΩøÁî®naiÁöÑvae„ÄÇ</span></h3><p><strong><em><span style=\"color:rgb(18, 184, 134)\">The¬†midchapter3¬†model¬†expands¬†its¬†body¬†size¬†range¬†based¬†on¬†the¬†foundation¬†of¬†version¬†2.¬†While¬†it¬†still¬†falls¬†under¬†the¬†category¬†of¬†specialized¬†models,¬†it¬†is¬†generally¬†more¬†inclined¬†towards¬†better¬†sensitivity¬†to¬†prompt¬†words¬†and¬†can¬†reach¬†higher¬†limits.¬†Normalization¬†has¬†been¬†weakened¬†compared¬†to¬†the¬†previous¬†two¬†versions.¬†It¬†is¬†still¬†recommended¬†to¬†use¬†NAI's¬†VAE.</span></em></strong><br /></p><h3 id=\"heading-205\"><strong><span style=\"color:rgb(121, 80, 242)\">Midchapter2ÁâàÊú¨ÂØπÊîπÂèò‰ΩìÂûãÁöÑÁ¥†ÊùêËøõË°åÈáçÊñ∞ÂàÜÂ±ÇË∞ÉÊï¥ÔºåÂπ∂‰∏î‰πüÂØπÂü∫Á°ÄÈÖçÊñπËøõË°åÊîπÂèòÔºåÂ∞ΩÈáè‰øùËØÅÁ®≥ÂÆöÁöÑÂΩ¢ÊÄÅÔºå‰ª•Êª°Ë∂≥ÂêÑÁßçÁî®Êà∑ÁöÑÈúÄÊ±ÇÔºåÂπ∂‰∏îÂØπËÉåÊôØÂçïË∞ÉÁöÑÈóÆÈ¢ò‰πüÂÅö‰∫Ü‰∏Ä‰∫õÊîπÂñÑ„ÄÇ</span></strong></h3><h3 id=\"heading-206\"><strong><em><span style=\"color:rgb(76, 110, 245)\">The Midchapter2 version re-layers and adjusts the materials that change the body shape, and also changes the basic formula to ensure a stable shape as much as possible to meet the needs of various users, and also makes some improvements to the problem of monotonous background.</span></em></strong></h3><h3 id=\"heading-207\"><strong><span style=\"color:rgb(18, 184, 134)\">Êñ∞ÁâàÊú¨ÂÅö‰∫Ü‰ΩìÂûãÁâπÂåñÂ§ÑÁêÜÔºåÂ∏∏ÊÄÅÂåñ‰ΩìÂûãÊõ¥ÂèØÁà±Â∞èÂ∑ßÔºåÂØπÁâπÊÄßÊèêÁ§∫ËØçÊïèÊÑüÂ∫¶ËæÉÈ´òÔºå‰∏çÂêåÁöÑÊùÉÈáçÈÉΩÊúâ‰∏çÈîôÁöÑÊïàÊûúÔºåÂπ∂‰∏îÂØπÈ¢úËâ≤È•±ÂíåÂ∫¶‰πüÂä†‰∫ÜË∞ÉÊï¥Ôºå‰ΩøÂÖ∂È¢úËâ≤ÁúãËµ∑Êù•Êõ¥ËàíÊúç„ÄÇÂ∑≤Êõ¥Êñ∞ÂåÖÂê´VAEÁöÑÁâàÊú¨Âú®files„ÄÇ</span></strong></h3><h3 id=\"heading-208\"><strong><em><span style=\"color:rgb(18, 184, 134)\">The new version strengthens the cute features to make it more in line with the cute style, and strengthens the color contrast to make the visual effect better.Updated version containing VAE in files.</span></em></strong></h3><h3 id=\"heading-209\"><span style=\"color:rgb(34, 139, 230)\">NeoChapter3ÁâàÊú¨Âú®ÁâàÊú¨2ÁöÑÂü∫Á°Ä‰∏äÔºåÂú®1‰∏™ËæìÂÖ•Â±ÇÂíå2‰∏™ËæìÂá∫Â±ÇËøõË°å‰∫ÜË∞ÉÊï¥ÔºåÂ∞ùËØï‰øÆÂ§ç‰∫ÜËÇ¢‰ΩìÂíåËøúÊôØÊâãÈÉ®Â¥©ÂùèÊÉÖÂÜµÔºåÂπ∂‰∏îÂ¢ûÂä†‰∫ÜÁªÜËäÇ(ÂåÖÊã¨ËÑ∏ÈÉ®‰ª•Âèä‰∫∫Áâ©Ë∫ØÂπ≤„ÄÅË°£ÊúçÂèäÂú∫ÊôØÁªÜËäÇ)Ôºå‰ª•ÂèäÂØπÊï¥‰ΩìÊûÑÂõæËøõË°å‰∫ÜÊîπÂñÑÔºåÂπ∂‰∏îËÄÉËôëÂà∞ËÆ≠ÁªÉTEÁöÑÂõ†Á¥†ÔºåÂ∞ÜclipÊç¢ÂõûËÆ≠ÁªÉÊó∂ÂéüÂßãÁöÑclipÔºå‰ª•‰æøÊõ¥Â•ΩÂú∞Ë¥¥ÂêàtagË°®Áé∞ÔºåËÉΩÁîªÂá∫ÁâàÊú¨2‰∏Ä‰∫õÊó†Ê≥ïË°®Áé∞ÁöÑÁâπÊÄßÔºåÊúâÂ∞Ü‰∏â‰∏™ÁâàÊú¨ÂÅöxyÂõæÔºåÂØπÊØîÂÖ∂ÁªÜËäÇÊûÑÂõæÂèòÂåñÔºåÂèäËÇ¢‰ΩìÊîπÂñÑÔºåÊîæÂú®Á§∫‰æãÂõæÁâáÊúÄÂêé‰∏ÄÂº†„ÄÇÂ∑≤‰∏ä‰º†Ê≤°ÊúâÂµåÂÖ•VAEÁöÑÁâàÊú¨Âú®filesÈáåÔºåÊÇ®ÂèØ‰ª•Ê†πÊçÆËá™Â∑±ÁöÑÂñúÂ•ΩÈöèÊÑèÊåÇËΩΩÊàñÂµåÂÖ•ÂêàÈÄÇÁöÑVAE„ÄÇ</span></h3><h3 id=\"heading-210\"><strong><em><span style=\"color:rgb(230, 73, 128)\">The NeoChapter3 version has been adjusted based on version 2, with modifications made to one input layer and two output layers. It attempts to fix issues with limb and distant hand distortion, while also adding more details, such as facial features, character torso, clothing, and scene details. The overall composition has been improved, taking into consideration the training factors of TE. In order to better align with tag performance, the clips have been reverted back to their original training state, allowing for the portrayal of certain characteristics that version 2 was unable to depict. Three versions are then depicted in an XY graph, comparing the changes in detailed composition and limb improvement. This is shown on the last example image.The uploaded version without VAE is in the files, you can mount or embed the appropriate VAE according to your preference.</span></em></strong></h3><h3 id=\"heading-211\"><strong><span style=\"color:rgb(130, 201, 30)\">ÂÖ≥‰∫éNeoChapter2ÁâàÊú¨Ê®°ÂûãÔºåÂ¢ûÂº∫‰∫ÜËÑ∏ÈÉ®ÁªÜËäÇÔºåÁõ∏ËæÉ‰∫é‰∏ä‰∏™ÁâàÊú¨ËÑ∏ÈÉ®ÁªÜËäÇÊ®°Á≥äÊÉÖÂÜµËøõË°å‰∫ÜÊîπÂñÑÔºåÊï¥‰ΩìËøëËøúÊôØÁªÜËäÇ‰∏∞ÂØåÂ∫¶‰πüÊúâÊèêÂçáÔºåËøÅÁßª‰∫ÜclipÂä†Âº∫‰∫ÜÂØπËØ≠ÊÑèÁöÑÁêÜËß£ËÉΩÂäõÔºåÊõ¥Â•ΩÁöÑË¥¥ÂêàtagÊèêÁ§∫ËØçÔºåËÇ¢‰Ωì‰∏äËøõË°å‰∫ÜÂä†Âº∫ÔºåÂπ∂‰∏îÂØπ‰∫éÊâãÈÉ®ÂàªÁîª‰πüËøõË°å‰∫Ü‰∏ÄÂÆöÁöÑ‰øÆÂ§ç„ÄÇËâ≤Ë∞ÉÊòé‰∫ÆÂ∫¶Á®çÊúâÊèêÂçá„ÄÇÂ∑≤Â∞ÜÂê´ÊúâVAEÁöÑÁâàÊú¨ÊõøÊç¢‰∫ÜfilesÈáåÁöÑVAEÊñá‰ª∂ÔºåÂÜÖÁΩÆanimeave.pt„ÄÇ</span></strong></h3><h3 id=\"heading-212\"><strong><em><span style=\"color:rgb(230, 73, 128)\">Regarding the NeoChapter2 version of the model, there have been enhancements made to facial details. Improvements have been made to address the issue of blurry facial details compared to the previous version. There is also an overall increase in the richness of details in both close-up and distant views. The integration of CLIP has further strengthened its understanding of semantics, resulting in better alignment with tag prompts. There have been improvements in depicting body movements and some fixes have been made to hand gestures as well.Additionally, there has been a slight increase in brightness levels.The version containing the VAE has been replaced with the VAE file in the \"files\" section, which is named </span></em></strong><a target=\"_blank\" rel=\"ugc\" href=\"http://animeave.pt\"><strong><em><span style=\"color:rgb(230, 73, 128)\">animeave.pt</span></em></strong></a><strong><em><span style=\"color:rgb(230, 73, 128)\">.</span></em></strong></h3><h3 id=\"heading-213\"><strong><span style=\"color:rgb(121, 80, 242)\">ÂÖ≥‰∫éÊñ∞Á´†ÁâàÊú¨ÔºåÂÅö‰∫Ü‰∏Ä‰∫õÈ£éÊ†º‰∏äÁöÑÊîπÂä®ÔºåÊÇ®Âú®‰ΩøÁî®ÂÆÉÁîüÊàêÂõæÂÉèÊó∂ÂèØ‰ª•ÊÑüÂèóÂà∞‰∏é‰πãÂâçÁâàÊú¨ÁöÑÂ∑ÆÂºÇÔºåÊâ©ÂÖÖ‰∫Ü‰∫∫Áâ©ÁöÑ‰ΩìÂûãÔºå‰ΩÜÊòØ‰øùÁïô‰∫ÜÂèØÁà±ÁöÑËÑ∏ÂûãÔºåÊï¥‰ΩìËâ≤Ë∞ÉÂÅèÊ∑°ÔºåÂ¶ÇÊûúÊÇ®ÊÉ≥Ë¶ÅÁîüÊàêÊõ¥È≤úËâ≥ÁöÑÂõæÂÉèÔºåÂª∫ËÆÆÊÇ®ÈÖçÂêàÂÖ∂‰ªñvae‰ΩøÁî®ÔºåÂπ∂‰∏îÂú®ÂêéÁª≠ÁöÑÁâàÊú¨Êàë‰πü‰ºöÂØπÈ¢úËâ≤ÊåÅÁª≠Ë∞ÉÊï¥‰ª•ËææÂà∞ÊúÄÂ•ΩÁöÑÊïàÊûúÔºåÈ°∫Â∏¶‰∏ÄÊèêÔºåÊñ∞ÁâàÊú¨ÁîüÊàêÁöÑËÑ∏ÁúüÁöÑÂæàÂèØÁà±ÔºåÊúüÂæÖÊÇ®‰ΩøÁî®‰ª•ÂêéÁöÑÂèçÈ¶à„ÄÇÂ∑≤‰∏ä‰º†.ckptÂåÖÂê´vaeÁöÑÁâàÊú¨ÔºåÂèØÂú®filesÈáåÈù¢ÈÄâÊã©‰∏ãËΩΩ„ÄÇ</span></strong></h3><h3 id=\"heading-214\"><strong><em><span style=\"color:rgb(230, 73, 128)\">Regarding the NeoChapter version, some stylistic changes have been made. You will notice a difference in the generated images compared to the previous version. The body proportions of the characters have been expanded while retaining their cute facial features. The overall color palette leans towards lighter tones. If you prefer more vibrant images, it is recommended to use other VAEs in conjunction with this version. In future updates, I will continue to fine-tune the color settings to achieve the best results. By the way, the faces generated by the new version are really adorable. I look forward to receiving your feedback after you've tried it out.The .ckpt file has been uploaded, which contains the version of VAE. You can choose to download it from the \"files\" section.</span></em></strong></h3><h3 id=\"heading-215\"><strong>ÂÖ≥‰∫éÊñ∞ÁâàÊú¨ÔºåÊàëÂ∞ÜÂú®‰ªãÁªçÈ°µÈù¢ÂçïÁã¨‰∏∫ÂÆÉÂÜôÁõ∏ÂÖ≥‰ªãÁªçÔºåÂ∏åÊúõÊÇ®ÂèØ‰ª•‰∫ÜËß£ÂÆÉÁöÑËØ¶ÊÉÖ‰ª•ÂèäÊÑüÂèóÂà∞ÂÆÉ</strong></h3><h3 id=\"heading-216\"><strong><em><span style=\"color:rgb(34, 139, 230)\">Regarding the new version, I will write a separate introduction for it on the introduction</span></em></strong></h3><h3 id=\"heading-217\"><strong>ÁöÑÈ≠ÖÂäõ„ÄÇ</strong></h3><h3 id=\"heading-218\"><strong><em><span style=\"color:rgb(34, 139, 230)\">page. I hope you can learn the details and feel its charm.</span></em></strong></h3><h3 id=\"heading-219\"><strong>Áõ∏ËæÉ‰∫é‰πãÂâçËµõÁíêÁíê‰ª•ÂèäÂπ≥Ê∂ÇÈ£éÊ†ºÁöÑÊ®°ÂûãÔºåÊàëÂØπËØ•Á≥ªÂàóÊ®°ÂûãÂú®ÁªÜËäÇ‰ª•ÂèäËâ≤Ë∞É‰∏äËøõË°å‰∫ÜÂä†Âº∫ÔºåÊÇ®</strong></h3><h3 id=\"heading-220\"><strong><em><span style=\"color:rgb(34, 139, 230)\">Compared to the previous models, such as Sally and the flat painting style, I have</span></em></strong></h3><h3 id=\"heading-221\"><strong>Âú®‰ΩøÁî®ËØ•Ê®°ÂûãÁöÑËøáÁ®ã‰∏≠Â∫îËØ•‰ºöÊÑüÂèóÂà∞ÊØî‰ª•ÂæÄÁâàÊú¨Êõ¥Â§öÁöÑÁªÜËäÇÂëàÁé∞Ôºå‰ª•ÂèäÊõ¥Âä†ËàíÈÄÇÁöÑËâ≤ÂΩ©„ÄÇÂπ∂</strong></h3><h3 id=\"heading-222\"><strong><em><span style=\"color:rgb(34, 139, 230)\">enhanced the series in terms of details and color tones.When using this model, you</span></em></strong></h3><h3 id=\"heading-223\"><strong>‰∏îÂú®ÁîªÈ£éÊñπÈù¢ËæÉ‰ª•ÂâçÁï•ÊòæÁîüÁ°¨ÁöÑÂú∞ÊñπÂÅö‰∫ÜÂúÜÊ∂¶ÂåñÂ§ÑÁêÜÔºå‰ΩøÂÖ∂Êõ¥Á¨¶ÂêàcuteÈ£éÊ†º„ÄÇ</strong></h3><h3 id=\"heading-224\"><strong><em><span style=\"color:rgb(34, 139, 230)\">should experience more detailed representation and more comfortable colors than in</span></em></strong></h3><h3 id=\"heading-225\"><strong>ÊàëÁõ∏‰ø°ÔºåÂØπ‰∫éÂñúÊ¨¢Ëøô‰∏ÄÈ£éÊ†ºÁ≥ªÂàóÊ®°ÂûãÁöÑÁî®Êà∑Êù•ËØ¥ÔºåÊÇ®‰ª¨ÈÉΩÂØπÂèØÁà±ÁöÑ‰∫ãÁâ©ÂÖÖÊª°ÁÉ≠Áà±„ÄÇÊàëÂ∏åÊúõËøô</strong></h3><h3 id=\"heading-226\"><strong><em><span style=\"color:rgb(34, 139, 230)\">previous versions. I have made the style smoother, giving it a more fitting cute</span></em></strong></h3><h3 id=\"heading-227\"><strong>‰∏ÄÊ®°ÂûãËÉΩÂ∏ÆÂä©ÊÇ®‰ª¨Âàõ‰ΩúÂá∫Â±û‰∫éËá™Â∑±ÁöÑÊúÄ‰Ω≥‰ΩúÂìÅ„ÄÇÂêåÊó∂ÔºåÊàë‰πü‰ºö‰∏çÊñ≠ÂØπËØ•Á≥ªÂàóÊ®°ÂûãËøõË°å‰ºòÂåñ„ÄÇ</strong></h3><h3 id=\"heading-228\"><strong><em><span style=\"color:rgb(34, 139, 230)\">aesthetic.I believe that those who appreciate this style of models have a deep love for</span></em></strong></h3><h3 id=\"heading-229\"><strong>Â¶ÇÊûúÊÇ®Êúâ‰ªª‰ΩïÈóÆÈ¢òÔºåËØ∑Âú®ËØÑËÆ∫Âå∫‰∏éÊàë‰∫§ÊµÅ„ÄÇ</strong></h3><h3 id=\"heading-230\"><strong><em><span style=\"color:rgb(34, 139, 230)\">adorable things. I hope this model can help you create your best works that truly belong to you. Furthermore, I will continue to optimize this series of models. If you have any questions, please feel free to communicate with me in the comments section.</span></em></strong></h3><h3 id=\"heading-231\"></h3><h3 id=\"heading-232\"><strong>Ëøô‰∏™Ê®°ÂûãÊòØÁßÅÁÇâÁöÑ‰∫ßÁâ©ÔºåÊï¥‰ΩìÈ£éÊ†ºÂÅèÂπºÂåñ„ÄÇÂÆÉÂèØ‰ª•ÊØîËæÉËΩªÊùæÁöÑÁîªÂá∫ÂèØÁà±È£éÊ†ºÁöÑ‰∫∫Áâ©Ôºå‰ΩÜÂπ∂ÈùûÂè™ËÉΩÁîªËêùËéâÈ£éÊ†º‰∫∫Áâ©ÔºåÊÇ®ÂèØ‰ª•Â∞ùËØïÂêÑÁßçÊúâÊÑèÊÄùÁöÑpromptÔºåÂπ∂‰∏îÂÆÉÁîªÈ£éÊôØ(ËÉåÊôØ)ÊïàÊûú‰πüÂæàÂ•Ω„ÄÇ<br />ÂÖ≥‰∫év2ÁâàÊú¨ÔºåÂ¢ûÂº∫Á®≥ÂÆöÊÄß‰ª•ÂèäÁªÜËÖªÁ®ãÂ∫¶ÔºåÊé®ËçêÂèÇÊï∞Â¶Ç‰∏ã:</strong>Steps:¬†20-30,¬†Sampler:¬†DPM++¬†SDE¬†Karras,¬†CFG¬†scale:¬†7,¬†Size:¬†512x768,¬†Denoising¬†strength:¬†0.6,¬†Clip¬†skip:¬†2,¬†Hires¬†upscale:¬†2,¬†Hires¬†steps:¬†10-25,¬†Hires¬†upscaler:¬†R-ESRGAN¬†4x+¬†Anime6B.<br /><strong>Negative prompt:</strong>NG_DeepNegative_V1_75T, EasyNegative, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, (worst quality, low quality:1.4), (bad anatomy), (inaccurate limb:1.2), bad composition, inaccurate eyes, extra digit,fewer digits, (extra arms:1.2), (bad-artist:0.6), bad-image-v2-39000<br /><br /><strong>The¬†reason¬†for¬†this¬†model's¬†name¬†is¬†that¬†it¬†can¬†easily¬†create¬†cute-style¬†images,¬†and¬†its¬†overall¬†color¬†tone¬†is¬†also¬†visually¬†appealing,¬†making¬†it¬†suitable¬†for¬†landscape-style¬†pictures¬†as¬†well.¬†We¬†hope¬†you'll¬†enjoy¬†it!<br />Regarding¬†the¬†V2¬†version,¬†to¬†enhance¬†stability¬†and¬†delicacy,¬†the¬†recommended¬†parameters¬†are¬†as¬†follows:</strong><br />Steps:¬†30,¬†Sampler:¬†DPM++¬†SDE¬†Karras,¬†CFG¬†scale:¬†7,¬†Size:¬†512x768,¬†Denoising¬†strength:¬†0.57,¬†Clip¬†skip:¬†2,¬†Hires¬†upscale:¬†2,¬†Hires¬†steps:¬†25,¬†Hires¬†upscaler:¬†R-ESRGAN¬†4x+¬†Anime6B.<br /><strong>Negative prompt:</strong>NG_DeepNegative_V1_75T, EasyNegative, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, (worst quality, low quality:1.4), (bad anatomy), (inaccurate limb:1.2), bad composition, inaccurate eyes, extra digit,fewer digits, (extra arms:1.2), (bad-artist:0.6), bad-image-v2-39000</h3>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832446+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "84728",
    "prompt": "Photon\n<p><strong>Photon</strong> aims to generate photorealistic and visually appealing images effortlessly.</p><p>Recommendation for generating the first image with Photon:</p><ul><li><p><strong>Prompt:</strong> A simple sentence in natural language describing the image.</p></li><li><p><strong>Negative:</strong> \"<em>cartoon, painting, illustration, (worst quality, low quality, normal quality:2)</em>\"</p></li><li><p><strong>Sampler:</strong> DPM++ 2M Karras | Steps: 20 | CFG Scale: 6</p></li><li><p><strong>Size:</strong> 512x768 or 768x512</p></li><li><p><strong>Hires.fix:</strong> R-ESRGAN 4x+ | Steps: 10 | Denoising: 0.45 | Upscale x 2</p></li><li><p>(avoid using negative embeddings <span style=\"color:rgb(209, 213, 219)\">unless absolutely necessary</span>)</p></li></ul><p>From this initial point, experiment by adding positive and negative tags and adjusting the settings. Most of the sample images follow this format.</p><h3 id=\"heading-6\">Development</h3><p>The development process was somewhat chaotic but essentially:</p><ul><li><p>It started from an old mix.</p></li><li><p>LORAs were trained on various topics using AI-generated photorealistic images.</p></li><li><p>These LORAs were mixed within the model using different weights.</p></li><li><p>In the midst of this mixing, hand generation broke.</p></li><li><p>LORAs were generated and remixed in an attempt to fix hand generation (not entirely successful).</p></li></ul><p>In future versions, I will try to:</p><ul><li><p>Completely eliminate the need for a negative prompt to generate high-quality images.</p></li><li><p>Fix the hand generation issue to minimize instances of poorly drawn hands.</p></li><li><p>Explore more automated training processes. I would love to have <span style=\"color:rgb(209, 213, 219)\">5,000 or 50,000 high-quality AI-generated photorealistic images for training purposes.</span></p></li></ul><p>I hope you enjoy using it as much as I enjoyed creating it! If you have any questions or suggestions, feel free to share. Have fun creating amazing images! üé®</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832466+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "47130",
    "prompt": "Realisian\n<h3 id=\"recommended-settings-1febuf5dn\">‚ñº <strong>Recommended Settings </strong>‚ñº</h3><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cc450b88-033c-4917-8e86-658435fb276b/width=525/cc450b88-033c-4917-8e86-658435fb276b.jpeg\" /></p><p><strong>Negative Prompt</strong></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/289190/realisian-negative-embedding\">Realisian-Neg</a></p></li></ul><p><strong>Sampling Method</strong></p><ul><li><p>DPM++ SDE Karras</p></li></ul><p><strong>Sampling Steps</strong></p><ul><li><p>12 (8 ‚âà 16)</p></li></ul><p><strong>Restore Faces</strong></p><ul><li><p>Off</p></li></ul><p><strong>Hires Fix (<u><span style=\"color:rgb(250, 82, 82)\">! Required !</span></u>)</strong></p><ul><li><p>On</p></li><li><p>Upscaler: Latent (bicubic antialised)</p></li><li><p>Hires Steps: 5 (4 ‚âà 10)</p></li><li><p>Denoising Strenght: 0.55 (0.4 ‚âà 0.7)</p></li><li><p>Upscale by: 2</p></li></ul><p><strong>CFG Scale</strong></p><ul><li><p>3 (2 ‚âà 5)</p></li></ul><p><strong>Clip Skip</strong></p><ul><li><p>1 (1 ‚âà 2)</p></li></ul><p><strong>VAE</strong></p><ul><li><p>None (Baked)</p></li></ul><p></p><h3 id=\"merge-based-on-eeyyadih1\">‚ñº <strong>Merge Based On </strong>‚ñº</h3><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6424\">ChilloutMix</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9052\">LOFI</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/18427\">È•≠ÁâπÁ®Ä</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/43331\">majicMIX realistic</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/22922\">Lyriel</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/25494\">BRA (Beautiful Realistic Asians)</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7371\">ReV Animated</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/22402/fantasticmix\">fantasticmix</a></p></li></ul><p></p><h3 id=\"more-info-052yxar65\">‚ñº <strong>More Info </strong>‚ñº</h3><ul><li><p><strong>Any questions or suggestions you can contact me through Discord </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://discordapp.com/users/62236703754035200\"><strong>Cisney Gassai#5108</strong></a><strong> or Twitter </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://twitter.com/Realisian\"><strong>@Realisian</strong></a><strong>.</strong></p></li><li><p><strong>For donations or requests you can do it on my </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/cisneygassai\"><strong>Ko-fi page</strong></a><strong> &lt;3.</strong></p></li></ul><h3 id=\"-4upnrrp26\"><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/cisneygassai\"><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6289b7c5-3220-47cf-873d-bf5c54dd41a6/width=525/6289b7c5-3220-47cf-873d-bf5c54dd41a6.jpeg\" /></a></h3><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/cisneygassai\"><strong>https://ko-fi.com/cisneygassai</strong></a></p></li></ul>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832480+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "6174",
    "prompt": "DivineEleganceMix\n<p>If you ran into any troubles with my mix, please read description below. There is plenty of useful information. Also, you can contact me through message system on CivitAI.</p><p>–ï—Å–ª–∏ –≤—ã —Å—Ç–æ–ª–∫–Ω—É–ª–∏—Å—å —Å –∫–∞–∫–∏–º-–ª–∏–±–æ –ø—Ä–æ–±–ª–µ–º–∞–º–∏ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –º–æ–µ–≥–æ –º–∏–∫—Å–∞, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ—á–∏—Ç–∞–π—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∏–∂–µ. –¢–∞–º –µ—Å—Ç—å –º–Ω–æ–≥–æ –ø–æ–ª–µ–∑–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –¢–∞–∫–∂–µ –≤—ã –º–æ–∂–µ—Ç–µ —Å–≤—è–∑–∞—Ç—å—Å—è —Å–æ –º–Ω–æ–π —á–µ—Ä–µ–∑ —á–∞—Ç –Ω–∞ CivitAI.</p><p></p><p><span style=\"color:rgb(193, 194, 197)\">Also try: </span><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/95587/divineanimemix\">DivineAnimeMix!</a></p><p></p><hr /><p></p><p><strong>Introduction:</strong></p><p></p><p>All models i've used before first release of DIvineElegance did not fit my requirements. I've decided to do something on my own to fix this issue. There was a lot of different mixes based on Anything v3 or v4 and i've taken it as a base as well.</p><p>At the beginning, it was a mix for my personal use, but it was warmly received by Unstable Diffusion discord community and some time later i've decided to share it here, on CivitAI.</p><p>Right now Divine series is my favorite models and quite unique thing for me. The main goal of DivineElegance - anime characters with as many details as it could have. Hair, clothes, backgrounds, all of this things should be beautiful, slightly more realistic and detailed.</p><p>I hope you also would like DivineElegance, so, stay tuned for newer versions of mix!</p><p></p><hr /><p></p><p><strong>Recommendations:</strong></p><ul><li><p>Use danbooru tagging for prompts</p></li><li><p>Do -&gt;not&lt;- use \"masterpiece\" or \"best quality\" tags (v9+)</p></li><li><p>Sampler: \"Euler a\" at / 30 steps</p></li><li><p>Cfg scale: 8</p></li><li><p>Clip Skip: 2 &lt;---- VERY IMPORTANT</p></li><li><p>99% of anime models only works with clip skip set to 2</p></li><li><p>ENSD (Eta noise seed delta) - leave blank</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/blob/main/vae/kl-f8-anime2.ckpt\">kl-f8-anime2 VAE</a></p></li><li><p>Negatives: <code>(EasyNegative:0.8), (worst quality, low quality:1.2), blurry, bokeh, dof, fog</code></p></li></ul><p></p><p><strong>Recommendations (Hires Fix)</strong>:</p><ul><li><p>Upscaler: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/FacehugmanIII/4x_foolhardy_Remacri/resolve/main/4x_foolhardy_Remacri.pth\">Remacri</a></p></li><li><p>Hires steps: 10-15</p></li><li><p>Denoising strength: 0.3</p></li><li><p>Upscale by: <em>any</em></p></li></ul><p></p><hr /><p></p><p><strong>Troubleshoot:</strong></p><p>My colors are bleached out. What should i do?</p><ul><li><p>You're missing a VAE file. For this mix i would recommend kl-f8-anime2 VAE. Just put it into SD folder -&gt; models -&gt; VAE folder. Then go to your WebUI, Settings -&gt; Stable Diffusion on the left list -&gt; SD VAE, choose your downloaded VAE.</p></li></ul><p></p><p>If you want to get mostly the same results, you definitely will need negative embedding:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\">EasyNegative</a>, it's better to use it at 0.8 weight.</p></li></ul><p></p><p><strong>Don't use</strong> EasyNegative (or other embeddings) with Style LoRAs, it may ruin the style!</p><ul><li><p>Until you like the result, of course.</p></li></ul><p></p><p><strong>Don't use</strong> a lot negative embeddings at the same time. It definitely will ruin any possible output on all models! If you want to use negative embeddings - use one for quality, and one for hands (if you want a placebo for hands).</p><p></p><hr /><p></p><p><strong>Technical support:</strong></p><p><span style=\"color:rgb(134, 142, 150)\">If you're ran into any problem with my mix, you can DM me on </span><strong><span style=\"color:rgb(134, 142, 150)\">discord</span></strong><span style=\"color:rgb(134, 142, 150)\">:</span></p><p><strong>troubledarkness</strong> - <span style=\"color:rgb(134, 142, 150)\">discord nickname.</span></p><p></p><p>I'll be glad to help | –ë—É–¥—É —Ä–∞–¥ –ø–æ–º–æ—á—å.</p><p></p><hr /><p></p><p><strong>Credits:</strong></p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://docs.google.com/document/d/1Mc3x-EKSrOFgIo6tBxQZZprFZWnAb9J0Jms_-CUZ1Oo/edit?usp=sharing\">DivineEleganceMix Recipes (pre-v6)</a></p><p></p><p>Really BIG thanks to:</p><ul><li><p>Nigurumi for<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nuigurumi/basil_mix\"> BasilMix</a></p></li><li><p>WarriorMama777 for <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs\">AbyssOrangeMixes</a> and recipes</p></li><li><p>andite for <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/anything-v4.0/blob/main/anything-v4.5.ckpt\">Anything4.5</a>/<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/yohan-diffusion/blob/main/Cocoa.ckpt\">Cocoa</a>/<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/pastel-mix\">PastelMix</a></p></li><li><p>Ikena for <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2583/grapefruit-hentai-model\">Grapefruit</a></p></li><li><p>Cyria for <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16161/zerotolerances\">ZeroTolerances</a></p></li><li><p>devdevice545734 for <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7152/facebombmix\">FaceBombMix</a></p></li><li><p>You, for reading, downloading and reviewing this mix</p></li></ul>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832501+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "72437",
    "prompt": "BadDream + UnrealisticDream (Negative Embeddings)\n<h1>Bad Dream + <a rel=\"ugc\" href=\"https://civitai.com/models/72437?modelVersionId=77173\">Unrealistic Dream</a></h1><h2>(Negative Embeddings, make sure to grab BOTH)</h2><p><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> üÖøÔ∏è or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> ‚òï</strong></p><p><br />Since I was refactoring my usual negative prompt with <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/71961/fast-negative-embedding\">FastNegativeEmbedding</a>, why not do the same with my super long <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384\"><strong>DreamShaper</strong></a> negative prompts?</p><p>I decided to condense them into 2 words which are the two embeddings presented here.</p><p>BadDream is good for \"dreamshaper style\" stuff, while <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/72437?modelVersionId=77173\">UnrealisticDream</a> is more suited for realistic images, but <strong>it's not standalone</strong>. You should use it together with BadDream or with other negative words.</p><p>They can also both be combined with <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/71961/fast-negative-embedding\">FastNegativeEmbedding</a>.</p><p>Enjoy!</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832516+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "15365",
    "prompt": "hanfu Ê±âÊúç\n<p>Thank Support Contribution ÊÑüË∞¢‰ª•‰∏ã‰∫∫ÂëòÁöÑÊîØÊåÅ‰∏éË¥°ÁåÆ</p><ul><li><p><span data-type=\"mention\" class=\"mantine-1yiar0p\" data-id=\"mention:456494\" data-label=\"liaoliaojun\">@liaoliaojun</span> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/ChitandaEru\">@ÊòéÊúàÊòéÊúà </a><a target=\"_blank\" rel=\"ugc\" href=\"https://space.bilibili.com/225168173\">@ÂçóÈôå </a>@Áé∞‰ª£Ê±âÊúçÁ†î‰π†Â∞èÁªÑ @Â∞èÂçÉ @ÂñÑÊûúÂøÉËä± @WEN @ÁßëÊôìÁîü @ÊûóÂ≠êÂÆâ <a target=\"_blank\" rel=\"ugc\" href=\"https://www.xiaohongshu.com/user/profile/6134a9fc0000000002026a79?xhsshare=CopyLink&amp;appuid=6134a9fc0000000002026a79&amp;apptime=1681707943\">@A++</a> <a target=\"_blank\" rel=\"ugc\" href=\"https://v.douyin.com/DFCxhyD/\">ËÆæËÆ°Â∏àÈõ®Êô®</a></p></li><li><p>È¶ñÈ°µÁ≤æ‰øÆÂõæ‰ΩúËÄÖÔºöËÆæËÆ°Â∏àÈõ®Êô® <a target=\"_blank\" rel=\"ugc\" href=\"https://v.douyin.com/DFCxhyD/\">https://v.douyin.com/DFCxhyD/</a></p></li><li><p>ÊÑüË∞¢ÊâÄÊúâÂ∑≤Áªè‰∏∫Ê±âÊúçÊ®°ÂûãÂÅöÂá∫Ë¥°ÁåÆÁöÑ‰∫∫ÔºåÊ±âÊúçÊ®°ÂûãÁöÑÊåÅÁª≠ÂèëÂ±ïÁ¶ª‰∏çÂºÄ‰Ω†‰ª¨ÁöÑÊîØÊåÅ‰∏éË¥°ÁåÆÔºÅ‰∫§ÊµÅÂàÜ‰∫´Ê±âÊúçÁ¥†ÊùêË¥°ÁåÆÂíåËµÑÊ∫ê„ÄÅÊ±âÊúçÁ¥†ÊùêÁöÑÂ§ÑÁêÜ„ÄÇÂ¶ÇÊûú‰Ω†ÊÉ≥Âä†ÂÖ•Êàë‰ª¨ÔºåËØ∑ËÅîÁ≥ªÈÇÆ‰ª∂Ëá≥me@liaoliaojun.com</p></li></ul><p><strong>ÈÉëÈáçÂ£∞ÊòéÔºöÊú¨Ê®°ÂûãÁ¶ÅÊ≠¢Áî®‰∫éËÆ≠ÁªÉÂü∫‰∫éÊòéÊòü„ÄÅÂÖ¨‰ºó‰∫∫Áâ©ËÇñÂÉèÁöÑÈ£éÊ†ºÊ®°ÂûãËÆ≠ÁªÉ„ÄÇ</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://sleepy-oyster-204.notion.site/hanfu-e7a2aab3ea58451bbe2400bb08955bb6\">hanfuÊ±âÊúçÊÄªÊñáÊ°£ hanfu ALL Document</a></p><p>È´òË¥®ÈáèÊ±âÊúçloraÊ®°ÂûãÔºåÊÑüÂèóÊ±âÊúç‰πãÁæé„ÄÇËØ∑‰∏çË¶ÅÁäπË±´ÔºåÁ´ãÂç≥‰∏ãËΩΩËØïÁî®ÂêßÔºÅ</p><p>High quality hanfu lora model, feel the beauty of hanfu. Please don't hesitate to download and try it now!</p><p><strong>!!!Ê±âÊúçÊï¥ÂêàÁâàÊú¨Ê±°ÊüìËæÉÂ§ßÔºåÈúÄË¶ÅÈ´òÊ∏Ö‰øÆÂ§ç„ÄÇÂçïÊúù‰ª£È£éÊ†ºÊ±âÊúçÊ±°ÊüìËæÉËΩª„ÄÇ</strong></p><p></p><p><strong>v3.0 - v1.0 ÁâàÊú¨ÊîØÊåÅÂ§öÈ£éÊ†ºÔºö</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://sleepy-oyster-204.notion.site/han-style-566fad9a5e134c9f80cf40f40cdd6bb5\"><strong>Ê±âÈ£é</strong></a><strong>„ÄÅ</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://sleepy-oyster-204.notion.site/tang-style-c4a0af02d2a844d1b8a4406e282291b7\"><strong>ÂîêÈ£é</strong></a><strong>„ÄÅ</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://sleepy-oyster-204.notion.site/song-style-766a8b462f654d7597164351581a4f7b\"><strong>ÂÆãÈ£é</strong></a><strong>„ÄÅ</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://sleepy-oyster-204.notion.site/ming-style-6afc9d984e644946b6c31f8fd6db1c8b\"><strong>ÊòéÈ£é</strong></a><strong>„ÄÅ</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://sleepy-oyster-204.notion.site/weijin-style-4a0888bd001d4788a0d070406258d672\"><strong>ÊôãÈ£é</strong></a></p><p><strong>v3.0 - v1.0 Supported multiple styles: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://sleepy-oyster-204.notion.site/han-style-566fad9a5e134c9f80cf40f40cdd6bb5\"><strong>han style</strong></a><strong>„ÄÅ</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://sleepy-oyster-204.notion.site/tang-style-c4a0af02d2a844d1b8a4406e282291b7\"><strong>tang style</strong></a><strong>„ÄÅ </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://sleepy-oyster-204.notion.site/song-style-766a8b462f654d7597164351581a4f7b\"><strong>song style</strong></a><strong>„ÄÅ </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://sleepy-oyster-204.notion.site/ming-style-6afc9d984e644946b6c31f8fd6db1c8b\"><strong>ming style</strong></a><strong>„ÄÅ</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://sleepy-oyster-204.notion.site/weijin-style-4a0888bd001d4788a0d070406258d672\"><strong> jin style</strong></a></p><p>v3.0 Weight (ÊùÉÈáç): 0.5~0.7</p><p></p><p>ÂæÆ‰ø°‰∫§ÊµÅÁæ§Ê∑ªÂä†Â∞èÂä©Êâã: hanfuaigc</p><p>QQ‰∫§ÊµÅÁæ§: 390640380</p><p>TagÂèÇËÄÉ‰∏ãÊñπÊñáÊ°£ÊàñÂêÑÁâàÊú¨ÁöÑÂõæÁâá‰ø°ÊÅØ„ÄÇ</p><p></p><h3>v3.0 tags Ëß¶ÂèëËØç</h3><p>ÊòéÈ£éÊ±âÊúç: hanfu, ming style</p><p>ÂÆãÈ£éÊ±âÊúç: hanfu, song style</p><p>ÂîêÈ£éÊ±âÊúç: hanfu, tang style</p><p>ÊôãÈ£éÊ±âÊúç: hanfu, jin style</p><p>Ê±âÈ£éÊ±âÊúç: hanfu, han style</p><p></p><h3>v2.9 tags Ëß¶ÂèëËØç</h3><p>ÊòéÈ£éÊ±âÊúç: ming hanfu, ming style outfits</p><p>ÂÆãÈ£éÊ±âÊúç: song hanfu, song style outfits</p><p>ÂîêÈ£éÊ±âÊúç: tang hanfu, tang style outfits</p><p>Ê±âÈ£éÊ±âÊúç: han hanfu, han style outfits</p><p></p><h3>v2.8 tags Ëß¶ÂèëËØç</h3><p>ÊòéÈ£éÊ±âÊúç: mingstyle, ming clothing, hanfu</p><p>ÂÆãÈ£éÊ±âÊúç: songstyle, song clothing, hanfu</p><p>ÂîêÈ£éÊ±âÊúç: tangstyle, tang clothing, hanfu</p><p>ÊôãÈ£éÊ±âÊúç: jinstyle, jin clothing, hanfu</p><p>Ê±âÈ£éÊ±âÊúç: hanstyle, han clothing, hanfu</p><p></p><h3>v2.0 tags Ëß¶ÂèëËØç</h3><p>ÊòéÈ£éÊ±âÊúç: hanfu, ming, ming dynasty, ming clothing</p><p>ÂÆãÈ£éÊ±âÊúç: hanfu, song, song dynasty, song clothing</p><p>ÂîêÈ£éÊ±âÊúç: hanfu, tang, tang dynasty, tang clothing</p><p>ÊôãÈ£éÊ±âÊúç: hanfu, jin, jin dynasty, jin clothing</p><p>Ê±âÈ£éÊ±âÊúç: hanfu, han, han dynasty, han clothing</p><p></p><h3>Tang StyleÔºàÊ±âÊúçÂîêÈ£éÔºâ: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/44395\">https://civitai.com/models/44395</a></h3><h3>Song StyleÔºàÊ±âÊúçÂÆãÈ£éÔºâ: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/47916\">https://civitai.com/models/47916</a></h3><h3><strong>Ming</strong> StyleÔºàÊ±âÊúçÊòéÈ£éÔºâ<strong>: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/65314/hanfu-ming\"><strong>https://civitai.com/models/65314/hanfu-ming</strong></a></h3><p></p><h3>Êú™Êù•ËÆ°ÂàíÔºö</h3><p>- [‚àö] ÂîêÈ£éÊãÜÂàÜ</p><p>- [‚àö] ÂÆãÈ£éÊãÜÂàÜ</p><p>- [‚àö] ÊòéÈ£éÊãÜÂàÜ</p><p>- [x] Ê±âÊúçÁî∑ÁîüÁâàÊú¨</p><p>- [ ] È´òË∑üÈûãÊîØÊåÅ</p><p>- [ ] Êï¥ÂêàÁâàÊú¨ÊîØÊåÅ</p><p></p><p><strong>ÈÉëÈáçÂ£∞ÊòéÔºöÊú¨Ê®°ÂûãÁ¶ÅÊ≠¢Áî®‰∫éËÆ≠ÁªÉÂü∫‰∫éÊòéÊòü„ÄÅÂÖ¨‰ºó‰∫∫Áâ©ËÇñÂÉèÁöÑÈ£éÊ†ºÊ®°ÂûãËÆ≠ÁªÉ„ÄÇ</strong></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832549+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "2220",
    "prompt": "Babes\n<p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/alexds9/models?sort=Newest\"><u><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3cb08649-9490-4842-bd84-d6ac90ae88aa/width=525/3cb08649-9490-4842-bd84-d6ac90ae88aa.jpeg\" /></u></a><a target=\"_blank\" rel=\"ugc\" href=\"https://linktr.ee/alexds9\"><strong><u><span style=\"color:rgb(92, 209, 255)\">üì≤ Commissions, Training, Consultation - Flux, Pony, SDXL + Characters, Styles, Faces +</span></u></strong></a><span style=\"color:rgb(193, 194, 197)\"> </span><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/alexds9\"><strong><span style=\"color:rgb(250, 82, 82)\">‚ù§Ô∏è Support</span></strong></a><strong> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/BKhkwwqK9m\"><strong><span style=\"color:rgb(250, 176, 5)\">ü´∂ Discord</span></strong></a><br />‚ÑπÔ∏è <strong><u>Babes 1.2p10 Pony</u></strong> - This version introduces a few interesting changes, continuing my effort to refine and evolve Babes with every version. In this version, I focused on adding a few hand gestures, such as: hand on chest, hand v sign, hand open palm, hand thumb up, hand pointing up, and both hands on waist. These gestures are significantly better now, but they are definitely far from perfect.<br />I also tried to improve the teeth, aiming for more defined, clear details and more consistent results, and I think that effort was successful.<br />This version includes a few adjustments to the semi-realistic base style and default faces. My goal was to make the model feel more rounded and distinct, while staying aligned with the established look of earlier versions. I feel that the fidelity remains very high, and I‚Äôm pleased with the direction the model is heading.<br />As always, each release is an opportunity for me to add creative flavor to the model. I‚Äôve continued to refine the model and hope to be able to keep making frequent updates, while Civitai is going through some worrying changes.<br />I really love what the model can do now, and I hope that people will enjoy this latest addition.<br />‚ÑπÔ∏è Renamed versions: 1.2-1.29 Pony versions changed to 1.2p00-1.2p09 or 1.2p0-1.2p9.<br />‚ÑπÔ∏è <strong><u>Babes 1.2p09 Pony</u></strong> ‚Äì A new training and a few new components added, aiming to polish and improve semi-realistic style further, adjustment to faces and skin, a little bit more details, enhancement of sharpness and contrast. <br />‚ÑπÔ∏è <strong><u>Babes 1.2p08 Pony</u></strong> ‚Äì Incorporated a few new components and new training, sharpened backgrounds, added more details, slicker 3D effects, expanded tonal range, and lowered close-up bias. This version can create truly incredible images‚Äîit's my pleasure and privilege to be able to create and publish it.<br />‚ÑπÔ∏è <strong><u>Babes 1.2p07 Pony</u></strong> ‚Äì This version comes with enhanced semi-realistic base style, adjustment to default faces, and improvement to saturation and lighting.<br />‚ÑπÔ∏è <strong><u>Babes 1.2p06 Pony </u></strong>‚Äì This version brings significant improvements to details and sharpness, along with major enhancements to compositions and backgrounds. For a more alternative look, I recommend using \"tattoos\" in the prompt. I have to admit, though, that hands are more challenging in this version.<br />‚ö†Ô∏è This model has been on Civitai‚Äôs generator since the first day of generator existence. However, after the recent attempt to support all checkpoints in the generator did not work as expected, Civitai has decided to stop supporting this model in the generator. I‚Äôm disappointed by this decision‚Äîthis is my first and most beloved model.<br />Ultimately, during the period when all models were briefly available in the generator, neither of the Babes versions met some required threshold. Maybe this happened because the latest version was in Early Access, splitting users between two versions‚ÄîI don‚Äôt know.<br />I checked the data from this model for exact numbers. I also found at least four models that are currently in the generator, which have a lower number of images generated with them than versions of this model (v1.2p04, v1.2p05) - despite being measured over a shorter period of time. So unfortunately, the decision by Civitai is not based on merit, unlike how it was presented.<br />Civitai promised that the new Creators Program would be more fair, but after reverting changes to support all checkpoints, we now see that two creators hold around 20 checkpoints in the generator‚Äîmeaning just two people have 10% of all available slots‚Äîincluding a single model with six versions. Other models have three or even four versions in the generator. This situation is an unfair for other creators and not helpful to users.<br />‚ÑπÔ∏è <u>Babes 1.2</u><strong><u>p0</u></strong><u>5 Pony</u> - <span style=\"color:rgb(193, 194, 197)\">This version looks amazing. It creates gorgeous faces and bodies, and overall, I like it a lot. Some of the changes include: less shiny skin, rebalanced contrast with renormalized colors, better proportions, and more realistic lighting.</span><br />‚ÑπÔ∏è <u>Babes 1.2</u><strong><u>p0</u></strong><u>4 Pony</u> - Additional polishing of base style, look and feel. Adjustment to more volumetric and less flat shading, slightly more metallic textures, can produce more darker images, has a wider variety of colors - particularly for clothes and hair.<br />üçä I want to thank all the people who are using and enjoying this model, all my other models, and supporting my work. As a token of appreciation to all the lovely people, I decided to discount Babes 1.2p03 Early Access bigly and boldly. Hope y‚Äôall are having a great 2025. Let‚Äôs Make AI Great Again!<br />‚ÑπÔ∏è <strong><u>Babes 1.2p03 Pony</u></strong> - Adjustment to base style, default faces, more vivid colors and more colorful images. I love the results, somehow I keep surprising myself all the time. üòÜ<br />‚ÑπÔ∏è <strong><u>Babes 1.2p02 Pony</u></strong> - Incorporating new components, including training from <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16300?modelVersionId=1205622\">Galena 1.3</a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/26566?modelVersionId=1228465\">Babes Kissable Lips 3.7</a>, and additional new finetuning. The base style is a continuation of Babes <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2220?modelVersionId=1064640\">1.2o00</a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2220?modelVersionId=1118499\">1.2po1</a> with a slight variation. The results look amazing in my humble opinion. üòä<br />‚ÑπÔ∏è <strong><u>Babes 1.2p01 Pony</u></strong> - Changes to the base style of Babes 1.2p00, intended to offer additional complementary options.<br />‚ÑπÔ∏è <strong><u>Babes 1.2p0 Pony</u></strong> - Finetuning based on <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/26566?modelVersionId=1009487\">Babes Kissable Lips 3.4</a>. <br />‚ÑπÔ∏è <strong><u>Babes 3.1</u></strong> includes new training, a new recipe, rebalanced styles, and enhancements to the base style.<br />‚ÑπÔ∏è <strong><u>Babes 3.0</u></strong> was trained with 43,000 images, including many new styles and subjects.<br />‚ÑπÔ∏è Styles: Babes 1.1 - \"<strong>basety style</strong>\", Babes 2 - \"<strong>abbe bi style</strong>\", Sassy Girls - \"<strong>sassy style</strong>\", Midjourney - \"<strong>midjourney style</strong>\".<br />‚ÑπÔ∏è Cartoon styles:</p><pre><code>othalama style, ronidu style, seviechan style, samdoesart style, thepit style, owler style, cherrmous style, arosen style, uodenim style, stanleylau style, amime style</code></pre><p>‚ÑπÔ∏è Recommended tags in the negative prompt:<strong> nose stud</strong>, <strong>piercing</strong><br />‚ÑπÔ∏è Misc trigger words: <strong>wild nature</strong>, <strong>suicidegirl</strong>, <strong>interior design</strong>, <strong>digital art</strong></p><p><strong><u>üìå Are your results not¬†100% identical¬†to any specific picture?</u></strong></p><ol><li><p>Make sure to use Hires-fix from example SwinIR_4x / 4x-UltraSharp / 4x-AnimeSharp / RealESRGAN_x4plus_anime_6B (<a target=\"_blank\" rel=\"ugc\" href=\"https://upscale.wiki/wiki/Model_Database\">Upscaler Download</a>), it is what I usually use for hires-fix.</p></li><li><p><strong>SD 1.5 - </strong>Use VAE:¬†<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\">vae-ft-mse-840000-ema-pruned</a> for better colors. Download it into \"stable-diffusion-webui/models/VAE\" folder. Select it in the settings.</p></li><li><p>I use xformers - it's a small performance improvement that might change the results. It is not a must to have and can be hard to install. Can be enabled with a command argument \"--xformers\" when launching WebUI.</p></li><li><p>WebUI is updated constantly with some changes that influence image generation. Many times technological progress is prioritized over backward compatibility.</p></li><li><p>Hardware differences may influence changes. I've heard that a bunch of people tested the same prompt with the same settings, and the results weren't identical.</p></li><li><p>I have seen on my own system, that when running as part of a batch, may change a little bit the results.</p></li><li><p>I suspect there are hidden variables inside modules we can't change that produce slightly different results due to internal state changes.</p></li><li><p>Any change in image dimension, steps, sampler, prompt, and many other things, can cause small or huge differences in results.</p></li></ol><p><strong><u>üìå Do you really want to get the exact result from the image? There are a few things that you can do, and possibly get even better results.</u></strong></p><ol><li><p>Make a single word changes to prompt/negative prompt and test, and push it slowly to your desired direction.</p></li><li><p>If the image has too much of something or doesn't have enough of something, try to use¬†<a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#attentionemphasis\">emphasis</a>. For example, too glossy? use \"(glossy:0.8)\", or less, or remove it from the prompt, or add it to the negative. Want more, use values 1.1-1.4, then additional descriptors in the same direction.</p></li><li><p>Use variations - use the same seed, and to the right of the seed check \"Extra\". Set \"Variation strength\" to a low value of 0.05, generate a few images, and watch how big the changes are. Increase if you want more changes, and reduce if you want fewer changes. That way you can generate a huge amount of images that are very similar to the original, but some of them will be even better.</p></li></ol><p><strong><u>üìå Recommendations to improve your results</u></strong><u>:</u></p><ol><li><p><strong>SD 1.5 - </strong>Use VAE for better colors and details. You can use VAE that comes with the model or download \"vae-ft-mse-840000-ema-pruned from (<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\">https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main</a>) , ckpt or safetensors file into \"stable-diffusion-webui/models/VAE\" folder. In the settings find \"SD VAE\", refresh it, and select \"vae-ft-mse-840000-ema-pruned\"(or the version included with the model). Click \"Apply settings\" button on the top. The VAE that comes with the model is \"vae-ft-mse-840000-ema-pruned\", you don't need both, use the one that you downloaded, it will work very well with most of the other models too.</p></li><li><p>Use hires-fix, SwinIR_4x / 4x-UltraSharp / 4x-AnimeSharp / RealESRGAN_x4plus_anime_6B (<a target=\"_blank\" rel=\"ugc\" href=\"https://upscale.wiki/wiki/Model_Database\">Upscaler Download</a>), first pass around 512x512, second above 960x960, and keep the ratio between the two passes the same if possible.</p></li><li><p>Use negatives, but not too much. Add them when you see something you don't like.</p></li><li><p>Use CFG 7.5 or lower, with heavy prompts, that use many emphases and are long, you can go as low as 3.5. And generally try to minimize the usage of emphasis, you can just put the more important things at the begging of the prompt. If everything is important, just don't use emphasis at all.</p></li><li><p>Make changes cautiously, changes made at the beginning of the prompt have more influence. So every concept can throw your results drastically.</p></li><li><p>Read and use the manual (<a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features\">https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features</a>).</p></li><li><p>Learn from others, copy prompts from images that look good, and play with them.</p></li><li><p>DPM++ 2M Karras is the sampler of choice for many people, including me. 40 steps are plenty, and I usually use 20.</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/BKhkwwqK9m\">Discord server</a> for help, sharing, show-offs, experiments, and challenges</p></li></ol>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832591+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "119229",
    "prompt": "ZavyChromaXL\n<p><strong><span style=\"color:rgb(34, 139, 230)\">V10 is sponsored significantly by Wizz (</span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/_Wizz_\"><strong><span style=\"color:rgb(34, 139, 230)\">https://civitai.com/user/_Wizz_</span></strong></a><strong><span style=\"color:rgb(34, 139, 230)\">) - check him out, amazingly kind and knowledgeable guy.</span></strong></p><hr /><p>Please consider joining my <a target=\"_blank\" rel=\"ugc\" href=\"https://patreon.com/Zavy376\"><strong>Patreon </strong></a>so I can keep most of my work available for everyone - I'll be releasing early access models there for a cheaper monthly fee than buying them here individually, and also will be providing exclusive models and more!<br /><br />For business inquiries, commercial licensing, custom models, and consultations, please get in touch at <a target=\"_blank\" rel=\"ugc\" href=\"mailto:hello@zavyai.com\"><strong>hello@zavyai.com</strong></a> or <a target=\"_blank\" rel=\"ugc\" href=\"mailto:sales@zavyai.com\"><strong>sales@zavyai.com</strong></a>. You can also contact me here through CivitAI DM or join my <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/jZZA4Dzmta\"><strong>Discord</strong></a>.<br /></p><p><strong><span style=\"color:rgb(250, 82, 82)\">If you see this model on a commercial product/website that is not CivitAI, then the website you are seeing it on is stealing and profiting on my work. Please contact me. If you currently offer it commercially, contact me to avoid being called out publicly.</span></strong><br /><br /><span style=\"color:rgb(253, 126, 20)\">Note: commercial licensing is a requirement for all generative services other than CivitAI. It's also a requirement for companies using it in a commercial setting; e.g. marketing materials, fashion shoots, apps for photo/video editing, etcetera. The only commercial usage that does not need a commercial license is for artists selling their imagery as prints and such.</span></p><hr /><p><strong><span style=\"color:rgb(64, 192, 87)\">Consider using DPM++ 3M SDE Exponential or DPM++ SDE Karras for this model, I personally like them best, 3M SDE Expo for most styles, DPM++ SDE Karras for photorealistic. Make sure to read the prompt advice further on in this section if you want to create photorealistic images as well as some of the sample images.</span></strong></p><h1 id=\"introduction-2bar7351j\">Introduction</h1><p>A model line that should be a continuance of the ZavyMix SD1.5 model for SDXL. The primary focus is to get a similar feeling in style and uniqueness that model had, where it's good at merging magic with realism, really merging them together seamlessly. Of course with the evolution to SDXL this model should have better quality and coherance for a lot of things, including the eyes and teeth than the SD1.5 models. This model has no need to use the refiner for great results, in fact it usually is preferable to not use the refiner. Recommended to use ultimate SD upscaler to get the most amazing results.</p><p></p><p><strong><span style=\"color:rgb(250, 176, 5)\">Continue reading for more information and some tips and tricks.</span></strong></p><p></p><p><strong>I kindly request that you share your creations both here and on my </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/jZZA4Dzmta\"><strong>Discord </strong></a><strong>server, as I would greatly appreciate the opportunity to see them and motivate me to spend more time in further ventures here.</strong></p><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2b988a76-bd50-4f61-ac72-e5cb64b830f1/width=525/2b988a76-bd50-4f61-ac72-e5cb64b830f1.jpeg\" /></p><p></p><h1 id=\"pros-and-cons-t936j4zmn\">Pros and cons</h1><h3 id=\"pros-gcjhfjj0m\">Pros</h3><ul><li><p>Much better saturation than base model.</p></li><li><p>Much better teeth, eyes, hands and feet.</p></li><li><p>Increased realism.</p></li><li><p>Less blurry edges but still keeps a certain pleasing softness to the image.</p></li><li><p>Better looking people.</p></li><li><p>Great texture and tonality.</p></li></ul><p></p><h3 id=\"cons-n4vybqwfz\">Cons</h3><ul><li><p>NSFW much better than base, but still somewhat lacking without LORAs.</p><p></p></li></ul><h1 id=\"roadmap-a9x7q2vp2\">Roadmap</h1><ol><li><p>Training the SDXL model continuously.</p></li><li><p>Pioneering uncharted LORA subjects (withholding specifics to prevent preemption).</p></li></ol><p></p><h1 id=\"tips-u90l304oi\">Tips</h1><ul><li><p>To better understand the preferences of the model, individuals are encouraged to utilise the provided prompts as a foundation and then customise, modify, or expand upon them according to their desired objectives.</p></li><li><p>Ditch the refiner, an img2img ultimate SD upscaler gets better results when you select this model for it.</p></li><li><p>For photorealism, use nmkdSiaxCX_200k for initial upscale, consider using ultramix_balanced for final upscale/pass to lessen grainy pictures.</p></li><li><p>Consider using face restoration techniques when the result for the face is subpar, but the rest of the image is interesting.</p></li><li><p>If you find that the details in your work are lacking, consider using wowifier if you‚Äôre unable to fix it with prompt alone. wowifier or similar tools can enhance and enrich the level of detail, resulting in a more compelling output.</p></li><li><p>ComfyUI is the UI I use for my SDXL images.</p></li><li><p>Your 1.5 LORAs won't work in SDXL.</p></li><li><p>Consider finding new prompts, don't use the standard 1.5 ones. SDXL likes a combination of a natural sentence with some keywords added behind.</p></li><li><p>To maintain optimal results and avoid excessive duplication of subjects, limit the generated image size to a maximum of 1024x1024 pixels or 640x1536 (or vice versa). If you require higher resolutions, it is recommended to utilise the Hires fix, followed by the img2img upscale technique, with particular emphasis on the controlnet tile upscale method. This approach will help you achieve superior results when aiming for higher resolution outputs. However, as this workflow doesn't work with SDXL yet, you may want to use an SD1.5 model for the img2img step.</p></li></ul><p></p><h1 id=\"prompts-0jws7ihuc\">Prompts</h1><p><strong>Recommended positive prompts for specifically photorealism</strong>: 2000s vintage RAW photo, photorealistic, film grain, candid camera, color graded cinematic, eye catchlights, atmospheric lighting, macro shot, skin pores, imperfections, natural, shallow dof, <strong>or other photography related tokens.</strong></p><p><strong>Recommended negative prompts</strong>: As few negative prompts as you can, only use it when it does something you do not want, like watermarks. Consider using high contrast, oily skin, plastic skin if the skin is too contrasting or too oily/plastic. Also make sure to add anime to negative prompt if you want better photorealism, and more mature looking characters.</p><p></p><p>You are further encouraged to include additional specific details regarding the desired output. This should involve specifying the preferred style, camera angle, lighting techniques, poses, color schemes, and other relevant factors.</p><p></p><h1 id=\"recommended-settings-3f1h9khrl\">Recommended settings</h1><ul><li><p>sdxl_vae.safetensors (baked in).</p></li><li><p>DPM++ 3M SDE Exponential, DPM++ SDE Karras, DPM++ 2M SDE Karras, DPM++ 2M Karras, Euler A</p></li><li><p>Steps 20~40 (lower range for DPM, higher range for Euler).</p></li><li><p>Hires upscaler: nmkdSiaxCX_200k, UltraMix_Balanced.</p></li><li><p>Hires upscale: Whatever maximum your GPU is capable of, but preferably between 1.5x~2x.</p></li><li><p>CFG scale 4-10 (preferably somewhere around cfg 6-7)</p></li></ul><p></p><p>Lightning LoRA specific settings:</p><ul><li><p>Euler sampler with SGM Uniform as Scheduler.</p></li><li><p>Steps 4 (use the 4 steps LoRA)</p></li><li><p>CFG scale 1-2 (CFG 1 at the higher weights for the LoRA)</p></li><li><p>LoRA weight 0.6-1</p></li></ul><p></p><h1 id=\"model-recipe-jtqkidrfi\">Model recipe</h1><p>Trained from SDXL 1.0.</p><p></p><h1 id=\"social-media-iq2pq1zc0\">Social media</h1><p>You are welcome to join my recently created <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/jZZA4Dzmta\">Discord </a>server, where we can engage in discussions, share our experiences in AI, and showcase the things we‚Äôve made with AI. You are encouraged to join and ask any questions or seek additional tips and tricks related to my models or AI in general. Your participation would be greatly appreciated.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832607+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "376450",
    "prompt": "DucHaiten-Pony-XL (no-score)\n<p><strong><em><u><span style=\"color:rgb(250, 82, 82)\">you like my content, support me at:</span></u></em></strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/duchaiten\">https://ko-fi.com/duchaiten</a></p><p><strong><em><u><span style=\"color:rgb(250, 82, 82)\">Patreon in here:</span></u></em></strong><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://linktr.ee/Duc_Haiten\">https://linktr.ee/Duc_Haiten</a><br /><br /><strong><span style=\"color:rgb(34, 139, 230)\">I created my discord server. I'm still quite new to discord server management, free to give opinions.</span></strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/vKEW6jqa49\">https://discord.gg/vKEW6jqa49</a></p><p></p><p><strong><u><span style=\"color:rgb(250, 176, 5)\">special note</span></u></strong><span style=\"color:rgb(250, 176, 5)\">: Using the model is very simple, like the scores, but also not like the scores. The idea behind it is training based on various artistic styles of different artists and some unique AI models, arranging them into separate keywords (perhaps I should have made them numerical codes like score_1234 in Pony base, such as style_123‚Äîmaybe next time I‚Äôll do that). Each keyword corresponds to a different style, representing an artist or a uniquely special AI style. Users can call up just one keyword to bring out that style, but that‚Äôs not the main intention. What I aim for are unique style combinations. You can call up multiple styles at once, for example: A, B, C, or B, C, A, or C, A, B.</span></p><p></p><p><span style=\"color:rgb(250, 176, 5)\">Any change in the keywords or the order of the keywords will result in different outcomes. You can even use parentheses like (A) or (A:1.2) to increase or decrease the weight of a keyword. This combination and arrangement will turn the initial 55 styles into hundreds or thousands of different styles, and as long as you don‚Äôt reveal your style combinations and keywords, it will be a one-of-a-kind creation unique to you. That was my original intention when creating this project.</span></p><p>Read more here:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/8523\">https://civitai.com/articles/8523</a></p><p></p><p><strong><u><span style=\"color:rgb(250, 82, 82)\">Because the image generator of civitai and automatic1111 are different, on civitai you need to set the number of steps about 10-15 steps higher than when using automatic1111.</span></u></strong></p><p></p><p><strong><u><span style=\"color:rgb(130, 201, 30)\">Update on October 16, 2024:</span></u></strong></p><p></p><p>Pony No Score v7, this will be a groundbreaking version that unlocks enormous potential for pony, marking the largest update to date. V7 integrates 55 styles into one model, each with separate trigger keywords, similar to how Pony previously added scores to the model. The goal is to create a model capable of producing a wide variety of artistic styles, rather than being limited to just a few that are difficult to control. Users can apply individual styles or combine different styles to create their own completely unique artistic vision. Once you hide your prompt and data, no one will know which style keywords you combined to craft such a distinct look‚Äîit will be uniquely yours.</p><p></p><p>I will write a detailed guide on how to use the model along with a list of styles here, so everyone can gain a clearer understanding of what I‚Äôm aiming for.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/8105\">https://civitai.com/articles/8105</a></p><p></p><p><strong><u><span style=\"color:rgb(130, 201, 30)\">Update on September 8, 2024:</span></u></strong></p><p></p><p>Finally caught up with pony base v6 LOL. This is probably the last update, aside from bug fixes. I feel like I've reached the limit with pony v6, and adding anything more might cause issues elsewhere.</p><p>Version 6.0 includes some anime data, better adjustments for NSFW, further tweaks to colors and lighting effects, and additional improvements in natural language.</p><p>And the most important thing is earning money. Don‚Äôt be fooled by how popular this model seems. In reality, I work 15-16 hours a day, without taking a break, just to earn enough to reinvest in research and model training, with barely enough left to live on. So now I want to see how much I can make with this early access feature on my most popular model.</p><p></p><p><strong><u><span style=\"color:rgb(130, 201, 30)\">Update on August 8, 2024:</span></u></strong></p><p>v5.1+v5.0+v4.0=v5.2</p><p><span style=\"color:rgb(253, 126, 20)\">Damn I forgot to turn on early access</span></p><p><span style=\"color:rgb(250, 82, 82)\">Version v5.2 works quite well both with and without scores</span></p><p></p><p><strong><u><span style=\"color:rgb(130, 201, 30)\">Update on August 4, 2024:</span></u></strong><br />Version 5.1, a complete overhaul of the text encoder and adjustments to the U-net. Efforts have been made to minimize minor bugs from versions 5 and 4. Once again, the default importance level of the 3D style has been downgraded. I do not want 3D to be added to images if it is not explicitly mentioned in the prompt. Of course, if reducing the 3D style too much makes many people feel dissatisfied, I will adjust it again. So please let me know your thoughts on this adjusted version.</p><p></p><p><strong><u>The parameter settings I have tested:</u></strong></p><p>- Sampling method: Euler a</p><p>- Schedule type: SGM Uniform</p><p>- Sampling steps: 30-36</p><p>- CFG Scale: 8-9</p><p></p><p><strong><span style=\"color:rgb(130, 201, 30)\">Update on July 23, 2024:</span></strong></p><p>Welcome to pony no score v5. I tried to save it until pony base v6.9 was released, but the waiting period was too long, so I couldn't wait any longer and got to work immediately. I need it to have more soul, more artistic depth, and to convey emotions in each created image. I am fed up with the dryness of AI-generated art, which only looks beautiful but feels empty, unlike something truly nurtured from the creator's soul. I don't know if you understand what I mean, but that is what I am trying to achieve. Perhaps the most noticeable change for you is that the 3D style will be minimized, and the 2D drawing style will undergo slight modifications, with colors feeling more cinematic, and the lighting and shadows will be better and more realistic.</p><p></p><p>Some other updates: improved text encoder, more shooting angles, more art and 2D data to replace Nijijourney data</p><p></p><p><u><span style=\"color:rgb(250, 82, 82)\">Recommended settings:</span></u></p><p>Sampling method: DPM++ SDE</p><p>Schedule type: SGM Uniform (this one is a must)</p><p>Sampling steps: 30-36</p><p>CFG Scale: 9</p><p></p><p><strong><span style=\"color:rgb(130, 201, 30)\">update May 27, 2024:</span></strong></p><p>This will be the final version until pony base v7 comes out. In addition, the alpha 1 version of the <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/477851?modelVersionId=531448\">pony-real</a> model has been released, everyone can check it out, but don't expect much from the alpha.</p><p></p><p><em><span style=\"color:rgb(250, 176, 5)\">Thank you very much and apologies to </span></em><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Deathless\"><strong><em><span style=\"color:rgb(76, 110, 245)\">Deathless</span></em></strong></a><em><span style=\"color:rgb(250, 176, 5)\">, who helped me find and process around 8,000-10,000 image data for the pony-no-score version 4.0, whom I forgot to mention. So much happened in a short time that it gave me a headache. Fortunately, he reminded me, at least he didn't curse me out harshly LOL.</span></em></p><p></p><p><span style=\"color:rgb(190, 75, 219)\">(By the way, currently I'm doing everything alone again, if anyone is interested and willing to help prepare data for training my model, please feel free to contact me.)</span></p><p></p><p><strong><span style=\"color:rgb(130, 201, 30)\">update May 22, 2024:</span></strong></p><p>Final beta version of v4, the next update will be its official version. When the official version of pony no score v4 is released, it will also be the day pony-realistic alpha will be uploaded</p><p></p><p><strong><span style=\"color:rgb(130, 201, 30)\">updated May 14, 2024:</span></strong></p><p>Version 3.5 for Pony-no_score.</p><p>- Edit the text encoder</p><p>- Update more 3D image data</p><p>- added more realistic skin models for 3d</p><p>- reduce unnecessary details that are not in the prompt (creativity is a bit reduced but accuracy will be higher)</p><p>- Enhance solid contours</p><p>This is a separate version from v4 in training, so I need the most objective reviews.</p><p></p><p><strong><span style=\"color:rgb(130, 201, 30)\">Update May 7, 2024:</span></strong></p><p>I must say that I am really surprised and happy to see everyone's warm reception for the DucHaiten-Pony-XL model (no-score). Each new version gets more attention than the previous version, it seems I'm still on the right track.</p><p>To express my sincere thanks to everyone, I will post the v4 beta version first, everyone can try it out and give advice and suggestions for it. Note that because it is only a beta version, there will be many changes in the future.</p><p></p><p><strong><span style=\"color:rgb(130, 201, 30)\">Update May 3, 2024:</span></strong></p><p>After hearing comments about v2 seeming to lose the diversity and balance of styles compared to v1, this time I tried to adjust that problem. In addition, a lot of new data has been added in v3. They are arranged to intersperse with Pony's previous data, with the purpose of supplementing and creating connections with each other. I do so with the desire to create a more complete ecosystem for ponies. But because I'm the only one doing it all on my own with such a small budget, I can only try to limit my abilities as much as possible. PS. Colors are more vivid and brighter.</p><p></p><p><strong><span style=\"color:rgb(130, 201, 30)\">updated April 28, 2024:</span></strong></p><p>The upgraded version 2.0 will have many major changes, first is adding more handsome men data, next is improving weak natural language capabilities, and finally adding more artistic feeling to the model. There are also some smaller adjustments like details and lighting</p><p></p><hr /><p></p><p>A model created from the original <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/257749?modelVersionId=290640\">pony</a> model and combined with my various models. I tried to keep almost all of pony's text encoder and only change the image data, so I recommend you learn more about pony if you don't know how to use \"<a target=\"_blank\" rel=\"ugc\" href=\"https://purplesmart.ai/collection/top?nsfw=0&amp;page=1&amp;model=11&amp;order=created_desc\">tag score</a>\" properly. When using this model, you will feel that the image is less random and don't has too many unnecessary details like the pony, and will feel smoother and cleaner, Eliminates the possibility that some prompts will produce harsh images or burnt colors, the face is made clearer, the hands, feet, and pose are adjusted for fewer errors. But if you gain one, you lose the other. It can only be said that each person has its own style, depending on your preferences.</p><p></p><p>If you want to use my models to create unlimited images at a small cost without having to install anything, <a target=\"_blank\" rel=\"ugc\" href=\"http://mage.space\">mage.space</a> will be a good choice, i have some models that are exclusively available on there.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832622+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "47085",
    "prompt": "EnvyBetterHands LoCon\n<h1>This model is a LoCon. You MUST install the Lycoris extension for it to load.</h1><p>I'm using <a rel=\"ugc\" href=\"https://github.com/hako-mikan/sd-webui-lora-block-weight\">Lora Block Weight</a>.  I believe you can also use <a rel=\"ugc\" href=\"https://github.com/kohya-ss/sd-webui-additional-networks\">Additional Networks</a> and <a rel=\"ugc\" href=\"https://github.com/KohakuBlueleaf/a1111-sd-webui-lycoris\">SD Webui Lycoris</a>.</p><p><strong>UPDATE 4/27/2023:</strong> I've hit a training plateau so I'm in the process of adding a bunch more images to the dataset, including some more complicated stuff like intertwined fingers. I'm probably going to have to drop the learning rate some more, so things may be slower from here on. I'll keep everyone posted as things progress.</p><p></p><p><strong>UPDATE: Prompting advice for beta 2:</strong></p><ul><li><p>This is a completely new train on top of vanilla Stable Diffusion 1.5. I did this based on the advice of a fellow enthusiast, and it's surprising how much more compatible it is with different model. It doesn't mess with the style of your model <em>at all</em> as far as I can tell, and it really only affects hands and occasionally arms, leaving everything else untouched.</p></li><li><p>It seems to work best at a strength of 1, although turning up higher than that (1.5, 2, etc) can help it on some images at the cost of making it worse on others. No need to mess with your CFG scale, as it doesn't cause things to overcook at these levels.</p></li><li><p>Freely mix it with other LoRAs.</p></li><li><p>I've had best results putting \"nice hands, perfect hands\" in the positive prompt (increasing the weight makes things worse), and \"(extra fingers, deformed hands, polydactyl:1.5)\" in the negative prompt. This is on EnvyMix v1 (and probably RevAnimated), but YMMV for other models.</p></li><li><p>\"Bad hands\" negative embeddings appear to make it worse, although I haven't tested this extensively.</p></li><li><p>As usual, this won't work miracles, but I do find that over a large number of images, it does make things generally better on average. Hopefully this will continue to improve with a few more nights of training.</p></li></ul><p><strong>Prompting advice for alpha 3 and beta 1:</strong></p><ul><li><p>Note that this advice is for RevAnimated 1.2. YMMV with other models.</p></li><li><p>It overcooks things a bit, but you need the strength set to 1.0 for it to really work well. You can work around this by reducing the CFG value to 5 or 6 or so. I've had good luck with enabling the dynamic thresholding extension and setting it to <em>mimic</em> CFG 5, and then I can set my CFG value to 9 or 10 and things come out fine.</p></li><li><p>I tried using it with another LoRA and got some pretty strange results, so YMMV there as well. Right now I'm just trying to get it to work consistently in a simple use case.</p></li><li><p>Oddly, I think it's regressed a bit on hands in neutral positions, but it's noticeably better at more complicated interactions, such as holding objects (which is why I have so many pictures of blacksmiths and librarians in the example images).</p></li><li><p>Keep your prompts simple and it tends to do better.</p></li><li><p>With RevAnimated, I tend to get 1 or 2 usable images out of every 8, with a bunch of other ones that are pretty close and can probably be fixed with inpainting.</p></li></ul><p><strong>Prompting advice for alpha 2:</strong></p><ul><li><p>It's getting stronger now, and it works best around strength 1. Setting it to 1.3 like the previous version will make things look bad.</p></li><li><p>My negative prompt is still \"(extra fingers, deformed hands:1.15), (worst quality, low quality, poor quality, bad quality:1.35)\"</p></li><li><p>I had good luck just putting \"nice hands\" in the main prompt.</p></li></ul><p><strong>Prompting advice For alpha 1:</strong></p><ul><li><p>Your prompt should contain these words: \"beautiful hands, perfect hands, fingernails\". I've had the best luck with them towards the middle, and at no emphasis.</p></li><li><p>The alpha1 LoCon seems to work best at a strength of around 1.3 (on RevAnimated 1.1, where I'm testing it right now -- YMMV for other models)</p></li><li><p>Don't use negative embeddings for improving hands. When I removed badhandv4 from my negative prompt, things improved noticeably. You may want to try without any negative embeddings at all. I haven't used them for a while now.</p></li><li><p>My negative prompt is: \"(extra fingers, deformed hands:1.15), (worst quality, low quality, poor quality, bad quality:1.35)\", which I arrived at through a lot of experimentation adjusting strengths and terms one at a time. It should work decently well.</p></li><li><p>This all gives me hope that there's a real shot at solving hands on SD 1.5. Even with good prompting, I'm generally not getting perfect results, but things are close. I'll consider this done when it creates well-formed hands without having to add anything to the positive or negative prompt.</p></li></ul><p><em>Now back to your regularly scheduled readme...</em></p><p>I'm testing the theory that maybe the reason MidJourney's hands are so much better now is that they just took the time to specifically train a network on a high quality set of pictures of hands, and literally nobody else has actually tried. This LoRA definitely isn't at MidJourney levels yet, but I've been training it over night for several nights now and adding to the dataset where it appears deficient, and quality seems to be steadily improving. As such, I'm going to post this now so people can start using it. Consider this an early alpha -- I'll only stop updating once it stops getting better.</p><p></p><p><strong>Example images are cherry-picked. </strong>Please don't expect this model to make all of your hand generations better. It may even make some of them worse, so you should evaluate its usefulness on a large number of images and not just one. If it works for you like it does for me, the a lot of your results should be the same or better quality (some will just be bad in different ways).</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832628+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "13213",
    "prompt": "ShojoVibeÂ∞ëÂ•≥ÊÑü \n<p>Â∏¶ÁßÅÊàøÂÜôÁúüÈ£éÁöÑ2D-3DÊ≥õÁî®Â∞ëÂ•≥ÊÑüÊ∑∑Ë°ÄËÑ∏</p><p>ËØçÊù°ÂÜô‰∏ä&lt;lora:shojovibe_v11:1&gt;Âç≥ÂèØ, Âª∫ËÆÆ0.6-0.8</p><p>Shojo's boudoir photography, a doll face LORAÔºåsuitable for most styles from 2d to 3d. </p><p>&lt;lora:shojovibe_v11:1&gt;Ôºå0.6-0.8 recommended.</p><p>=======================================</p><p>v1.1 Ê†∑ÂõæÁî® <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8281/perfect-world\">Perfect World ÂÆåÁæé‰∏ñÁïå</a> Ê®°ÂûãÁîüÊàêÔºåÊé®ËçêÈ¶ñÈÄâÁî®Ëøô‰∏™Ê®°Âûã„ÄÇÊÉ≥Ë¶ÅÈïøËÖøÊàñËÄÖÊõ¥Â§öÂèØÂ°ëÊÄßÁöÑÊ®°ÂûãÊé®Ëçê<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/13034\">Lucky Strike Mix</a>ÔºåÈÖçÂêàÁöÑ‰πü‰∏çÈîôÔºåËÑ∏‰ºöÊòæÂæóÁ®çÂπº‰∏ÄÁÇπ„ÄÇ</p><p>‰∫åÊ¨°ÂÖÉÊé®ËçêÁî®<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7240/meinamix\">meinamix</a>Êàñ<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7152/facebombmix\">facebombmix</a></p><p></p><p>v1.1 Samples generated by <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8281/perfect-world\">Perfect World</a>, recommend primary choice</p><p>also recommend <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/13034\">Lucky Strike Mix</a> for longer legs and better background.</p><p>also work for anime style. recommend: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7240/meinamix\">meinamix</a> or <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7152/facebombmix\">facebombmix</a></p><p>=======================================</p><p>v1.1 Update: Â¢ûÂä†Ê∑∑Ë°ÄÊÑü„ÄÅÂ∞ëÂ•≥ÊÑü„ÄÇÂáèÂ∞ëÊòéÊòüÁõ∏‰ººÂ∫¶„ÄÇÂ¢ûÂä†Á®≥ÂÆöÊÄß„ÄÇÁï•ÂæÆÊîπÂñÑÁöÆËÇ§ËøáÊöó„ÄÇÂáèÂ∞èÊó†Áõ∏Â∫îËØçÊù°‰∏ãË£∏Èú≤ÁöÑÂá†Áéá„ÄÇ</p><p>Â∑≤Áü•ÈóÆÈ¢òÔºöÂèëËâ≤ÊØîËæÉÈöæÊîπ„ÄÇÊúçË£ÖÂíåËÉåÊôØÁõ∏‰ººÊÄßËæÉÈ´ò„ÄÇÁõÆÂâçËß£ÂÜ≥ÊñπÊ°àÊòØ‰ΩøÁî®<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/13034\">Lucky Strike Mix</a>„ÄÇ</p><p></p><p>v1.1 Update: add little bit biracial feel, more shojo, improve stability, better lighting, reduce resemblance of celebrity</p><p><u>Known issues</u>: difficult to change hair color or clothes. similar background (too much wood element).</p><p><strong>Solution: </strong>use<strong> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/13034\">Lucky Strike Mix</a>. add wood, wood texture, wood floor, etc., in negative prompt</p><p>=======================================</p><p>‰∏çÂä†ÊúçË£ÖËØçÊù°ÂÆπÊòìÈú≤ËÉ∏ËØ∑Ê≥®ÊÑèÔºàÂõ†‰∏∫ÂæêËã•ÁëÑÂÜôÁúüÈõÜ‰Ω†ÊáÇÁöÑ</p><p>warning: to avoid nude picture, try add clothes description, add 'topless', 'nude' in negative prompt.</p><p>Á¶ÅÊ≠¢Â∞ÜÊ≠§Ê®°ÂûãÂïÜ‰∏ö‰ΩøÁî®Êàñ‰º†Êí≠Êàê‰∫∫ÂÜÖÂÆπ„ÄÇ</p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832635+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "1162518",
    "prompt": "Plant Milk üåø - Model Suite\n<p><strong>üí° </strong><span style=\"color:rgb(250, 176, 5)\"><strong>Newest Version</strong></span><span style=\"color:rgb(64, 192, 87)\"><strong> </strong></span><strong>- Walnut </strong><em>(Euler or Euler a sampler recommended)</em></p><p>üåø <span style=\"color:rgb(64, 192, 87)\"><strong>Community Favorites</strong> </span>- <strong><em>Flax</em></strong><em>, </em><strong><em>Hemp II</em></strong><em>, and </em><strong><em>Walnut</em></strong></p><pre><code>Model Series: multi-series\nVersion: Walnut (ymk3.0.0)\nCreated on: ~March/14/25</code></pre><hr /><p><strong>‚Ñπ </strong><span style=\"color:rgb(34, 139, 230)\"><strong>Notice</strong></span><strong> - Do not reprint this model. This model can be merged and shared, however derivatives cannot be used for commercial purposes (generative services, commissioned models, SeaArt, PixAI, etc.)</strong></p><h3 id=\"info\"><strong>Info</strong></h3><p>A multi-series model page to showcase various 'flavors' of similar or continuations of related illustrious/noob based model merges. This page hosts various styles. Go through and decide on your favorite(s). Some versions may be more 'lora heavy' in comparison to the others.</p><p><strong><em>view more on</em></strong><em> </em><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Ocean3\"><em>Hugging Face</em></a></p><hr /><p></p><h3 id=\"recommended-use\"><strong>Recommended Use</strong></h3><p><span style=\"color:rgb(250, 176, 5)\"><strong>&lt; See example images &gt;</strong></span></p><p><span style=\"background-color:rgb(31, 31, 31);color:rgb(232, 232, 232);font-family:&quot;Google Sans&quot;, Roboto, Arial, sans-serif;font-size:16px\">‚Ä¢ </span><strong>Euler</strong> or <strong>Euler a</strong> or <strong>HeunPP2</strong> or <strong>Restart</strong> sampler, <strong>3</strong> or <strong>~3-6 </strong>cfg, <strong>~28</strong> steps</p><p><span style=\"color:rgb(250, 176, 5)\"><strong>Some versions may also work well with:</strong></span></p><p><span style=\"background-color:rgb(31, 31, 31);color:rgb(232, 232, 232);font-family:&quot;Google Sans&quot;, Roboto, Arial, sans-serif;font-size:16px\">‚Ä¢ </span><strong>Euler a CFG++</strong> sampler, <strong>SGM Uniform</strong> scheduler, <strong>~2</strong> cfg, <strong>~28</strong> steps<br />You can find additional sampler and schedulers via the ForgeUI/a1111 extension <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/DenOfEquity/webUI_ExtraSchedulers\">here</a>.</p><p>---</p><p><span style=\"color:rgb(64, 192, 87)\"><strong><em>Euler, 3 cfg, 28 </em></strong></span><strong><em>steps is a good starting point for most versions</em></strong><br /></p><p><span style=\"color:rgb(64, 192, 87)\"><strong>Hires fix</strong></span> - This is optional of course, and I recommend adjusting any use to your context and application. The example images utilize this both on and off.</p><hr /><p></p><p><span style=\"color:rgb(255, 125, 125)\"><strong>Disclaimer</strong></span></p><pre><code>This model(s) may output NSFW content unintentionally depending on parameters used. Make sure you tailor your prompts accordingly. For example \"nsfw\" in the negative prompt.\n\nThe purpose of sharing this model is not to showcase obscene material in a public forum. The use of this learning model is entirely at the discretion of the user, and they have the freedom to choose whether or not to create SFW or NSFW content. The decision of whether to engage with SFW or NSFW content lies with the user and their own personal preferences. The AI model(s) do not contain explicit visual content that can be accessed easily.</code></pre><p></p><hr /><h3 id=\"version-log\"><strong>Version Log</strong></h3><p><strong>Walnut üåø </strong><em>(Euler or Euler a sampler recommended)</em></p><pre><code>Model Series: ymk\nVersion: Walnut (ymk3.0.0)\nCreated on: ~March/14/25</code></pre><p><strong>Hemp II üåø </strong><em>(Euler or Euler a sampler recommended)</em></p><pre><code>Model Series: ldbr\nVersion: Vanilla (ldbr4.1.1)\nCreated on: ~January/30/25</code></pre><p><strong>Vanilla üåø </strong><em>(Euler or Euler a sampler, 3-6 cfg recommended)</em></p><pre><code>Model Series: epg\nVersion: Hemp (epg1.0.1)\nCreated on: ~March/4/25</code></pre><p></p><p><strong>Hemp üåø </strong><em>(Euler or HeunPP2 sampler recommended)</em></p><pre><code>Model Series: ldbr\nVersion: Hemp (ldbr4.0.1)\nCreated on: ~January/30/25</code></pre><p></p><p><strong>Coconut üåø </strong><em>(Euler A or DDPM sampler recommended)</em></p><pre><code>Model Series: dmai\nVersion: Coconut (dmai1.1.0)\nCreated on: ~December/27/24</code></pre><p></p><p><strong>Almond üåø </strong><em>(Euler sampler recommended)</em></p><pre><code>Model Series: pfi\nVersion: Almond (pfi3.0.0)\nCreated on: ~March/5/25</code></pre><p></p><p><strong>Flax üåø</strong></p><pre><code>Model Series: ldbr\nVersion: Flax (ldbr3.0.0)\nCreated on: ~January/24/25</code></pre><p></p><p><strong>Oat üåø</strong></p><pre><code>Model Series: GRK\nVersion: Oat (GRK3.0.0)\nCreated on: ~January/15/25</code></pre><p><em>Additional version information to be added.</em></p><hr /><h3 id=\"license-and-use\"><strong>License &amp; Use</strong></h3><p>SDXL -<strong> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Stability-AI/generative-models/blob/main/model_licenses/LICENSE-SDXL1.0\">CreativeML Open RAIL++-M</a><br />Illustrious - <a target=\"_blank\" rel=\"ugc\" href=\"https://freedevproject.org/faipl-1.0-sd/\">https://freedevproject.org/faipl-1.0-sd/</a><br />NoobAI-XL - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/license/1140829\">https://civitai.com/models/license/1140829</a></p><p></p><p><strong>Terms of use</strong></p><pre><code>- You are solely responsible for any legal liability resulting from unethical use of this model(s)\n- If you use any of these models for merging, please state what steps you took to do so and clearly indicate where modifications have been made.</code></pre><p><span style=\"color:rgb(125, 194, 255)\"><strong>Note</strong></span></p><pre><code>If you see any conflicts or corrections to be made, please let me know.</code></pre><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832648+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "1277670",
    "prompt": "‚ú® JANKU v5 NSFW Trained + NoobAI + RouWei Illustrious XL ‚ú®\n<p><strong>üíñ Support &amp; Share the Magic! </strong><br />Love these tools? <strong>Like, add to collection, and tag this resource </strong>in your creations‚ÄîI love to see what you make! üé®‚ú®</p><hr /><p>‚ú® <strong>Tired of typing prompts + want viral-ready art? </strong><br />Pair <strong>Lazy Embeddings </strong>üõãÔ∏è‚ö° (<em>zero-typing magic for all models </em>) with <strong>TrendCraft </strong>ü™ÑüöÄ (<em>30-day trend-trained detailer </em>) for effortless masterpieces. Check them out: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1302719\">Lazy Embeddings</a><a target=\"_blank\" rel=\"ugc\" href=\"https://chat.qwen.ai/c/link\"> </a>+ Trendcraft (<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1378661/trendcraft-the-peoples-style-detailer-all-models-support\">Pony XL</a><a target=\"_blank\" rel=\"ugc\" href=\"https://chat.qwen.ai/c/link\"> </a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1350877/trendcraft-the-peoples-style-detailer-all-models-support\">Illustrious </a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1365604/trendcraft-the-peoples-style-detailer-all-models-support\">Noob Vpred</a>, or <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1390819\">SDXL </a>base trained version)</p><p></p><p><strong>üëâ Join me</strong> on <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/tWrKk3jcXx\">our discord server</a> (<a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/tWrKk3jcXx\">https://discord.gg/tWrKk3jcXx</a>)! <strong>Share art, ask for help, or just chat</strong>. We have <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/13331/7k-followers-updates-and-civchan-bot-launch\">CivChan bot plus games</a> there!</p><p><strong>üëâ Support future updates: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/janxd\">Buy me a coffee </a>or tip buzz! Every bit helps. Thank you for fueling the art! üöÄ</p><hr /><h3 id=\"janku-v5.0\">üö® <strong>JANKU v5.0 </strong>üåü</h3><p><strong>‚ú® Key Features:</strong></p><ul><li><p><strong>üî• LoRA-Free Workflow: </strong>Generate high-quality art <em>without </em>stacking detailers (unless you‚Äôre adding niche styles/concepts).</p></li><li><p><strong>Large character list support: </strong>Character list shared in <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/tWrKk3jcXx\">our discord server</a>.</p></li><li><p><strong>üîû NSFW Mastery:</strong></p><ul><li><p><strong>Better anatomy </strong>(yes, even in <em>complicated </em>poses) + improved male framing.</p></li><li><p><strong>NSFW by default</strong>: if you don't want it, put <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1302719?modelVersionId=1601074\">lazynsfw </a>in negative!</p></li><li><p>ü§∑‚Äç‚ôÇÔ∏è <strong>If you know you know</strong> ü§∑‚Äç‚ôÇÔ∏è</p></li></ul></li><li><p><strong>No more stability issues </strong>‚Äîgenerate confidently at 1536x1536 <em>without upscaling. My personal resolution to use is 1024 x 1536.</em></p></li><li><p><strong>üé® Crisp Details: </strong>Enhanced backgrounds, outfits, and character features.</p></li><li><p><strong>üëÄ Prompt Responsiveness: </strong>Gets your vision right the first time (<em>might be intense for some‚Äîadjust CFG!</em>).</p></li><li><p><strong>üîß VAE Baked In: </strong>No extra steps‚Äîjust generate.</p></li><li><p>Read version details for the version you are using for more information!</p></li></ul><p><strong>‚ú®Improvements from </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/950531?modelVersionId=1330983\"><strong>RouWei</strong></a></p><ul><li><p>Easy and versatile prompting with great aesthetic, anatomy, and stability</p></li><li><p>Vibrant colors, smooth gradients, and full brightness range</p></li><li><p>Over <a target=\"_blank\" rel=\"ugc\" href=\"https://mega.nz/folder/lGQSVDyZ#uzuzfSlPRzgsWsxPQPbuhw\">35k artist styles</a> pure training (no merged weights), and customizable options. The list in .txt can be found on <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/tWrKk3jcXx\">our discord server</a>.</p><ul><li><p><strong>Note: </strong>you must use <code>by artistname</code> to trigger it!</p></li></ul></li><li><p>Eliminates watermarks, tag/character bleed, and strange artifacts for better coherence</p></li><li><p>Improved prompt following, stable styles, and accurate artist representation</p></li></ul><hr /><h3 id=\"recommended-settings\">üõ†Ô∏è <strong>Recommended Settings</strong></h3><ul><li><p><strong>Steps: </strong>25-30 (I use 30 normally)</p></li><li><p><strong>CFG: </strong>3-5 (<em>I use 5 normally</em>)</p><ul><li><p><strong>ONSITE GEN</strong> - I recommend CFG 3 for v4.0 to start off.</p></li></ul></li><li><p><strong>Sampler: </strong>Euler /<strong> </strong>Euler A (my go-to)</p></li><li><p><strong>Scheduler: </strong>Normal or Simple or SGM UNIFORM</p></li><li><p><strong>Resolution: </strong>1024x1536 (<em>native quality‚Äîno upscaling needed!). Standard Illustrious &amp; SDXL resolutions also supported (</em><strong>1024 x 1024</strong>, 1152 x 896, 896 x 1152, <strong>1216 x 832</strong>,<strong> 832 x 1216</strong>, 1344 x 768, 768 x 1344, 1536 x 640, 640 x 1536).</p></li><li><p><strong>Prompting</strong>: Use my <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1302719\">embeddings </a>for <strong>positive </strong>and <strong>negative </strong>and even <strong>NSFW </strong>embeddings to prevent or add üôà. No more guessworks for prompting! If you don't want to use embeddings, use your normal NoobAI/Illustrious quality triggers. Artist and booru tag support. Rating tag support.</p><ul><li><p><strong>v4.0</strong> - Download the new lazypos v2.0, don't use the old v1.0 for v4.0!!</p></li></ul></li></ul><p><strong>Pro Tips</strong></p><ul><li><p>Using <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1302719\">embeddings</a> for onsite gen doesn't cost you more buzz, if anything it helps you save buzz since you're not generating bad images!</p></li><li><p>Check my images‚Äô metadata for exact prompts/settings. Import them into ComfyUI to reverse-engineer my workflow!</p></li></ul><hr /><h3 id=\"fixes-and-feedback\">ü©∫ <strong>Fixes &amp; Feedback</strong></h3><ul><li><p><strong>Eyes still wonky? </strong>Use eye detailer, but most of the time you don't need unless the subject is further away.</p></li><li><p><strong>Found a bug? </strong>Report it‚ÄîI‚Äôll fix it in next version. I only generate with this model, so I‚Äôll keep improving it. I won't publish something I won't use myself.</p></li></ul><hr /><h3 id=\"why-i-made-this\">‚ù§Ô∏è <strong>Why I Made This</strong></h3><p>Tired of juggling 10 LoRAs for NSFW art? Me too. I want a NSFW checkpoint with more knowledge of characters and other common booru tags. This checkpoint is my <em>personal playground </em>‚Äîdesigned for creators who want <strong>bold, detailed, no-BS generations.</strong></p><p><strong>Future updates? </strong>Always. Let‚Äôs push boundaries together.</p><hr /><p><strong>Key upgrades:</strong></p><ul><li><p><strong>NSFW-focused tone </strong>with playful warnings (üîû, üö®).</p></li><li><p><strong>RouWei base merged with brightness and contrast fixed.</strong></p><p></p></li></ul><p><span style=\"color:rgb(230, 73, 128)\"><strong>Please share your feedback to improve the checkpoint together! ‚ù§Ô∏è</strong></span></p><p></p><p></p><hr /><p><strong>JANKU Checkpoint License &amp; Terms of Service</strong></p><p>By using JANKU, you agree to:</p><ol><li><p><strong>Comply with the </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Laxhar/noobai-XL-1.0/blob/main/README.md#model-license\"><strong>NoobAI-XL 1.0 License </strong></a>:</p><ul><li><p>No commercial use (outputs cannot be monetized).</p></li><li><p>Derivative models/LoRAs must remain open-source under the same license. When sharing derivatives, include a<strong> </strong>listing all model versions used.</p></li><li><p>No generation of harmful/illegal content.</p></li></ul></li><li><p><strong>User Responsibility </strong>:</p><ul><li><p>You are fully liable for all outputs. Use prompts to filter content.</p></li></ul></li><li><p><strong>Restrictions </strong>:</p><ul><li><p>No redistribution of modified versions without adhering to open-source terms.</p></li><li><p>No use for unlawful or harmful purposes.</p></li></ul></li></ol><p>Failure to comply voids usage rights.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832669+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "376130",
    "prompt": "Nova Anime XL\n<h1 id=\"nova-anime-xl\"><span style=\"color:rgb(190, 75, 219)\"><strong>Nova Anime </strong></span><span style=\"color:rgb(165, 135, 255)\"><strong>XL</strong></span></h1><p><span style=\"color:rgb(134, 142, 150)\">Nova Anime XL is Nova Anime: Anime/2.5D/3D checkpoint model for SDXL</span></p><p><span style=\"color:rgb(134, 142, 150)\">Pony version aims to get the similar look as both Nova Anime and Nova Domain</span></p><p><em>All images on example were created with diffusers with custom png tags</em></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1919380957851118193-Nova-Anime-XL-IL-v110\">PixAI - IL v11.0</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1911784373154262548-Nova-Anime-XL-IL-v100\">PixAI - IL v10.0</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1896210191422814425-Nova-Anime-XL-IL-v90\">PixAI - IL v9.0</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1885701165704197321-Nova-Anime-XL-IL-v80\">PixAI - IL v8.0</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1875202059696147371-Nova-Anime-XL-IL-v70\">PixAI - IL v7.0</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1863979941311864939-Nova-Anime-XL-IL-v60\">PixAI - IL v6.0</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1854748617339644763\">PixAI - IL v5.5</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1852520410433188008\">PixAI - IL v5.0</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1841864021434036598\">PixAI - IL v4.0 Happy Valentine</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1830987180899634413?utm_source=copy_web\">PixAI - IL v3.0 Happy New Year</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1814306013175304086\">PixAI - Illustrious v1.0</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1824470228898525885\">PixAI - Illustrious v2.0</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1827004160691369539\">PixAI - IL v2.5 Merry Christmas</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1741795202305284106\">PixAI - Pony v1-v2</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1773408482480963680\">PixAI - Pony v3</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1784314636120510122\">PixAI - Pony v4</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1792965070231956505\">PixAI - Pony v5</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1802718259462146644\">PixAI - Pony v6</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art/model/1806709091944314188\">PixAI - v7.0</a></p><h2 id=\"rules\"><strong>Rules</strong></h2><p>You cannot use the generated images for commercial use <u>if it's not edited</u> (or just turning it to black and white)<br />You can share images without any restriction <em><u>if you don't monetize it</u></em></p><p>Advertising this model to outside is always welcome</p><h2 id=\"recommend-settings\"><strong>Recommend Settings</strong></h2><p>Sampler: Euler a</p><p>Steps: 20~30</p><p>Clip Skip: 1-2</p><p>Denoising Strength: 0.65 - 0.8<br /><strong>(Pony)</strong></p><p>CFG Scale: 5~7</p><p>Prompt: score_9, score_8_up, score_7_up, score_6_up, score_5_up, score_4_up, source_anime, BREAK<br /></p><p>Negative Prompts: score_4, score_5, 3d, jpeg artifacts, username, watermark, signature, normal quality, worst quality, large head, low quality, text, error, missing fingers, extra digits, fewer digits, bad eye<br /><br /><strong>(Illustrious)</strong></p><p>CFG Scale: 4~6<br />Prompt: masterpiece, best quality, amazing quality, 4k, very aesthetic, high resolution, ultra-detailed, absurdres, newest, scenery, {Prompt}, BREAK, depth of field, volumetric lighting<br /><br />Negative Prompts: modern, recent, old, oldest, cartoon, graphic, text, painting, crayon, graphite, abstract, glitch, deformed, mutated, ugly, disfigured, long body, lowres, bad anatomy, bad hands, missing fingers, extra digits, fewer digits, cropped, very displeasing, (worst quality, bad quality:1.2), bad anatomy, sketch, jpeg artifacts, signature, watermark, username, signature, simple background, conjoined,bad ai-generated</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832675+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "12262",
    "prompt": "Night Sky YOZORA Style Model\n<h1><strong>Night Sky YOZORA Model ‚Äî‚Äî‚ÄúFor ultimate image quality and large image sizeÔºà&gt;1536 x 1024Ôºâ‚Äù</strong></h1><h3><strong>Trained by <span data-type=\"mention\" class=\"mantine-1yiar0p\" data-id=\"mention:34898\" data-label=\"YozoRaAru\">@YozoRaAru</span></strong></h3><h2><strong><em><u>Â¶ÇÊûú‰Ω†ÈúÄË¶ÅÊõ¥Â•ΩÁöÑËâ≤ÂΩ©Ë°®Áé∞ÔºåÊàëÊé®Ëçê‰Ω†ËØï‰∏Ä‰∏ã</u></em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/21200/color-box-model\"><strong><em><u>Color Box</u></em></strong></a></h2><h2><strong><em><u>If you want better colour representation There is a new style model </u></em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/21200/color-box-model\"><strong><em><u>Color Box</u></em></strong></a></h2><p><strong>YOZORA</strong> is a model that pursues perfection and is <strong>filled with personal preferences</strong>. I trained it using images that I like, which give it an unparalleled level of detail and completion. It can provide you with very exquisite character images.</p><p>In addition to training, I also blended it with dozens of other high-quality models that I personally like, and I tried layer blending as well. Among these models, I selected NovelAI's original model as the major weight because it can give it excellent adaptability to a variety of prompts. I haven't tried testing it with landscape + character yet, but I believe it can also perform excellently in that aspect.</p><ul><li><p>For the <strong><em>best results</em></strong>, please ensure that your <strong><em>final resolution &gt; 1536x1024</em></strong>. This is <strong><em>necessary</em></strong> for generating exquisite illustrations</p><p></p></li></ul><p>Here are some recommended settings for the parameters:</p><ul><li><p><strong>Clip skip</strong>: It is recommended to set it at no less than 2. <strong>YOZORA</strong> already has a rich level of detail, and setting it at 1 may make the image appear cluttered and confusing.</p></li><li><p><strong>Resolution</strong>: <strong>YOZORA</strong> may <strong>not be suitable for generating small images</strong> because the extreme level of detail may become too crowded. It is recommended <strong>do not use Hires.fix</strong> to generate <strong>large images</strong>. A larger resolution is equivalent to a larger canvas, making it easier for YOZORA to capture details. It is recommended to use <strong>1536 x 1024</strong> or higher for Hires.fix.</p></li><li><p><strong>Negative prompts</strong>: It is recommended to use <strong>EasyNegative</strong> to provide brief and precise descriptions.</p></li></ul><p>The name YOZORA means <strong>\"strolling among the stars in the night sky\"</strong>. I hope that she can bring you the excitement and joy of a sky full of stars on a starry night.</p><p></p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:34:50.832680+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  }
]