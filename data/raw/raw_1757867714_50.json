[
  {
    "id": "3627",
    "prompt": "Protogen v2.2 (Anime) Official Release\n<h3>Research Model - <a target=\"_blank\" rel=\"ugc\" href=\"https://www.reddit.com/r/StableDiffusion/comments/1079c0d/protogen_checkpoint_merging_data_reference/\">How to Build Protogen</a></h3><p>By Downloading you agree to the<br /><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/spaces/CompVis/stable-diffusion-license\">CreativeML Open RAIL-M</a><br />Running on Apple Silicon devices ? <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/coreml/coreml-Protogen\">Try this instead</a><br />Trigger words are available for the hassan1.4 and f222, might have to google them :)</p><h3><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/spaces/darkstorm2150/protogen-web-ui\"><strong>Live Demo at Available on Hugging Face</strong></a></h3><p><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://preview.redd.it/et9c6e3bsoda1.jpeg?width=1076&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=aa2049832da52e4e650e847e023147629e7faf40\"><strong>Model Weights</strong></a> thanks to reddit user <a target=\"_blank\" rel=\"ugc\" href=\"https://www.reddit.com/user/jonesaid\">u/jonesaid</a><br /></p><p>This is a cocktail mix of everything, mostly accurate for hands and skin texture, Enjoy!<br /><strong><br /></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.studiobinder.com/blog/ultimate-guide-to-camera-shots/\"><strong>Comprehensive guide to camera control</strong></a><strong><br /></strong></p><p>Using the tag \"modelshoot style\" can center the image on the intended subject.</p><h3>By downloading you agree to any licenses listed below.</h3><p>Models used</p><ul><li><p>f222_v1.ckpt</p></li><li><p>elldrethSLucidMix_V10.cpkt</p></li><li><p>hassanBlendAllVersio_hassanBlend14.ckpt</p></li><li><p>seek_art_mega_v1.ckpt (<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1315/seekart-mega\">license</a>)</p></li><li><p>modelshoot-1.0.ckpt</p></li></ul><p></p><p>Fun Camera Prompt Commands by MC Mic</p><pre><code>(from_above:1.3), (from_below:1.3),(from_side:1.3),(from_behind:1.3),</code></pre><p>Movement Control</p><pre><code>(hand_on_hip:1.2), (sitting:1.2),</code></pre>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898252+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "55700",
    "prompt": "bad_prompt Negative Embedding\n<h2>bad_prompt Version 1 and 2 (reupload from Huggingface)</h2><h2><a rel=\"ugc\" href=\"https://civitai.com/models/56519/negativehand-negative-embedding\">~Check out my new negative Embedding!~</a></h2><h3><strong>Foreword</strong></h3><p><strong>Since alot of people asked for it. Here is a reupload to civitai for my negative Embedding.</strong></p><p><strong>Disclaimer: A new negative embedding is still under develop and I will upload it on civit soon!</strong></p><p></p><p><strong>~Text from Huggingface~</strong></p><p><strong>Link: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/datasets/Nerfgun3/bad_prompt\"><strong>https://huggingface.co/datasets/Nerfgun3/bad_prompt</strong></a></p><p></p><h2><strong>Idea</strong></h2><p>The idea behind this embedding was to somehow train the negative prompt as an embedding, thus unifying the basis of the negative prompt into one word or embedding.</p><p>Side note: Embedding has proven to be very helpful for the generation of hands! :)</p><h2>Usage</h2><p>To use this embedding you have to download the file aswell as drop it into the \"\\stable-diffusion-webui\\embeddings\" folder.</p><p>To activate the embedding, you will have to write the name of the file in the negative prompt!</p><p><strong>Please put the embedding in the negative prompt to get the right results!</strong></p><p>For special negative tags such as \"malformed sword\", you still need to add them yourself. The negative embedding is trained on a basic skeleton for the negative prompt, which should provide a high-resolution image as a result.</p><h3>Version 1:</h3><p>Issue: Changing the style to much.</p><p>~not downloadable on civit~</p><h3>Version 2:</h3><p>With this version I tried to reduce the amount of vectors used, aswell as the issue with the changing artstyle. The newer version is still a work in progress, but its already way better than the first version. Its in files section!</p><p>To use it in the negative prompt: <code>\"bad_prompt_version2\"</code></p><p>I hope you enjoy the embedding. If you have any questions, you can ask me anything via Discord: \"Nerfgun3#7508\"</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898284+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "480835",
    "prompt": "Pony Amateur ‚ú®\n<h2 id=\"model-versions-3hz1drtv6\"><a target=\"_blank\" rel=\"ugc\" href=\"http://ko-fi.com/zyloo\"><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b1ed0fa2-119a-44f2-a1df-efcf794f4484/width=525/b1ed0fa2-119a-44f2-a1df-efcf794f4484.jpeg\" /></a><span style=\"color:rgb(18, 184, 134)\">üóÉ </span><strong><em><span style=\"color:rgb(18, 184, 134)\">Model </span></em><span style=\"color:rgb(18, 184, 134)\">Versions</span></strong></h2><p><em>Newer versions aren‚Äôt necessarily better than older ones, each has its own distinct style and characteristics.</em></p><ul><li><p><strong>CC &amp; Grain (V3):</strong> Stronger color correction and grain, achieving a high-quality, grainy aesthetic of amateur film photography.</p></li><li><p><strong>Standard (V2):</strong> Higher-quality yet amateurish, candid feel. It's easy to use straight out of the box, making it a great all-purpose option. <em>(</em>ü§ù<em>Special thanks to </em><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/blacksnowskill\"><em>@blacksnowskill</em></a><em>.)</em></p></li><li><p><strong>Rough (V1):</strong> A more damaged and textured look with a rougher aesthetic. Slightly more complex to use, but capable of producing excellent results with a bit of effort.</p><p></p></li></ul><h2 id=\"recommended-parameters-459ljszuk\">üè† <strong><em><span style=\"color:rgb(18, 184, 134)\">Recommended Parameters</span></em></strong></h2><h3 id=\"settings:-b9yq7igmp\"><em><span style=\"color:rgb(130, 201, 30)\">Settings:</span></em></h3><ul><li><p><strong>Strength<em>: </em></strong><em>0.2-0.9</em>.</p></li><li><p><strong>Clip Skip</strong>: <em>2</em></p></li></ul><h3 id=\"additional-information:-r2ab80wwv\"><em><span style=\"color:rgb(130, 201, 30)\">Additional Information:</span></em></h3><ul><li><p>Useful Trigger Words:</p><ul><li><p>photo</p></li><li><p>film grain</p></li><li><p>grainy</p></li><li><p>amateur</p></li><li><p>lowres</p></li><li><p>2000s nostalgia</p></li><li><p>webcam photo</p></li><li><p>flash</p><p></p></li></ul></li></ul><h2 id=\"training-loras-g7d7dhjpm\">üèãÔ∏è‚Äç‚ôÄÔ∏è <strong><em><span style=\"color:rgb(18, 184, 134)\">Training LoRas</span></em></strong></h2><ul><li><p><em>Read the following </em><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/5545/pony-realism-lora-training-and-preset\"><strong><em>article </em></strong></a><em>for tips and my training preset</em></p><p></p></li></ul><h2 id=\"buzz-for-the-best-images-cb69ihca6\">‚ö°Ô∏è <span style=\"color:rgb(253, 126, 20)\">Buzz for the Best Images </span>‚ö°Ô∏è</h2>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898301+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "456882",
    "prompt": "STYLES | PONY & ANIMAGINE\n<p></p><p></p><p><strong>Style1</strong>: <br />...got no idea what's this style called, soo its style1<br /><br /><strong>AIU 0.1</strong>: <br />mostly like skin texture with slightly different style compared to tpony<br />(trigger words: sweat, wet, oiled, shiny skin)</p><p></p><p><strong>VEY 0.1</strong>: <br />guess I'll have to train it again. it doesn't get a very different style (which I dun like) compared to pony base style sometimes.<br /><br /><strong>ALH 0.1</strong>: <br />ahh not one of my favourite styles, but trained to test how it works out</p><p></p><p><strong>CYR 0.1</strong>: <br />guess this is a popular style, saw lots of AI artist use this style in pixiv. not sure I got it right tho. like to see some results!<br /><br /><strong>MOC 0.1</strong>: <br />the moc text (the original AI creator's watermark) is showing up time to time.<br /><br /><strong>RMS 0.1</strong>: <br />feels like a model that I shouldn't have make, its just NOT a GOOD style for me, intended to create plump females, at least dataset is like that. <br />anyways just uploaded (use weight around 1.0 - 0.5)<br />kind of similar to orange mix and other 1.5 sd styles, isnt it?<br /><br /><strong>STS 0.1:</strong><br />for some reason \"blush\" works like trigger word. did enable shuffle caption tho, <br />so you cant create anyone without blushing face. sucks ofc, guess I'll train a one.</p><p></p><p><strong>STS 0.4:</strong></p><p>Okay, finally \"blush\" isn't the trigger word, unfortunately couldn't completely remove the trigger word, so put <strong>\"<span style=\"color:rgb(250, 176, 5)\">TSS</span>\"</strong> as the trigger word.</p><p></p><p>PLM 0.1: <span style=\"color:rgb(250, 82, 82)\">BAD LORA</span></p><p></p><p><strong>CKS 0.2:</strong></p><p>requested lora. kind of similar to t-pony style.<span style=\"color:rgb(250, 176, 5)\"> </span>trigger word <span style=\"color:rgb(250, 176, 5)\">- cksxin</span><br />dataset credits for <span data-type=\"mention\" class=\"mantine-1yiar0p\" data-id=\"mention:85942\" data-label=\"yeyebeixin\">@yeyebeixin</span>.<strong><span style=\"color:rgb(193, 194, 197)\"> </span></strong><span style=\"color:rgb(193, 194, 197)\">(provided with 10GB dataset which includes about 4600 images)</span></p><p></p><p><strong>RAR 0.1:</strong></p><p>trigger word <span style=\"color:rgb(250, 176, 5)\">- RAR</span></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898308+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "120723",
    "prompt": "DetailedEyes_XL\n<p>use 0 images for finetune XLbaseÔºåshould fit any XL model(even anime)</p><p>add detailed eyes„ÄÅdetailed face and detailed skin</p><p>including neg part and fixed bad hands</p><p>Less effect over 75 tokens</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898312+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "1025051",
    "prompt": "Illustrij\n<h2 id=\"hey-guys\"><em>hey guys, </em><span style=\"color:rgb(250, 176, 5)\"><em>‚ò∫</em></span></h2><p><em>as u know I rlly love comic-anime-hybrid based checkpoints and digital art rendering with a touch of 3D on its way to semirealism. So I've thought it would be time to test Illustrious. This is how I wanna present to u ~ </em><strong><em>Illustrij</em></strong><em> ~ my first merged Illustrious checkpoint :)</em></p><hr /><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/651c5243-5a09-4d9f-8f31-124fec9b1532/width=525/651c5243-5a09-4d9f-8f31-124fec9b1532.jpeg\" /></p><hr /><h3 id=\"about-v18-love-new\">üé∂ <span style=\"color:rgb(190, 75, 219)\">ab</span><span style=\"color:rgb(121, 80, 242)\">ou</span><span style=\"color:rgb(76, 110, 245)\">t v</span><span style=\"color:rgb(34, 139, 230)\">18 </span><span style=\"color:rgb(250, 176, 5)\"><strong>‚ô• NEW</strong></span></h3><hr /><p><em>Ur feedback is important to me ‚ò∫</em></p><p>Why no update for so long? <em>Sometimes u take a step back to make the next leap.</em></p><pre><code>\n| ‚ô• | a little finer\n| ‚ô• | a touch more restraint &amp; therefore more on point\n| ‚ô• | less shine, more shimmer\n| ‚ô• | one more dance step towards my hidden aim ~ ADetailer optional \n~ less must, more can\n</code></pre><p>| <span style=\"color:rgb(250, 176, 5)\"><strong>‚ô•</strong></span> | <strong>Specs:</strong> DPM++ 2M Karras¬∑ 30 Steps ¬∑ 832√ó1216 ¬∑ CFG 4 ¬∑ Hires √ó1.526 ¬∑ SFW &amp; NSFW</p><p>| <span style=\"color:rgb(250, 176, 5)\"><strong>‚ô•</strong></span> | quality tags option examples:</p><p>| + | masterpiece, best quality,</p><p>| ~ | worst quality, bad quality, young,</p><p><em>I'm happy if u feel comfortable with the new version ‚ô•</em></p><p><em>~‚ô• Reij</em></p><hr /><h3 id=\"about-v17\">üé∂ <span style=\"color:rgb(190, 75, 219)\">ab</span><span style=\"color:rgb(121, 80, 242)\">ou</span><span style=\"color:rgb(76, 110, 245)\">t v</span><span style=\"color:rgb(34, 139, 230)\">17</span></h3><hr /><p><span style=\"color:rgb(190, 75, 219)\">reco</span><span style=\"color:rgb(121, 80, 242)\">mm</span><span style=\"color:rgb(102, 80, 242)\">en</span><span style=\"color:rgb(76, 110, 245)\">ded se</span><span style=\"color:rgb(34, 139, 230)\">ttings e</span><span style=\"color:rgb(21, 170, 191)\">xampl</span><span style=\"color:rgb(18, 184, 134)\">es:</span></p><ul><li><p>30 steps</p></li><li><p>Euler a</p></li><li><p>Clip skip 2</p></li><li><p>no extra VAE (VAE included)</p></li><li><p>tags / _tags</p></li><li><p>resolutions 832x1216 +++</p></li></ul><p><em>+prompt:</em></p><pre><code>masterpiece, best quality, ultra-detailed, 8k resolution, high dynamic range, absurdres, stunningly beautiful, intricate details, sharp focus, detailed eyes, cinematic color grading, high-resolution texture, </code></pre><p><em>Small mini upgrader for face focus images with hand motions, gives images a more focused touch regardless of the prompt:</em></p><pre><code>photorealistic portrait, nails, </code></pre><p>-prompt:</p><pre><code>(worst quality:2), (low quality:2), (normal quality:2), bad anatomy, bad proportions, poorly drawn face, poorly drawn hands, missing fingers, extra limbs, blurry, pixelated, distorted, lowres, jpeg artifacts, watermark, signature, text, (deformed:1.5), (bad hands:1.3), overexposed, underexposed, censored, mutated, extra fingers, cloned face, bad eyes</code></pre><p><em>I am happy if u enjoy and stay curious abt ur new adventures with Illustrij</em></p><p><em>with </em>‚ô•Ô∏è<em> Reij</em></p><hr /><h2 id=\"about-v16\"><span style=\"color:rgb(76, 110, 245)\">ab</span><span style=\"color:rgb(34, 139, 230)\">ou</span><span style=\"color:rgb(21, 170, 191)\">t v</span><span style=\"color:rgb(18, 184, 134)\">16</span></h2><h3 id=\"back-to-the-core-forward-in-form\"><em>Back to the Core, Forward in Form</em></h3><p><strong>üîπ Illustrij 16</strong></p><p><em>is a fusion ~ a conscious pause between old and new. She remains true to herself and recognizes her original reflection more than ever. What seems like a return is also progress: a rediscovery of the origin with a new perspective.</em></p><p><em>The semi-realistic base with a subtle anime touch remains, but now with a touch more video game aesthetic ~ stylized but tangible, inspired by character designs that balance between playable figure and digital fantasy. The look is more oriented towards the origins ~ before the big 2.5D shift ~ and picks up the iconic face shape of previous versions: familiar, rounder, clearer.</em></p><p><em>This time, the special focus is on the realistic reaction of the body: skin that responds to movement, light and shadow that create depth and presence. SFW and NSFW are still supported - but with more emphasis on the body through credible lighting and play of form. v16 wraps itself in a cocoon of ‚ÄúBack to the Roots‚Äù, interwoven with a sweet-cheeky duality ~ sweet but cheeky, like at the beginning. From this inner reconciliation a new self emerges: a balance between nostalgia and artistic development.</em></p><p><span style=\"color:rgb(190, 75, 219)\">reco</span><span style=\"color:rgb(121, 80, 242)\">mm</span><span style=\"color:rgb(102, 80, 242)\">en</span><span style=\"color:rgb(76, 110, 245)\">ded se</span><span style=\"color:rgb(34, 139, 230)\">ttings e</span><span style=\"color:rgb(21, 170, 191)\">xampl</span><span style=\"color:rgb(18, 184, 134)\">es:</span></p><ul><li><p>30 steps</p></li><li><p>Euler a</p></li><li><p>Clip skip 2</p></li><li><p>no extra VAE (VAE included)</p></li><li><p>tags / _tags</p></li><li><p>resolutions 832x1216 +++</p></li></ul><p><em>+prompt:</em></p><pre><code>masterpiece, best quality, high quality, absurdres, very aesthetic, 8k, depth of field, subject focus, face_focus, detailed eyes, </code></pre><p>-prompt:</p><pre><code>lowres, bad anatomy, deformed face, watermark, logo, </code></pre><p><strong><em>optional for the ‚Äútiny extra‚Äù glossy look </em></strong>ü´¶</p><p><em>+prompt:</em></p><pre><code>masterpiece, best quality, absurdres, gradient, face_focus, detailed eyes, very awa, nail polish, glossy skin, \n(+ optional: realistic skin)</code></pre><p>-prompt:</p><pre><code>bad quality, worst quality, lowres, jpeg artifacts, bad anatomy, signature, watermark, censored, </code></pre><p><em>I am happy if u enjoy and stay curious abt ur new adventures with Illustrij</em></p><p><em>with </em>‚ô•Ô∏è<em> Reij</em></p><hr /><h2 id=\"about-v15\"><span style=\"color:rgb(76, 110, 245)\">ab</span><span style=\"color:rgb(34, 139, 230)\">ou</span><span style=\"color:rgb(21, 170, 191)\">t v</span><span style=\"color:rgb(18, 184, 134)\">15</span></h2><p><strong>üîπ Illustrij 15</strong></p><p><strong><em>keeping a semirealistic look by spawning with hyperrealistic, near-photographic skin textures, a clean airbrush finish, and cinematic lighting. The look blends digital editorial aesthetics with anime-inspired elegance. Her clothing is form-flattering with textile-realistic sheen ‚Äì</em></strong></p><p><strong><em>v15 is polished, stylized, and ready to bring ur imagination to life :)</em></strong></p><p><em>situational: this version tends to be a bit more body-forward, so if that's not ur style, adding ‚Äúnudity‚Äù to the negative prompt helps tone it down. Ur feedback matters ~ that‚Äôs why this update brings more \"depth\". I am happy if u have fun exploring and can‚Äôt wait to see what u create! ~‚ô•</em></p><p><em>with </em>‚ô•Ô∏è<em> Reij</em></p><p><span style=\"color:rgb(190, 75, 219)\">reco</span><span style=\"color:rgb(121, 80, 242)\">mm</span><span style=\"color:rgb(102, 80, 242)\">en</span><span style=\"color:rgb(76, 110, 245)\">ded se</span><span style=\"color:rgb(34, 139, 230)\">ttings e</span><span style=\"color:rgb(21, 170, 191)\">xampl</span><span style=\"color:rgb(18, 184, 134)\">es:</span></p><ul><li><p>30 steps</p></li><li><p>Euler a, DPM++ 2M</p></li><li><p>Clip skip 2</p></li><li><p>no extra VAE (VAE included)</p></li><li><p>tags / _tags</p></li><li><p>resolutions 832x1216 (‚óÑ‚Ä¢ showcase images) &amp; 1040x1510</p></li></ul><p>+prompt:</p><pre><code>high_quality, highres, detailed_eyes, detailed, masterpiece, best quality, absurdres, 8k, HDR, face_focus, </code></pre><p>alternatively:</p><pre><code>masterpiece, high quality, very_awa, newest, absurdres, highres, depth_of_field, </code></pre><pre><code>realistic_skin,</code></pre><p>-prompt:</p><pre><code>lowres, bad anatomy, deformed face, </code></pre><p>alternatively:</p><pre><code>poorly_detailed, jpeg_artifacts, worst_quality, bad_quality, lowres, bad anatomy, deformed face, glossy_skin</code></pre><hr /><h2 id=\"about-v14\"><span style=\"color:rgb(76, 110, 245)\">ab</span><span style=\"color:rgb(34, 139, 230)\">ou</span><span style=\"color:rgb(21, 170, 191)\">t v</span><span style=\"color:rgb(18, 184, 134)\">14</span></h2><p><strong>üîπ Illustrij v14 ~ she moves with us</strong><br /><em>While preparing the showcase, she caught me all over again ~ and that‚Äôs what I love most about </em>Illustrij.<em><br />We meet her with or without expectations ~ it doesn‚Äôt matter. She surprises, reveals new shades of herself, and stirs that quiet curiosity that pulls us deeper.</em></p><p><em>She dances with the prompt ~ playful, bold, sensual. Not loud, but vividly alive.<br />Her look is familiar, yet this time she feels more tangible than ever ~ softer fills, intentional lighting, and a glow that embraces instead of overwhelming.<br />Her clothing? Almost like skin ~ clinging to her with every movement, emotion, breath. As if it wants to sway with her, feel with her, live with her.</em></p><p>Illustrij<em> v14 doesn‚Äôt live in the frame.<br />She lives the frame.</em></p><p></p><p><strong>üî∏ Showcase Note:</strong><br /><em>All showcase images are rendered at 1040 √ó 1510 ~ because she just wanted to show a little more of herself.<br />A bit more room, a bit more motion. That‚Äôs so Illustrij: more pixels, more presence, more of that signature sway.</em> ü©∞‚ú®</p><p></p><p><em>If she twirled her way into ur heart too ~ she‚Äôd love a </em>‚ô•Ô∏è<em>.<br />And so would I.</em> ‚ú®ü©∞</p><p></p><p><em>I am happy if u enjoy and stay curious abt ur results ~‚ô•</em></p><p><em>with </em>‚ô•Ô∏è<em> Reij</em></p><p></p><p><span style=\"color:rgb(190, 75, 219)\">reco</span><span style=\"color:rgb(121, 80, 242)\">mm</span><span style=\"color:rgb(102, 80, 242)\">en</span><span style=\"color:rgb(76, 110, 245)\">ded se</span><span style=\"color:rgb(34, 139, 230)\">ttings e</span><span style=\"color:rgb(21, 170, 191)\">xampl</span><span style=\"color:rgb(18, 184, 134)\">es:</span></p><pre><code>30 steps</code></pre><pre><code>Euler a</code></pre><pre><code>Clip skip 2</code></pre><pre><code>CFG 7</code></pre><pre><code>no extra VAE (VAE included)</code></pre><pre><code>tags / _tags</code></pre><pre><code>resolutions 1040 x 1510</code></pre><p>+prompt:</p><pre><code>masterpiece, detailed_eyes, high_quality, best_quality, highres, absurdres, 8k, subject_focus, depth_of_field, </code></pre><p>-prompt:</p><pre><code>poorly_detailed, jpeg_artifacts, worst_quality, bad_quality, </code></pre><hr /><h2 id=\"about-v13\"><span style=\"color:rgb(76, 110, 245)\">ab</span><span style=\"color:rgb(34, 139, 230)\">ou</span><span style=\"color:rgb(21, 170, 191)\">t v</span><span style=\"color:rgb(18, 184, 134)\">13</span></h2><p>üñ§ <em>Tiny update ~ big heart</em> ‚ú®</p><p><em>Hey friends~</em></p><p><em>although I wasn't planning on doing a revision so quickly, a quiet spark inside me made me want to update Illustrij with a lil more soul ~ especially in her hands, her gestures, her presence. She's still herself, just a touch more expressive.</em></p><p></p><p>‚ú®<em> At the same time, on-site generation has brought new challenges ~ and one of them is staying true to her unique face without needing facefixes. That‚Äôs why I‚Äôve been merging and refining more often lately. It's not just tinkering ~ it‚Äôs me listening closely to her, shaping her gently, and trying to bring her essence through without compromise.</em></p><p></p><p><em>It‚Äôs a small change, but it carries a lot of love. Maybe it‚Äôs just a subtle shift‚Ä¶ or maybe it‚Äôs the detail someone was waiting for. Either way, I couldn‚Äôt keep it to myself </em>‚ô°</p><p><em>But I didn't want to just overwrite her former self. So: The current version is now available for free download as a small thank u and souvenir ~ and in a few days the updated version will gently take her place in the on-site generation, assuming we make it through the auction.</em></p><p></p><p><em>Thank u so much for being here through all her forms ‚ô° Every detail, every evolution ~ it means the world to share it with u.</em></p><p><em>Let‚Äôs keep creating ~ together, gently, beautifully.</em></p><p><em>With üíñ ~ Reij</em></p><p></p><p><em>All showcase images are in on site resolution 832 x 1216 with hires x1,526 ~ without Adetailer</em></p><p><span style=\"color:rgb(190, 75, 219)\">reco</span><span style=\"color:rgb(121, 80, 242)\">mm</span><span style=\"color:rgb(102, 80, 242)\">en</span><span style=\"color:rgb(76, 110, 245)\">ded se</span><span style=\"color:rgb(34, 139, 230)\">ttings e</span><span style=\"color:rgb(21, 170, 191)\">xampl</span><span style=\"color:rgb(18, 184, 134)\">es:</span></p><pre><code>30 steps</code></pre><pre><code>Euler a</code></pre><pre><code>Clip skip 2</code></pre><pre><code>CFG 7</code></pre><pre><code>no extra VAE (VAE included)</code></pre><pre><code>tags / _tags</code></pre><pre><code>resolutions 1024*1024+</code></pre><p>+prompt:</p><pre><code>high_quality, highres, detailed_eyes, beautiful, detailed, masterpiece, best quality, absurdres, 8k, HDR, face_focus, </code></pre><p>‚ò∫<em> I decided to showcase her in a new vibe: </em>üé® <em>Retro Pop Art Grunge</em>.</p><p><em>‚ò∫ To get the showcase image style feel free to add:</em></p><pre><code>retro, grunge, popart</code></pre><p>+prompt:</p><pre><code>worst_quality, bad_quality, poorly_detailed,</code></pre><p></p><hr /><h2 id=\"about-v12\"><span style=\"color:rgb(76, 110, 245)\">ab</span><span style=\"color:rgb(34, 139, 230)\">ou</span><span style=\"color:rgb(21, 170, 191)\">t v</span><span style=\"color:rgb(18, 184, 134)\">12</span></h2><p>‚ú® <em>Hey friends~</em></p><p><em>Back again with a new version of my precious comic-anime hybrid: </em><strong><em>Illustrij v12</em></strong><em> üå∏</em></p><p><em>U know how much I love that digital art rendering that leans into soft 3D, with a touch of lightplay and emotion. And with v12, she‚Äôs blooming more than ever ~ with more depth, warmth and expression.<br />She‚Äôs not just a model ~ she‚Äôs a little soul. A vibe. A mood. A presence.<br />I don‚Äôt just build tools ~ I shape characters. And she, like the others, feels like her.</em></p><p><em>üñ§ This version has a stronger sense for light, character design and stylistic harmony ~ especially suited for natural and studio-style shots. I focused the previews more on my current fav: soft retro-grunge aesthetics üßÉüåæ but she‚Äôs still versatile like always! (The other styles are all still possible, give it a try~)</em></p><p><em>If she speaks to u ~ a like, a comment or a creation means the world.<br />Thank u for being here ‚ô°</em></p><p></p><p><em>All showcase images are in on site resolution 832 x 1216 with hires x1,526 ~ without Adetailer</em></p><hr /><h2 id=\"about-v11\"><span style=\"color:rgb(76, 110, 245)\">ab</span><span style=\"color:rgb(34, 139, 230)\">ou</span><span style=\"color:rgb(21, 170, 191)\">t v</span><span style=\"color:rgb(18, 184, 134)\">11</span></h2><p><em>hey guys, ‚ò∫</em></p><p><em>the current version places more focus on light, prompting, Illustrij character design and depth.</em></p><p><span style=\"color:rgb(190, 75, 219)\">reco</span><span style=\"color:rgb(121, 80, 242)\">mme</span><span style=\"color:rgb(76, 110, 245)\">ndet se</span><span style=\"color:rgb(34, 139, 230)\">ttings e</span><span style=\"color:rgb(21, 170, 191)\">xampl</span><span style=\"color:rgb(18, 184, 134)\">es:</span></p><pre><code>30 steps</code></pre><pre><code>Euler a</code></pre><pre><code>Clip skip 2</code></pre><pre><code>CFG 7</code></pre><pre><code>no extra VAE (VAE included)</code></pre><pre><code>_tags</code></pre><pre><code>resolutions 1024*1024+</code></pre><p><em>Locally u can of course also use a resolution around 1040x1510 ‚ò∫</em></p><p>+prompt:</p><pre><code>high_quality, highres, detailed_eyes, beautiful, detailed, masterpiece, best quality, absurdres, 8k, HDR, face_focus, </code></pre><pre><code>masterpiece, high_quality, highres, depth_of_field, subject_focus, 8K, </code></pre><pre><code>(masterpiece:1.3), (best_quality:1.3), (ultra_detailed:1.2), (official_art), (absurdres), \nintricate_details, refined_textures, volumetric_lighting, perfect_shadow, realistic_depth, hyperfocus, (depth_of_field:1.2), detailed_eyes,</code></pre><p>-prompt:</p><pre><code>worst_quality, bad_quality, poorly_detailed, extra_fingers, malformed_hands, deformed_feet, blurry, young</code></pre><pre><code>worst_quality, bad_quality, poorly_detailed,</code></pre><hr /><h2 id=\"about-v10\"><span style=\"color:rgb(76, 110, 245)\">ab</span><span style=\"color:rgb(34, 139, 230)\">ou</span><span style=\"color:rgb(21, 170, 191)\">t v</span><span style=\"color:rgb(18, 184, 134)\">10</span></h2><p><em>Hey guys, </em>‚ò∫</p><p><em>over the last few days I've continued to work on Illustrij, spawned v10 with softer skin, new expression ~ to create a bit more liveliness. Even with the latest changes, Illustrij isn't perfect - I'm continuing to work on making it possible to create images without Adetailer. If the distance is further away, I would currently recommend Facefix or Adetailer. The new onsite generation presents me with new challenges ~ so I continue to tinker diligently and still experimenting, v10 is more oriented towards v8 again with an inclusion of v9.</em></p><p><em>The newest version is more balanced in the mix between semi-realism and anime elements.</em></p><p></p><p><span style=\"color:rgb(190, 75, 219)\">reco</span><span style=\"color:rgb(121, 80, 242)\">mme</span><span style=\"color:rgb(76, 110, 245)\">ndet se</span><span style=\"color:rgb(34, 139, 230)\">ttings e</span><span style=\"color:rgb(21, 170, 191)\">xampl</span><span style=\"color:rgb(18, 184, 134)\">es:</span></p><pre><code>Euler a</code></pre><pre><code>Clip skip 2</code></pre><pre><code>CFG 5-7</code></pre><pre><code>no extra VAE (VAE included)</code></pre><pre><code>_tags</code></pre><pre><code>resolutions 1024*1024+</code></pre><p><em>‚ò∫ mostly I'm using the following resolutions: 832*1216 &amp; 1040*1510 or 720*1280 &amp; 900*1600</em></p><p><em>‚ò∫ for hands and feet u are welcome to use the following quality tags:</em></p><p>+prompt:</p><pre><code>detailed_hands, elegant_fingers, beautiful_feet</code></pre><p>-prompt:</p><pre><code>extra_fingers, malformed_hands, deformed_feet,</code></pre><p><em>example quality prompt recommendation:</em></p><p>+prompt</p><pre><code>masterpiece, high_quality, highres, sharp_focus, detailed_eyes,</code></pre><p>-prompt:</p><pre><code>worst_quality, bad_quality, poorly_detailed, extra_fingers, malformed_hands, deformed_feet, blurry,</code></pre><p><em>Have fun being creative ‚ò∫ I am happy if u enjoy and stay curious abt ur results ~‚ô•</em></p><h3></h3><p><span style=\"color:rgb(190, 75, 219)\">a littl</span><span style=\"color:rgb(121, 80, 242)\">e comp</span><span style=\"color:rgb(76, 110, 245)\">arison </span><span style=\"color:rgb(34, 139, 230)\">V7 to V1</span><span style=\"color:rgb(21, 170, 191)\">0:</span></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/53483fef-5091-49a5-9239-f61bea4c955b/width=525/53483fef-5091-49a5-9239-f61bea4c955b.jpeg\" /><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e12dc68e-9720-4f26-85fc-e5a8773106ea/width=525/e12dc68e-9720-4f26-85fc-e5a8773106ea.jpeg\" /></p><hr /><h2 id=\"about-v9\"><span style=\"color:rgb(76, 110, 245)\">ab</span><span style=\"color:rgb(34, 139, 230)\">ou</span><span style=\"color:rgb(21, 170, 191)\">t v</span><span style=\"color:rgb(18, 184, 134)\">9</span></h2><p><em>Tinkered around a bit with my own models and Loras back to a more balanced anime-semireal style and added a little NSFW touch.</em> ‚ò∫</p><p></p><p><span style=\"color:rgb(190, 75, 219)\">hent</span><span style=\"color:rgb(121, 80, 242)\">ai &amp; N</span><span style=\"color:rgb(76, 110, 245)\">SFW</span></p><p><em>With hentai and NSFW images, the model sometimes has its own idea the less ur pre-prompting ~ maybe u would like to get involved?</em></p><p><em>These two posts offer a little foretaste:</em></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/14082774\">https://civitai.com/posts/14082774</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/14081639\">https://civitai.com/posts/14081639</a></p><p><em>more animebased:</em> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/14088147\">https://civitai.com/posts/14088147</a></p><p></p><p><em>Since Illustrij is based on combining elements of semirealism and anime, the newer versions spawn with more depth and a 2.5 D feeling. Through promptings we can determine the direction a bit, whether more semi-realism or anime </em>‚ò∫<em> entirely according to ur own taste. For more anime I recommend the following settings:</em></p><p><span style=\"color:rgb(190, 75, 219)\">reco</span><span style=\"color:rgb(121, 80, 242)\">mme</span><span style=\"color:rgb(76, 110, 245)\">ndet re</span><span style=\"color:rgb(34, 139, 230)\">solutio</span><span style=\"color:rgb(21, 170, 191)\">n</span></p><p><span style=\"color:rgb(21, 170, 191)\">1024*1024 / 832*1216 / 720*1280</span></p><p><span style=\"color:rgb(190, 75, 219)\">reco</span><span style=\"color:rgb(121, 80, 242)\">mme</span><span style=\"color:rgb(76, 110, 245)\">ndet se</span><span style=\"color:rgb(34, 139, 230)\">ttings e</span><span style=\"color:rgb(21, 170, 191)\">xampl</span><span style=\"color:rgb(18, 184, 134)\">es Anime+</span></p><pre><code>Clip skip 2</code></pre><pre><code>Euler </code></pre><pre><code>local: 15-25 steps</code></pre><pre><code>CFG 7-10</code></pre><p>+prompt</p><pre><code>(masterpiece, high_quality, highres, anime_style, flat_colors, gradient), retro_artstyle 1980 \\(style\\), 2D, sketch, </code></pre><p>- prompt</p><pre><code>worst_quality, bad_quality, poorly_detailed, young, realistic, 3D, semireal</code></pre><p><span style=\"color:rgb(190, 75, 219)\">reco</span><span style=\"color:rgb(121, 80, 242)\">mme</span><span style=\"color:rgb(76, 110, 245)\">ndet se</span><span style=\"color:rgb(34, 139, 230)\">ttings e</span><span style=\"color:rgb(21, 170, 191)\">xampl</span><span style=\"color:rgb(18, 184, 134)\">es Semi</span><span style=\"color:rgb(64, 192, 87)\">realism+</span></p><pre><code>Clip skip 2</code></pre><pre><code>Euler a</code></pre><pre><code>on site: 50 steps / local: 25+</code></pre><pre><code>CFG 4 (2-7)</code></pre><p>+prompt</p><pre><code>(masterpiece, high_quality, highres, flat_colors, gradient),</code></pre><pre><code>best_quality, absurdres, ultra-detailed, highly_aesthetic, highly_detailed_eyes, depth_of_field, subject_focus,</code></pre><pre><code>(masterpiece, high_quality, highres, flat_colors, gradient), ultra-detailed, highly_aesthetic, highly_detailed_eyes, depth_of_field, subject_focus,</code></pre><p>-prompt example</p><pre><code>worst_quality, bad_quality, poorly_detailed,</code></pre><pre><code>bad_anatomy, low_quality, poor_lighting, out_of_focus, misaligned, poorly_drawn, cluttered_background, unnatural_pose, disproportionate, unattractive_expression, soft_shading, clean_lines, no_background, </code></pre><p><em>In both variations, Illustrij remains a mix of semi-realism and anime, with different emphasis. ‚ò∫ In summary, the more steps and the lower the CFG, the more semi-realism, the fewer steps, and the higher the CFG, the more anime-touched.</em></p><p></p><p><em>I am happy if u enjoy and stay curious abt ur results ‚ô•</em></p><p></p><hr /><h2 id=\"about-v8\"><span style=\"color:rgb(76, 110, 245)\">ab</span><span style=\"color:rgb(34, 139, 230)\">ou</span><span style=\"color:rgb(21, 170, 191)\">t v</span><span style=\"color:rgb(18, 184, 134)\">8</span></h2><p><em>V8 is an experiment to integrate some of my Loras into Illustrij ~ without triggers of course ;) Let me know if u like the direction and how we can develop Illustrij further. I also tried to ensure that the model's style remained true to itself while leaving out the negative prompt.</em></p><p><em>V8 can create furry aswell.</em></p><p><em>I'm looking forward to ur results and hope u have a lot of fun being creative.</em></p><p><em>recommended settings:</em></p><pre><code>Euler a / Euler</code></pre><pre><code>25-30 steps</code></pre><pre><code>CFG 5-7</code></pre><pre><code>Clip skip 2</code></pre><pre><code>_ might wanna be ur friend for tags</code></pre><p>‚ò∫ <em>Showcase resolution: 720*1280. I would recommend using ADetailer for further distance.</em></p><p>+prompt example</p><pre><code>masterpiece,best quality,amazing quality,very aesthetic,absurdres,newest,detailed eyes,</code></pre><p>-prompt example</p><pre><code>u can leave empty</code></pre><p>or</p><pre><code>worst_quality, bad_quality,</code></pre><p><span style=\"color:rgb(190, 75, 219)\"><strong>a littl</strong></span><span style=\"color:rgb(121, 80, 242)\"><strong>e comp</strong></span><span style=\"color:rgb(76, 110, 245)\"><strong>arison o</strong></span><span style=\"color:rgb(34, 139, 230)\"><strong>f V7 and V</strong></span><span style=\"color:rgb(21, 170, 191)\"><strong>8</strong></span></p><p><span style=\"color:rgb(21, 170, 191)\"><strong><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/988d528c-8138-465b-8485-a58a618d9320/width=525/988d528c-8138-465b-8485-a58a618d9320.jpeg\" /></strong></span><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b498346d-2922-4f43-8be5-323df3ec134b/width=525/b498346d-2922-4f43-8be5-323df3ec134b.jpeg\" /></p><hr /><h2 id=\"about-v7\"><span style=\"color:rgb(76, 110, 245)\">ab</span><span style=\"color:rgb(34, 139, 230)\">ou</span><span style=\"color:rgb(21, 170, 191)\">t v</span><span style=\"color:rgb(18, 184, 134)\">7</span></h2><p><em>V7 takes a big step back to the roots and yet somewhere completely different ~ quest: keeping the balance . . . focus on painting a 2.5D lightning effect by drawing the Illustrij faces. I'm curious to see whether u like it and look forward to ur creations ~‚ô•</em></p><p><em>Please let me know if u like the new direction ‚ò∫</em></p><p><em>recommended settings: </em>720*1280 / Euler a / CFG 7 / steps 25+ / Clip skip 2</p><p>üê∞ furry optional</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d2cb64c3-22fb-4ea7-8eff-347272770443/width=525/d2cb64c3-22fb-4ea7-8eff-347272770443.jpeg\" /></p><hr /><h2 id=\"about-v6\"><span style=\"color:rgb(76, 110, 245)\">ab</span><span style=\"color:rgb(34, 139, 230)\">ou</span><span style=\"color:rgb(21, 170, 191)\">t v</span><span style=\"color:rgb(18, 184, 134)\">6</span></h2><p><em>The new versions spawns with a touch of 2.5 D remdering ~ with a </em><strong><em>flat-shaded anime style</em></strong><em>, but </em><strong><em>subtle 3D lighting and depth</em></strong><em>, making images look almost tangible.</em></p><p></p><p><em>I hope you like it and stay tuned for your results ~‚ô•</em></p><p></p><ul><li><p>showcase resolution: 1040 x 1510</p><p><u>prompt examples:</u></p></li></ul><p><em>Prompting is basically similar to the previous versions. After playn around with and testing old quality prompts ~ at the moment I prefer to use </em>\"<span style=\"color:rgb(21, 170, 191)\">masterpiece, best quality, amazing quality, very aesthetic, absurd, newest, detailed eyes</span>\" or \"<span style=\"color:rgb(21, 170, 191)\">masterpiece, best quality</span>,\"<em> for +prompt and</em> \"<span style=\"color:rgb(253, 126, 20)\">worst quality, bad quality,</span><em>\" for -prompt.</em></p><p><em>Of course these are just examples, u can vary them to suit ur own taste.</em></p><hr /><h2 id=\"about-v5\"><span style=\"color:rgb(76, 110, 245)\">ab</span><span style=\"color:rgb(34, 139, 230)\">ou</span><span style=\"color:rgb(21, 170, 191)\">t v</span><span style=\"color:rgb(18, 184, 134)\">5</span></h2><p><em>hey guys, ‚ò∫</em></p><pre><code>the gap between v4 and v5 was only a few days ago, but I've been \"tinkering around\" a bit and didn't want to keep it from you.\n\nTrying to work on getting the quality closer to hires without hires - but there are still a few steps to go ^^\nFor people who have good hardware and can generally use a lot of Loras etc. at the same time the difference might not be that big, but I feel for the people who have small graphics cards :I \nThe quality isn't perfect, but I've been working on it a bit ~ soft filling, clean renderings ~ the plan was to create an own style, subtly painted ~ anime-based, but still kissed by reality.\n\nI hope you like the merge and I'm really looking forward to your results ‚ô•</code></pre><p><em>Belonging to the style u prefer u can switch the promptings 4 sure by ur own taste. In general, I mostly use</em> <span style=\"color:rgb(18, 184, 134)\">\"masterpiece,best quality,amazing quality,very aesthetic,absurdres,newest,detailed eyes\" </span><em>for general quality prompting, and besides depending on whether I want more anime or anime semi 3D touched</em> <em>I am writing </em>\"<span style=\"color:rgb(18, 184, 134)\">A professional,high-quality,hyper-realistic portrait of a woman, 3D</span>\" <em>for the semianime 3D version and</em> \"<span style=\"color:rgb(18, 184, 134)\">A professional,high-quality portrait of a woman</span>\" <em>for anime e.g. or as a conclusion for semi-anime:</em></p><p>\"<span style=\"color:rgb(18, 184, 134)\">masterpiece, best quality, high resolution, very aesthetic, absurdres, newest, professional, high-quality, hyper-realistic, portrait of a woman, looking at viewer, detailed eyes, realistic body,</span>\"</p><p><em>and neg.:</em></p><p>\"<span style=\"color:rgb(190, 75, 219)\">(lowres:1.2), (worst quality:1.4), (low quality:1.4), (bad anatomy:1.4), multiple views, jpeg artifacts, artist name, censored, young, 2D</span>\"</p><p><em>Sometimes I either leave out the negatives completely or write, for example, </em>\"<span style=\"color:rgb(190, 75, 219)\">lowres, worst </span>\"<span style=\"color:rgb(190, 75, 219)\">aesthetic, bad quality, worst quality, bad anatomy, sketch, jpeg artifacts, ugly, young, soft rendering, face marks</span>\"</p><p><em>depending on whether I use</em> <span style=\"color:rgb(18, 184, 134)\">Euler</span><em> or </em><span style=\"color:rgb(18, 184, 134)\">Euler a</span> <em>as sampler ^^</em></p><p><em>Usually I structure my prompts based on this:</em></p><ul><li><p>subject description: who or what can be seen? (what does she/it look like? hair, eyes, clothing, description of the scene),</p></li><li><p>light and shadow description,</p></li><li><p>which angle, perspective, motion? quality</p></li></ul><p><em>and</em></p><ul><li><p>detailed description</p></li></ul><p><em>or the quality at the very beginning and then the rest of the structure :)</em></p><p></p><p><em>If u're tasty for more? Here is a lil insight into the prompt structure: </em><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/10509/il-portreij-step-by-step\"><em>https://civitai.com/articles/10509/il-portreij-step-by-step</em></a></p><hr /><h2 id=\"about-v4\"><span style=\"color:rgb(76, 110, 245)\">ab</span><span style=\"color:rgb(34, 139, 230)\">ou</span><span style=\"color:rgb(21, 170, 191)\">t v</span><span style=\"color:rgb(18, 184, 134)\">4</span></h2><p><em>hey guys, ‚ò∫</em></p><p><em>for V4 I changed the recipe a little to improve the quality a tiny bit and also to expand the options for prompts.</em></p><hr /><h2 id=\"about-v3\"><span style=\"color:rgb(76, 110, 245)\">ab</span><span style=\"color:rgb(34, 139, 230)\">ou</span><span style=\"color:rgb(21, 170, 191)\">t v</span><span style=\"color:rgb(18, 184, 134)\">3</span></h2><p><em>style closer to V1 anime based with a lil qualy upgrade ‚ò∫</em></p><p><em>Showcase images without ADetailer</em></p><hr /><h2 id=\"about-v2\"><span style=\"color:rgb(76, 110, 245)\">ab</span><span style=\"color:rgb(34, 139, 230)\">ou</span><span style=\"color:rgb(21, 170, 191)\">t v</span><span style=\"color:rgb(18, 184, 134)\">2</span></h2><p><em>a lil more 3D touched without using 3D in promptings</em></p><p><em>by writing \"</em><span style=\"color:rgb(253, 126, 20)\"><em>realistic</em></span><em>\" the style will become more into semirealism and without its closer to a semianime based style</em></p><p><span style=\"color:rgb(253, 126, 20)\"><em>furry</em></span><em> optional</em></p><p><em>a lil quality upgrade, just a lil ^.^</em></p><p>üå∂Ô∏è <em>sidefact for NSFW fans: viewer can interact with character by describing what hands can do (see sample images in the showcase)</em></p><hr /><h2 id=\"about-v1\"><span style=\"color:rgb(76, 110, 245)\">ab</span><span style=\"color:rgb(34, 139, 230)\">ou</span><span style=\"color:rgb(21, 170, 191)\">t v</span><span style=\"color:rgb(18, 184, 134)\">1</span></h2><p><em>If u like the style in the showcase images, u can add</em></p><p><span style=\"color:rgb(250, 176, 5)\"><strong><em>high-resolution, realistic, 3D,</em></strong></span></p><p><span style=\"color:rgb(250, 176, 5)\"><em>detailed skin, detailed eyes, shadows, dark light, eyelashes, upper body, cheeky, posing, holographic color,</em></span></p><p><em>to ur prompt. Without it the style becomes more anime based.</em></p><p></p><p><em>At further distance I would recommend using ADetailer.</em></p><p></p><p><em>Today I can't say yet in which direction the merger is developing, but as a pony and flux fan, I can only say that I love the color intensity of Illustrious. I recently tested it and got a taste for it, maybe you'll like it too ‚ò∫</em></p><p></p><p><em>I am happy if u enjoy and stay curious abt ur results </em><span style=\"color:rgb(190, 75, 219)\"><em>‚ô•</em></span></p><hr /><h3 id=\"a-small-comparison-from-v1-to-v5\">a small comparison from <strong>V1</strong> to<strong> V5</strong></h3><p><strong><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5e3ae227-6062-40ab-b157-e99b4a20c4fb/width=525/5e3ae227-6062-40ab-b157-e99b4a20c4fb.jpeg\" /></strong><span style=\"color:rgb(121, 80, 242)\"><strong>‚¨ÜÔ∏è </strong></span>masterpiece, best quality, 1girl, face, portrait, looking at viewer, closed mouth, close up</p><p><span style=\"color:rgb(134, 142, 150)\">worst quality, bad quality</span></p><p><em>~</em>~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*</p><p><em>I hope it gives a little impression of the development </em><span style=\"color:rgb(250, 176, 5)\"><em>‚ò∫</em></span></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898384+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "5373",
    "prompt": "Makima (Chainsaw Man) LoRA\n<h2>Makima (Chainsaw Man) LoRA</h2><p><strong>Making models can be expensive. Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> üÖøÔ∏è or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> ‚òï</strong></p><p>There is already a pretty good embedding, but this was still requested as a LoRA net, so I made it.</p><p>I've tested it on some of my anime models and seems to work as per usual. You find prompts and models in the PNG data reported in the info (bottom right corner of the pics). <strong>Pic 2 and 5 have been made using </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/10028\"><strong>NeverEnding Dream (NED)</strong></a><strong>.</strong><br /><br />The main trigger word is <code>makima \\(chainsaw man\\)</code> but, as usual, you need to describe how you want her, as the model is not overfitted. Weight should be <strong>between 1 and 1.4 for the offset version (0.5-0.7 for the original one)</strong>. The pic with the bunny costume is also using my <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4844/ratatatat74-style-lora\">ratatatat74 LoRA</a>. Pic 1, 3, and 10 have been made by <strong>Joobilee</strong>.</p><p></p><p><strong>How to use LoRA's in auto1111:</strong></p><ul><li><p>Update webui (use <code>git pull</code> <a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/embed/mn8fMF10XN4?start=31&amp;end=60\">like here</a> or redownload it)</p></li><li><p>Copy the file to <code>stable-diffusion-webui/models/lora</code></p></li><li><p>Select your LoRA like in <a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/watch?v=-bMeyXOZwN0\">this video</a></p></li><li><p><strong>Make sure to change the weight according to the instructions </strong>(by default it's <code>:1</code>)</p></li></ul>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898391+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "14978",
    "prompt": "Âï•Áé©ÊÑèÂÆåÁääÂ≠êÔºàÂ§ßÊ¶ÇÊòØ‰∏ÄÁßçÂè§Êó©ÁîªÈ£éÔºâ- old fish\n<p>Â§™Êáí‰∫Ü‰∏çÊÉ≥ÂÜô‰ªãÁªç</p><p>‚ÄúÂï•Áé©ÊÑèÂÆåÁääÂ≠ê‚Äù</p><p>Âú®‰∏ÄÊ¨°ÂàÜÂ±ÇËûçÂêàÁöÑÂÆûÈ™å‰∏≠Âá∫‰∫Ü‰∏Ä‰∏™ÈóÆÈ¢òÔºåÂéüÊú¨‰ª•‰∏∫ÊòØÂÆûÈ™å‰∫ãÊïÖÔºåÊ≤°ÊÉ≥Âà∞ÂæóÂà∞‰∫ÜËøô‰∏™Ê®°Âûã</p><p></p><p>Êàë‰∏çÁü•ÈÅìËøôÂ±û‰∫éÂì™ÁßçÈ£éÊ†º</p><p></p><p>Êé®ËçêÂèÇÊï∞</p><p>Steps: 10, Sampler: DPM++ 2S a Karras, CFG scale: 7, Seed: 2316919499, Size: 512x640, Denoising strength: 0.5, Clip skip: 2, Hires upscale: 2, Hires steps: 10, Hires upscaler: R-ESRGAN 4x+</p><p></p><p>·É¶( ¬¥ÔΩ•·¥óÔΩ•` )ÊØîÂøÉ</p><p>‰ª•‰∏ãÊú∫Áøª</p><p></p><p>In a hierarchical fusion experiment, there was a problem, originally thought to be an experimental accident, but did not expect to get this model</p><p>I don't know what style it is</p><p>Recommended parameter</p><p>Steps: 10, Sampler: DPM++ 2S a Karras, CFG scale: 7, Seed: 2316919499, Size: 512x640, Denoising strength: 0.5, Clip skip: 2, Hires upscale: 2, Hires steps: 10, Hires upscaler: R-ESRGAN 4x+</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898395+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "5041",
    "prompt": "Cheese Daddy's Landscapes mix\n<h1><u>Try out the Noise Offset version of the 2.0 and 3.5! </u><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/15037/cheese-daddys-landscapes-mix-or-offset-noise\">Here</a></h1><p><strong>If you like my work, consider buying</strong><a rel=\"ugc\" href=\"https://ko-fi.com/cheesedaddy\"><strong> me a coffee </strong>‚òï</a></p><p><strong>V4.1 (experimental):</strong></p><p>removed <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7371/rev-animated\">rev_animated</a></p><p>added <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4201/realistic-vision-v20\">realistic vision</a></p><p>fixed the model</p><p></p><p><strong>Recommendation: clip skip 1</strong> (clip skip 2 sometimes generate weird images)</p><p>2:3 aspect ratio (512x768 / 768x512) or 1:1 (512x512)</p><p>DPM++ 2M CFG 5-7</p><p>prompts that i always add: award winning photography, Bokeh, Depth of Field, HDR, bloom, Chromatic Aberration ,Photorealistic,extremely detailed, trending on artstation, trending on CGsociety, Intricate, High Detail, dramatic, art by midjourney, masterpiece, best quality, high quality,extremely detailed CG unity 8k wallpaper</p><p></p><p><strong>V4.0:</strong></p><p>added <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4823/deliberate\">deliberate 2.0</a></p><p>added <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7371/rev-animated\">rev animated</a></p><p>fixed hands with <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nuigurumi/basil_mix/blob/main/Basil_mix_fixed.safetensors\">basil_mix</a></p><p></p><p><strong>V3.5: ADDED Pastel mix</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5414/pastel-mix-stylized-anime-model\">https://civitai.com/models/5414/pastel-mix-stylized-anime-model</a></p><p><br /><strong>V3: ADDED AnythingV3 and fixed the model: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/66/anything-v3\"><strong>https://civitai.com/models/66/anything-v3</strong></a></p><p></p><p>RECOMMENDED VAE'S</p><p></p><p>kl-f8-anime2</p><p>Anything-V3.0</p><p></p><p>RECOMMENDED LORA'S FOR BETTER RESULTS</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/SatyamSSJ10/Satyam_Public_LORA/blob/main/Jordan_3.safetensors\">Jordan 3</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/closertodeath/ctdlora/blob/main/dpep2%20768.pt\">dpep2 768</a></p><p>0.8 weight</p><p><br /><strong>V2: ADDED Deliberate</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4823/deliberate\">https://civitai.com/models/4823/deliberate</a><br /><br />Roboetics: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3738/roboetics-mix\">https://civitai.com/models/3738/roboetics-mix</a><br />Inkpunk: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1087/inkpunk-diffusion\">https://civitai.com/models/1087/inkpunk-diffusion</a><br />DreamShaper: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384/dreamshaper\">https://civitai.com/models/4384/dreamshaper</a><br />ChromaV5: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/SomaMythos/ChromaV5\">https://huggingface.co/SomaMythos/ChromaV5</a><br />H&amp;A's 3DKX 1.1:<strong> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2504/handas-3dkx-11\">https://civitai.com/models/2504/handas-3dkx-11</a><br />Analog diffusion: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1265/analog-diffusion\">https://civitai.com/models/1265/analog-diffusion</a><br />The Ally's Mix: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1202/the-allys-mix\">https://civitai.com/models/1202/the-allys-mix</a><br />Tokens: Analog style, chromav5, nvinkpunk<br /><br />Chromav5 Keywords: Chromatic Aberration; Geometric Shapes; Bokeh; Depth of Field; Photorealistic; Cosmic; Detailed; Bloom; HDR</p><p></p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898400+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "18207",
    "prompt": "Ether Real Mix\n<h1 id=\"hello-this-is-ether-real-mix-l0hg1u80l\">üî∏üå§Ô∏è <strong><em>Hello, this is Ether Real Mix</em></strong> üå§Ô∏èüî∏</h1><p>Ether Real Mix is a stylized realism model focused on flexibility. It's capable of producing a variety of subjects in multitudes of styles. It still has some shortcomings inherit to anime models such as light biases in generating females and humans.</p><p>This model is intended to act as a <em>'blank canvas'</em>. Add your favorite <em>LORA's</em> and <em>embeddings</em> to customize it to your liking!</p><p><strong>‚ú®<em> Please Share Your Cool Creations Below! </em>‚ú®</strong></p><p></p><h3 id=\"*-ether-real-mix-version-4-5w9405zf6\"><strong><em>* Ether Real Mix - Version 4</em></strong></h3><p>Ether Real Mix 4 looks to further refine the realistic/semi-realistic aesthetic through LORA block merging, updating ingredients, and (hopefully) improving anatomy and hands within the constraints of a realistic SD 1.5 model.</p><p>I shuffled out a lot of models that felt redundant or just no longer fit the goals of Ether Real. The aesthetic is tuned towards a Niji inspired feel thanks to <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Terry9993\"><em>Terry9993's</em></a> Niji styled LORA's. Overall, I'm looking to strike a balance between anime-esque realism while also not having outputs that feel too derivative of Nijijourney.</p><p>VAE is baked in.</p><p>More detailed list of changes coming soon(tm).</p><p>SDXL/Pony model coming soon(tm)?</p><p><em><s>SD3 coming soon(tm)?</s></em></p><h3 id=\"-ye61tx121\"></h3><h3 id=\"*-huggingface-archive-0x1czxi7t\"><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/gamerdan69/EtherMix\"><strong><em>* Huggingface Archive</em></strong></a></h3><h3 id=\"-fpnst4s8t\"></h3><h2 id=\"generation-recommendations-vm6814rdd\"><strong>‚òÑÔ∏è<em> Generation Recommendations</em></strong></h2><p><strong>*</strong> All preview images were generated with no LORA's, embeddings, extensions or img to img/inpainting. Just pure text to image with hi-res fix upscaling.</p><p>Use whatever sampler, steps, CFG you prefer.</p><p>Most sample images were generated with:</p><ul><li><p>Sampler: DPM++ 2M Karras</p></li><li><p>Steps: 20 - 28</p></li><li><p>CFG: 7 - 11</p></li><li><p>Clip Skip: 1</p></li><li><p>ENSD: 31337</p></li></ul><p>Higher CFG can lead to more vibrant results.</p><p></p><p><strong><em>Negative Prompt Example:</em></strong></p><p><em>\"NSFW, (worst quality, low quality:1.3)\"</em></p><p>I recommend this simple negative prompt if you wish to achieve a similar style to the preview images. You can further alter positive and negative prompts based on the type of style you'd like to achieve.</p><p><strong><em>Style focused negative prompt examples:</em></strong></p><p>* Photorealism feel:</p><ul><li><p><em>\"sketch, drawing, anime, cartoon, illustration, NSFW, (worst quality, low quality:1.3)\"</em></p></li></ul><p>* Flat Anime/Cartoon:</p><ul><li><p><em>\"realistic, photorealistic, photograph, 3D, NSFW, (worst quality, low quality:1.3)\"</em></p></li></ul><h3 id=\"-d5kf17rys\"></h3><p>Sample images were further upscaled using AUTO1111 Hi-res fix. Please utilize it if you wish to achieve similar results.</p><ul><li><p>Latent (nearest-exact)</p></li><li><p>Upscale by: 2</p></li><li><p>Denoising strength: 0.55</p></li></ul><p>Are your results changing too much after Hi-res fix? Please try <a target=\"_blank\" rel=\"ugc\" href=\"https://openmodeldb.info/models/4x-Remacri\"><em>4x-foolhardy-Remarci.</em></a></p><p><em>(Also recommended for simple style illustrations, anime, cartoon, etc.)</em></p><ul><li><p>4x-foolhardy-Remarci</p></li><li><p>Upscale by: 2</p></li><li><p>Denoising strength: 0.45 - 0.55</p></li></ul><p></p><h3 id=\"recommended-vae:-bzcb1hvkr\"><em>Recommended VAE:</em></h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/blob/main/vae/kl-f8-anime2.ckpt\"><em>Waifu Diffusion VAE kl-f8-anime2</em></a></p><p><em>Strongly recommended </em>as the model was tuned with this specific VAE's colors and saturation in mind.</p><p></p><h3 id=\"prompting-advice-9aw6j0ton\">üñäÔ∏è<strong><em> Prompting Advice</em></strong></h3><p>Prompt however you like. The model was merged with both Danbooru-style tag prompting as well as natural language in mind. You're free to mix and match prompting styles, the model should understand it.</p><ul><li><p><strong><em>Generating unprompted girls/humans?</em></strong> Try removing <em>\"masterpiece, best quality, .....\"</em></p></li></ul><p>If you look at the prompts included with the sample images they demonstrate that even with a very loose and vague style of prompting you can achieve fun, high quality images.</p><p>Try mixing natural language and booru-styled tags. Experiment and give the AI some freedom to interpret your ideas!</p><p></p><p><strong><em>General guidelines:</em></strong></p><ul><li><p>Prompt in the style of anime/booru-style models, <em>\"masterpiece, best quality, ..... \"</em></p><ul><li><p>More anime style images, stronger bias towards females/humans</p></li></ul></li><li><p>Prompt in the style of photography/non-anime models, <em>\"professional photograph of ..... \"</em></p><ul><li><p>More realistic images, higher style variety, (probably) less bias</p></li></ul></li></ul><h3 id=\"-qhy2n0wzw\"></h3><h2 id=\"model-merging-info-v4-ick57ja67\"><strong>üìô<em> Model Merging Info - v4</em></strong></h2><p>I have no training or real knowledge of machine learning. I merged the model using the information provided on <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs\"><em>WarriorMama777's AOM model page</em></a> as well as the ones in <a target=\"_blank\" rel=\"ugc\" href=\"https://rentry.org/BlockMergeExplained\"><em>these</em></a> <a target=\"_blank\" rel=\"ugc\" href=\"https://rentry.org/Merge_Block_Weight_-china-_v1_Beta\"><em>Rentrys.</em></a> I very arbitrarily mixed the UBM weights of each model, modifying the values with trial and error until I was visually satisfied with it.</p><p></p><p>I utilized the <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/hako-mikan/sd-webui-supermerger\"><em>SuperMerger</em></a> extension for AUTO1111 by hako-mikan.</p><p></p><h3 id=\"please-refer-to-the-'about-this-version'-for-more-detailed-information.-m8s8wzejv\"><em>Please refer to the </em><strong><em>'About This Version'</em></strong><em> for more detailed information.</em></h3><h3 id=\"-ucd05uwzb\"></h3><h2 id=\"credits-17sxip77z\"><strong>üß°<em> Credits</em></strong></h2><p>Thank you to WarriorMama777 for providing <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9942/abyssorangemix3-aom3\"><em>AOM</em></a> and other various mixes as well as detailing your workflow which inspired me to try mixing my own models.</p><p>Thank you to hako-mikan for creating the <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/hako-mikan/sd-webui-supermerger\"><em>SuperMerger</em></a> extension allowing a quicker workflow for merging.</p><p>Thank you to those that have contributed to these <a target=\"_blank\" rel=\"ugc\" href=\"https://rentry.org/BlockMergeExplained\"><em>MBW</em></a> <a target=\"_blank\" rel=\"ugc\" href=\"https://rentry.org/Merge_Block_Weight_-china-_v1_Beta\"><em>Rentrys.</em></a></p><p>Thank you to gsdf, rqdwdw for <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4468/counterfeit-v25\"><em>Counterfeit.</em></a></p><p>Thank you to RunDiffusion for <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/82972/rundiffusion-fx-photorealistic\"><em>RunDiffusion FX Photorealistic.</em></a></p><p>Thank you to DynamicWang for <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/61170?modelVersionId=304593\"><em>AWPortrait</em></a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/84476/awpainting\"><em>AWPainting.</em></a></p><p>Thank you to KondooAI for <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/46422/juggernaut\"><em>Juggernaut.</em></a></p><p>Thank you to Xerxemi and Xynon for <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Xynon/SD-Silicon\"><em>SD-Silicon.</em></a></p><p>Thank you to Lykon for <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384?modelVersionId=128713\"><em>Dreamshaper 8.</em></a></p><p>Thank you to Terry9993 for <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/47909/nijiexpressivev2\"><em>NijiExpressive v2</em></a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/130311/niji-cool-perfect-anime-lora\"><em>Niji v3 Fantastic.</em></a></p><p>Thank you to Ashen-sensored for <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/ashen-sensored/lora-isolation-collection\"><em>Silicon Landscape Isolation.</em></a></p><p>Thank you to AUTO1111 for creating the web UI.</p><p>Thank you to StabilityAI for starting everything with Stable Diffusion.</p><p>Thank you to CivitAI and Huggingface for providing places where open source AI can flourish.</p><p>Thank you to the entire SD community for continuing to openly share and create.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898420+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "1302719",
    "prompt": "‚ú® Lazy Embeddings for ALL illustrious NoobAI Pony SDXL models LazyPositive LazyNegative (Positive and Negative plus more!)\n<p><strong>üíñ Support &amp; Share the Magic! </strong><br />Love these embeddings? <strong>Like, add to collection, and tag this resource </strong>in your creations‚ÄîI‚Äôd <em>adore </em>to see what you make! üé®‚ú®</p><p><strong>üëâ Looking for amazing anime model that can do both SFW &amp; NSFW? Check out </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1277670/janku-v30-noobai-eps-rouwei-nsfw-illustrious-xl\"><strong>JANKU </strong></a><strong>by yours truly, you won't be disappointed. It is highly tested with my embedding! It also has ONSITE generation support!</strong></p><p><strong>üëâ More goodies on my profile! Follow for updates!</strong></p><p><strong>üëâ Join me</strong> on <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/tWrKk3jcXx\">our discord server</a> (<a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/tWrKk3jcXx\">https://discord.gg/tWrKk3jcXx</a>)! <strong>Share art, ask for help, or just chat</strong>. We have <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/articles/13331/7k-followers-updates-and-civchan-bot-launch\">CivChan bot plus games</a> there!</p><p><br /><strong>‚òï Support future updates: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/janxd\">Buy me a coffee </a>or tip buzz! Every bit helps. Thank you for fueling the art! üöÄ</p><hr /><p><strong>Want to improve your images with zero effort even more? </strong>‚ú®</p><p>TrendCraft is the <em>only </em>detailer LoRA trained on the <strong>last 30 days of trending CivitAI images </strong>‚Äîjust plug into <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1378661/trendcraft-the-peoples-style-detailer-all-models-support\">Pony XL</a><a target=\"_blank\" rel=\"ugc\" href=\"https://chat.qwen.ai/c/link\"> </a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1350877/trendcraft-the-peoples-style-detailer-all-models-support\">Illustrious </a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1390819?modelVersionId=1571948\">SDXL</a>, or <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1365604/trendcraft-the-peoples-style-detailer-all-models-support\">Noob Vpred</a><a target=\"_blank\" rel=\"ugc\" href=\"https://chat.qwen.ai/c/link\"> </a>workflows for instant, viral-ready upgrades. No prompts, no work. ü™Ñüî•</p><hr /><h3 id=\"lazy-embeddings:-for-creators-who-hate-typing-(but-love-results)\"><strong>üé® Lazy Embeddings: For Creators Who Hate Typing (But Love Results) üõãÔ∏è</strong></h3><p><strong>Why waste time typing prompts? </strong>üí§<br />Lazy Embeddings = <strong>pre-loaded magic </strong>for Illustrious/NoobAI/SDXL/Pony XL. Just drop <code>lazypos</code> + <code>lazyneg</code> and <em>go </em>. No copy-pasting, no tears.</p><hr /><p><strong>‚ö° How to Be Lazy (Illustrious/Noob/SDXL):</strong></p><ol><li><p><strong>Positive Prompt: </strong>Start with <code>lazypos</code> (or<code>embedding:lazypos</code> for ComfyUI).</p></li><li><p><strong>Negative Prompt: </strong>Start with <code>lazyneg</code> (or <code>embedding:lazyneg</code>). If you are using onsite generation, make sure to use lazyneg v3.1 or higher. </p></li><li><p><strong>Done. </strong>Seriously. üôÉ</p></li></ol><p><strong>Pony XL Users:</strong></p><ul><li><p><strong>Positive: </strong><code>lazyup</code> (or <code>embedding:lazyup</code>).</p></li><li><p><strong>Negative: </strong><code>lazydn</code> (or <code>embedding:lazydn</code>).</p></li><li><p><strong>Pro Tip: </strong><code>lazympos</code> + <code>lazyup</code> = ‚ú® <em>next-level quality </em>‚ú®</p></li></ul><hr /><p><strong>üî• If Hands Suck: </strong><br />Add <code>lazyhand</code> to your <strong>NEGATIVE </strong>prompt. <strong>Too lazy? </strong>Just use <code>lazyhand</code> + <code>lazyneg</code> (<em>boom </em>, fixed).</p><p>üôà<strong>NSFW:</strong></p><p>Block NSFW with <code>lazynsfw</code> in <strong>negative </strong>prompt. If you want more use it in positive prompt!</p><p><strong>Pony Users</strong>: Use <code>lazyxxx</code> instead of <code>lazynsfw</code> for the same effect!</p><p><strong>Realism/Anime:</strong> Use <code>lazyreal</code> in negative if you want only anime output. In positive, if you want realistic people output.</p><p><strong>Mature characters: </strong>Use <code>lazyloli</code> in negative to make characters more mature and don't get flag on CivitAI!</p><hr /><p><strong>üåü Why Lazy Wins:</strong></p><ul><li><p><strong>‚ö° Zero Effort: </strong>Skip the prompt grind.</p></li><li><p><strong>üõ†Ô∏è Universal: </strong>Works with <em>any </em>Illustrious/Noob/Pony/SXDL model.</p></li><li><p><strong>ü§ñ Battle-Tested: </strong>Trained on prompts real artists <em>actually use </em>.</p></li></ul><p><strong>üí° Peak Laziness: </strong><br /><code>lazypos</code> + <code>lazyneg</code> = <strong>flawless art with 2 words </strong>. Check the examples‚Äî<em>it‚Äôs easier than scrolling TikTok </em>.</p><hr /><p><strong>Stay Lazy. Generate Smarter. üöÄ </strong><br /><em>(Because life‚Äôs too short for repetitive typing.)</em></p><p><strong>Protip</strong>: <span style=\"color:rgb(250, 82, 82)\">Embeddings don't cost any extra buzz for using.</span> If anything, it will save you buzz since you won't generate bad images!</p><h3 id=\"can't-see-lazy-embeddings-for-onsite-generation\"><strong>üõ†Ô∏è Can‚Äôt See Lazy Embeddings for Onsite Generation?</strong></h3><ol><li><p><strong>Enable Advanced Mode: </strong><br />Go to <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/account\">Account Settings </a>‚Üí Toggle ‚ÄúAdvanced Mode‚Äù ‚Üí Now you can select Lazy Embeddings for <em>any </em>model.</p></li></ol><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f70e6506-5989-4fe3-ad88-0c19a5bce612/width=525/f70e6506-5989-4fe3-ad88-0c19a5bce612.jpeg\" /><strong>üöÄ ComfyUI Users:</strong></p><ul><li><p>Drop embeddings into your <code>embeddings</code> folder.</p></li><li><p><strong>Positive Prompt: </strong><code>embedding:lazypos</code></p></li><li><p><strong>Negative Prompt: </strong><code>embedding:lazyneg</code></p></li><li><p><strong>Pro Tip: </strong>Use <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/pythongosssss/ComfyUI-Custom-Scripts\">ComfyUI-Custom-Scripts </a>for autocomplete magic! (Though <code>lazypos</code>/<code>lazyneg</code> are short enough to remember üòé)</p></li></ul><p>üí´<strong>Examples done with my model, </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1277670\"><strong>JANKU</strong></a>:</p><h2 id=\"here-is-what-they-are-doing-under-the-hood-so-you-don't-have-to-type-it!-please-note-i'm-always-taking-feedback-and-updating-these-embeddings.-i-use-them-daily!\"><strong><u><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f81c93e2-b960-446b-9f93-d788d263ee32/width=525/f81c93e2-b960-446b-9f93-d788d263ee32.jpeg\" /></u></strong>Here is what they are doing under the hood so you don't have to type it! Please note I'm always taking feedback and updating these embeddings. I use them daily!</h2><p><strong><u>Illustrious XL / NoobAI / SDXL - see below for Pony XL</u></strong></p><p><strong>Positive prompt (lazypos v2.0):</strong></p><pre><code>masterpiece, newest, absurdres, best quality, amazing quality, very aesthetic, ultra-detailed, highly detailed</code></pre><p><strong>Negative prompt (lazyneg v3.0):</strong></p><pre><code>low quality, worst quality, lowres, username, sketch, censor, blurry, distorted, bad anatomy, signature, watermark, patreon logo, artist name</code></pre><p>Protip: Use <code>lazyhand</code> embedding in <strong>NEGATIVE </strong>if you want to fix the hands for the seed!</p><p><strong><u>Pony XL</u></strong></p><p><strong>Positive prompt (ponyup):</strong></p><pre><code>score_9, score_8_up, score_7_up, score_6_up, score_5_up, score_4_up</code></pre><p>ponyup7 only includes <code>score_9, score_8_up, score_7_up</code></p><p>ponyup6 only includes <code>score_9, score_8_up, score_7_up, score_6_up</code></p><p><strong>Negative prompt (ponydn):</strong></p><pre><code>score_4, score_5, score_6</code></pre><h3 id=\"other-versions:\"><u>Other versions</u>:</h3><p>lazympos</p><pre><code>masterpiece, best quality, amazing quality</code></pre><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898427+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "16055",
    "prompt": "Ê≤ÅÂΩ© Colorwater\n<h1 id=\"heading-23\">Ê≤ÅÂΩ©</h1><p></p><p><strong>Ê∂¶Áâ©‰ª•Ê∞¥ÔºåÁ∫≥ÂΩ©‰∫éÂøÉ„ÄÇ</strong></p><p>[ENG Instructions below]</p><p>tusi.art/u/607323927751959196</p><ul><li><p>ËØ∑Ê≥®ÊÑèÔºåÊØè‰∏™ÁâàÊú¨ÁöÑÂÄæÂêëÂêÑ‰∏çÁõ∏ÂêåÔºå<s>Â¶ÇÊûú‰Ω†ÂñúÊ¨¢ÊúÄÊúâÈÄèÊòéÊÑüÁöÑÊ∞¥ÂΩ©ÊïàÊûúÔºåËØ∑ÈÄâÊã©v1Ôºå‰ΩÜÂÆÉÈÄÇÈÖçÁöÑÊ®°ÂûãÁõ∏ÂØπËæÉÂ∞ë„ÄÇ</s></p></li><li><p>v4ÊòØÁõÆÂâçÊúÄÊé®ËçêÁöÑÁâàÊú¨‰∫Ü„ÄÇ</p></li><li><p>ÂÖ∂‰ªñÁâàÊú¨ÂêÑÊúâËøõÂåñÁöÑÊñπÂêëÔºåÊúâÂÖ¥Ë∂£Ê¨¢ËøéÂ§öÂ§öÂ∞ùËØïÔºÅ</p><p></p></li><li><p>Please note that each version has a different tendency.</p></li><li><p><s>If you like the most transparent watercolor effect, please choose the original v1, but it fits relatively few models.</s></p></li><li><p>v4 is the most recommended version right now.</p></li><li><p>Other versions have their own evolutionary direction, so feel free to try more if you're interested!</p></li></ul><p></p><ul><li><p>ËøôÊòØ‰∏Ä‰∏™Ê∞¥ÂΩ©È£éÊ†ºÁöÑLoRAÔºåËøòÂú®‰∏çÊñ≠ÂÆåÂñÑ‰∏≠ÔºåÊ¨¢ËøéÂêÑÁßçfeedbackÔºÅ</p></li></ul><ul><li><p>This is a watercolor style LoRA, still in the process of improvement, welcome all kinds of feedbacks!</p></li></ul><p></p><h3 id=\"heading-24\">v4 ‰ΩøÁî®ËØ¥ÊòéÔºö</h3><ul><li><p>v4 ÁâàÊú¨Âú®ÈÄÇÈÖçÂ§ö‰∏™Ê®°ÂûãÁöÑËÉΩÂäõ‰∏äÊúâ‰∫ÜÊûÅÂ§ßÊîπËøõÔºå‰∏çÂÜçËµòËø∞ÔºåËØ∑ÂèÇËÄÉsampleÂõæÁâáÂ∞±‰ºöÈ©¨‰∏äÊòéÁôΩ‰∫Ü„ÄÇÂêåÊ†∑ÁöÑÔºå‰πüÂèØ‰ª•ÂíåÂ§ßÈáèÁöÑÂÖ∂‰ªñ‰ºòÁßÄlora‰∏ÄËµ∑Â∑•‰ΩúÔºåÂè™ÈúÄË¶ÅÊ≥®ÊÑèÁªÑÂêàÊùÉÈáç„ÄÇ</p></li><li><p>Êé®ËçêËÆæÁΩÆÔºöÊùÉÈáç=0.8-1ÔºåCFG=3-6</p></li><li><p>The v4 version is a great improvement in the ability to adapt multiple models, so without further ado, please refer to the sample image and you will understand immediately. Likewise, it can work with a large number of other lora, just be careful with the combination weights.</p></li><li><p>Recommended settings: weight=0.8-1, CFG=3-6</p></li></ul><p></p><p></p><h3 id=\"heading-25\">v3 ‰ΩøÁî®ËØ¥ÊòéÔºö</h3><p>ÂÖ®Èù¢Âº∫ÂåñÔºÅ</p><ul><li><p>ÈÄöÁî®ÁöÑÊ®°ÂûãÊé®ËçêÈÖçÁΩÆÔºöCFG&lt;7ÔºåÊùÉÈáç0.65-0.75ÔºåCFG‰∏éËâ≤ÂΩ©ÊµìÊ∑°ÂÆåÂÖ®ÊåÇÈí©Ôºå‰ΩÜËØ∑Ê≥®ÊÑèÔºåÊ†πÊçÆÊ®°Âûã‰∏çÂêåÔºåÊúâ‰∫õÂú®7Â∑¶Âè≥Â∞±‰ºöÂá∫Áé∞ËøáÊãüÂêàÁöÑÁé∞Ë±°„ÄÇ‰ΩÜÊúâ‰∏Ä‰∫õ‰∏âÊ¨°ÂÖÉÊ®°Âûã‰ºöÂú®7‰πã‰∏äÊúâÊØîËæÉÂ§çÂè§ÁöÑÈáçÊ∞¥ÂΩ©Ë°®Áé∞„ÄÇ</p></li><li><p>ÂíåÂÖ∂‰ªñLoRAÈÖçÂêà‰ΩøÁî®Êó∂ËØ∑Ê≥®ÊÑèÈÅøÂÖçÂä†ÊùÉÂíåËøáÈ´òÁöÑÊÉÖÂÜµÔºå‰∏ÄËà¨Êù•ËØ¥ÔºåÂä†ÊùÉÊÄªÂÄº‰∏çË∂ÖËøá1.2ÊØîËæÉÂêàÈÄÇÔºåÂ¶ÇÊûúÈúÄË¶ÅÊ∞¥ÂΩ©È£éÊ†ºËæÉÂ§öÁöÑÊòæÁé∞ÔºåÂàôÈúÄË¶Å‰øùÊåÅÊ≤ÅÂΩ©ÁöÑÊùÉÈáç‰∏∫ÊúÄÈ´òÁöÑÈÇ£‰∏™„ÄÇ</p><p>‰∏æ‰æãÔºö‰∏ãÂõæ‰∏∫‰ΩøÁî®Â¢®ÂøÉÂíåÁñèÂèØËµ∞È©¨ÂÖ±3‰∏™LORAÁöÑÊïàÊûúÔºåÊùÉÈáçÊØî‰∏∫0.5+0.35+0.35</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0f4b8de6-162a-4d28-32a5-1b6ca7e94b00/width=525/0f4b8de6-162a-4d28-32a5-1b6ca7e94b00\" /></p></li></ul><p>Instructions for v3</p><p>Power Enhanced!</p><p>Generic model recommended configuration: CFG&lt;7, weight 0.65-0.75, CFG is fully linked to color intensity, but please note that depending on the model, some overfitting will occur at around 7.But there are some realistic models will have a more vintage heavy watercolor performance on top of 7.</p><p>When using with other LoRA, please pay attention to avoid weighting and too high, generally speaking, the total weighted value is not more than 1.2 is more appropriate, if you need more watercolor style to appear, you need to keep the weight of the QIN color as the highest one.</p><p>Example: The image upstairs shows the effect of using Coloerwater, Moxin and Shukezouma total of 3 LORA, the weighting ratio is 0.5 + 0.35 + 0.35</p><p></p><p></p><p></p><p></p><h3 id=\"heading-26\">v2 ‰ΩøÁî®ËØ¥ÊòéÔºö</h3><p>Áé∞Âú®ÁöÑÊ≤ÅÂΩ©ËøõË°å‰∫ÜÂêÑÁßçÂº∫ÂåñÔºåÊúâ‰∫Ü‰∏ÄÂÆöÁöÑÂÜôÂÆûËÉΩÂäõÔºÅ</p><ul><li><p>‰∫åÊ¨°ÂÖÉÁ±ªÊ®°ÂûãÊé®ËçêÈÖçÁΩÆÔºöCFG&lt;6ÔºåÊùÉÈáç0.85-1</p></li></ul><ul><li><p>‰∏âÊ¨°ÂÖÉÁ±ªÊ®°ÂûãÊé®ËçêÈÖçÁΩÆÔºöCFG&lt;5ÔºåÊùÉÈáç0.5-0.7</p></li></ul><p>ÁõÆÂâçÂØπ‰∫é‰∫∫Áâ©Èù¢ÈÉ®ÁöÑÈ£éÊ†ºËøòÊòØÊúÄÂ§ßÈôêÂ∫¶‰øùÁïô‰∫ÜÊ®°ÂûãÁöÑÂéüÂßãÈ£éÊ†ºÔºåv3Áâà‰ºöÂØπËøôÈÉ®ÂàÜÂ∞ùËØïËøõË°åÊîπËøõÔºåËøΩÊ±ÇÂÜôÂÆûÈ£éÊ†ºÔºåÂà∞Êó∂ÂÄô‰ºöÂ∞Ü‰∫å„ÄÅ‰∏âÊ¨°ÂÖÉÂàÜÂºÄÁâàÊú¨‰æõÂ§ßÂÆ∂Â∞ùËØï„ÄÇ</p><p>ÊÑüË∞¢ÂêÑ‰ΩçÁöÑÂ•ΩËØÑÔºÅ</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/88f2f73d-91a9-4be4-492d-e7be6fb33800/width=525/88f2f73d-91a9-4be4-492d-e7be6fb33800\" /></p><h3 id=\"heading-27\">Instructions for v2 version</h3><p>Now Colorwater has undergone various enhancements and has a try on realistic style!</p><p>Recommended configuration</p><ul><li><p>Anime-like models: CFG&lt;6, weight 0.85-1</p></li><li><p>Realistic-like models: CFG&lt;5, weight 0.5-0.7</p></li></ul><p>At present, the style of the character's face is still the maximum to retain the original style of the model, v3 version will try to improve this part, the pursuit of realistic style.If things go well, there will be two diff versions by the time they are completed for everyone to try.</p><p>Thank you all for your kind comments!</p><p></p><p></p><p></p><p></p><h3 id=\"heading-28\">v1 ‰ΩøÁî®ËØ¥ÊòéÔºö</h3><ul><li><p>Ê∞¥ÂΩ©ÁöÑÈ£éÊ†º‰ºöÊ†πÊçÆCFGÁöÑÂÄºÂèòÂåñÔºåÂª∫ËÆÆ‰ΩìÈ™å‰ªé2~6ÁöÑ‰∏çÂêåÂèòÂåñÔºåÊõ¥È´òÂÄºÁöÑ‰ΩøÁî®ËØ∑Ê≥®ÊÑèÊòØÂê¶ËÉΩ‰∏é‰Ω†ÁöÑÊ®°ÂûãÂåπÈÖç„ÄÇÊÄªÁöÑÊù•ËØ¥ÔºåCFGÁöÑÈ´ò‰ΩéÂíåÊ∞¥ÂΩ©ÁöÑÊµìÊ∑°Ê≠£Áõ∏ÂÖ≥„ÄÇ</p></li></ul><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c647e2d1-1e6b-48d8-53a6-ffa0098e6400/width=525/c647e2d1-1e6b-48d8-53a6-ffa0098e6400\" /></p><ul><li><p>ÊùÉÈáçÊé®Ëçê‰ΩøÁî®0.85-1ÔºåÂ¶Ç‰∏éÂÖ∂‰ªñloraÊê≠ÈÖçËØ∑Ëá™Ë°åÂà§Êñ≠„ÄÇ</p></li><li><p>Áî±‰∫é‰∏Ä‰∫õÂéüÂõ†ÔºåÊï∞ÊçÆÈõÜÁâπÊÑèÊéíÈô§‰∫Ü‰∫∫ËÑ∏Áõ∏ÂÖ≥ÁöÑÊï∞ÊçÆÔºåÊâÄ‰ª•Â§ßÈÉ®ÂàÜ‰∏ªÊ®°ÂûãÂú®‰∫∫Áâ©Èù¢ÈÉ®ÁöÑË°®Áé∞ÈÉΩËøòÊòØËá™Â∑±ÂéüÊú¨ÁöÑÁâπËâ≤ÔºåËØ∑Ê†πÊçÆÈúÄË¶ÅËá™Â∑±Ë∞ÉÊï¥Âç≥ÂèØ„ÄÇ</p></li></ul><p></p><h3 id=\"heading-29\">Instructions for v1 version</h3><ul><li><p>The style of watercolor will change according to the value of CFG, it is recommended to experience different variations from 2~6. For higher values, please pay attention to whether it can match your model. In general, the high CFG is positively related to the intensity of the watercolor.</p></li><li><p>The weights are recommended to use 0.85-1, please use your own judgment if matching with other lora.</p></li><li><p>For some reasons, the dataset deliberately excludes face-related data, so most of the main models in the character face are still their own original features, please just adjust yourself as needed.</p><p></p></li></ul>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898431+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "340248",
    "prompt": "Sinfully Stylish (dramatic lighting)\n<p><span style=\"color:rgb(76, 110, 245)\">If you would like so support me with more than Buzz consider buying an NFT. My current listings on OpenSea are:</span></p><ul><li><p><span style=\"color:rgb(76, 110, 245)\">Exuberant Pastels - SFW 1: </span><a target=\"_blank\" rel=\"ugc\" href=\"https://opensea.io/collection/exuberant-pastels-sfw-1/overview\"><span style=\"color:rgb(76, 110, 245)\">https://opensea.io/collection/exuberant-pastels-sfw-1/overview</span></a></p></li><li><p><span style=\"color:rgb(76, 110, 245)\">Exuberant Pastels - NSFW 1:</span><a target=\"_blank\" rel=\"ugc\" href=\"https://opensea.io/collection/exuberant-pastels-nsfw-1/overview\"><span style=\"color:rgb(76, 110, 245)\"> https://opensea.io/collection/exuberant-pastels-nsfw-1/overview</span></a></p></li></ul><hr /><h3 id=\"sinfully-stylish:-it's-like-a-secret-sauce-that-you-put-on-everything-because-it-makes-everything-taste-betterexcept-it's-for-lighting.-:)sinfully-stylish-was-designed-to-provide-candlelight-like-lighting-with-low-placed-lights-casting-long-warm-shadows.-but-people-have-found-an-endless-array-of-ways-to-use-it.-kd6ibamsd\"><strong>Sinfully Stylish: </strong><br />It‚Äôs like a secret sauce that you put on everything because it makes everything taste better‚Äîexcept it‚Äôs for lighting. :)<br /><br />Sinfully stylish was designed to provide candlelight like lighting with low placed lights casting long warm shadows. But people have found an endless array of ways to use it.</h3><p>If you enjoy it, please consider posting images directly to the gallery and also maybe a review. Please follow my page to keep track of Sinfully Stylish and my other style LoRAS.<br />---------------------------------------------------------------</p><p>[Update 01.28.25] Sinfully Stylish v1.0 is now available for everyone! At the request of a commenter I created an Illustrious version and its also out no (no early access because I have no idea if it will be any good). Look for a generation contest to celebrate the release soon. <br /><br />[Update 01.13.25] Sinfully Stylish v1.0 is now available for early access! Let me know what you think. These were trained with a far more extensive data set that I hope will make the model even more flexible without losing its je ne sais quoi. <br /><br />[Update 08.21.24] Sinfully Stylish v0.2 is now available for early access! Let me know what you think. It will be upgraded to v1 when I update Pony and SDXL. I hope to get that done over the weekend, but no promises. :)</p><p>[Update 08.14.24] Sinfully Stylish 1.0 is coming soon! I‚Äôm in the process of finalizing and testing a few versions. If you have any feedback on the model, please share it so I can try to incorporate your suggestions.</p><p>[[Outdated updates removed due to the new Civitai generator buzz program.]]</p><p>[Update 04.15.24] Most people have had better results with SDXL v0.1 compared to Pony v0.1. I created Pony v0.2 to see if it might perform better with Pony. The verdict is still out, but I will update once I and others have had more time to test it.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898435+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "124421",
    "prompt": "XXMix_9realisticSDXL\n<p></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/u/596916453177820173/posts\">https://tensor.art/u/596916453177820173/posts</a></p></li><li><p>Here¬†are¬†some¬†details¬†for¬†generating¬†illustrations‰∏Ä‰∫õÂõæ‰æãÁîüÊàêÁöÑ‰ø°ÊÅØÂú®ËøôÈáå</p></li><li><p>Official Version v1</p><p>Trigger word: xxmixgirl (It's better to include a trigger word, but it's not necessary.)</p><p>Negative: (worst quality, low quality, illustration, 3d, 2d, painting, cartoons, sketch), tooth, open mouth, bad hand, bad fingers</p><p>Image size: 768*1280</p><p>Full body: It is recommended to enable HiRes and use Adobe Photoshop for facial retouching.</p><p>Portrait photo: HiRes is not necessary, facial retouching can be done using Adobe Photoshop.</p><p>Sampling iterations: 30</p><p>CFG Scale: 8-10</p></li><li><p><span style=\"color:rgb(193, 194, 197)\">¬†</span><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/zyx_xx\">buy¬†me¬†a¬†coffee¬†‚òï</a></p></li><li><p><strong>Ê≠£ÂºèÁâàv1</strong></p><p>Ëß¶ÂèëËØç:<strong>xxmixgirl</strong>-------Ê≤°ÊúâËß¶ÂèëËØç‰πüÂèØ‰ª•ÔºåÊúÄÂ•ΩËøòÊòØÂ∏¶‰∏äËß¶ÂèëËØç„ÄÇ</p><p>ÂèçÂêëÊèêÁ§∫ËØç:<strong>(worst quality, low quality, illustration, 3d, 2d, painting, cartoons, sketch), tooth, open mouth,bad hand,bad fingers,</strong></p><p>ÂõæÁâáÂ∞∫ÂØ∏:768*1280</p><p>ÂÖ®Ë∫´ÔºöÂª∫ËÆÆÂºÄhiresÔºåÁî®ad‰øÆËÑ∏„ÄÇ</p><p>ËÇñÂÉèÁÖßÔºöÂèØ‰ª•‰∏çÂºÄhiresÔºåÂèØ‰ª•Áî®ad‰øÆËÑ∏</p><p>ÈááÊ†∑Ê¨°Êï∞Ôºö30</p><p>CFG ScaleÔºö8-10</p><hr /><hr /></li><li><p>Test_v1</p></li><li><p><strong><u>Please read the text description carefully first</u></strong></p></li><li><p>Please pair with this Lora for better results</p></li><li><p><strong>At present, the characters have a strong sense of distortion, and the skin texture details are not clear enough. I hope to address these issues through continuous iterations.</strong></p></li><li><p>XXMix_9realisticSDXL¬†is¬†a¬†fine-tuned¬†model¬†based¬†on¬†the¬†Stable¬†Diffusion¬†XL¬†model,¬†aiming¬†to¬†improve¬†the¬†poor¬†performance¬†of¬†Stable¬†Diffusion¬†XL¬†in¬†terms¬†of¬†the¬†attractiveness¬†of¬†Asian¬†female¬†characters.¬†The¬†current¬†v1¬†version¬†is¬†still¬†in¬†the¬†experimental¬†stage,¬†with¬†many¬†issues,¬†but¬†I¬†will¬†continue¬†to¬†iterate¬†and¬†optimize.</p></li><li><p>Trigger¬†Words:¬†xxmix¬†girl¬†woman¬†(in¬†some¬†cases,¬†it¬†may¬†be¬†necessary¬†to¬†increase¬†the¬†weight¬†of¬†keywords)</p></li><li><p>The¬†known¬†issues¬†include:</p></li></ul><ol><li><p>The¬†character¬†name¬†or¬†face¬†style¬†change¬†may¬†not¬†work¬†in¬†some¬†cases.¬†In¬†this¬†situation,¬†you¬†can¬†try¬†to¬†increase¬†the¬†weight¬†of¬†the¬†trigger¬†words.</p></li><li><p>Since¬†the¬†model¬†is¬†trained¬†based¬†on¬†a¬†10241024¬†canvas¬†size,¬†other¬†image¬†ratios¬†may¬†result¬†in¬†a¬†higher¬†error¬†rate.¬†It¬†is¬†recommended¬†to¬†use¬†a¬†10241024¬†canvas¬†size¬†as¬†much¬†as¬†possible,¬†and¬†I¬†will¬†try¬†to¬†train¬†with¬†different¬†canvas¬†sizes¬†in¬†subsequent¬†iterations.</p></li><li><p>Regarding¬†reverse¬†prompt¬†words:¬†The¬†reverse¬†prompt¬†words¬†we¬†currently¬†use¬†can¬†maintain¬†good¬†performance¬†of¬†the¬†model¬†in¬†terms¬†of¬†Asian¬†facial¬†features.¬†If¬†you¬†try¬†to¬†use¬†different¬†reverse¬†prompt¬†words,¬†the¬†results¬†may¬†not¬†be¬†as¬†good¬†as¬†the¬†ones¬†I¬†am¬†currently¬†using.¬†However,¬†if¬†you¬†find¬†more¬†suitable¬†reverse¬†prompt¬†words¬†for¬†this¬†large¬†model,¬†I¬†hope¬†you¬†can¬†share¬†them¬†with¬†everyone.</p></li><li><p>Due¬†to¬†the¬†aspect¬†ratio¬†of¬†the¬†images,¬†this¬†model¬†is¬†currently¬†more¬†suitable¬†for¬†generating¬†half-body¬†portraits¬†or¬†close-up¬†portraits.¬†If¬†you¬†need¬†to¬†generate¬†full-body¬†images,¬†it¬†is¬†recommended¬†to¬†enable¬†the¬†Hires¬†or¬†use¬†the¬†faterdetail¬†extension¬†plugin.</p></li></ol><p></p><ul><li><p>ÁõÆÂâçËßíËâ≤Â§±ÁúüÊÑüËæÉÂº∫ÔºåÁöÆËÇ§Á∫πÁêÜÁªÜËäÇ‰∏çÂ§üÊòéÊòæÔºåÊàëÂ∏åÊúõËÉΩÂú®‰∏çÊñ≠Âú∞Ëø≠‰ª£‰∏≠ÊîπÊéâËøô‰∫õÈóÆÈ¢ò„ÄÇ</p></li><li><p>XXMix_9realisticSDXLÊòØ‰∏Ä‰∏™Âü∫‰∫éStable¬†Diffusion¬†XLÊ®°ÂûãËÆ≠ÁªÉÁöÑÂæÆË∞ÉÊ®°ÂûãÔºåÊó®Âú®ÊèêÈ´òStable¬†Diffusion¬†XLÂú®‰∫öÊ¥≤Â•≥ÊÄßËßíËâ≤È¢úÂÄºÊñπÈù¢Á≥üÁ≥ïÁöÑË°®Áé∞„ÄÇÁõÆÂâçÁöÑv1ÁâàÊú¨‰ªçÂ§Ñ‰∫éËØïÈ™åÈò∂ÊÆµÔºåÂ≠òÂú®ËÆ∏Â§öÈóÆÈ¢òÔºå‰ΩÜÊàë‰ºöÁªßÁª≠ËøõË°åËø≠‰ª£‰ºòÂåñ„ÄÇ</p></li><li><p>Ëß¶ÂèëËØçTrigger¬†WordsÔºöxxmix¬†girl¬†womanÔºàÂú®Êüê‰∫õÊÉÖÂÜµ‰∏ãÔºåÂèØËÉΩÈúÄË¶ÅÂ¢ûÂä†ÂÖ≥ÈîÆËØçÁöÑÊùÉÈáçÔºâ</p></li></ul><p>ÁõÆÂâçÂ∑≤Áü•ÁöÑÈóÆÈ¢òÂåÖÊã¨Ôºö</p><p>1.Âá∫Áé∞‰∫∫Áâ©ÂêçÂ≠óÊàñËÄÖÁîªÈ£éËØ•ËÑ∏ÂûãÊúâÂá†Áéá‰∏çÁîüÊïàÔºåËøôÊó∂ÔºåÂèØ‰ª•Â∞ùËØïÂ¢ûÂä†Ëß¶ÂèëËØçÁöÑÊùÉÈáç„ÄÇ</p><p>2.Áî±‰∫éÊ®°ÂûãÊòØÂü∫‰∫é1024*1024ÁöÑÁîªÂπÖËøõË°åËÆ≠ÁªÉÁöÑÔºåÂõ†Ê≠§ÂÖ∂‰ªñÊØî‰æãÁöÑÂõæÁâáÂèØËÉΩ‰ºöÂØºËá¥ËæÉÈ´òÁöÑÈîôËØØÁéá„ÄÇÂª∫ËÆÆÂ∞ΩÈáè‰ΩøÁî®1024*1024ÁöÑÁîªÂπÖÔºåÊàë‰ºöÂú®ÂêéÁª≠Ëø≠‰ª£‰∏≠Â∞ùËØï‰ΩøÁî®‰∏çÂêåÁîªÂπÖÁöÑËÆ≠ÁªÉÈõÜËøõË°åËÆ≠ÁªÉ„ÄÇ</p><p>3.ÂÖ≥‰∫éÂèçÂêëÊèêÁ§∫ËØçÔºöÁõÆÂâçÊàë‰ª¨‰ΩøÁî®ÁöÑÂèçÂêëÊèêÁ§∫ËØçËÉΩÂ§ü‰øùÊåÅÊ®°ÂûãÂú®‰∫öÊ¥≤ËÑ∏ÈÉ®ÊïàÊûúÊñπÈù¢ÁöÑËâØÂ•ΩË°®Áé∞„ÄÇÂ¶ÇÊûúÊÇ®Â∞ùËØï‰ΩøÁî®‰∏çÂêåÁöÑÂèçÂêëÊèêÁ§∫ËØçÔºåÊïàÊûúÂèØËÉΩ‰∏çÂ¶ÇÊàëÁõÆÂâçÊâÄ‰ΩøÁî®ÁöÑÊèêÁ§∫ËØç„ÄÇ‰ΩÜÊòØÔºåÂ¶ÇÊûúÊÇ®ÊâæÂà∞‰∫ÜÊõ¥ÈÄÇÂêàËøô‰∏™Â§ßÂûãÊ®°ÂûãÁöÑÂèçÂêëÊèêÁ§∫ËØçÔºåÊàëÂ∏åÊúõÊÇ®ËÉΩ‰∏éÂ§ßÂÆ∂ÂàÜ‰∫´„ÄÇ</p><p>4.Áî±‰∫éÁîªÈù¢ÊØî‰æãÁöÑÂéüÂõ†ÔºåÁõÆÂâçËøô‰∏™Ê®°ÂûãÊõ¥ÈÄÇÂêàÁîüÊàêÂçäË∫´ÂÉèÊàñËÇñÂÉè„ÄÇÂ¶ÇÊûúÈúÄË¶ÅÁîüÊàêÂÖ®Ë∫´ÂÉèÔºåÂª∫ËÆÆÂºÄÂêØÈ´òÊ∏Ö‰øÆÂ§çÂäüËÉΩÊàñ‰ΩøÁî®faterdetailÊâ©Â±ïÊèí‰ª∂„ÄÇ</p><p></p><p></p><ul><li><p>XXMix_9realisticSDXL„ÅØ„ÄÅStable¬†Diffusion¬†XL„É¢„Éá„É´„Çí„Éô„Éº„Çπ„Å´„Åó„ÅüÂæÆË™øÊï¥„É¢„Éá„É´„Åß„ÄÅStable¬†Diffusion¬†XL„ÅÆ„Ç¢„Ç∏„Ç¢Â•≥ÊÄß„Ç≠„É£„É©„ÇØ„Çø„Éº„ÅÆÈ°î„ÅÆÈ≠ÖÂäõ„Å´Èñ¢„Åô„ÇãÊÇ™„ÅÑ„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„ÇíÊîπÂñÑ„Åô„Çã„Åì„Å®„ÇíÁõÆÁöÑ„Å®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇÁèæÂú®„ÅÆv1„Éê„Éº„Ç∏„Éß„É≥„ÅØ„Åæ„Å†ÂÆüÈ®ìÊÆµÈöé„Åß„ÅÇ„Çä„ÄÅÂ§ö„Åè„ÅÆÂïèÈ°å„Åå„ÅÇ„Çä„Åæ„Åô„Åå„ÄÅÁßÅ„ÅØÂºï„ÅçÁ∂ö„ÅçÂèçÂæ©ÊúÄÈÅ©Âåñ„ÇíË°å„ÅÑ„Åæ„Åô„ÄÇ</p></li><li><p>„Éà„É™„Ç¨„Éº„ÉØ„Éº„ÉâÔºöxxmix¬†girl¬†womanÔºàÂ†¥Âêà„Å´„Çà„Å£„Å¶„ÅØ„ÄÅ„Ç≠„Éº„ÉØ„Éº„Éâ„ÅÆÈáç„Åø„ÇíÂ¢ó„ÇÑ„ÅôÂøÖË¶Å„Åå„ÅÇ„Çä„Åæ„ÅôÔºâ</p></li></ul><p>ÁèæÂú®„ÅÆÊó¢Áü•„ÅÆÂïèÈ°å„ÅØ‰ª•‰∏ã„ÅÆÈÄö„Çä„Åß„Åô„ÄÇ</p><p>1.„Ç≠„É£„É©„ÇØ„Çø„ÉºÂêç„ÇÑÈ°î„ÅÆ„Çπ„Çø„Ç§„É´„ÅÆÂ§âÊõ¥„ÅåÂäπ„Åã„Å™„ÅÑÂ†¥Âêà„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ„Åì„ÅÆÂ†¥Âêà„ÄÅ„Éà„É™„Ç¨„Éº„ÉØ„Éº„Éâ„ÅÆÈáç„Åø„ÇíÂ¢ó„ÇÑ„Åó„Å¶„Åø„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p><p>2.„É¢„Éá„É´„ÅØ10241024„ÅÆ„Ç≠„É£„É≥„Éê„Çπ„Çµ„Ç§„Ç∫„ÅßË®ìÁ∑¥„Åï„Çå„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅ‰ªñ„ÅÆÁîªÂÉèÊØîÁéá„Åß„ÅØ„Ç®„É©„ÉºÁéá„ÅåÈ´ò„Åè„Å™„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ„Åß„Åç„Çã„Å†„Åë10241024„ÅÆ„Ç≠„É£„É≥„Éê„Çπ„Çµ„Ç§„Ç∫„Çí‰ΩøÁî®„Åô„Çã„Åì„Å®„Çí„ÅäÂãß„ÇÅ„Åó„Åæ„Åô„ÄÇÁßÅ„ÅØÂæåÁ∂ö„ÅÆÂèçÂæ©„ÅßÁï∞„Å™„Çã„Ç≠„É£„É≥„Éê„Çπ„Çµ„Ç§„Ç∫„ÅÆ„Éà„É¨„Éº„Éã„É≥„Ç∞„Çª„ÉÉ„Éà„Çí‰ΩøÁî®„Åó„Å¶Ë®ìÁ∑¥„ÇíË©¶„Åø„Åæ„Åô„ÄÇ</p><p>3.ÈÄÜ„Éó„É≠„É≥„Éó„Éà„ÉØ„Éº„Éâ„Å´„Å§„ÅÑ„Å¶ÔºöÁèæÂú®‰ΩøÁî®„Åó„Å¶„ÅÑ„ÇãÈÄÜ„Éó„É≠„É≥„Éó„Éà„ÉØ„Éº„Éâ„ÅØ„ÄÅ„É¢„Éá„É´„Åå„Ç¢„Ç∏„Ç¢‰∫∫„ÅÆÈ°î„ÅÆÁâπÂæ¥„Å´Èñ¢„Åô„ÇãËâØÂ•Ω„Å™„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„ÇíÁ∂≠ÊåÅ„Åß„Åç„Çã„Çà„ÅÜ„Å´„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇÁï∞„Å™„ÇãÈÄÜ„Éó„É≠„É≥„Éó„Éà„ÉØ„Éº„Éâ„ÇíË©¶„Åó„Å¶„Åø„Çã„Å®„ÄÅÁßÅ„ÅåÁèæÂú®‰ΩøÁî®„Åó„Å¶„ÅÑ„Çã„Éó„É≠„É≥„Éó„Éà„ÉØ„Éº„Éâ„Åª„Å©ÂäπÊûúÁöÑ„Åß„Å™„ÅÑ„Åã„ÇÇ„Åó„Çå„Åæ„Åõ„Çì„ÄÇ„Åü„Å†„Åó„ÄÅ„Åì„ÅÆÂ§ßÂûã„É¢„Éá„É´„Å´ÈÅ©„Åó„ÅüÈÄÜ„Éó„É≠„É≥„Éó„Éà„ÉØ„Éº„Éâ„ÅåË¶ã„Å§„Åã„Å£„ÅüÂ†¥Âêà„ÅØ„ÄÅÁöÜ„Åï„Çì„Å®ÂÖ±Êúâ„Åó„Å¶„ÅÑ„Åü„Å†„Åë„Çã„Å®Â¨â„Åó„ÅÑ„Åß„Åô„ÄÇ</p><p>4.ÁîªÈù¢„ÅÆÊØîÁéá„ÅÆ„Åü„ÇÅ„ÄÅÁèæÂú®„ÅÆ„É¢„Éá„É´„ÅØÂçäË∫´ÂÉè„ÇÑ„Éù„Éº„Éà„É¨„Éº„Éà„ÅÆÁîüÊàê„Å´ÈÅ©„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇÂÖ®Ë∫´ÂÉè„ÇíÁîüÊàê„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„ÇãÂ†¥Âêà„ÅØ„ÄÅÈ´òËß£ÂÉèÂ∫¶‰øÆÂæ©Ê©üËÉΩ„ÇíÊúâÂäπ„Å´„Åô„Çã„Åã„ÄÅfaterdetailÊã°Âºµ„Éó„É©„Ç∞„Ç§„É≥„Çí‰ΩøÁî®„Åô„Çã„Åì„Å®„Çí„ÅäÂãß„ÇÅ„Åó„Åæ„Åô„ÄÇ</p><p></p><p></p><ul><li><p>XXMix_9realisticSDXLÏùÄ¬†Stable¬†Diffusion¬†XL¬†Î™®Îç∏ÏùÑ¬†Í∏∞Î∞òÏúºÎ°ú¬†Ìïú¬†ÎØ∏ÏÑ∏¬†Ï°∞Ï†ï¬†Î™®Îç∏Î°ú,¬†Stable¬†Diffusion¬†XLÏùò¬†ÏïÑÏãúÏïÑ¬†Ïó¨ÏÑ±¬†Ï∫êÎ¶≠ÌÑ∞¬†ÏñºÍµ¥¬†Í∞ÄÏπò¬†Ï∏°Î©¥ÏóêÏÑú¬†ÎÇòÏÅú¬†ÏÑ±Îä•ÏùÑ¬†Í∞úÏÑ†ÌïòÎ†§Í≥†¬†Ìï©ÎãàÎã§.¬†ÌòÑÏû¨¬†v1¬†Î≤ÑÏ†ÑÏùÄ¬†Ïó¨Ï†ÑÌûà¬†Ïã§Ìóò¬†Îã®Í≥ÑÏóê¬†ÏûàÏúºÎ©∞¬†ÎßéÏùÄ¬†Î¨∏Ï†úÍ∞Ä¬†ÏûàÏßÄÎßå,¬†Í≥ÑÏÜç¬†Î∞òÎ≥µ¬†ÏµúÏ†ÅÌôîÎ•º¬†ÏßÑÌñâÌï†¬†Í≤ÉÏûÖÎãàÎã§.</p></li><li><p>Ìä∏Î¶¨Í±∞¬†ÏõåÎìú:¬†xxmix¬†girl¬†woman¬†(ÏùºÎ∂Ä¬†Í≤ΩÏö∞ÏóêÎäî¬†ÌÇ§ÏõåÎìú¬†Í∞ÄÏ§ëÏπòÎ•º¬†ÎäòÎ¶¥¬†ÌïÑÏöîÍ∞Ä¬†ÏûàÏùÑ¬†Ïàò¬†ÏûàÏäµÎãàÎã§)</p></li><li><p>ÌòÑÏû¨¬†ÏïåÎ†§ÏßÑ¬†Î¨∏Ï†úÎäî¬†Îã§ÏùåÍ≥º¬†Í∞ôÏäµÎãàÎã§.</p></li></ul><p>1.Ï∫êÎ¶≠ÌÑ∞¬†Ïù¥Î¶ÑÏù¥ÎÇò¬†Í∑∏Î¶º¬†Ïä§ÌÉÄÏùºÏù¥¬†ÏñºÍµ¥¬†ÌòïÌÉúÏóê¬†Ï†ÅÏö©ÎêòÏßÄ¬†ÏïäÏùÑ¬†ÌôïÎ•†Ïù¥¬†ÏûàÏäµÎãàÎã§.¬†Ïù¥Îïå¬†Ìä∏Î¶¨Í±∞¬†ÏõåÎìúÏùò¬†Í∞ÄÏ§ëÏπòÎ•º¬†ÎäòÎ†§Î≥¥Ïã≠ÏãúÏò§.</p><p>2.Î™®Îç∏ÏùÄ¬†1024*1024¬†ÌÅ¨Í∏∞Ïùò¬†Ï∫îÎ≤ÑÏä§Î•º¬†Í∏∞Î∞òÏúºÎ°ú¬†ÌõàÎ†®ÎêòÏóàÍ∏∞¬†ÎïåÎ¨∏Ïóê¬†Îã§Î•∏¬†ÎπÑÏú®Ïùò¬†Ïù¥ÎØ∏ÏßÄÎäî¬†ÎÜíÏùÄ¬†Ïò§Î•òÏú®ÏùÑ¬†Ï¥àÎûòÌï†¬†Ïàò¬†ÏûàÏäµÎãàÎã§.¬†Í∞ÄÎä•Ìïú¬†Ìïú¬†1024*1024¬†ÌÅ¨Í∏∞Ïùò¬†Ï∫îÎ≤ÑÏä§Î•º¬†ÏÇ¨Ïö©ÌïòÎäî¬†Í≤ÉÏù¥¬†Ï¢ãÏúºÎ©∞,¬†ÌõÑÏÜç¬†Î∞òÎ≥µÏóêÏÑú¬†Îã§Î•∏¬†ÌÅ¨Í∏∞Ïùò¬†Ï∫îÎ≤ÑÏä§¬†ÌõàÎ†®¬†ÏÑ∏Ìä∏Î•º¬†ÏÇ¨Ïö©ÌïòÏó¨¬†ÌõàÎ†®ÏùÑ¬†ÏãúÎèÑÌï†¬†Í≤ÉÏûÖÎãàÎã§.</p><p>3.Ïó≠Î∞©Ìñ•¬†ÌîÑÎ°¨ÌîÑÌä∏¬†Îã®Ïñ¥Ïóê¬†Í¥ÄÌï¥ÏÑú:¬†ÌòÑÏû¨¬†ÏÇ¨Ïö©¬†Ï§ëÏù∏¬†Ïó≠Î∞©Ìñ•¬†ÌîÑÎ°¨ÌîÑÌä∏¬†Îã®Ïñ¥Îäî¬†Î™®Îç∏Ïù¥¬†ÏïÑÏãúÏïÑ¬†ÏñºÍµ¥¬†Ìö®Í≥º¬†Ï∏°Î©¥ÏóêÏÑú¬†Ï¢ãÏùÄ¬†ÏÑ±Îä•ÏùÑ¬†Ïú†ÏßÄÌï†¬†Ïàò¬†ÏûàÎèÑÎ°ù¬†Ìï©ÎãàÎã§.¬†Îã§Î•∏¬†Ïó≠Î∞©Ìñ•¬†ÌîÑÎ°¨ÌîÑÌä∏¬†Îã®Ïñ¥Î•º¬†ÏÇ¨Ïö©ÌïòÎ†§Í≥†¬†ÌïòÎ©¥,¬†ÌòÑÏû¨¬†ÏÇ¨Ïö©¬†Ï§ëÏù∏¬†ÌîÑÎ°¨ÌîÑÌä∏¬†Îã®Ïñ¥ÎßåÌÅºÌö®Í≥ºÏ†ÅÏù¥ÏßÄ¬†ÏïäÏùÑ¬†Ïàò¬†ÏûàÏäµÎãàÎã§.¬†Í∑∏Îü¨ÎÇò¬†Ïù¥¬†ÎåÄÌòï¬†Î™®Îç∏Ïóê¬†Îçî¬†Ï†ÅÌï©Ìïú¬†Ïó≠Î∞©Ìñ•¬†ÌîÑÎ°¨ÌîÑÌä∏¬†Îã®Ïñ¥Î•º¬†Ï∞æÏúºÏã†Îã§Î©¥,¬†Îã§Î•∏¬†ÏÇ¨ÎûåÎì§Í≥º¬†Í≥µÏú†Ìï¥¬†Ï£ºÏãúÎ©¥¬†Í∞êÏÇ¨ÌïòÍ≤†ÏäµÎãàÎã§.</p><p>4.¬†ÌôîÎ©¥¬†ÎπÑÏú®¬†ÎïåÎ¨∏Ïóê¬†ÌòÑÏû¨¬†Ïù¥¬†Î™®Îç∏ÏùÄ¬†Î∞òÏã†ÏÉÅÏù¥ÎÇò¬†Ï¥àÏÉÅÌôî¬†ÏÉùÏÑ±Ïóê¬†Îçî¬†Ï†ÅÌï©Ìï©ÎãàÎã§.¬†Ï†ÑÏã†ÏÉÅÏùÑ¬†ÏÉùÏÑ±Ìï¥Ïïº¬†ÌïòÎäî¬†Í≤ΩÏö∞,¬†Í≥†Ìï¥ÏÉÅÎèÑ¬†Î≥µÏõê¬†Í∏∞Îä•ÏùÑ¬†ÌôúÏÑ±ÌôîÌïòÍ±∞ÎÇò¬†faterdetail¬†ÌôïÏû•¬†ÌîåÎü¨Í∑∏Ïù∏ÏùÑ¬†ÏÇ¨Ïö©ÌïòÎäî¬†Í≤ÉÏù¥¬†Ï¢ãÏäµÎãàÎã§.</p><p><br /></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898439+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "22530",
    "prompt": "[Guide] Make your own Loras, easy and free\n<h1 id=\"you-don't-need-to-download-anything-this-is-a-guide-with-online-tools.-click-&quot;show-more&quot;-below.-01lpdx3gp\">You don't need to download anything, this is a guide with online tools. Click \"Show more\" below.</h1><h3 id=\"you-can-find-an-updated-version-of-this-guide-in-my-new-website-a-comfy-place-where-experienced-ai-artists-and-model-creators-can-share-their-work.-q3kf4dz9y\">You can find an updated version of this guide in <a target=\"_blank\" rel=\"ugc\" href=\"https://arcenciel.io/articles/1\">my new website</a>, a comfy place where experienced AI artists and model creators can share their work.</h3><p></p><h2 id=\"preamble-22ef046eh\">üè≠ Preamble</h2><p>Even if you don't know where to start or don't have a powerful computer, I can guide you to making your first Lora and more!</p><p>In this guide we'll be using resources from my <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/hollowstrawberry/kohya-colab/blob/main/README.md\">GitHub page</a>. If you're new to Stable Diffusion I also have a <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hollowstrawberry/stable-diffusion-guide/blob/main/README.md#index\">full guide</a> to generate your own images and learn useful tools.</p><p>I'm making this guide for the joy it brings me to share my hobbies and the work I put into them. I believe all information should be free for everyone, including image generation software. However I do not support you if you want to use AI to trick people, scam people, or break the law. I just do it for fun.</p><p></p><h3 id=\"what-you-need-oyeiuxfio\">üìÉWhat you need</h3><ul><li><p>An internet connection. You can even do this from your phone if you want to (as long as you can prevent the tab from closing).</p></li><li><p>Knowledge about <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hollowstrawberry/stable-diffusion-guide/blob/main/README.md#lora\">what Loras are and how to use them</a>.</p></li><li><p>Patience. I'll try to explain these new concepts in an easy way. Just try to read carefully, use critical thinking, and don't give up if you encounter errors.</p></li></ul><p></p><h1 id=\"making-a-lora-dix3hv2d6\">üé¥Making a Lora</h1><p>It has a reputation for being difficult. So many options and nobody explains what any of them do. Well, I've streamlined the process such that <strong>anyone</strong> can make their own Lora starting from nothing in under an hour. All while keeping some advanced settings you can use later on.</p><p>You could of course <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hollowstrawberry/stable-diffusion-guide/blob/main/README.md#train\">train a Lora in your own computer</a>, granted that you have an Nvidia graphics card with 6 GB of VRAM or more. We won't be doing that in this guide though, we'll be using Google Colab, which lets you borrow Google's powerful computers and graphics cards for free for a few hours a day (some say it's 20 hours a week). You can also pay $10 to get up to 50 extra hours, but you don't have to. We'll also be using a little bit of Google Drive storage.</p><p>This guide focuses on anime, but it also works for photorealism. However I won't help you if you want to copy real people's faces without their consent.</p><p></p><h3 id=\"types-of-lora-00ll0cf15\">üé° Types of Lora</h3><p>As you may know, a Lora can be trained and used for:</p><ul><li><p>A character or person</p></li><li><p>An artstyle</p></li><li><p>A pose</p></li><li><p>A piece of clothing</p></li><li><p>etc</p></li></ul><p>However there are also different types of Lora now:</p><ul><li><p><strong>LoRA</strong>: The classic, works well for most cases.</p></li><li><p><strong>LoCon</strong>: Has more layers which learn more aspects of the training data. Very good for artstyles.</p></li><li><p><strong>LoHa</strong>, <strong>LoKR</strong>, <strong>(IA)^3</strong>: These use novel mathematical algorithms to process the training data. I won't cover them as I don't think they're very useful.</p></li></ul><p></p><h2 id=\"first-half:-making-a-dataset-v969jx9gj\">üìä First Half: Making a Dataset</h2><p>This is the longest and most important part of making a Lora. A dataset is (for us) a collection of <strong>images</strong> and their <strong>descriptions</strong>, where each pair has the same filename (eg. \"1.png\" and \"1.txt\"), and they all have something in common which you want the AI to learn. The quality of your dataset is essential: You want your images to have at least 2 examples of: poses, angles, backgrounds, clothes, etc. If all your images are face close-ups for example, your Lora will have a hard time generating full body shots (but it's still possible!), unless you add a couple examples of those. As you add more variety, the concept will be better understood, allowing the AI to create new things that weren't in the training data. For example a character may then be generated in new poses and in different clothes. You can train a mediocre Lora with a bare minimum of 5 images, but I recommend 20 or more, and up to 1000.</p><p>As for the descriptions, for general images you want short and detailed sentences such as \"<em>full body photograph of a woman with blonde hair sitting on a chair</em>\". For anime you'll need to use booru tags (<em>1girl, blonde hair, full body, on chair</em>, etc.). Let me describe how tags work in your dataset: You need to be detailed, as the Lora will reference what's going on by using the base model you use for training. If there is something in all your images that you <strong>don't </strong>include in your tags, it will <strong>become part of your Lora</strong>. This is because the Lora absorbs details that can't be described easily with words, such as faces and accessories. Thanks to this you can let those details be absorbed into an <strong>activation tag</strong>, which is a unique word or phrase that goes at the start of every text file, and which makes your Lora easy to prompt.</p><p>You may gather your images online, and describe them manually. But fortunately, you can do most of this process automatically using my new <a target=\"_blank\" rel=\"ugc\" href=\"https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb\">üìä <strong>dataset maker colab</strong>.</a></p><p>Here are the steps:</p><p><strong>1Ô∏è‚É£ Setup</strong>: This will connect to your Google Drive. Choose a simple name for your project, and a folder structure you like, then <strong>run the cell</strong> by clicking the floating play button to the left side. It will ask for permission, accept to continue the guide.</p><ul><li><p>If you already have images to train with, upload them to your Google Drive's \"lora_training/datasets/project_name\" (old) or \"Loras/project_name/dataset\" (new) folder, and you may choose to skip step 2.</p></li></ul><p><strong>2Ô∏è‚É£ Scrape images from Gelbooru</strong>: In the case of anime, we will use the vast collection of available art to train our Lora. Gelbooru sorts images through thousands of <strong>booru tags</strong> describing everything about an image, which is also how we'll tag our images later. Follow the instructions on the colab for this step; basically, you want to request images that contain specific tags that represent your concept, character or style. When you run this cell it will show you the results and ask if you want to continue. Once you're satisfied, type yes and wait a minute for your images to download.</p><p><strong>3Ô∏è‚É£ Curate your images</strong>: There are a lot of duplicate images on Gelbooru, so we'll be using the FiftyOne AI to detect them and mark them for deletion. This will take a couple minutes once you run this cell. They won't be deleted yet though: eventually an interactive area will appear below the cell, displaying all your images in a grid. Here you can select the ones you don't like and mark them for deletion too. Follow the instructions in the colab. It is beneficial to delete low quality or unrelated images that slipped their way in. When you're finished, send Enter in the text box above the interactive area to apply your changes.</p><p><strong>4Ô∏è‚É£ Tag your images</strong>: We'll be using the WD 1.4 tagger AI to assign anime tags that describe your images, or the BLIP AI to create captions for photorealistic/other images. This takes a few minutes. I've found good results with a tagging threshold of 0.35 to 0.5. After running this cell it'll show you the most common tags in your dataset which will be useful for the next step.</p><p><strong>5Ô∏è‚É£ Curate your tags</strong>: This step for anime tags is optional, but very useful. Here you can assign the activation tag (also called trigger word) for your Lora. If you're training a style, you probably don't want any activation tag so that the Lora is always in effect. If you're training a character, I myself tend to delete (<strong>prune</strong>) common tags that are intrinsic to the character, such as body features and hair/eye color. This causes them to get <strong>absorbed</strong> by the activation tag. <em>Pruning makes prompting with your Lora easier, but also less flexible</em>. Some people like to prune all clothing to have a single tag that defines a character outfit; I do not recommend this, as too much pruning will affect some details. A more flexible approach is to <strong>merge</strong> tags, for example if we have some redundant tags like \"striped shirt, vertical stripes, vertical-striped shirt\" we can replace all of them with just \"striped shirt\". You can run this step as many times as you want.</p><p><strong>6Ô∏è‚É£ Ready</strong>: Your dataset is stored in your Google Drive. You can do anything you want with it, but we'll be going straight to the second half of this tutorial to start training your Lora!</p><p></p><h2 id=\"second-half:-settings-and-training-h4lfbvllh\">‚≠ê Second Half: Settings and Training</h2><p>This is the tricky part. To train your Lora we'll use my <a target=\"_blank\" rel=\"ugc\" href=\"https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb\">‚≠ê Lora trainer colab</a> or the <a target=\"_blank\" rel=\"ugc\" href=\"https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL.ipynb\">üåü XL Lora trainer colab</a> depending if you want to train for a SD1.5 model or an SDXL model. They are very similar, and they consist of a single cell with all the settings you need. Many of these settings don't need to be changed. However, this guide and the colab will explain what each of them do, such that you can play with them in the future.</p><p>Here are the settings:</p><p>‚ñ∂Ô∏è <strong>Setup</strong>: Enter the same project name you used in the first half of the guide and it'll work automatically. Here you can also change the base model for training. There are 2 recommended default ones, but alternatively you can copy a direct download link to a custom model of your choice. Make sure to pick the same folder structure you used in the dataset maker.</p><p>‚ñ∂Ô∏è <strong>Processing</strong>: Here are the settings that change how your dataset will be processed.</p><ul><li><p>The resolution should stay at 512 this time, which is normal for Stable Diffusion. Increasing it makes training much slower, but it does help with finer details. (SDXL has a default of 1024)</p></li><li><p><em>flip_aug</em> is a trick to learn more evenly, as if you had more images, but makes the AI confuse left and right, so it's your choice.</p></li><li><p><em>shuffle_tags</em> should always stay active if you use anime tags, as it makes prompting more flexible and reduces bias.</p></li><li><p><em>activation_tags</em> is important, set it to 1 if you added one during the dataset part of the guide. This is also called <em>keep_tokens</em>.</p></li></ul><p>‚ñ∂Ô∏è <strong>Steps</strong>: We need to pay attention here. There are 4 variables at play: your number of images, the number of repeats, the number of epochs, and the batch size. These result in your total steps.</p><p>You can choose to set the total epochs or the total steps, we will look at some examples in a moment. Too few steps will undercook the Lora and make it useless, and too many will overcook it and distort your images. This is why we choose to save the Lora every few epochs, so we can compare and decide later. For this reason, I recommend few repeats and many epochs.</p><p>There are many ways to train a Lora. The method I follow nowadays involves balancing these values to produce 250-1000 steps depending on the amount of images. Note that styles may need to train for more epochs with a smaller learning rate. If you're training in XL you need around half as many repeats. Here are some examples for XL:</p><ul><li><p>10 images √ó 10 repeats √ó 10 epochs √∑ 2 batch size = 500 steps</p></li><li><p>20 images √ó 5 repeats √ó 10 epochs √∑ 4 batch size = 250 steps</p></li><li><p>100 images √ó 1 repeats √ó 10 epochs √∑ 4 batch size = 250 steps</p></li><li><p>1000 images √ó 1 repeat √ó 6 epochs √∑ 8 batch size = 750 steps</p></li></ul><p>‚ñ∂Ô∏è <strong>Learning</strong>: The most important settings. However, you don't need to change any of these your first time. In any case:</p><ul><li><p>The <strong>unet</strong> learning rate dictates how fast your Lora will absorb information. Like with steps, if it's too small the Lora won't do anything, and if it's too large the Lora will deepfry every image you generate. There's a flexible range of working values, specially since you can change the intensity of the lora in prompts. Assuming you set dim between 8 and 32 (see below), I recommend 5e-4 unet for almost all situations. If you want a slow simmer, 1e-4 or 2e-4 will be better. Note that these are in scientific notation: 1e-4 = 0.0001</p></li><li><p>The <strong>text encoder </strong>learning rate is less important, specially for styles. It helps learn tags better, but it'll still learn them without it. It is generally accepted that it should be either half or a fifth of the unet, good values include 1e-4 or 5e-5. Use google as a calculator if you find these small values confusing.</p></li><li><p>The <strong>scheduler</strong> guides the learning rate over time. This is not critical, but still helps. I always use cosine with 3 restarts, which I personally feel like it keeps the Lora \"fresh\". Feel free to experiment with <em>cosine, constant</em>, and <em>constant with warmup</em>. Can't go wrong with those. There's also the warmup ratio which should help the training start efficiently, and the default of 5% works well.</p></li></ul><p>‚ñ∂Ô∏è <strong>Structure</strong>: Here is where you choose the type of Lora from the 2 I mentioned in the beginning. Also, the <strong>dim</strong>/<strong>alpha</strong> mean the size of your Lora. Larger does not usually mean better. I personally use 16/8 which <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/17922/ninomae-inanis-hololive-4-outfits\">works great for characters</a> and is only 18 MB.</p><p>‚ñ∂Ô∏è <strong>Ready</strong>: Now you're ready to run this big cell which will train your Lora. It will take 5 minutes to boot up, after which it starts performing the training steps. In total it should be less than an hour, and it will put the results in your Google Drive.</p><p></p><h2 id=\"third-half:-testing-cctnujff6\">üèÅ Third Half: Testing</h2><p>You read that right. I lied! üòà There are 3 parts to this guide.</p><p>When you finish your Lora you still have to test it to know if it's good. Go to your Google Drive inside the /lora_training/outputs/ folder, and download everything inside your project name's folder. Each of these is a different Lora saved at different epochs of your training. Each of them has a number like 01, 02, 03, etc.</p><p>Here's a simple workflow to find the optimal way to use your Lora:</p><ol><li><p>Put your final Lora in your prompt with a weight of 0.7 or 1, and include some of the most common tags you saw during the tagging part of the guide. You should see a clear effect, hopefully similar to what you tried to train. Adjust your prompt until you're either satisfied or can't seem to get it any better.</p></li><li><p>Use the <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hollowstrawberry/stable-diffusion-guide/blob/main/README.md#plot\">X/Y/Z plot</a> to compare different epochs. This is a builtin feature in webui. Go to the bottom of the generation parameters and select the script. Put the Lora of the first epoch in your prompt (like \"&lt;lora:projectname-01:0.7&gt;\"), and on the script's X value write something like \"-01, -02, -03\", etc. Make sure the X value is in \"Prompt S/R\" mode. These will perform replacements in your prompt, causing it to go through the different numbers of your lora so you can compare their quality. You can first compare every 2nd or every 5th epoch if you want to save time. You should ideally do batches of images to compare more fairly.</p></li><li><p>Once you've found your favorite epoch, try to find the best weight. Do an X/Y/Z plot again, this time with an X value like \":0.5, :0.6, :0.7, :0.8, :0.9, :1\". It will replace a small part of your prompt to go over different lora weights. Again it's better to compare in batches. You're looking for a weight that results in the best detail but without distorting the image. If you want you can do steps 2 and 3 together as X/Y, it'll take longer but be more thorough.</p></li><li><p>If you found results you liked, congratulations! Keep testing different situations, angles, clothes, etc, to see if your Lora can be creative and do things that weren't in the training data.</p></li></ol><p>Finally, here are some things that might have gone wrong:</p><ul><li><p>If your Lora doesn't do anything or very little, we call it \"undercooked\" and you probably had a unet learning rate too low or needed to train longer. Make sure you didn't just make a mistake when prompting.</p></li><li><p>If your Lora does work but it doesn't resemble what you wanted, again it might just be undercooked, or your dataset was low quality (images and/or tags). Some concepts are much harder to train, so you should seek assistance from the community if you feel lost.</p></li></ul><ul><li><p>If your Lora produces distorted images or artifacts, and earlier epochs don't help, or you even get a \"nan\" error, we call it \"overcooked\" and your learning rate or repeats were too high.</p></li></ul><ul><li><p>If your Lora is too strict in what it can do, we'll call it \"overfit\". Your dataset was probably too small or tagged poorly, or it's slightly overcooked.</p></li></ul><p></p><p>If you got something usable, that's it, now upload it to Civitai for the world to see. Don't be shy. Cheers!</p><p></p><p>Check out my new website, a comfy place where experienced AI artists and model creators can share their work: <a target=\"_blank\" rel=\"ugc\" href=\"https://arcenciel.io\">https://arcenciel.io</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898478+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "3666",
    "prompt": "Protogen x3.4 (Photorealism) Official Release\n<p>Research Model - <a target=\"_blank\" rel=\"ugc\" href=\"https://www.reddit.com/r/StableDiffusion/comments/1079c0d/protogen_checkpoint_merging_data_reference/\">How to Build Protogen</a><br /><strong>ProtoGen_X3.4 - Enbrace the ugly, if you dare...</strong><br />By Downloading you agree to the<br /><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/coreco/seek.art_MEGA/blob/main/LICENSE.txt\">Seek Art Mega License</a><strong>, </strong>and the<strong> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/spaces/CompVis/stable-diffusion-license\">CreativeML Open RAIL-M</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://preview.redd.it/et9c6e3bsoda1.jpeg?width=1076&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=aa2049832da52e4e650e847e023147629e7faf40\"><strong>Model Weights</strong></a> thanks to reddit user <a target=\"_blank\" rel=\"ugc\" href=\"https://www.reddit.com/user/jonesaid\">u/jonesaid</a><br />Running on Apple Silicon devices ? <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/coreml/coreml-Protogen\">Try this instead</a><br />Trigger words are available for the hassan1.4 and f222, might have to google them :)<br /></p><p>Seriously, removing off (ugly) on negative prompts brings out some really detailed shots of what real life consist of, decay, rubble, grass, worned clothing...Have fun and keep it fluffy!</p><p></p><h3><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/spaces/darkstorm2150/protogen-web-ui\"><strong>Live Demo at Available on Hugging Face</strong></a></h3><p><strong><br /></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.studiobinder.com/blog/ultimate-guide-to-camera-shots/\"><strong>Comprehensive guide to camera control</strong></a><strong><br /></strong></p><p>This is Protogen_v2.2 with 5% of the following</p><ul><li><p>roboDiffusion_v1.ckpt</p></li><li><p>openjourney-v2-unpruned.ckpt</p></li><li><p>analog-diffusion-1.0.ckpt</p></li><li><p>rpg_v2Beta.ckpt</p></li></ul><p></p><p>The result is Photorealism, with RPG elements, Scifi, and some creative flow from OpenJourney model.</p><p></p><p>Let me know how are the outputs on <strong>The Dicussion Below</strong>, and I will continue to release more models based on the feedback...Enjoy!</p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898483+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "86277",
    "prompt": "Manmaru mix\n<p><span style=\"color:rgb(193, 194, 197)\">I don't speak English so I'm translating at DeepL. Let me know if the English is weird.</span></p><p></p><p>This model is based on the Thumbelina v2.0 Model character sketch,<br />which was adjusted to make it look less hand-drawn and to make the background appear clearer.</p><p></p><p>„Åì„ÅÆ„É¢„Éá„É´„ÅØThumbelina v2.0 Model„ÅÆ„Ç≠„É£„É©„Éá„Çí„ÇÇ„Å®„Å´„ÄÅ<br />ÊâãÊèè„ÅçÊÑü„ÇíËñÑ„Åè„Åó„ÄÅËÉåÊôØ„Åå„Åè„Å£„Åç„ÇäÂá∫„Çã„Çà„ÅÜ„Å´Ë™øÊï¥„Åó„Åæ„Åó„Åü„ÄÇ</p><p></p><p><strong>Update History / Êõ¥Êñ∞Â±•Ê≠¥</strong></p><ul><li><p>V2<br />The background is clearer than in V1. Also, the hands should be just a little bit better...<br />After using it myself for a while, I noticed that the face of the output is cuter than V1. That's my subjective opinion.<br />ËÉåÊôØ„ÅåV1„Çà„Çä„Çà„Çä„Åè„Å£„Åç„Çä„Åó„Åæ„Åó„Åü„ÄÇ„ÅÇ„Å®„ÄÅ„Åª„Çì„ÅÆ„Å°„Çá„Å£„Å®„Å†„Åë„ÄÅÊâã„ÅÆÊèèÂÜô„Åå„Åæ„Åó„Å´„Å™„Å£„Å¶„ÅÑ„Çã„ÅØ„Åö„Éª„Éª„Éª<br />„Åó„Å∞„Çâ„ÅèËá™ÂàÜ„Åß‰Ωø„Å£„Å¶„Åø„Å¶„ÄÅÈ°î„ÅåV1„Çà„Çä„Åã„Çè„ÅÑ„Åè„Å™„Å£„Å¶„ÅÑ„Çã„Åì„Å®„Å´Ê∞ó„Å•„Åç„Åæ„Åó„Åü„ÄÇÁßÅ„ÅÆ‰∏ªË¶≥„Åß„Åô„Åå„ÄÇ</p></li><li><p>V3<br />The hand rendering is more decent.<br />It is still not as good as other models, but it is much better.<br />Also, the background is clearer and the overall composition is less broken.<br />Êâã„ÅÆÊèèÂÜô„Åå„Çà„Çä„Åæ„Å®„ÇÇ„Å´„Å™„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åù„Çå„Åß„ÇÇ„Åæ„Å†„Åª„Åã„ÅÆ„É¢„Éá„É´„Å´ÊØî„Åπ„Åü„Çâ<br />ÊÇ™„ÅÑ„Åß„Åô„Åå„ÄÅ„Å†„ÅÑ„Å∂„Åæ„Åó„Å´„Å™„Çä„Åæ„Åó„Åü„ÄÇ<br />„Åæ„Åü„ÄÅËÉåÊôØ„Åå„Çà„Çä„ÅØ„Å£„Åç„Çä„Å®„Å™„Çä„ÄÅÂÖ®‰Ωì„ÅÆÊßãÂõ≥„ÇÇÂ£ä„Çå„Çã„Åì„Å®„ÅåÂ∞ë„Å™„Åè„Å™„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ</p></li></ul><p></p><p><strong>Merging Method / „Éû„Éº„Ç∏ÊñπÊ≥ï</strong></p><p>V1</p><ol><li><p>A:Thumbelina_v20.safetensors<br />B:nostalgiaMix_nostalgia.safetensors<br />Sum Merge : -0.6 (THIS IS \"minus\"!! „Éû„Ç§„Éä„Çπ„Åß„ÅôÔºÅÔºÅ)<br />„ÄÄ-&gt;tmp.safetensors</p></li><li><p>A:flat2DAnimerge_v20.safetensors<br />B:tmp.safetensors<br />C:featurelessMix_v10.safetensors<br />MBW:<br />„ÄÄalpha:0.25,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5<br />„ÄÄbeta:0.5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0</p></li></ol><p>V2</p><ol><li><p>A:flat2DAnimerge_v20.safetensors<br />B:cocotifamix_v20This.safetensors<br />Sum Merge : 0.5<br />„ÄÄ-&gt;tmp.safetensors</p></li><li><p>A:manmaruMix_v10.safetensors<br />B:tmp.safetensors<br />MBW:<br />alpha:0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1</p></li></ol><p></p><p>V3</p><p>There are so many steps because of trial and error!<br />Ë©¶Ë°åÈåØË™§„Åó„Åü„Åã„Çâ„ÇÅ„Å£„Å°„ÇÉÊÆµÈöéÂ§ö„ÅÑ„ÇàÔºÅ</p><ol><li><p>A:Thumbelina_v20.safetensors<br />B:nostalgiaMix_nostalgia.safetensors<br />sum merge : -0.4 (this is minas / „Éû„Ç§„Éä„Çπ„Åß„Åô)<br />-&gt; tmp01.safetensors</p></li><li><p>A:tmp01.safetensors<br />B:featurelessCuteMix_v10.safetensors<br />sum merge : 0.5<br />-&gt; tmp02.safetensors</p></li><li><p>A:tmp02.safetensors<br />LoRA merge : 3dSlider_JRPG_v1:0.25<br />-&gt; tmp03.safetensors</p></li><li><p>A:manmaruMix_v20.safetensors<br />B:featurelessCuteMix_v10<br />sum merge : 0.1<br />-&gt;tmp04.safetensors</p></li><li><p>A:tmp04.safetensors<br />LoRA merge : 3dSlider_JRPG_v1:0.25<br />-&gt;tmp05.safetensors</p></li><li><p>A:tmp04.safetensors<br />B:tmp05.safetensors<br />sum merge : 0.5</p></li></ol><p>„ÄÄ<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/97653?modelVersionId=183895\"><u><span style=\"color:rgb(34, 139, 230)\">z-vae v2.0</span></u></a><span style=\"color:rgb(193, 194, 197)\"> has been merged. / </span><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/97653?modelVersionId=183895\"><u><span style=\"color:rgb(34, 139, 230)\">z-vae v2.0</span></u></a><span style=\"color:rgb(193, 194, 197)\">„Çí„Éû„Éº„Ç∏Ê∏à„Åø„Åß„Åô„ÄÇ(thx verxonous86495!)</span></p><p></p><p><strong>Origin of the model name / „É¢„Éá„É´Âêç„ÅÆÁî±Êù•</strong></p><p>\"manmaru\" = \"„Åæ„Çì‰∏∏\", means \"perfectly round\".<br />Because the eye shape output by this model is round.</p><p>„Åì„ÅÆ„É¢„Éá„É´„ÅßÂá∫Âäõ„Åï„Çå„ÇãÁõÆ„ÅÆÂΩ¢„Åå„Åæ„Çì‰∏∏„Å™„ÅÆ„Åß„ÄÅ\"manmaru\"„ÄÇ</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898488+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "119032",
    "prompt": "unaestheticXL | Negative TI\n<p>„ÅÑ„Çç„ÅÑ„Çç„ÅÇ„Çã„ÅÆ„ÅßÂ•Ω„Åø„ÅÆ„ÇÑ„Å§„Çí‰Ωø„Å£„Å¶„Åè„Å†„Åï„ÅÑ</p><p>Of course, since there are various options, please use your preferred one.</p><p>Âº∑Âº±„ÇÑÁµÑ„ÅøÂêà„Çè„Åõ„ÇÇ„ÅÇ„Çä„Åß„Åô</p><p>It can be strong or weak or a combination of the two.</p><p>„É¢„Éá„É´„Å®„ÅÆÁõ∏ÊÄß„ÇÇ„ÅÇ„Çã„ÅÆ„Åß„Ç≥„É≥„Éà„É©„Çπ„Éà„Åå„Åä„Åã„Åó„ÅÑÂ†¥Âêà„ÅØÈÅï„ÅÜTI„Çí‰ΩøÁî®„Åó„Å¶„Åè„Å†„Åï„ÅÑ</p><p>Use a different ‚ÄùTI‚Äù if the contrast is not right, as it may be compatible with the model</p><p></p><p>Support</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/aikimi\">https://ko-fi.com/aikimi</a></p><p>maybe</p><p>anime: _sky3.1 , v1.0, _hk1</p><p>semireal: v3.1 , _AYv1, 2v10</p><p>real: _Jug6 , v1.3,_Alb2</p><p></p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898492+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "34553",
    "prompt": "AingDiffusion\n<p><strong><u><span style=\"color:rgb(250, 82, 82)\">Read \"About this version\" to see what changes were made to the model. I might make changes you don't like and you may want to stay on the older version.</span></u></strong></p><p></p><h3 id=\"heading-5\">The only authorized generation service outside Civitai is <a target=\"_blank\" rel=\"ugc\" href=\"http://yodayo.com\">yodayo.com</a></h3><p>Maintaining a stable diffusion model is very resource-burning. Please consider supporting me via <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/kayfahaarukku\">Ko-fi</a>.</p><p>AingDiffusion will ALWAYS BE FREE.</p><p>EXP models will be updated here to reduce confusion: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/52780\">https://civitai.com/models/52780</a>.</p><p>===<br />AingDiffusion (read: Ah-eeng Diffusion) is a merge of a bunch of anime models. This model is capable of generating high-quality anime images.<br /><br />The word \"aing\" came from informal Sundanese; it means \"I\" or \"My\". The name represents that this model produces images relevant to my taste.</p><p></p><h2 id=\"guide-to-generate-good-images-with-this-model\">Guide to generating good images with this model</h2><ul><li><p><strong>(NOT REQUIRED SINCE v7.7. FOR AINGDIFFUSION v7.7 AND UP, SET THE VAE TO NONE)</strong> <s>Use the VAE I included with the model. To set up VAE, </s><a target=\"_blank\" rel=\"ugc\" href=\"https://stable-diffusion-art.com/how-to-use-vae/#Install\"><s>you can refer to this guide</s></a>.</p></li><li><p>Use any negative textual inversion (e.g. EasyNegative), they will help you a lot.</p></li><li><p><strong>Recommended samplers are \"Euler a and DPM++ 2M Karras\" for AingDiffusion v7.1 and up.</strong></p></li><li><p>Hi-res fix is <strong>a must</strong> if you want to generate high-quality and high-resolution images. For the upscaler, I highly recommend <strong>4x-UltraMix Balanced or 4x-AnimeSharp</strong>.</p></li><li><p>Set Clip skip to 2 [<strong>optional, if you need more creativity to the output and not following the prompt 100%</strong>], ENSD (eta noise seed delta) to 31337 [to replicate image], and eta (noise multiplier) for ancestral samplers to 0.667.</p></li></ul><p></p><h2 id=\"heading-8\">FAQ</h2><p><strong>Q: What's up with the frequent updates?</strong></p><p>A: AingDiffusion is a model I use daily, not something I merge to gain popularity or for the sake of download count. I made constant efforts to improve the model whenever possible and wanted to share the improvements as quickly as possible.</p><p><strong>Q: I can't generate good images with your model.</strong></p><p>A: The first thing to remember is that every little change matters in the world of Stable Diffusion. Try adjusting your prompt, using different sampling methods, adding or reducing sampling steps, or adjusting the CFG scale.<img src=\"http://localhost:7860/file=E:/stable-diffusion-webui/outputs/txt2img-grids/xyz_grid-0024-692667804.png\" /><img src=\"http://127.0.0.1:7860/file=E:/stable-diffusion-webui/outputs/txt2img-grids/xyz_grid-0019-2172059715.png\" /></p><p>Keep experimenting and have fun with the models! üòÑ</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898500+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "84586",
    "prompt": "AAM - AnyLoRA Anime Mix - Anime Screencap Style Model\n<h1 id=\"heading-2586\">AnyLoRA Anime Mix (AAM)</h1><h2 id=\"heading-2587\">Anime Screencap Style Model</h2><p><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> üÖøÔ∏è or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> ‚òï. </strong><br /><strong>A ‚ù§Ô∏è, a kind comment or a review is greatly appreciated.</strong></p><h2 id=\"heading-12\">Please check out <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/269232\">AAM XL</a> too</h2><h3 id=\"heading-650\">Purpose of this model</h3><ul><li><p>Make amazing anime style artworks on its own.</p></li><li><p>Train character loras where the dataset is mostly made of anime screencaps, allowing less anime style transfer and less overfitting.</p></li><li><p>Use anime styles if the lora is \"weak\" and doesn't give enough flat coloring.</p></li><li><p>It's also pretty good at generating hentai stuff.</p></li></ul><p></p><h3 id=\"heading-236\">Suggested settings</h3><ul><li><p><strong>Set the ETA Noise Seed Delta (ENSD) to 31337</strong></p></li><li><p><strong>Set CLIP Skip to 2</strong></p></li><li><p><strong>DISABLE face restore. It's terrible, never use it</strong></p></li><li><p><strong>Use negative prompts and embeddings that don't ruin the style</strong></p></li><li><p><strong>Use AnimeVideo or Foolhardy as upscalers. If you know what to do, Latent makes an interesting effect (see the first example and the Miku one)</strong></p></li><li><p><strong>(optional to reproduce some results) Set \"Do not make DPM++ SDE deterministic across different batch sizes.\" <span style=\"color:rgb(134, 142, 150)\">Only my old images use that. </span></strong><br /><strong><span style=\"color:rgb(134, 142, 150)\">(this setting is not actually good, so I'm gonna disable it, but might be the reason some results are different)</span></strong></p></li></ul><p></p><p><strong><span style=\"color:rgb(253, 126, 20)\">LCM </span>version</strong><br />Use it with 5-15 steps, ~2 cfg. <strong><u><span style=\"color:rgb(253, 126, 20)\">LCM VERSION WORKS ONLY WITH LCM SAMPLER</span></u></strong> (to get it on Auto1111 you currently need a plugin).</p><p>Being a distilled model it has lower quality compared to the base one. However it's MUCH faster and perfect for video and real time applications.</p><p></p><h3 id=\"heading-651\">Brief history</h3><p>Chatting on Discord, I noticed my Mushoku Tensei style LoRA, while trained on AnyLoRA, was performing a bit better on CyberAlchemist's AnimeMix base model. I read on his HF that the model was a supermerge of AnythingElse, his AnimeMix lora and various other style loras. Since AnimeMix was already including many of my old anime style loras, I wanted to experiment and try to make a model that could maximize the result of my Mushoku Tensei style, going beyond what AnyLoRA and AnimeMix could do.</p><p>After testing many different versions, adjusting the settings and receiving feedback from the Discord channel, I ended up with a version that works very well on anime loras trained on AnyLoRA (base). Especially my Mushoku Tensei one which felt very weak on AnyLoRA.</p><p>I don't advise using this for anime style training (limit to generation after training it on AnyLoRA or NAI), but it might actually be fairly good for character loras where your dataset is made mostly of anime screencaps. It should technically reduce the anime style impact making the character lora less overfitted. I'll definitely experiment with it in the following weeks.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898509+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "28779",
    "prompt": "PrimeMix\n<p>Êñ∞Ê®°ÂûãÂú®<a target=\"_blank\" rel=\"ugc\" href=\"https://tusi.art/models/603784333515349886\">https://tusi.art/models/603784333515349886</a> ÂèëÂ∏É‰∫Ü Â§ßÂÆ∂ÂèØ‰ª•ÂéªËØïÁî®‰∏Ä‰∏ãÂô¢</p><p>AnimeÁâàÊú¨ ‰∏çÂÅöÂØπÊØî‰∫Ü Â∞±ÊòØÊõ¥Âπ≥Èù¢ÂíåÂä®Êº´È£éÊ†º ÁúãÁúã‰æãÂõæÂ∞±Â•Ω‰∫Ü</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8231dd00-85fb-4f01-aa66-a5399be11b00/width=525/8231dd00-85fb-4f01-aa66-a5399be11b00.jpeg\" /></p><p></p><p></p><p></p><p></p><p>-2.0ÁöÑ‰∏Ä‰∫õÁâàÊú¨ÊèêÂçáÂú®‰∫é Âº∫Âåñ‰∫Ü‰∫∫Áâ©ÁöÆËÇ§Ë°£ÊúçÁöÑÈÄè‰∫ÆÊÑüÔºåÂº∫Âåñ‰∫ÜÊöóÈÉ®ÁöÑÁªÜËäÇÔºåÂπ∂Á®çÂæÆÂä†Âº∫‰∫Ü‰∏Ä‰∫õÊâãÈÉ®ÂÖ≥ËäÇ Ë¥®ÊÑüÊèêÂçáÊõ¥Â§ö</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/35dd0361-a730-40d5-dca2-d4d56fdb5300/width=525/35dd0361-a730-40d5-dca2-d4d56fdb5300.jpeg\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5b5312a0-db43-4c44-b79d-64c56b9eac00/width=525/5b5312a0-db43-4c44-b79d-64c56b9eac00.jpeg\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2c876f86-8953-40c6-77e9-54ff71747d00/width=525/2c876f86-8953-40c6-77e9-54ff71747d00.jpeg\" /></p><p></p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cbf5cee2-e7ee-458e-c49b-5ae113b3e400/width=525/cbf5cee2-e7ee-458e-c49b-5ae113b3e400.jpeg\" /></p><p></p><p>1.5ÁöÑ‰∏Ä‰∫õÂØπÊØî Ë¥®ÊÑüÂÖâÂΩ±ÊèêÂçá Ëâ≤ÂΩ©ÂØπÊØîÂæàÊ£í</p><p>ËØ∑Ê≥®ÊÑè ÊàëÁöÑË¥üÈù¢ËØçÊ±áÂπ∂‰∏çÊòØÂçïÁ∫ØÁöÑËØçÊ±á ËÄåÊòØ‰∏Ä‰∏™‰∏™embeddings ‰Ω†‰ª¨ÂèØ‰ª•Âú®Ëøô‰∏™ÁΩëÁ´ô‰∏ãÂà∞Ëøô‰∫õËØçÊ±áÂπ∂Âú®Ë¥üÈù¢ÊèêÁ§∫ËØç‰∏≠Áî®‰∏ä ÂèØ‰ª•Â∏ÆÂä©‰Ω†‰ª¨ËææÂà∞ÊàëÊÉ≥Ë¶ÅÁöÑÊïàÊûú</p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/66397126-5ab8-4b5f-6f7c-1d1d17da8300/width=525/66397126-5ab8-4b5f-6f7c-1d1d17da8300\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5a9e4a96-b2aa-48ea-9003-6c4aca57fb00/width=525/5a9e4a96-b2aa-48ea-9003-6c4aca57fb00\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e31f6753-99b3-43db-b4f5-d1570e394700/width=525/e31f6753-99b3-43db-b4f5-d1570e394700\" /></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898512+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "53601",
    "prompt": "Â®ú‰πåÊñØÂòânwsj_realistic\n<p>‰∫≤Áà±ÁöÑÂÆ°Ê†∏ÂëòÂ§ß‰∫∫ÔºÅËøô‰∏™lora‰∏çÊòØÁúü‰∫∫Âì¶ÔºÅËôΩÁÑ∂ÊõæÁªèÁ°ÆÂÆûÊúâÊàëÊú¨‰∫∫ÁöÑÈù¢ÈÉ®ÁâπÂæÅÔºå‰ΩÜÊòØÂ∑≤ÁªèÁªèËøáÂ§öÊ¨°ÁæéÂåñÔºåÁõÆÂâçÂ∑≤ÁªèÂÆåÂÖ®ÊòØ‰∏Ä‰∏™ËôöÊãü‰∫∫loraÔºå‰∏ñÁïå‰∏ä‰∏çÂ≠òÂú®Ê≠§‰∫∫ÔºÅÊâÄ‰ª•ËØ∑‰∏çË¶Å‰∏ãÊû∂ÊàëÔºÅ</p><p>Dear auditor! This lora is not a real person! Although it does have my own facial features, it has been beautified many times and is now completely a virtual human Lora. This person does not exist in the world! So please don‚Äôt take me down!</p><p></p><p>ÊàëÁöÑÁ§æ‰∫§Âπ≥Âè∞ÔºåÊäñÈü≥ÂíåBÁ´ôÂêåÂêçÈÉΩÂè´Â®ú‰πåÊñØÂòâÔºÅ‰πüÂèØ‰ª•Âä†ÂÖ•ÊàëÁöÑqqÁæ§‰∏ÄËµ∑‰∫§ÊµÅ!</p><p>‰∏ÄÁæ§:321159940</p><p>‰∫åÁæ§:554810562</p><p></p><p>V4.0ÁâàÊú¨ÔºöfluxÊù•Âï¶ÔºÅÊàëÁöÑLora‰πüÂøÖÈ°ªÊõ¥Êñ∞Êõ¥È´òÊ∏ÖÁöÑÁâàÊú¨‰∫ÜÔºÅÊ≥®ÊÑèËøô‰∏™ÁâàÊú¨ÁöÑÁ¥†ÊùêËøòÊòØÊØîËæÉÊóßÁöÑÔºåÊâÄ‰ª•‰∫∫Áâ©ÁöÑÁúüÂÆûÊÑüÁ®çÂº±ÔºåÊàëÊ≠£Ë¶Åmix‰∏Ä‰∏™Êõ¥ÁúüÂÆûÁöÑÁâàÊú¨Ôºå‰ΩÜÊòØ‰ªã‰∫éÂæàÂ§öÊúãÂèãÂ∞±ÊòØÂñúÊ¨¢ÊóßÁöÑNWSJËÑ∏ÂûãÔºåÊâÄ‰ª•Ëøô‰∏™ÁâàÊú¨ËøòÊòØÂèëÂá∫Êù•ÁªôÂ§ßÂÆ∂‰ΩøÁî®ÔºÅÊàëËøòÁºñÂÜô‰∫ÜÈÖçÂ•óÁöÑÂ∑•‰ΩúÊµÅÔºåÊàëÁöÑfluxÁâàÊú¨Êó∂Â∞öÊäΩÂç°Êú∫ÔºåÂä†‰∏äÊç¢ËÑ∏Ê®°ÂùóÂèàÂèØ‰ª•ÂºÄÂøÉÁöÑÊäΩÂç°Âï¶ÔºÅ</p><p></p><p>V3.0ÁâàÊú¨ÔºöÊé®ËçêÊùÉÈáç0.7-0.8ÔºåÂú®KWÂ∞èÂßêÂßêÁöÑÊåáÂØº‰∏ã‰ΩøÁî®‰∫Ü1024ÁöÑÁ¥†ÊùêËøõË°åËÆ≠ÁªÉÔºåÁîüÊàêÁöÑËÑ∏ÈÉ®‰ºöÊ∏ÖÊô∞ÂæàÂ§öÔºåÂÖâÂ§¥ÂíåÁó£Â§öÁöÑÈóÆÈ¢ò‰πüÂ∑≤ÁªèËß£ÂÜ≥ÔºÅÁõ¥Âá∫ÂíåÊîæÂú®ADÊèí‰ª∂Èáå‰ΩøÁî®ÈÉΩOKÔºÅ</p><p>ÊÑüË∞¢Â§ßÂÆ∂ÁöÑÊîØÊåÅÔºåÂ®úÂ®úËøôÂ∞±ÁªôÁ£ï‰∏Ä‰∏™ÔºåËÆ∞ÂæóÂÖ≥Ê≥®ÊàëÂìüÔºÅÊãúÊãúÔºÅ</p><p></p><p>V2.0ÁâàÊú¨ÔºöËß¶ÂèëËØçPerfectNwsjMajicÔºå‰πãÊâÄ‰ª•Áî®Ëøô‰∏™ÂêçÂ≠óÊòØÂõ†‰∏∫Êàë‰∏∫‰∫ÜÊéíÈô§ÂéüÁîüÂèëÂûã‰∏≠ÂàÜÂàòÊµ∑ÁöÑÂπ≤Êâ∞ÔºåÁîüÊàê‰∫Ü‰∏ÄÊâπÂÖâÂ§¥ÂõæÔºåÊûúÁÑ∂ÂæàÂ•ΩÁöÑËßÑÈÅø‰∫ÜËøô‰∏™Áº∫Èô∑„ÄÇÁé∞Âú®Â®úÂ®úÂèØ‰ª•ÂÆåÁæéÁöÑÈÄÇÈÖçÂêÑÁßçÂèëÂûãÁöÑÂÖ≥ÈîÆÂ≠ó‰∫ÜÔºÅMajicÁöÑÂêéÁºÄÊòØ‰∏∫‰∫ÜÊèêÈÜíÂ§ßÂÆ∂Ëøô‰∏™Ê®°ÂûãÁî®MajicÁ≥ªÂàóÊ®°ÂûãÊõ¥ÂÆπÊòìËøòÂéüÂ®úÂ®úÁöÑËÑ∏ÂûãÔºÅ,ÂàáËÆ∞ÂàáËÆ∞ÔºÅÊùÉÈáç‰∏ÄÂÆö‰∏çÂèØÈ´ò‰∫é0.8Ôºå‰∏çÁÑ∂ÁôæÂàÜÁôæÁîüÊàêÂÖâÂ§¥Â®úÂ®ú=0=ÔºåÊé®ËçêÊùÉÈáç0.7ÔºÅ</p><p></p><p>V1.1ÁâàÊú¨ÔºöÊùÉÈáçÊé®Ëçê0.8</p><p></p><p>V1ÁâàÊú¨ÔºöÊùÉÈáçÊé®Ëçê0.6-0.7</p><p></p><p></p><p></p><p></p><p>hi everyone</p><p>ÊàëÊòØÂ®ú‰πåÊñØÂòâÔºåÂêçÂ≠óÊù•Ê∫ê‰∫éÂÆ´Â¥éÈ™èÁöÑÂä®ÁîªÁâáÈ£é‰πãË∞∑ÁöÑÂ®ú‰πåÊñØÂòâ</p><p>ËøôÊòØ‰∏Ä‰∏™Âü∫‰∫éÊàëËá™Â∑±ÁöÑÁúü‰∫∫ËÑ∏ÂûãÁîüÊàêÁöÑËôöÊãü‰∫∫lora</p><p>ÈÖçÊñπÊòØÂéüÁîüÁöÑÁúü‰∫∫loraÊùÉÈáç0.8+majicrealV4Â∫ïÊ®°+fashiongirlÊùÉÈáç0.2+shojovibeÊùÉÈáç0.2</p><p>ÁîüÊàê‰∫ÜÊñ∞ÁöÑ‰∏ÄÊâπÂõæÁâáËÆ≠ÁªÉËÄåÊàê</p><p>ÊàëÁß∞‰πã‰∏∫Â®ú‰πåÊñØÂòârealistic</p><p>Âú®Â∞èËåÉÂõ¥ÂÖ¨Â∏ÉLora‰πãÂêéÊî∂Âà∞‰∫ÜÂæàÂ§öÁæé‰∏ΩÁöÑÂõæÁâáÔºåÂΩìÁÑ∂‰πüÊúânsfwÁöÑÂõæÁâá</p><p>‰Ωú‰∏∫‰∏Ä‰∏™Â≠¶ÁæéÊúØÁöÑËâ∫ÊúØÁîüÊàëÊòØ‰∏çÂú®ÊÑèËøô‰∫õÁöÑ</p><p>ËØ∑‰∏çË¶ÅÂêùÂï¨ÂéªÂ∞ùËØïËøô‰∏™ËÑ∏ÂûãÂêßÔºåÊúüÂæÖÁúãÂà∞Â§ßÂÆ∂ÁöÑËâ∫ÊúØÂìÅÔºÅ</p><p>PS.Ëøô‰∏™loraÊé®ËçêÊùÉÈáçÂú®0.6-0.8‰πãÈó¥Ôºå‰∏≠ÂàÜÂàòÊµ∑ÁöÑÁâπÂæÅÊúâÁÇπÈöæÂéªÈô§ÔºåÂõ†‰∏∫ÊàëÊú¨‰∫∫Â∞±ÊòØËøô‰∏™ÂèëÂûãÔºåÂ¶ÇÊûúÊúâËß£ÂÜ≥ÊñπÊ°àËÆ∞ÂæóÁïôË®ÄÁªôÊàëÔºÅ</p><p>ÊàëÁöÑÁ§æ‰∫§Âπ≥Âè∞ÔºöDYÂíåBÁ´ôÈÉΩÊòØÂ®ú‰πåÊñØÂòâÔºåÊù•Ë∑üÊàë‰∫§ÊµÅÂêßÔºÅ</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898528+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "99619",
    "prompt": "Control LoRA Collection\n<p><strong><span style=\"color:rgb(250, 82, 82)\">Excited to release a new quality control LoRA for NoobAI XL v-pred!</span></strong></p><p><strong><span style=\"color:rgb(230, 73, 128)\">It took a month to develop this LoRA and package it into an easy-to-use format.</span></strong></p><p><strong><span style=\"color:rgb(190, 75, 219)\">NoobAI XL is an excellent model, but suffers from a variety of issues - wherein you have to use smoothing, quality and detail LoRAs or fine-tunes to get high quality results.</span></strong></p><p><strong><span style=\"color:rgb(121, 80, 242)\">This LoRA significantly improves coherency of the output latents and prompt obedience using a variety of techniques</span><em><span style=\"color:rgb(121, 80, 242)\"> while retaining all model knowledge</span></em><span style=\"color:rgb(121, 80, 242)\">.</span></strong></p><p><strong><span style=\"color:#4c6ef5\">If the effect is too strong, start with 0.5 LoRA strength, which will fix many issues without affecting the original tonality as much.</span></strong></p><p><strong>Effect:</strong></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8ef50b7f-2144-4fa6-8555-59d15640e16b/width=525/8ef50b7f-2144-4fa6-8555-59d15640e16b.jpeg\" />For reference this is the target image:</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8f902827-0550-4ab2-894a-8b397d6c8965/width=525/8f902827-0550-4ab2-894a-8b397d6c8965.jpeg\" />Source: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/images/46921580\">https://civitai.com/images/46921580</a></p><p>You can see the LoRA brings out the prompting intention more clearly, and has significant details. The stength:0 image is very far from the intended result, unless you try many different seeds.</p><h1 id=\"control-lora-collection-ypxxuegjq\">Control LoRA Collection</h1><p>A collection of various control LoRAs for use in gens, merges and fine tunes.</p><h2 id=\"model-fix-series-fjdaez018\">Model Fix series</h2><p>NAI v-pred fix: fixes issues with NoobAI XL v-pred models</p><h2 id=\"detail-series-uiucglotf\">Detail series</h2><p>SDXL Enhance: controls the details and compositional elements of SDXL-base models.</p><p>CFG ScaleBoost: boost the CFG scale of your gens using a LORA without burning out your latents.</p><p>Original rainbow messageL</p><p><strong><span style=\"color:rgb(190, 75, 219)\">Announcing the release of the CFG Scale Boost LoRA! </span><span style=\"color:rgb(121, 80, 242)\">After much research I've discovered a method which allows you to pseudo-control the CFG scale of your gens using a special LoRA. </span><span style=\"color:rgb(76, 110, 245)\">It is listed under Pony but will work with every SDXL model (including Illustrious XL)! </span><span style=\"color:rgb(34, 139, 230)\">It has the biggest effect on the backgrounds, where it will fill them out and make the scenes feel more complete without frying your gens.</span><span style=\"color:rgb(21, 170, 191)\"> Second, it has a detailer-like effect on the main subject, but not always! Experimentation is key.</span><span style=\"color:rgb(64, 192, 87)\"> I recommend 0.3-0.7 strength.</span><span style=\"color:rgb(190, 75, 219)\"> </span><span style=\"color:rgb(250, 176, 5)\">Released under EA as many sleepless nights were dedicated to this project, which I originally wasn't going to release publicly. </span><span style=\"color:rgb(253, 126, 20)\">Works with negative values as well, allowing you to control the composition and detail of your art to a fine degree, something not possible with typical detail LoRAs.</span></strong></p><h2 id=\"realism-series-01aun8i1t\">Realism series</h2><p><strong>Update</strong>: Finally added a Pony version!</p><p><strong>Original description</strong>:</p><p>This LoRA will make your model either 2D/anime &lt;-&gt; 3D/photorealistic depending on how to use it.</p><p>For example &lt;lora:realistic:-1.0&gt; (negative values) will strengthen the 2D style and &lt;lore:realistic:1.0&gt; (positive values) will strengthen the photo style.</p><p>Potential uses:</p><ul><li><p>Adjust the style of your model slightly to make it look more original</p></li><li><p>Make a realistic model more realistic (such as when the skin is too smooth/plastic)</p></li><li><p>Make a 2D/anime model more stylised by making it more 2D</p></li><li><p>Combined with the detail LoRA (linked in the resources) you can reduce details in your anime model and make it look more 2D to create a unique cell shaded style</p></li></ul><p>This LoRA works well with blended models. It is neutral and won‚Äôt overwrite the style of your gens.</p><p>Tip: depending on what model you‚Äôre using will determine what range of values will be suitable. 1.0 might be too much for some models and not enough for others, for example. This is especially true of negative values.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/3t2CAF9DRj\">Discord</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898536+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "7094",
    "prompt": "Arcane Style LoRA\n<h2>Arcane Style LoRA</h2><p><strong>Making models can be expensive. Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> üÖøÔ∏è or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> ‚òï</strong></p><p>Greatest show of 2021, time to bring this style to 2023 Stable Diffusion with LoRA.</p><p>This should be used with <strong>AnyLoRA</strong> (that's neutral enough) at <strong>around 1 weight for the offset version, 0.65 weight for the original one</strong> (with highres fix R-ESRGAN 0.4 denoise for better results). Trigger is <code>arcane style</code> but I noticed this often works even without it.</p><p>Allow me to remind <strong>this is not a character LoRA </strong>(I didn't tag characters in the dataset). Still ,as you can see, it can get pretty close to the original characters with accurate prompting. This should also work with most of my character LoRA's (used Ahri and Lucy to test).</p><p>Please enjoy.</p><p><br /><strong>How to use LoRA's in auto1111:</strong></p><ul><li><p>Update webui (use <code>git pull</code> <a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/embed/mn8fMF10XN4?start=31&amp;end=60\">like here</a> or redownload it)</p></li><li><p>Copy the file to <code>stable-diffusion-webui/models/lora</code></p></li><li><p>Select your LoRA like in <a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/watch?v=-bMeyXOZwN0\">this video</a></p></li><li><p><strong>Make sure to change the weight if needed</strong> (by default it's <code>:1</code>)</p></li></ul><p><br /></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898541+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "54233",
    "prompt": "GHIBLI_Background\n<p><strong>ÔºàÔºàPlease download the </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4468?modelVersionId=7425\"><strong><em>counterfeitv2.5</em></strong></a><strong> model and </strong><a rel=\"ugc\" href=\"https://civitai.com/models/22354\"><strong>clearVAE</strong></a><strong> before using it ÔºâÔºâ ÔºÅÔºÅÔºÅ</strong></p><p><strong><em>If you are interested in the field of AIGC design, please join my channel to discuss it</em></strong></p><p><strong><em>Discord</em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/rX3UwAkQN2\"><strong><em>https://discord.gg/rX3UwAkQN2</em></strong></a></p><p><strong><em>QQÁæ§607134175</em></strong></p><p><strong>The site preview image will compress the image quality, please double-click to view the original HD image</strong></p><p><strong>The beautiful Ghibli scene has a powerful expression for both architecture and landscape</strong></p><p><strong>v5.0 update</strong></p><p><strong>Updated more training sample set parameters, wider generalization, optimize the performance of the built environmentÔºåthis is the <em><u>best Ghibli style</u></em> model you have ever used, beautiful watercolor style</strong></p><p><strong>if you like my model, please pay attention or give feedback below, I will continue to update</strong></p><p><strong><em><u>The model prohibits commercial use, handling, and any blending, and the author retains ownership of the model</u></em></strong></p><p>ËØ•Ê®°ÂûãÁ¶ÅÊ≠¢ÂïÜÁî®ÔºåÊê¨ËøêÔºå‰ª•Âèä‰ªª‰ΩïËûçÂêàË°å‰∏∫Ôºå‰ΩúËÄÖ‰øùÁïôÊ®°ÂûãÊâÄÊúâÊùÉ</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898546+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "125907",
    "prompt": "RealCartoon-XL\n<h3 id=\"you-can-also-run-this-model-on-magespace-and-sinkin.ai!-https:www.mage.space-mphka8wqt\">You can also run this model on Magespace and Sinkin.ai! <a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/\">https://www.mage.space/</a></h3><ol><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/9200bfc93333da71123999f3550aabaa\">V5 - https://www.mage.space/play/9200bfc93333da71123999f3550aabaa</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/0a2a61c6d4a668ef51f552df0231067d\">V7 - https://www.mage.space/play/0a2a61c6d4a668ef51f552df0231067d</a></p></li></ol><p></p><h3 id=\"https:sinkin.aimrr7vrj4-l3nsclats\"><a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/RR7Vrj4\"><u>https://sinkin.ai/m/RR7Vrj4</u></a></h3><p></p><h3 id=\"want-to-send-some-support-(buy-a-cup-at-ko-fi)-bjhotbx0s\">Want to send some support? <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/7whitefire7\">(Buy a cup at Ko-fi)</a></h3><p>FYI VAE IS BAKED IN</p><p>Version 3 has <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/madebyollin/sdxl-vae-fp16-fix\">https://huggingface.co/madebyollin/sdxl-vae-fp16-fix</a> baked in.</p><p></p><p><em>RealCartoon-XL is an attempt to get some nice images from the newer SDXL. It still is a bit soft on some of the images, but I enjoy mixing and trying to get the checkpoint to do well on anything asked of it. This model level is definitely pushing my computer, so takes a bit longer to actually get it things tested and mixed :)</em></p><p><em>The mission is the same of the SD1.5 versions. Which is to get a checkpoint to pretty much do well on prompts while looking good with good variety</em></p><p><em>I hope you all enjoy it! </em><strong><em>Please review and share your images</em></strong><em>. I very much appreciate the support with the downloads and feedback </em><strong><em>(THANK YOU ALL)</em></strong><em>. Never thought it would get this much attention.</em></p><p></p><h2 id=\"the-process:-rulkj1zs3\">The Process:</h2><p><br />The starting checkpoints for merging were a couple of top ones of course (<strong>The checkpoints do/did not have restrictions on checkpoint mergers. Some of these are in my recommended resources as well</strong>). I also baked in the VAE <strong><em>(sdxl_vae.safetensors)</em></strong>.</p><p>Currently this checkpoint is at its beginnings, so it may take a bit of time before it starts to really shine. I will continue to update it as time progresses...but I do hope you all enjoy it as it develops.</p><p></p><h2 id=\"the-settings:-jja68d2bw\">The Settings:</h2><p>Still figuring out SDXL, but here is what I have been using:</p><ul><li><p><strong>Width:</strong> 1216 (normally would not adjust unless I flipped the height and width)</p></li><li><p><strong>Height: </strong>832</p></li><li><p><strong>Sampling Method:</strong> \"Eular A\" and \"DPM++ 2M Karras\" are favorites.</p></li><li><p><strong>Sampling steps:</strong> 30 - 55 normally (<strong>30 being my starting point, but going up to 55 and even 60 a lot of the time</strong>)</p></li><li><p><strong>Hires.fix settings:</strong> Upscaler (R-ESRGAN 4x+, 4k-UltraSharp most of the time), Hires Steps (10), Denoising Str (0.34 - 0.45 normally), Upscale (1.5 or 2 does well)</p></li><li><p><strong>Clip Skip:</strong> 2</p><p></p></li></ul><p>Some settings I run on the web-Ui to help get the images without crashing:</p><p>set COMMANDLINE_ARGS=--medvram --no-half-vae --opt-sdp-attention</p><p>__________________________________________________________________________________________________</p><h3 id=\"license-and-use-vgzvg4rj1\">License &amp; Use</h3><p>This model is open access and available to all, with a¬†CreativeML OpenRAIL-M¬†license further specifying rights and usage.</p><ul><li><p>1. You can't use the model to deliberately produce nor share illegal or harmful outputs or content.</p></li><li><p>2. The authors claims no rights on the outputs you generate, you are free to use them and are accountable for their use which must not go against the provisions set in the license.</p></li><li><p>3. You may re-distribute the weights. If you do, please be aware you have to include the same use restrictions as the ones in the license and share a copy of the modified CreativeML OpenRAIL-M to all your users (please read the license entirely and carefully).</p><p></p><p>Please read the full license here¬†Stable Diffusion</p></li></ul><h3 id=\"use-restrictions:-qq2g2d930\">Use Restrictions:</h3><p>You agree not to use the Model or Derivatives of the Model:</p><p>- In any way that violates any applicable national, federal, state, local or international law or regulation</p><p>- For the purpose of exploiting, harming or attempting to exploit or harm minors in any way</p><p>- To generate or disseminate verifiably false information and/or content with the purpose of harming others</p><p>- To generate or disseminate personal identifiable information that can be used to harm an individual</p><p>- To defame, disparage or otherwise harass others</p><p>- For fully automated decision making that adversely impacts an individual‚Äôs legal rights or otherwise creates or modifies a binding, enforceable obligation</p><p>- For any use intended to or which has the effect of discriminating against or harming individuals or groups based on online or offline social behavior or known or predicted personal or personality characteristics</p><p>- To exploit any of the vulnerabilities of a specific group of persons based on their age, social, physical or mental characteristics, in order to materially distort the behavior of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm</p><p>- For any use intended to or which has the effect of discriminating against individuals or groups based on legally protected characteristics or categories</p><p>- To provide medical advice and medical results interpretation</p><p>- To generate or disseminate information for the purpose to be used for administration of justice, law enforcement, immigration or asylum processes, such as predicting an individual will commit fraud/crime commitment (e.g. by text profiling, drawing causal relationships between assertions made in documents, indiscriminate and arbitrarily-targeted use).</p><h3 id=\"terms-of-use:-angsygwbd\">Terms of use:</h3><p>- You are solely responsible for any legal liability resulting from unethical use of this model(s)</p><p>- If you use any of these models for merging, please state what steps you took to do so and clearly indicate where modifications have been made.</p><h3 id=\"note:-yvd97j3af\">Note:</h3><p>If you see any conflicts or corrections to be made, please let me know.</p><p><br /></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898557+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "176554",
    "prompt": "ËñÑÂ°ó„Çä / USNR STYLE\n<p>Online generation</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.shakker.ai/modelinfo/2a2d4a6fd159426c85bbcdbd1e32a48b?from=personal_page&amp;versionUuid=38034b4eb695495ea0a4dc67ed25d596\">shakker</a></p><p></p><p>Recommended Settings:</p><p>Sampling Method: DPM++ 2M SDE</p><p>Schedule Type: SGM Uniform</p><p>CFG Scale: 6-4</p><p></p><p>Âª∫ËÆÆËÆæÁΩÆ:</p><p>ÈááÊ†∑ÊñπÊ≥ïÔºöDPM++ 2M SDE</p><p>Schedule typeÔºöSGM Uniform</p><p>CFG ScaleÔºö6-4</p><p></p><p>If you enjoy using this LoRA model, consider supporting my work through <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/mechanoid\">Ko-fi</a> to help upgrade my hardware capabilities.</p><p><span style=\"background-color:rgb(254, 254, 254);color:rgb(34, 34, 34);font-family:-apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;;font-size:20px\">If you'd like me to develop a personalized LoRA model tailored to your needs, check out my custom service offerings on </span><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/EWIGKEIT831\">Patreon</a><span style=\"background-color:rgb(254, 254, 254);color:rgb(34, 34, 34);font-family:-apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;;font-size:20px\">!</span></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898561+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "25831",
    "prompt": "SXZ Luma\n<h1 id=\"luma-65abl56iy\">üåï LUMA</h1><p>This is anime-based semi-realistic mix of checkpoints and loras tweaked for <span style=\"color:rgb(255, 238, 153)\">good results on simple prompts</span>.<br />Model is fully compatible with all LoRA that I made and will make in the future.</p><p><strong><span style=\"color:rgb(250, 176, 5)\">All the content I make is and will be completely free on</span></strong><span style=\"color:rgb(250, 176, 5)\"> </span><strong><span style=\"color:rgb(250, 176, 5)\">CivitAI.</span></strong><span style=\"color:rgb(250, 176, 5)\"><br />But if you want to support me with a coin, then </span><a target=\"_blank\" rel=\"ugc\" href=\"https://boosty.to/sadxzero/donate\">you can do it here</a>.</p><h2 id=\"luma-a3-vae-style-and-artist-list-(please-note-that-some-of-styles-need-additional-tags-like-&quot;retro-artstyle-faux-traditional-media-painting&quot;-etc):-t4ileo3d4\"><strong>Luma A3 VAE Style and Artist List </strong>(please note, that some of styles need additional tags like \"retro artstyle, faux traditional media, painting\", etc)<strong>:</strong></h2><p>Please note that tags<strong> \"<span style=\"color:rgb(250, 176, 5)\">3D, REALISTIC, ANIME</span>\" </strong>in positive or negative may <strong>change look of your images significantly.</strong></p><p>I also higly recommend to add <strong>\"score_5, score_4,<span style=\"color:rgb(144, 146, 150)\"> </span>ps1 screenshot, 3d, niji\"</strong> in negative prompt, if you're not going to use it in positive.</p><p>Also note, that i added somme extra tags for concepts.</p><p><strong>For example:</strong><br /><strong>altshaped </strong>- will help you make humanoids with alternative anatomy</p><p><strong>overdesigned </strong>- will help you make some complex designes if your prompt assumes it.</p><p>Complete style list:</p><pre><code>123wsty\nahriman, anime\nalbrecht d√ºrer\nalex ross, retro artstyle\nalexkonstad\naloija\namadmir\nanato finnstark\nanbudehuang\nanime\narcane\nasahiart, automaton, altshaped\nboris valejo\nbrenda burke\nburda, grungetech\ncastlevania, anime\ncher-ro\ncherrygig\nchibi herowars\nclaude monet\ncmg\ndarkest dungeon, high contrast\ndashiana\ndegenesis\ndemessance\ndeus ex, cyberpunk\ndisney, flat color\ndkeeno\ndrakonoart\ndravacus\ndreelrayk\neddie mendoza\nedgerunners, anime\nelden ring\nfanfoxy\ngalyosef, 3d\nganas\ngreg rutkowski\nhades\nhearthstone\nhenry asencio\nhizipro, high contrast\nikenaga yasunari\nindus\nivan kramskoy\njandrew, scenery, environment\njeremy mann\njim lee\njohn william waterhouse\njojo\njose parra\njparked\njunejenssen\nkael ngu\nkrrat, overdesigned\nkylepunk\nlaurelin\nleicai\nlol\nlovk1y\nmakoto shinkai, style\nmangamie\nmarta nael\nmax kostin\nmengxuanli\nmixppl\nmohrbacher, divine, altshaped\nmtg\nnadar\nnicolasaviori\nniji\nnixeu\nothalam\npainting \\(medium\\)\npapsuev\npeterskore\nphoto, realistic, cinematic\npixar, 3d\nps1 screenshot\nqichao wang\nrakavka\nreliah\nretrofuturism syd mead\nsaiya-art\nsanchare\nscenery, environment\nshinjuku\nsmite\nstephen pan\nstumpyfongo\nsugarpunk, cyberpunk\ntck, altshaped\ntemplarpainter\ntixnen\ntomas duchek\ntrufanov\nvalentin serov\nvalorant\nvegera\nviktor vasnetsov\nvincent van gogh\nwarcraft\nwayfinder\nwlop\nwroniec\nwushenyou\nyumingli\nyuriiiko, flat color\nzack snyder style, movie still, cinematic, realistic\nzexiguo, overdesigned</code></pre><h2 id=\"pdxl-usage:-cwr2ovbry\"><strong>PDXL Usage:</strong></h2><p><strong>Clip Skip 2</strong><br /><strong>Sampler: </strong><em>Euler a / DPM ++3M SDE (SGM Uniform) (or any your favorite)</em><br /><strong><em>Steps: </em></strong><em>30-40</em><br /><strong><em>CFG Scale: </em></strong><em>5-7</em><br /><strong>Hires.fix: </strong><em>x1.5</em><br /><strong>Upscaler: 8x_NMKD-Superscale_150000_G </strong>for realism<strong> </strong>or<strong> R-ESRGAN 4x+ Anime6B </strong>for illustrations<strong> </strong><em>(Denoising strenght 0.2-0.3)</em><br /><strong>Hires steps: </strong><em>15</em><br /><strong><span style=\"color:rgb(250, 82, 82)\">Never use Face Restoration!</span></strong><br /><strong>If you want better faces just use </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/alexv0iceh/AutoChar\"><strong>AutoChar</strong></a> or<strong> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\"><strong>AfterDetailer.</strong></a></p><p><strong>Useful tags (negative):</strong></p><pre><code>wrinkled skin, double head, mutant, bad anatomy, fewer digits, bad hands, extra limbs, twisted, cropped, out of frame</code></pre><p></p><h3 id=\"1.5-usage-y6upnjt2g\"><strong>1.5 Usage</strong></h3><p><strong>Recommended embeddings:</strong><br />1. <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\">easynegative</a><br />2. <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/gsdf/Counterfeit-V3.0/blob/main/embedding/EasyNegativeV2.safetensors\">easynegativev2</a><br />3. <a target=\"_blank\" rel=\"ugc\" href=\"https://cdn.discordapp.com/attachments/1032948846197747731/1069660323709190195/bad-hands-5.pt\">bad-hands-5</a><br />4. <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16993/badhandv4-animeillustdiffusion\">badhandv4</a></p><p><strong>Recommended extensions:</strong><br />1. <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/95923?modelVersionId=102438\">AutoChar</a><br />2. <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\">AfterDetailer</a></p><h3 id=\"my-regular-settings:-eo6gt088m\">My regular settings:</h3><p><strong>Clip Skip 2</strong><br /><strong>Necessary negative prompt: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\">easynegative </a>or <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/gsdf/Counterfeit-V3.0/blob/main/embedding/EasyNegativeV2.safetensors\">easynegativev2</a><br /><strong>VAE: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/blob/main/vae/kl-f8-anime2.ckpt\"><strong>kl-f8-anime2</strong></a><br /><strong>Sampler: </strong><em>any</em><br /><strong>ENSD: </strong><em>31337</em><br /><strong>Hires.fix: </strong><em>x1.5 and higher</em><br /><strong>Upscaler:</strong><br /><strong>Option 1: 8x_NMKD-Superscale_150000_G </strong>for realism<strong> </strong>or<strong> R-ESRGAN 4x+ Anime6B </strong>for illustrations<strong> </strong><em>(Denoising strenght 0.3-0.5)</em><br /><strong>Option 2: </strong><em>Latent (any) or Lanczos (Denoising strength 0.5-0.6)</em><br /><strong><span style=\"color:rgb(250, 82, 82)\">Never use Face Restoration!</span></strong><br /><strong>If you want better faces just use </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/alexv0iceh/AutoChar\"><strong>AutoChar</strong></a> or<strong> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\"><strong>AfterDetailer.</strong></a></p><p><span style=\"color:rgb(250, 176, 5)\">In 0.9X version you may use tags like </span><code>3d, realistic</code><span style=\"color:rgb(250, 176, 5)\"> in positive or negative prompt to increase/decrease realistic shading. (Check sample images for examples)</span></p><p>But you may feel free to experiment.</p><p>Please note that <strong>this model is horny sometimes</strong>, so I strongly recommend to tag some clothes (pants or something) and using these tags in a negative prompt <strong>to avoid NSFW</strong>: <code>nsfw, naked, nude</code></p><p><strong>Useful tags (not necessary, just minor tweaks): </strong><code>volumetric light, realistic, dark atmosphere, volumetric light, caustics, absurdres, eye focus, contrast, dark scene, bright scene</code></p><p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/fe971a32-68bb-4ba1-49f0-732d3d99f300/width=525/fe971a32-68bb-4ba1-49f0-732d3d99f300.jpeg\" /></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898577+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "5477",
    "prompt": "Lucy (Cyberpunk Edgerunners) LoRA\n<h2>Lucy (Cyberpunk Edgerunners) LoRA</h2><p><strong>Making models can be expensive. Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> üÖøÔ∏è or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://snipfeed.co/lykon\"><strong>buy me a coffee</strong></a><strong> ‚òï</strong></p><p>Another hard LoRA for another great character design. Both version (35 and 42) are flexible enough. I'd say that 35 is a bit better with her normal outfit, but 42 is a bit more precise with her naked (but it still needs some help with triggers like <code>(robot joints:0.5)</code> and <code>mechanical parts</code>). None of them seem to get her back pattern perfectly, as the dataset was not very consistent, but the 42 epoch version is a little bit more precise on that. Trigger is <code>lucy \\(cyberpunk\\)</code>, weight should be <strong>around 1 for the offset version (0.65 for the old ones) </strong>on AnyLoRA ckpt<strong>. </strong> <br /><br />The as a LoRA this is flexible enough to allow you to change her hairstyle, clothes, have just pieces of her outfit or all of it. But if you type <code>jacket</code> you get her jacket, if you type <code>shorts</code> you get her shorts, etc. <br /><br /><strong>How to use LoRA's in auto1111:</strong></p><ul><li><p>Update webui (use <code>git pull</code> <a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/embed/mn8fMF10XN4?start=31&amp;end=60\">like here</a> or redownload it)</p></li><li><p>Copy the file to <code>stable-diffusion-webui/models/lora</code></p></li><li><p>Select your LoRA like in <a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/watch?v=-bMeyXOZwN0\">this video</a></p></li><li><p><strong>Make sure to change the weight</strong> (by default it's <code>:1</code> which is usually too high)</p></li></ul><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898583+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "856285",
    "prompt": "Pony: People's Works v1-v6\n<h1 id=\"intro.-y75qe5fb2\"><strong><span style=\"color:rgb(250, 82, 82)\">Intro. ÁÆÄ‰ªãÔºö</span></strong></h1><p>A <strong><span style=\"color:rgb(250, 176, 5)\">style LoCon</span></strong> trained on <span style=\"color:rgb(250, 176, 5)\">pony-based model images collected from Civitai site with \"most collections\" and \"most reactions\"</span>.</p><p>ËøôÊòØ‰∏Ä‰∏™ËÆ≠ÁªÉËá™<span style=\"color:rgb(250, 176, 5)\">Civitai‰∏äÁÇπËµûÊúÄÂ§öÂíåÊî∂ËóèÊúÄÂ§öÁöÑponyÁ≥ªÊ®°ÂûãÂõæÁâá</span>ÁöÑ<strong><span style=\"color:rgb(250, 176, 5)\">ÁîªÈ£éLoCon</span></strong>„ÄÇ</p><p></p><p>This lora does not intend to simulate any specific artist style or technique. It <span style=\"color:rgb(250, 176, 5)\">MIGHT</span> reflects <span style=\"color:rgb(250, 176, 5)\">community taste</span> and the <span style=\"color:rgb(250, 176, 5)\">visual attractiveness of a picture</span> to a certain extent. Styles may change subtly depending on different prompts.</p><p>Ëøô‰∏™loraÂπ∂‰∏çÊÑè‰∫éËøòÂéüÊüê‰∏™ÁâπÂÆöÁöÑÁîªÂ∏àÁîªÈ£éÊàñËÄÖÁªòÁîªÊäÄÂ∑ß„ÄÇÂÆÉÂú®ÊüêÁßçÁ®ãÂ∫¶‰∏ä<span style=\"color:rgb(250, 176, 5)\">ÂèØËÉΩ</span>ÂèçÂ∫î‰∫Ü<span style=\"color:rgb(250, 176, 5)\">Á§æÂå∫ÂÆ°Áæé</span>Âíå<span style=\"color:rgb(250, 176, 5)\">ÂõæÁâáÁöÑËßÜËßâÂê∏ÂºïÂäõ</span>„ÄÇ ‰∏çÂêåÁöÑÊèêÁ§∫ËØç‰∏ãÂèØËÉΩ‰ºöÊúâÂæÆÂ¶ôÁöÑÁîªÈ£éÂèòÂåñ„ÄÇ</p><p></p><h1 id=\"usage-8kxup8w9f\"><strong><span style=\"color:rgb(250, 82, 82)\">Usage ‰ΩøÁî®ÊñπÊ≥ïÔºö</span></strong></h1><p>Versions before V2 do not have specific trigger words. Please use the quality tags provided with the corresponding model.</p><p>For V3 and later versions, the following tags were trained:</p><p>V2‰ª•ÂâçÁöÑÁâàÊú¨Ê≤°ÊúâÁâπÂÆöËß¶ÂèëËØç„ÄÇËØ∑‰ΩøÁî®ÂØπÂ∫îÊ®°ÂûãËá™Â∏¶ÁöÑË¥®ÈáèÊèêÁ§∫ËØç„ÄÇ</p><p>ÂØπ‰∫év3ÂèäÂêéÁª≠ÁâàÊú¨ÔºåËÆ≠ÁªÉ‰∫Ü‰ª•‰∏ãÊ†áÁ≠æÔºö</p><p></p><p>positive:</p><pre><code>masterpiece, best quality, very aesthetic</code></pre><p>negative:</p><pre><code>worst quality, low quality, displeasing</code></pre><p>‰Ω†ÂèØ‰ª•Âú®Ê≠§Âü∫Á°Ä‰∏äÁºñËæëÊèêÁ§∫ËØç„ÄÇ</p><p></p><h1 id=\"data-generation-hue452llf\"><strong><span style=\"color:rgb(250, 82, 82)\">Data Generation Êï∞ÊçÆÁâàÊú¨Ôºö</span></strong></h1><h2 id=\"v6:-je4q1aox1\"><span style=\"color:rgb(253, 126, 20)\">v6:</span></h2><p>Added over 500 new images, some of which are selected from Flux. I removed some older images that I deemed to be of lower quality.</p><p>The total number of images in data set now exceeds 3,000, with more than 20 concepts manually enhanced/edited across 6 versions of the dataset.</p><p>The model‚Äôs rank has been increased as well.</p><p>Êñ∞Ê∑ªÂä†‰∫Ü500+Âº†ÂõæÁâáÂÖ∂‰∏≠Êúâ‰∏ÄÈÉ®ÂàÜÈÄâËá™fluxÁîüÊàêÁöÑÂõæÂÉè„ÄÇÂà†Èô§‰∫Ü‰∏ÄÈÉ®ÂàÜÊàëËÆ§‰∏∫ÂìÅË¥®‰∏ç‰Ω≥ÁöÑÊóßÂõæÁâá„ÄÇ</p><p>Áé∞Âú®ÊÄªÁöÑÂõæÁâáÊï∞Ë∂ÖËøá‰∫Ü3000Ôºå6‰∏™ÁâàÊú¨ÁöÑÊï∞ÊçÆÊÄªÂÖ±ÊâãÂä®Â¢ûÂº∫/‰øÆÊ≠£‰∫Ü20Â§öÊù°Ê¶ÇÂøµ„ÄÇ</p><p>Â¢ûÂä†‰∫ÜÊ®°ÂûãÁöÑrank„ÄÇ</p><h2 id=\"v5.9:-irqtg0puz\"><span style=\"color:rgb(253, 126, 20)\">v5.9:</span></h2><p>The model's performance is not as expected, but I believe the images in the training data set are just fine. I'm planning to adjust the tags manually and see how will the results change.</p><p>Ê®°ÂûãÊïàÊûú‰∏çÂ¶ÇÈ¢ÑÊúüÔºå‰ΩÜÊòØÊàëËßâÂæóËÆ≠ÁªÉÈõÜÁöÑÂõæÁâáÊú¨Ë∫´Â∫îËØ•Ê≤°‰ªÄ‰πàÈóÆÈ¢ò„ÄÇÊâìÁÆóÂÖàÊâãÂä®‰øÆÊ≠£tagÁúãÁúãÊïàÊûú„ÄÇ</p><p>2025/1/3Êõ¥Êñ∞Ôºö</p><p>Manually updated some tags, but they seem unrelated to brightness and colors. Tentatively guessing it might be related to noise offset.</p><p>ÊâãÂä®Êõ¥Êñ∞‰∫Ü‰∏ÄÈÉ®ÂàÜÊ†áÁ≠æÔºå‰ΩÜÊòØÂÆÉ‰ª¨ÂíåÊòéÊöóËâ≤ÂΩ©Êó†ÁîöÂπ≤Á≥ª„ÄÇÊöÇÊó∂ÁåúÊµãÂèØËÉΩÂíånoise offsetÊúâÂÖ≥„ÄÇ</p><h2 id=\"v5:-qvonms90p\"><span style=\"color:rgb(253, 126, 20)\">v5:</span></h2><p>The dataset has been expanded to 2,154 images, with around 1,000 Pony images as the primary training target.</p><p>Although V-pred models can use LoRA trained on Eps-pred based models, the output quality drops significantly. This version will be trained separately on two different types of models.</p><p>Recent versions of NoobAI exhibit noticeable artifacts, but the 'jpeg artifact' tag from Danbooru doesn‚Äôt seem to work effectively. To address this issue, about 30 typical and visually noticeable images were specifically selected as negative examples.</p><p>An phenomenon has been observed: Pony v6 and NoobAI tend to generate a triangular lift at the roots of hairstyles with sidelocks. On Danbooru, this lift is sometimes tags as 'hair intakes' or 'curtained hair,' but Pony applies this structure to every character. This is a key reason why hairstyles generated by Pony often don't match the intended design during character training. A similar issue was observed with NoobAI. My guess is that this feature is prevalent in a dataset outside of Danbooru and was not correctly tagged.</p><p>The images in the dataset were filtered, and about two-thirds were correctly annotated. Currently, adding 'hair intakes' to the prompt <strong><em>might somewhat</em></strong> alleviate this issue, but I haven‚Äôt found a complete fix for it yet.</p><p>Êï∞ÊçÆÈõÜÊâ©ÂÖÖÂà∞2154Âº†Âõæ„ÄÇÂÖ∂‰∏≠‰Ωú‰∏∫‰∏ªË¶ÅËÆ≠ÁªÉÁõÆÊ†áÁöÑponyÂõæÁâáÁ∫¶1000Âº†„ÄÇ</p><p>ËôΩÁÑ∂V-predÊ®°Âûã‰πüËÉΩ‰ΩøÁî®Âü∫‰∫éEps-predÊäÄÊúØÁöÑÊ®°ÂûãËÆ≠ÁªÉÁöÑloraÔºå‰ΩÜÊòØÁîüÊàêË¥®Èáè‰ºöÂ§ßÊâìÊäòÊâ£„ÄÇËøô‰∏™ÁâàÊú¨Â∞Ü‰ºöÂàÜÂà´Âú®‰∏§‰∏™‰∏çÂêåÁ±ªÂûãÁöÑÊ®°Âûã‰∏äËÆ≠ÁªÉ„ÄÇ</p><p>noobAIËøëÊúüÁâàÊú¨ÊúâÊØîËæÉÊòéÊòæÁöÑ‰º™ÂΩ±Ôºå‰ΩÜÊòØdanbooru‰∏äÁöÑ‚Äújpeg artifact‚ÄùÂπ∂Ê≤°ÊúâËµ∑‰ΩúÁî®„ÄÇÂõ†Ê≠§‰∏ìÈó®ÈíàÂØπËøô‰∏™ÈóÆÈ¢òÈÄâÊã©‰∫ÜÁ∫¶30Âº†ËæÉ‰∏∫ÂÖ∏ÂûãÁöÑ„ÄÅËÇâÁúºÂèØËßÅÁöÑÂõæÁâá‰Ωú‰∏∫Ë¥üÈù¢Ê°à‰æã„ÄÇ</p><p>ËßÇÂØüÂà∞‰∏Ä‰∏™Áé∞Ë±°Ôºöpony v6ÂíånoobAIÂú®ÁîüÊàêÊúâ‰æßÂèëÁöÑÂèëÂûãÊó∂ÔºåÂÄæÂêë‰∫éÂú®ÂèëÊ†πÂ§ÑÁîüÊàê‰∏Ä‰∏™‰∏âËßíÂΩ¢ÁöÑÁøòËµ∑„ÄÇÂú®danbooruÈáåÔºåËøôÁßçÁøòËµ∑ÊúâÊó∂‰ºöË¢´Ê†áÊ≥®‰∏∫‚Äúhair intakes‚ÄùÂíå‚Äúcurtained hair‚ÄùÔºå‰ΩÜÊòØpony‰ºöÁªôÊØè‰∏Ä‰∏™ËßíËâ≤ÈÉΩÂ•ó‰∏äËøôÊ†∑ÁöÑÁªìÊûÑ„ÄÇËøô‰πüÊòØponyËÆ≠ÁªÉËßíËâ≤Êó∂ÔºåÂèëÂûãËÆ≠ÁªÉ‰∏çÂÉèÁöÑ‰∏Ä‰∏™ÈáçË¶ÅÂéüÂõ†„ÄÇnoob‰πüËßÇÂØüÂà∞‰∫ÜÁ±ª‰ººÁöÑÁé∞Ë±°ÔºåÊàëÁöÑÁåúÊµãÊòØdanbooru‰ª•Â§ñÁöÑÊüê‰∏™ËÆ≠ÁªÉÈõÜÂ§ßÈáèÂ≠òÂú®Ëøô‰∏™ÁâπÂæÅÔºå‰ΩÜÊ≤°ÊúâÂØπËøô‰∏™ÁâπÂæÅËøõË°åÊ≠£Á°ÆÊ†áÊ≥®„ÄÇ</p><p>ÂØπÊï∞ÊçÆÈõÜÈáåÁöÑÂõæÁâáËøõË°å‰∫ÜÁ≠õÈÄâÔºåÂÖ∂‰∏≠Á∫¶2/3ÁöÑÂõæÁâáËøõË°å‰∫ÜÊ≠£Á°ÆÁöÑÊ†áÊ≥®„ÄÇÁé∞Âú®ÔºåÂú®promptÈáåÂÜô‰∏ä‚Äúhair intakes‚Äù<strong><em>ÂèØËÉΩÂèØ‰ª•‰∏ÄÂÆöÁ®ãÂ∫¶‰∏ä</em></strong>ÂáèËΩªËøô‰∏™Áé∞Ë±°Ôºå‰ΩÜÊòØÊàëËøòÊ≤°ÊúâÊâæÂà∞Ê†πÊ≤ªËøô‰∏™ÊØõÁóÖÁöÑÂäûÊ≥ï„ÄÇ</p><p></p><h2 id=\"v4:-asbjwur3n\"><span style=\"color:rgb(253, 126, 20)\">v4:</span></h2><p>Partially optimized the dataset tags. Trained based on <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/833294?modelVersionId=1022833\">NoobAI Epsilon-pred v1</a> .</p><p>Pony-based models have a strong tendency to generate earrings, ear piercing, and other types of accessories, sometimes messing up the ear structure of characters. I reorganized the related tags, cropped and manually edited some images in the dataset with minor structural issues, and removed pics that were too difficult to fix.</p><p>ÂØπÊï∞ÊçÆÈõÜÁöÑÊ†áÊ≥®ÊñπÂºèËøõË°å‰∫ÜÈÉ®ÂàÜ‰ºòÂåñ„ÄÇÂü∫‰∫éNoobAI Epsilon-pred v1ËÆ≠ÁªÉ„ÄÇ</p><p>PonyÁ≥ªÊ®°ÂûãÊúâÂæàÂº∫ÁÉàÁöÑÁîüÊàêËÄ≥ÁéØ„ÄÅËÄ≥Èíâ‰ª•ÂÖ∂‰ªñÁ±ªÂûãÁöÑËÄ≥ÈÉ®È•∞ÂìÅÁöÑÂÄæÂêëÔºåÊúâÊó∂Ëøò‰ºöÁ†¥Âùè‰∫∫Áâ©ËÄ≥ÈÉ®ÁöÑÁªìÊûÑ„ÄÇÂØπÁõ∏ÂÖ≥ÁöÑÊ†áÊ≥®ËøõË°å‰∫ÜÊï¥ÁêÜ„ÄÇÂâ™Ë£Å„ÄÅÊâãÂ∑•‰øÆÊîπ‰∫ÜÊï∞ÊçÆÈõÜ‰∏≠‰∏ÄÈÉ®ÂàÜÁªìÊûÑÈîôËØØ‰∏ç‰∏•ÈáçÁöÑÂõæÔºåÂâîÈô§‰∫Ü‰∏Ä‰∫õÂ§™Èöæ‰øÆÊîπÁöÑÂõæÁâá„ÄÇ</p><p></p><h2 id=\"v3:-v5pauzm92\"><span style=\"color:rgb(253, 126, 20)\">v3:</span></h2><p>Dataset extended to 1429 images, including examples with positive tags and negative tags.</p><p>774 of the images are the most \"wanted\" style.</p><p>Trained on <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/795765?modelVersionId=889818\">Illustrious v0.1</a>.</p><p>Êï∞ÊçÆÈõÜÊâ©Â±ïÂà∞‰∫Ü1429Âº†ÂõæÁâáÔºåÂåÖÊã¨‰∫ÜÊ≠£Âèç‰∏§Áßç‰æãÂ≠ê„ÄÇ</p><p>ÂÖ∂‰∏≠774Âº†ÊòØËÆ≠ÁªÉÁöÑÁõÆÊ†áÈ£éÊ†º„ÄÇ</p><p>Âü∫‰∫éIllustrious v0.1ËÆ≠ÁªÉ„ÄÇ</p><p></p><h2 id=\"v2:-l3tov2gru\"><span style=\"color:rgb(253, 126, 20)\">v2:</span></h2><p>Dataset extended to 374 images. Use quality tags and aesthetic tags which comes with models to control generation quality.</p><p>ËÆ≠ÁªÉÊï∞ÊçÆÈõÜÊâ©Â±ïÂà∞‰∫Ü374Âº†„ÄÇÂ∞ùËØï‰ΩøÁî®Ê®°ÂûãËá™Â∏¶ÁöÑË¥®ÈáèÊèêÁ§∫ËØçÊù•Á®≥ÂÆöÁîüÊàêË¥®Èáè„ÄÇ</p><p></p><h2 id=\"v1:-sxhcgv4c6\"><span style=\"color:rgb(253, 126, 20)\">v1:</span></h2><p>Trained 224 images from Civitai, 393 images for regularization.</p><p>Trained 2 versions based on <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/260267?modelVersionId=403131\"><span style=\"color:rgb(34, 139, 230)\">Animagine v3.1</span></a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/257749/pony-diffusion-v6-xl\"><span style=\"color:rgb(34, 139, 230)\">Pony v6</span></a>.</p><p>ËÆ≠ÁªÉ‰∫ÜCÁ´ô‰∏ä224Âº†ÂõæÁâáÔºå393Âº†Ê≠£ÂàôÊï∞ÊçÆÈõÜ„ÄÇ</p><p>ÊúâAnimagine v3.1ÂíåPony v6‰∏§‰∏™ÁâàÊú¨„ÄÇ</p><p></p><h3 id=\"test-ver.4:-gn79wmymh\"><span style=\"color:rgb(119, 119, 120)\">test ver.4:</span></h3><p><span style=\"color:rgb(119, 119, 120)\">It is a little bit underfitted but still works. I found that those quality tags and authentic tags (best quality, masterpiece, very aesthetic, ...) Animagine v3.1 has been trained can change the art style generated by this checkpoint. Fixing it in the next test version.</span></p><p><span style=\"color:rgb(119, 119, 120)\">Êúâ‰∫õÊ¨†ÊãüÂêà‰ΩÜÊòØÁõÆÂâçÊòØÊúâÊïàÁöÑ„ÄÇÊàëÂèëÁé∞Animagine v3.1Ëá™Â∏¶ÁöÑË¥®ÈáèÊéßÂà∂ËØçÂíåÁæéÂ≠¶ÊèêÁ§∫ËØç‰ºöÊîπÂèòÁîüÊàêÂõæÁâáÁöÑÁîªÈ£éÔºåÊâÄ‰ª•Ëøô‰∏™ÂÆûÈ™åÁâàÊú¨ÈúÄË¶Å‰∏çÂ°´ÂÜôË¥®ÈáèËØç„ÄÇ‰∏ã‰∏ÄÁâà‰ºö‰øÆÂ§ç„ÄÇ</span></p><h3 id=\"-q7lx3mz73\"></h3>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898593+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "312530",
    "prompt": "CyberRealistic XL\n<p><span style=\"color:rgb(250, 176, 5)\">Like what I build here? You‚Äôll <em>love</em> the chaos behind the scenes - </span><a target=\"_new\" rel=\"ugc\" href=\"https://patreon.com/cyberdelia\"><span style=\"color:rgb(250, 176, 5)\"><u>Check my Patreon</u></span></a></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9036cf48-01d9-4eff-a953-cb83f4fe5f0e/width=525/9036cf48-01d9-4eff-a953-cb83f4fe5f0e.jpeg\" /><span style=\"color:rgb(250, 82, 82)\">Give CyberRealistic XL a try </span><a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/models/880857249260565779/CyberRealistic-XL-v6.0\"><span style=\"color:rgb(250, 82, 82)\"><u>here</u></span></a><span style=\"color:rgb(250, 82, 82)\">! Want unlimited access? Take a look at the one-time purchase for full use.</span></p><p>This is the model you reach for when you want super clean, photo-realistic results.<br />It‚Äôs sharp, powerful, and somehow just nails gorgeous images every single time.</p><hr /><p>‚öôÔ∏è <span style=\"color:rgb(21, 170, 191)\"><strong>Recommended Settings</strong></span></p><pre><code>Sampling method: DPM++ 2M SDE Karras \nVAE: is already Baked In\nSampling steps: 30+ Steps\nResolution: 832x1216 / 896x1152\nCFG: 3-5\nClip Skip: 1\nUpscale: 1.5 upscale (0.3 - 0.35 denoise)\nUpscalers: 4x_NickelbackFS_72000_G / 4x_foolhardy_Remacri / 4x_NMKD-Siax_200k</code></pre><p></p><hr /><p>üß†<span style=\"color:rgb(21, 170, 191)\"><strong> Prompting</strong></span></p><p>Example negative prompt:</p><pre><code>cartoon, illustration, anime, painting, CGI, 3D render, low quality, watermark, logo, label</code></pre><p>or use <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1531979/cyberrealistic-negative-sdxl\">CyberRealistic Negative</a></p><p></p><hr /><p>‚ú® <span style=\"color:rgb(21, 170, 191)\"><strong>Optional Adetailer</strong></span></p><pre><code>Adetailer model: face_yolov9c.pt\nIf you only want the main face being refined set 'Mask only the top k largest' to 1.</code></pre><p></p><hr /><p>üîó <span style=\"color:rgb(21, 170, 191)\"><strong>Links</strong></span><br />Backup location: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/cyberdelia/CyberRealisticXL\">HuggingFace</a><br /></p><hr /><p>‚òï<strong> </strong><span style=\"color:rgb(21, 170, 191)\"><strong>Fuel the Project</strong></span><br />If this model gave you stellar results, <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/cyberdelia\">consider buying me a coffee</a>. Or two. Or, you know‚Ä¶ a GPU.</p><p></p><hr /><p>‚ö†Ô∏è <span style=\"color:rgb(21, 170, 191)\"><strong>Heads-Up</strong></span><br />This model can make mature or sensitive content. You‚Äôre fully responsible for what you create, so use it responsibly (or if you can‚Äôt resist, at least be artistically irresponsible).</p><hr /><p>üí¨ <span style=\"color:rgb(21, 170, 191)\"><strong>Want Better Prompts?</strong></span><br />Use this custom ChatGPT to auto-generate polished prompts for <strong>CyberRealistic XL</strong>:<br />üîó [<a target=\"_blank\" rel=\"ugc\" href=\"https://chatgpt.com/g/g-6834133e3ab881918a91b3ec6b9eb01f-cyberrealistic-prompt-helper\">Try it now on ChatGPT</a>]</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898602+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "46422",
    "prompt": "Juggernaut\n<p>SURPRISE ;)</p><p>Merry Christmas, everyone. </p><p>As a little Christmas gift for you all, I've been working on a new version for the SD 1.5 version of Juggernaut in my spare time for the past few weeks.</p><p>I took a small portion of the JuggernautXL dataset and trained it on SD 1.5 (Base Juggernaut Final), while also updating the epiCRealism model in the merge. However, the RPG and Diva models that were added in the 'Aftermath' version have been removed.</p><p>Images were created with the following settings: </p><p><strong>512*768 </strong></p><p><strong>Sampler: DPM++ 2M Karras </strong></p><p><strong>Steps: 35 </strong></p><p><strong>CFG: 7 </strong></p><p><strong>HiRes Fix: </strong></p><p><strong>Sampler: 4xNMKD Siax 200k </strong></p><p><strong>Steps: 15 </strong></p><p><strong>Denoise: 0.5 </strong></p><p><strong>Upscale: 2</strong></p><p></p><p></p><p>Lastly, the recipe for the last Juggernaut (Aftermath) version on SD 1.5:</p><p>SD 1.5 Base</p><p>Training Set 1 (0.65)</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/81458\">Absolute Reality</a> (0.18)</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/25694?modelVersionId=105035\">epiCRealism V3</a> (0.2)</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/98755?modelVersionId=105639\">Humans</a> (0.15)</p><p>Skin Enhancer (0.15)</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/41809?modelVersionId=53221\">Better Portrait Lighting</a> (0.2)</p><p>Training Set 2 (0.55)</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1116?modelVersionId=124626\">RPG 5</a> (0.38)</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/113337?modelVersionId=122472\">Divas</a> (0.15)</p><p>And of course the NinjaFix made by <span data-type=\"mention\" class=\"mantine-1yiar0p\" data-id=\"mention:833907\" data-label=\"chillpixel\">@chillpixel</span></p><p>Thanks all those Creators for their hard work :)</p><p></p><p>Of Course you can run \"Juggernaut\" on <a target=\"_blank\" rel=\"ugc\" href=\"https://tensor.art/u/597789882022103034\">Tensor.Art</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898605+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "315703",
    "prompt": "[Pony] Geekpower AI Styles\n<p>Most of the sample pictures on all loras are done with controlnet/img2img so expect different results if you trying to remix with the civitai generator.</p><p>For local users this is the model of controlnet I use.<br /><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/2vXpSwA7/iroiro-lora/blob/main/test_controlnet2/CN-anytest_v4-marged.safetensors\">https://huggingface.co/2vXpSwA7/iroiro-lora/blob/main/test_controlnet2/CN-anytest_v4-marged.safetensors</a></p><p>I use it at 0.5 strength without any preprocessor.</p><p></p><p>30/09/24<br />Edited somethingweird lora page to use as a repo for AI artstyles, might need to re select it on the generator.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898608+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "477851",
    "prompt": "DucHaiten-Pony-Real\n<p><strong><span style=\"color:rgb(250, 176, 5)\">The model is trained on pony-no-score, but is aimed at a realistic style.</span></strong></p><p></p><p><strong><span style=\"color:rgb(34, 139, 230)\">I created my discord server. I'm still quite new to discord server management, free to give opinions.</span></strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/FPhQvFsqe2\">https://discord.gg/FPhQvFsqe2</a></p><p></p><p>you like my content, support me at:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/duchaiten\">https://ko-fi.com/duchaiten</a></p><p>Patreon in here:<br /><a target=\"_blank\" rel=\"ugc\" href=\"https://linktr.ee/Duc_Haiten\">https://linktr.ee/Duc_Haiten</a></p><p>If you want to use my models to create unlimited images at a small cost without having to install anything, <a target=\"_blank\" rel=\"ugc\" href=\"http://mage.space\">mage.space</a> will be a good choice, i have some models that are exclusively available on there.</p><p></p><hr /><p></p><p><strong><u><span style=\"color:rgb(130, 201, 30)\">Update on September 13, 2024:</span></u></strong></p><p><br />Version 2.0 adds several data updates, with the most important adjustment being the shift from cool to warm colors. The lighting has also been toned down to reduce glare, making it easier to see certain details in the dark. The overall image is slightly darker, creating a more somber atmosphere when needed, but it can still be bright or warm depending on the situation.</p><p></p><p><strong><u><span style=\"color:rgb(130, 201, 30)\">Update on August 4, 2024:</span></u></strong></p><p>v1.1 revised the text encoder, adjusting it so that the data should be more equal and not overlap each other.</p><p></p><p><strong><span style=\"color:rgb(130, 201, 30)\">Updated on July 5, 2024:</span></strong><br />Finally, Pony real v1 is complete, earlier than expected since Pony v6.9 is still about 3 months away from release, so further training is no longer meaningful. I will stop and decide to wait for Pony v6.9 to be released. In the meantime, I will temporarily switch to training other models. Although the training of the Pony real model has stopped, it does not mean it has been abandoned. In fact, with a very large data source and thorough training, to some extent it can be considered another Pony base model, different from the Pony base model of PurpleSmartAI. Of course, it is not perfect; no model is perfect. Therefore, everyone can combine it with various Loras while waiting for the next updates. But I can say it is still very flexible and retains the most essential aspects of Pony, while fixing a bunch of bugs from Pony base v6.</p><p>I have worked very hard to balance between a realistic style and effects, characters, poses, anime, surreal, or anything related to art in general. It is very difficult, so sometimes I had to make some compromises. It will not be as real as photos you can freely take in real life; this model aims for the realistic feeling you get in movies that use a lot of realistic effects and ultra-realistic Unreal Engine graphics. I have also clearly defined the keywords, so you will need to type detailed and accurate prompts to get clear and precise styles or effects, or what clothes, hairstyles, etc., the characters have. I have trained it in many natural languages and separated two types of captions corresponding to two ways of typing prompts into two different clips, making it more diverse in terms of styles, prompts, and keywords. It won't follow a template, be monochromatic, or single-styled. But of course, it still focuses more on 3D and realism, because that was my initial goal<br /><br />You can choose not to add tag_score to the prompt, but adding it will still make it look better.</p><p>Oh, one last thing, beautiful Asian girls are not produced on the same doll manufacturing line.</p><p></p><p><strong><span style=\"color:rgb(250, 82, 82)\">The best settings on automatic1111 are:</span></strong></p><p><strong><span style=\"color:rgb(21, 170, 191)\">- Sampling method:</span></strong> DPM++ SDE (slow but makes the image more realistic, with fewer errors, and closer to the prompt)</p><p><strong><span style=\"color:rgb(21, 170, 191)\">- Schedule type:</span></strong> SGM Uniform (produces images closer to the prompt)</p><p><strong><span style=\"color:rgb(21, 170, 191)\">- CFG Scale:</span></strong> 9 (fewer errors)</p><p><strong><span style=\"color:rgb(21, 170, 191)\">- Sampling steps:</span></strong> from 30-40 (starting from step 36 onwards, the image will have more accurate details and fewer small errors. The higher the steps, the better these small details will look. However, the higher the number of steps, the more likely color errors and contrasting color patches will appear.)</p><p></p><p><strong><span style=\"color:rgb(130, 201, 30)\">Update on June 23, 2024:</span></strong></p><p>Can someone please remind AstraliteHeart to quickly release pony v6.9, I want to use it to train pony real v1 and pony no score v5.</p><p>In this Beta 8 version, I improved the colors to be more vivid, with a bit of gold and cinematic depth. More artistic data is trained, improving the natural language part.</p><p></p><p><strong><span style=\"color:rgb(130, 201, 30)\">Update on June 15, 2024:</span></strong></p><p>Why hasn't the model become as realistic as other pony real models so far? This is entirely intentional, or you could say that I have chosen a much more challenging path: transforming it into a real pony model while still fully retaining surreal details, beautiful effects, and famous characters in the pony base. However, you can completely enhance its realism by using keywords related to realistic style and quality, as well as adding some opposite keywords in the negative prompt section. Additionally, try using natural language prompts combined with some NSFW keywords if you wish.</p><p></p><p><strong><span style=\"color:rgb(130, 201, 30)\">Update on June 8, 2024:</span></strong><br />alpha 7 focuses on making image textures more realistic, which has resulted in some non-realistic pony details being reduced, along with the addition of tag_scores which are now mandatory</p><p></p><p><strong><span style=\"color:rgb(130, 201, 30)\">Update on June 3, 2024:</span></strong></p><p>- <strong><u>Alpha 5:</u></strong> A lot of new data has been added, but I focused on fixing bugs and increasing stability first, so the model's realism has only improved slightly.</p><p>- <strong><u>Fixed Noise Spots:</u></strong> Resolved the common noise spots issue seen in pony models. This bug occurred when creating images with certain keywords or combinations of keywords that the pony model didn‚Äôt like. Yes, no more inexplicable noisy spots in the images.</p><p>- <strong><u>Reduced Dependence on </u></strong><code>tag_score</code><strong><u>:</u></strong> The influence of <code>tag_score</code> on image quality has been reduced to about 10%. Sometimes, it may even worsen the results.</p><p>- <strong><u>Still in Alpha:</u></strong> This is still an alpha version, so many issues still need to be addressed. Please let me know your feedback after trying this Alpha 5 version.</p><p></p><p><strong><span style=\"color:rgb(130, 201, 30)\">Updated May 27, 2024:</span></strong></p><p>This is Alpha 1 version, also the first training version of the model, so there are many errors, not real enough, so don't wait too much. The reason for posting the Alpha version is to attract LOL interaction</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898617+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "9486",
    "prompt": "OrangeChillMix\n<h2 id=\"heading-14\">v7.0 Fixed</h2><p><span style=\"color:rgb(193, 194, 197)\">Pruned and fixed problems.</span></p><p></p><h2 id=\"heading-30\">v7.0</h2><p>A mix of <strong>AbyssOrangeMix3</strong>, <strong>Chilloutmix-Ni </strong>and<strong> PerfectWorld</strong></p><p></p><h2 id=\"heading-31\">v5.0</h2><p>A mix of <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4451/abyssorangemix2-hardcore\"><strong>AbyssOrangeMix2 Hardcore</strong></a><strong> </strong>and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6424/chilloutmix\"><strong>Chilloutmix-Ni</strong></a></p><p></p><p><strong><u>I really love this models!! Thanks!</u></strong></p><p></p><p>This mix can make perfect smooth deatiled face/skin, realistic light and scenes, even more detailed fabric materials. Also can make picture more anime style, the background is more like painting.</p><p></p><p>This merge is still on testing, Single use this merge will cause face/eyes problems, I'll try to fix this in next version, and <u>i recommend to use 2d/3d </u><strong><u>LoRA</u></strong><u> with </u><strong><u>Hires.fix</u></strong><u> to make face better</u>. I'll slowly upload my generated picture on this site.</p><p></p><p><u>Sample images used some</u><strong><u> LoRA</u></strong><u> and </u><strong><u>Hires.fix</u></strong><u>. if you use my prompt the result may be different.</u></p><p></p><p>Sample images use:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6779/arknights-texas-the-omertosa\"><strong>Arknights-Texas the Omertosa</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7448/korean-doll-likeness\"><strong>Korean Doll Likeness</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9332/hutaov1\"><strong>hutao.v1</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8484/yae-miko-or-realistic-genshin\"><strong>Yae Miko | Realistic Genshin</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8171/hms-cheshire-azur-lane\"><strong>HMS Cheshire (Azur Lane)</strong></a></p><p>And <strong>my own LoRA mix</strong></p><p></p><p><strong><u>I hope you enjoy this merge!!! Thanks!</u></strong></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898622+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "16997",
    "prompt": "Standing Full Body with Background Style LoRA (Â∏¶ËÉåÊôØÁ´ãÁªò/ËÉåÊôØ‰ªò„ÅçÁ´ã„Å°Áµµ)\n<p>Trined on tachi-e (standing full body) with background from multiple mobile games. This LoRA is suited for both portrait &amp; landscape orientation images.</p><p>Usage:</p><ul><li><p>Trigger words:</p><ul><li><p><code>white background, full body</code>: tachi-e with background (separately described), try using <code>(white background:1.5)</code> if it's not working; the higher the strength of <code>white background</code>, the larger the white area</p></li><li><p><code>simple background, full body</code>: tachi-e w/o background (no describe, portrait orientation)</p></li><li><p><code>white background, full body, border, outside border</code>: tachi-e w/ background and border cut-out</p></li><li><p><code>white background, no human</code>: scenery tachi-e w/o characters</p></li></ul></li><li><p>Elements:</p><ul><li><p>Clothes: <a target=\"_blank\" rel=\"ugc\" href=\"https://danbooru.donmai.us/wiki_pages/tag_group%3Aattire\">https://danbooru.donmai.us/wiki_pages/tag_group%3Aattire</a> (I'd emphasize for defeated tachi-e, use <code>torn clothes, torn legwear, torn shirt, torn dress</code>, also try adding <code>nsfw</code> and you'll see what happens)</p></li><li><p>Basic elements: <code>fire/flame/water/ice/snow/lightning/electricity/clouds/wind/fog</code> ... etc.</p></li><li><p>Color: <code>{color} theme</code>, use <code>{color} background, white background</code> and you'll get a two-tone background, also you can use <code>colorful</code></p></li><li><p>Plants: <code>tree/flower/floral background/meadow</code> ... etc.</p></li><li><p>Animals: <code>cat/dog/rabbit</code> ... etc. and you can add monsters like <code>ghost/zombie/dragon</code> .. etc. See: <a target=\"_blank\" rel=\"ugc\" href=\"https://danbooru.donmai.us/wiki_pages/tag_group%3Alegendary_creatures\">https://danbooru.donmai.us/wiki_pages/tag_group%3Alegendary_creatures</a></p></li><li><p>Architecture: gothic architecture/east asian architecture/cityscape/architecture/skyscraper/bridge/door ... etc.</p></li><li><p>Theme: <code>fantasy/steampunk/cyberpunk</code> ... etc. See: <a target=\"_blank\" rel=\"ugc\" href=\"https://danbooru.donmai.us/wiki_pages/tag_group%3Atechnology\">https://danbooru.donmai.us/wiki_pages/tag_group%3Atechnology</a></p></li><li><p>Others:</p><ul><li><p>Symbols: <code>magic circle/hexagram</code> ... etc. See: <a target=\"_blank\" rel=\"ugc\" href=\"https://danbooru.donmai.us/wiki_pages/tag_group%3Asymbols\">https://danbooru.donmai.us/wiki_pages/tag_group%3Asymbols</a></p></li><li><p>Ornaments: <code>book/chair/gem</code> ... etc.</p></li><li><p>Expressions, postures &amp; gestures: <a target=\"_blank\" rel=\"ugc\" href=\"https://danbooru.donmai.us/wiki_pages/tag_group%3Aface_tags\">https://danbooru.donmai.us/wiki_pages/tag_group%3Aface_tags</a> / <a target=\"_blank\" rel=\"ugc\" href=\"https://danbooru.donmai.us/wiki_pages/tag_group%3Aposture\">https://danbooru.donmai.us/wiki_pages/tag_group%3Aposture</a> / <a target=\"_blank\" rel=\"ugc\" href=\"https://danbooru.donmai.us/wiki_pages/tag_group%3Agestures\">https://danbooru.donmai.us/wiki_pages/tag_group%3Agestures</a></p></li><li><p>Image composition: <code>dutch angle/from above/fisheye</code> ... etc. See: <a target=\"_blank\" rel=\"ugc\" href=\"https://danbooru.donmai.us/wiki_pages/tag_group%3Aimage_composition\">https://danbooru.donmai.us/wiki_pages/tag_group%3Aimage_composition</a></p></li><li><p>All other things you can imagine</p></li></ul></li></ul></li><li><p>Use with other LoRAs: characters, poses, concepts etc.</p></li></ul><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898629+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "1274",
    "prompt": "Dreamlike Diffusion 1.0\n<h2>Dreamlike Diffusion 1.0 is SD 1.5 fine tuned on high quality art, made by <a target=\"_blank\" rel=\"ugc\" href=\"http://dreamlike.art\">dreamlike.art</a></h2><p>Use the same prompts as you would for SD 1.5. Add <strong>dreamlikeart</strong> if the artstyle is too weak.</p><p>Non-square aspect ratios work better for some prompts. If you want a portrait photo, try using a 2:3 or a 9:16 aspect ratio. If you want a landscape photo, try using a 3:2 or a 16:9 aspect ratio.</p><p>Use slightly higher resolution for better results: 640x640px, 512x768px, 768x512px, etc.</p><p>  </p><h2>You can use this model online for free on <a target=\"_blank\" rel=\"ugc\" href=\"http://dreamlike.art\">dreamlike.art</a>!</h2><p>  </p><p>  </p><p><strong>License</strong></p><p>This model is licesed under a <strong>modified</strong> CreativeML OpenRAIL-M license.</p><p>- <strong>You can't host or use the model or its derivatives on websites/apps/etc., from which you earn, will earn, or plan to earn revenue or donations. If you want to, please email us at contact@dreamlike.art</strong></p><p>- <strong>You are free to host the model card and files (Without any actual inference or finetuning) on both commercial and non-commercial websites/apps/etc. Please state the full model name (Dreamlike Diffusion 1.0) and include a link to the model card (</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0)**\"><strong>https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0)</strong></a></p><p>- <strong>You are free to host the model or its derivatives on completely non-commercial websites/apps/etc (Meaning you are not getting ANY revenue or donations). Please state the full model name (Dreamlike Diffusion 1.0) and include a link to the model card (</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0)**\"><strong>https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0)</strong></a></p><p>- <strong>You are free to use the outputs of the model or the outputs of the model's derivatives for commercial purposes in teams of 10 or less</strong></p><p>- You can't use the model to deliberately produce nor share illegal or harmful outputs or content</p><p>- The authors claims no rights on the outputs you generate, you are free to use them and are accountable for their use which must not go against the provisions set in the license</p><p>- You may re-distribute the weights. If you do, please be aware you have to include the same use restrictions as the ones in the license and share a copy of the <strong>modified</strong> CreativeML OpenRAIL-M to all your users (please read the license entirely and carefully) Please read the full license here: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0/blob/main/LICENSE.md\">https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0/blob/main/LICENSE.md</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898632+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "17083",
    "prompt": "bad-picture negative embedding for ChilloutMix\n<p>March 17, 2023 edit: quick note on how to use a negative embeddings.  You download the file and put it into your embeddings folder.  Since I use A1111 Webui, that is stable-diffusion-webui/embeddings.  If you use a different program you will have to check with its documentation on where to put embeddings.  </p><p>After you have put the file in the appropriate folder, you then use the embedding by entering its name into the \"negative prompt\" box instead of the normal prompt.  The name, by default, will be either bad-picture-chill-75v, bad-picture-chill-32v, or bad-picture-chill-1v, depending on which one you downloaded.  If you rename the file, that will change the activation word to whatever you renamed the file.  So if you renamed \"bad-picture-chill-75v.pt\" to \"pizza-is-great.pt\" the activation phrase changes to \"pizza-is-great\"</p><p>End of edit.</p><p></p><p></p><p>This is a \"bad prompt\" style embedding- it is trained to be used in the negative prompt. It is made specifically for ChilloutMix (version chilloutmix_NiPrunedFp32Fix.safetensors [fc2511737a]), so it may or may not work well on a non-chilloutmix model. The prompts used for the pictures were mostly taken from the comment section on the ChilloutMix page.</p><p></p><p>It comes in 1 vector, 32 vector, and 75 vector versions- the higher you go, the more detail you will be able to squeeze out, but the closer you will get to deep-frying your image. Check out the comparison images that I uploaded as part of the 75 vector version- you'll probably have to right-click and \"open image in new tab\" to properly zoom in.</p><p></p><p>The 'Training Images\" download for each version is a .zip that has all the saved .pt versions that were generated during the training. Look there if you want a version that has more or less steps. If you want the <em>actual</em> training images, click on the \"Actual Training Images\" version which should be below the 1V version of the embedding.</p><p></p><p>Preview images: all preview images were generated at 512x512 with highres enabled @ a factor of 2 and 0.75 denoising, resulting in a final image of 1024x1024. Model: chilloutmix_NiPrunedFp32Fix.safetensors [fc2511737a]</p><p></p><p>Sometimes the original prompt or original negative prompt will include a LORA or embedding- here are links to them. <strong>Note:</strong> these are not used in the single image previews, only the original prompts that I borrowed and put into the stacked comparison images.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/AnonPerson/ChilloutMix/blob/main/Japanese-doll-likeness.safetensors\">Japanese Dolllikeness lora (robot lady image)</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\">easynegative embed (armored lady) (impossibly tight black bodysuit lady)</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/datasets/Nerfgun3/bad_prompt/tree/main\">bad-prompt embed (evil dogzilla looking thing)</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4629/deep-negative-v1x\">ng_deepnegative_v1_75 embed (fox ears lady)</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898636+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "107289",
    "prompt": "RealCartoon-Pixar\n<h3 id=\"you-can-also-run-this-model-on-sinkin.ai-and-mage.space:-1g1rcu86t\"><strong><em>You can also run this model<span style=\"color:rgb(219, 222, 225)\"> on </span></em></strong><a target=\"_blank\" rel=\"ugc\" href=\"http://sinkin.ai\"><strong><em><span style=\"color:rgb(219, 222, 225)\">sinkin.ai</span></em></strong></a><strong><em><span style=\"color:rgb(219, 222, 225)\"> and mage.space:</span></em></strong></h3><ol><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/\"><strong><em>https://www.mage.space/</em></strong></a><strong><em> (Really helps out if you want to support to)</em></strong></p><ol><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/5087f5d07f90564bdf393c93eb4e8598\">V5 - https://www.mage.space/play/5087f5d07f90564bdf393c93eb4e8598</a></p></li></ol></li></ol><ol><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.shakker.ai/userpage/76e974968502489794d7d7938e6dda54/publish\">https://www.shakker.ai/userpage/76e974968502489794d7d7938e6dda54/publish</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/gLv9zeq\"><strong><em>https://sinkin.ai/m/gLv9zeq</em></strong></a></p></li></ol><p></p><h3 id=\"want-to-send-some-support-(buy-a-cup-at-ko-fi)-4hh5a9v2i\">Want to send some support? <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/7whitefire7\">(Buy a cup at Ko-fi)</a></h3><p>A branch off CheckPoint from <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/94809/realcartoon3d\">RealCartoon3D</a></p><h2 id=\"the-process:-zfmvf2jb6\">The Process:</h2><p><br />This Checkpoint is a branch off from the <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/94809/realcartoon3d\">RealCartoon3D</a> checkpoint. This one's goal is to produce a more \"Pixar\" look overall. I really enjoy the 3D cartoony look and wanted to create something that would hopefully have the quality of <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/94809/realcartoon3d\">RealCartoon3D</a>, but in a PIXAR style. The process is the same as the base checkpoint (RealCartoon3D); but I look for more \"cartoon style\" merges. This (like the others) gets updates from <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/94809/realcartoon3d\">RealCartoon3D</a> as well (in fact this is what really drives this branch off as the PIXAR look is not as common a checkpoint to have variation from). As with the base model, I try not to use checkpoints that are restricted on merges.</p><p></p><h2 id=\"the-settings:-jjuawuast\">The Settings:</h2><ul><li><p><strong>Width:</strong> 512 (normally would not adjust unless I flipped the height and width)</p></li><li><p><strong>Height: </strong>768 (Have done up to 1024, but<strong> 904 works really well</strong>)</p></li><li><p><strong>Sampling Method:</strong> \"Eular A\" became pretty much the default as versions moved along, but \"DPM++ SDE Karra\" and \"DPM++ 2M Karras\" are favorites for me as well.</p></li><li><p><strong>Sampling steps:</strong> 30-50 normally (<strong>30 being my starting point, but going up to 45 a lot of the time</strong>)</p></li><li><p><strong>Hires.fix settings:</strong> Upscaler (R-ESRGAN 4x+, 4k-UltraSharp most of the time), Hires Steps (10 - <strong>20</strong>), Denoising Str (0.34 - 0.45 normally), Upscale (1.5 or 2 does well)</p></li><li><p><strong>Clip Skip:</strong> 2</p></li></ul><p>Would <em>run ADetailer to help enhance the eyes but many times in the later versions I would not run this as it was not needed.</em></p><p></p><h2 id=\"why-so-many-versions:-q8a5n4a7c\">Why So Many Versions:</h2><p>Because I wanted to share all the results that I felt reached a desired outcome. Allowed me to have fun, and I saw that many enjoyed them. Which motivated me to keep trying. Again, thank you.</p><p>__________________________________________________________________________________________________</p><h3 id=\"license-and-use-2ojpybyva\">License &amp; Use</h3><p>This model is open access and available to all, with a¬†CreativeML OpenRAIL-M¬†license further specifying rights and usage.</p><ul><li><p>1. You can't use the model to deliberately produce nor share illegal or harmful outputs or content.</p></li><li><p>2. The authors claims no rights on the outputs you generate, you are free to use them and are accountable for their use which must not go against the provisions set in the license.</p></li><li><p>3. You may re-distribute the weights. If you do, please be aware you have to include the same use restrictions as the ones in the license and share a copy of the modified CreativeML OpenRAIL-M to all your users (please read the license entirely and carefully).</p><p></p><p>Please read the full license here¬†Stable Diffusion</p></li></ul><h3 id=\"use-restrictions:-u49m04ole\">Use Restrictions:</h3><p>You agree not to use the Model or Derivatives of the Model:</p><p>- In any way that violates any applicable national, federal, state, local or international law or regulation</p><p>- For the purpose of exploiting, harming or attempting to exploit or harm minors in any way</p><p>- To generate or disseminate verifiably false information and/or content with the purpose of harming others</p><p>- To generate or disseminate personal identifiable information that can be used to harm an individual</p><p>- To defame, disparage or otherwise harass others</p><p>- For fully automated decision making that adversely impacts an individual‚Äôs legal rights or otherwise creates or modifies a binding, enforceable obligation</p><p>- For any use intended to or which has the effect of discriminating against or harming individuals or groups based on online or offline social behavior or known or predicted personal or personality characteristics</p><p>- To exploit any of the vulnerabilities of a specific group of persons based on their age, social, physical or mental characteristics, in order to materially distort the behavior of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm</p><p>- For any use intended to or which has the effect of discriminating against individuals or groups based on legally protected characteristics or categories</p><p>- To provide medical advice and medical results interpretation</p><p>- To generate or disseminate information for the purpose to be used for administration of justice, law enforcement, immigration or asylum processes, such as predicting an individual will commit fraud/crime commitment (e.g. by text profiling, drawing causal relationships between assertions made in documents, indiscriminate and arbitrarily-targeted use).</p><h3 id=\"terms-of-use:-ffq0uiwr8\">Terms of use:</h3><p>- You are solely responsible for any legal liability resulting from unethical use of this model(s)</p><p>- If you use any of these models for merging, please state what steps you took to do so and clearly indicate where modifications have been made.</p><h3 id=\"note:-6pigjie79\">Note:</h3><p>If you see any conflicts or corrections to be made, please let me know.</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898647+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "960593",
    "prompt": "T-Rex Studio V2 NEW!!- Hentai +18 - | STYLE | PONY XL | Illustrious XL | - COMMISSION - by YeiyeiArt\n<p><a target=\"_blank\" rel=\"ugc\" href=\"https://linktr.ee/Yeiyeiart\"><u><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9002f063-c1c0-42a2-84a6-a3731ef799fb/width=525/9002f063-c1c0-42a2-84a6-a3731ef799fb.jpeg\" /></u></a><em><u>New style model to create incredible works of art in the style of </u></em><strong><em><u>T-rex Hentai Studio</u></em></strong><em><u>!</u></em></p><p><strong><span style=\"color:rgb(236, 236, 236)\">Trigger Word</span></strong><span style=\"color:rgb(236, 236, 236)\">: \"</span><strong><span style=\"color:rgb(250, 176, 5)\">TRexStudio</span></strong><span style=\"color:rgb(236, 236, 236)\">\"</span></p><h1 id=\"illustrious-xl-n23qss7nh\"><strong>Illustrious XL</strong></h1><p><strong><span style=\"color:rgb(255, 255, 255)\">Trigger Word</span></strong>: \"<strong><span style=\"color:rgb(250, 176, 5)\">TRexStyle</span></strong>\"</p><p><strong><span style=\"color:rgb(255, 255, 255)\">Add for better Results</span></strong>: \"<strong><span style=\"color:rgb(250, 82, 82)\">highres, hi res, best quality, masterpiece,, (anime coloring, anime screencap), shiny skin</span></strong>\"</p><h1 id=\"pony-xasrf70oc\"><strong><span style=\"color:rgb(236, 236, 236)\">PONY</span></strong></h1><p><strong><span style=\"color:rgb(236, 236, 236)\">Recommended prompts</span></strong><span style=\"color:rgb(236, 236, 236)\">: \"</span><strong><em><span style=\"color:rgb(230, 73, 128)\">score_9, score_8_up, score_7_up, score_6_up, source_anime, anime screencap</span></em></strong><span style=\"color:rgb(236, 236, 236)\">\"</span></p><p><strong><em>Have fun and don't forget to <span style=\"color:rgb(130, 201, 30)\">follow me</span> for more models!</em></strong></p><p><em>‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è</em></p><p><strong><em>The</em></strong><em> </em><strong><em>best <span style=\"color:rgb(250, 176, 5)\">DISNEY PRINCESS </span><u>COLLECTION </u></em></strong><em>here --&gt; </em><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/YeiYeiArt/models?tag=character\"><strong><em>COLLECTION </em></strong></a><strong><em>&lt;---</em></strong></p><p><strong>All my</strong> <strong><span style=\"color:rgb(250, 176, 5)\">STYLES </span></strong>here ---&gt; <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/YeiYeiArt/models?tag=style\"><strong>STYLES </strong></a>&lt;---<br /><strong>CHECK ALL MY MODELS</strong> here ---&gt; <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/YeiYeiArt/models\"><strong>ALL MY MODELS</strong></a><strong> </strong>&lt;---</p><p>‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è</p><p><strong><em><u><span style=\"color:rgb(250, 176, 5)\">ADVICE</span>!!</u></em></strong></p><p><strong><u><span style=\"color:rgb(255, 255, 255)\">If you want any </span><span style=\"color:rgb(255, 150, 241)\">COMISSION</span><span style=\"color:rgb(255, 255, 255)\">, contact me via:</span></u></strong></p><ul><li><p><strong><u><span style=\"color:rgb(250, 176, 5)\">Email</span>: </u></strong><a target=\"_blank\" rel=\"ugc\" href=\"mailto:jeanc.romero.ib@gmail.com\"><strong><u>jeanc.romero.ib@gmail.com</u></strong></a></p></li><li><p><strong><u><span style=\"color:rgb(76, 110, 245)\">Discord </span>--&gt; </u><em><u><span style=\"color:rgb(76, 110, 245)\">jeangcr</span></u></em></strong></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://yeiyeiart.gumroad.com/\">https://yeiyeiart.gumroad.com/</a></p></li></ul><p><strong><em><u>Check my comissions!</u></em></strong></p><p><strong><em><u><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f152cc85-bd4a-41fc-901c-2a04749eee32/width=525/f152cc85-bd4a-41fc-901c-2a04749eee32.jpeg\" /></u></em></strong></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898652+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "8029",
    "prompt": "Elegant hanfu ruqun style\n<p>The training set is mainly about the illustrations of Hanfu works of many artists,which style is pure,fresh,quiet and elegant.</p><p>The lora weight I recommend is 0.8 to 1.0.</p><p>ENJOY IT WWW</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898655+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "3950",
    "prompt": "Art & Eros (aEros) - A tribute to beauty\n<p>PLEASE READ DESCRIPTION</p><p>Deprecated model, consider updating to: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5935/liberty\">https://civitai.com/models/5935/liberty</a> it is also <strong><u>licenseless</u></strong></p><p><strong>Very NSFW biased model!!</strong></p><p><em>FINAL UPDATE</em> - <u>Two files added:</u></p><p>-<strong>aErosNoVAE:</strong> It is the exact same file as aEros prunned but<strong><u> without the VAE requirement</u></strong>, which also means that you <em>can now train embeddings</em> succesfully with aEros. (VAE would still be <em>recommended</em> for normal use).</p><p>-<strong>aErosNoVAE-inpainting:</strong> An <u>inpainting focused</u> version fo the model mixing it with SD 1.5 inpainting model.</p><p></p><p>UPDATE: This model has experimented a <u>restrictive change of license </u><strong>ONLY </strong>because it inherited it from some of it's building models.</p><p>Until further notice, I am not developing it anymore.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0/blob/main/LICENSE.md\">https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0/blob/main/LICENSE.md</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0\">https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0</a></p><p></p><p>Check any info or questions at our private Discord here: <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/z88HpDwbGq\">https://discord.gg/z88HpDwbGq</a></p><p></p><p><strong>it needs vae-ft-mse-840000-ema-pruned (or another one if you want to get experimental) or it will output broken images.</strong></p><p>Art&amp;Eros is out!!! This is my second model. It is similar to REA (my previous model) in it's concept, and many of it's building materials are the same, so most that worked for REA works for aEros, but it is not an evolution of it. It has been rebuild from the ground to be 'better, faster, stronger'.</p><p>My thanks to everybody who made it possible, because I if there's anything good on it is because the source material was great too. In no particular order to <em>Hassan</em>, <em>AloeVera</em>, the <em>CivitAI Team</em>, <em>Izuek</em>, <em>Someone88</em>, <em>wavymulder</em>, <em>UnstableDiffusion Team, justmaier, moist, sviasem, kavellion</em> and any other creator I might not have been able to cite.</p><p><strong>The main download is the PRUNED safetensors NoVAE version. You have the unpruned ckpt as an optional download.</strong></p><p><u>ABOUT:</u></p><p>First it may not be the best begginer checkpoint out there. I consider myself experienced at prompting so I haven't tried much basic prompts, however I doubt that a plain \"pretty naked woman, big boobs\" is going to take you very far with it. However, although I prompt a bit different than that I have tested that <strong>it understands the words from the language of PhotoReal v0.5</strong> (it is contained within the merge), so if you are having troubles getting good outputs from it you can begin from there, but in general, try to use a more natural language than an array of commas: <a target=\"_blank\" rel=\"ugc\" href=\"https://docs.google.com/document/d/1-DDIHVbsYfynTp_rsKLu4b2tSQgxtO5F6pNsNla12k0/edit\">https://docs.google.com/document/d/1-DDIHVbsYfynTp_rsKLu4b2tSQgxtO5F6pNsNla12k0/edit</a></p><p>There's also one screenshot with a very basic example prompt for you to get the idea.</p><p>According to my testing it is a very powerful model for it's purpose, but it is a project I made for myself which means that depending on what you want it may or may not lack certain areas. It has been intensively tested to <strong>generate photorealistic(ish) images of different types of girls in different poses in different places wearing different things with different artistic moods</strong>. Nothing more, nothing less. From hardcore, to to group, to drawing, are out of the scope uses that may or may not work (But have improved since REA). <strong>It's community report that it is very good at fantasy and landscapes/interiors too.</strong></p><p>List of keywords known: <em>'elden ring style', 'postapocalypse', 'knollingcase', 'cyborgdiffusion', 'analog style', 'swpunk', 'synthwave', 'dreamlikeart', 'modelshoot style'</em></p><p><u>'bf' is no longer a trigger word, nor part of the model.</u></p><p><u>HOW TO USE IT:</u></p><ul><li><p>You <strong>MUST USE vae-ft-mse-840000-ema-pruned</strong> (or experimentally other VAEs). Otherwise it breaks.</p></li><li><p>Some users report having problems using something different than Automatic1111webui. Cannot troubleshoot that myself.</p></li><li><p>This model <strong>DOES <u>NOT</u> REQUIRE TO USE TRIGGER WORDS</strong>.</p></li><li><p>Trigger words are general <strong>style or composition modifiers</strong>. They can be used alone or in combination and will give an special mood (or mix) to the image.</p></li><li><p>Trigger words have only been tested using them <strong>at the beggining</strong> of the prompt.</p></li><li><p>There is no longer a proper order to mix trigger words between them, needs experimenting for your desired outputs.</p></li><li><p>Works for a wide variety of steps from 20 to 130 tested. <strong>I use 66 Euler A + hires fix.</strong></p></li><li><p>It works on it's own without triggers at making general or NSFW images of ladies of high quality.</p></li><li><p>Resolutions tested are <em>512x512, 384x704, 512x768</em> and <em>768x768</em>.</p></li></ul><p><u>MERGED:</u></p><p>I haven't kept track of all the steps done in the merge (I used a weird methodology), but this is what's inside in different proportions:</p><ul><li><p>PhotoReal v0.5: <a target=\"_blank\" rel=\"ugc\" href=\"https://docs.google.com/document/d/1-DDIHVbsYfynTp_rsKLu4b2tSQgxtO5F6pNsNla12k0/edit\">https://docs.google.com/document/d/1-DDIHVbsYfynTp_rsKLu4b2tSQgxtO5F6pNsNla12k0/edit</a></p></li><li><p>Elden Ring Style: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5/elden-ring-style\">https://civitai.com/models/5/elden-ring-style</a></p></li><li><p>Postapocalypse: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1136/postapocalypse\">https://civitai.com/models/1136/postapocalypse</a></p></li><li><p>Analog Diffusion: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1265/analog-diffusion\">https://civitai.com/models/1265/analog-diffusion</a></p></li><li><p>SXD: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1169/sxd\">https://civitai.com/models/1169/sxd</a></p></li><li><p>Knollingcase: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1092/knollingcase\">https://civitai.com/models/1092/knollingcase</a></p></li><li><p>Hassan's 1.4 and CandyBerry: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1173/hassanblend-all-versions\">https://civitai.com/models/1173/hassanblend-all-versions</a></p></li><li><p>PurePornPlus: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1235/purepornplus-merge\">https://civitai.com/models/1235/purepornplus-merge</a></p></li><li><p>SimpMaker 3K1: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1258/aloeveras-simpmaker-3k-series\">https://civitai.com/models/1258/aloeveras-simpmaker-3k-series</a></p></li><li><p>Modelshoot style: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2147/modelshoot-style\">https://civitai.com/models/2147/modelshoot-style</a></p></li><li><p>SynthPunk Search: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2856/synthpunk-search\">https://civitai.com/models/2856/synthpunk-search</a></p></li><li><p>MoistMix: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3450/moistmix\">https://civitai.com/models/3450/moistmix</a></p></li><li><p>Dreamlike Diffusion: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1274/dreamlike-diffusion-10\">https://civitai.com/models/1274/dreamlike-diffusion-10</a></p></li><li><p>Cyborg Diffusion: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1365/cyborg-diffusion\">https://civitai.com/models/1365/cyborg-diffusion</a></p></li><li><p>It also works GREAT as an extra style modifier with this hypernetwork for extra artistic outputs: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1141/mjv4-hypernetwork\">https://civitai.com/models/1141/mjv4-hypernetwork</a></p></li><li><p>Honorable mention tu Uber, whose model is not part of the merge, but helped me imrprove general hardcore capacity of aEros: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2661/uber-realistic-porn-merge-urpm\">https://civitai.com/models/2661/uber-realistic-porn-merge-urpm</a></p></li></ul><p><u>TROUBLESHOOT:</u></p><ul><li><p>Images are a chaotic trip of LSD colors: <em>You are not using the VAE.</em></p></li><li><p>I promiss that I have the VAE!!!: <em>If you swear over the grave of Chanquete, then another user of Discord found the solution, but please, BE SURE THAT YOU HAVE THE VAE WORKING FOR OTHER MODELS:</em></p><p><strong>xtrebel - </strong><em>\"In case anyone else is still having trouble with LSD colors, despite having the correct VAE loaded like me... I discovered this checkbox in settings has to be off/unchecked for it to properly load the VAE:</em><br /><em>[ ] ignore selected VAE for stable diffusion checkpoints that have their own .</em><a target=\"_blank\" rel=\"ugc\" href=\"http://vae.pt\"><em>vae.pt</em></a><em> next to them</em>\"</p></li><li><p>Images seem like real images but are a mess of body horror and whatnot: <em>You need to keep working in your prompt. This is <u>NOT</u> an easy to use model (not rocket science either).</em></p></li></ul><p><u>FUTURE:</u></p><p>This project is considered finished. From now on it is going to become my base model. I may start to train it as the big kids do. But I am more likely gonna try to update it with the updates some of the building materials have experimented. Be it aEros v2 or a totally new thing... Who knows? The sky is the limit!!! Stay tuned on:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://linktr.ee/ainecaptain\">https://linktr.ee/ainecaptain</a></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898663+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "128607",
    "prompt": "NightVisionXL\n<p>Like the work I do and want to say thanks? <a target=\"_blank\" rel=\"ugc\" href=\"https://www.buymeacoffee.com/socalguitarist\">Buy me a coffee</a> or <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/user?u=33487230\">Support me on Patreon for exclusive early access to my models and more!</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/SKrfwWNa9u\"><u>Join us on SCG-Playground where we have fun contests, discuss model and prompt creation, AI news and share our art to our hearts content in THE FLOOD! </u>üíñüíñüíñ</a></p><hr /><p><strong>NightVisionXL</strong> started as a lightly trained, photography focused SDXL model that specialized in photographic output. Over the past few months, NightVision has received dozens of trainings and tunings chasing the dragon that is pleasing aesthetic output.  With the release of version 8.X, I feel like I'm much closer to my goal of effortless beautiful output that is aesthetically pleasing without requiring confusing negatives or comma separated nonsense.  </p><p></p><p><strong>NightVisionXL</strong> speaks natural language. Prompt it like you would describe a scene to a human being, and you'll be surprised by how well it can understand and comprehend your prompts.  </p><p></p><p>I'm trying something new with V8 of NightVision, and I hope the results show in the output. I continue to scrape beautiful imagery that I think will train well, and this particular update is no exception with hundreds of beautiful license free AI images that I've sourced from MJ, Dalle3, Civit, Playground and my own outputs.  On top of that, I'm also utilizing  HF datasets for license free photography and the LAION-POP dataset, filtered to remove low quality images prior to training. Captioning is done using my own Spicy Burrito captioning tool (available to my Patreon subscribers on discord!) that  creates incredibly verbose and effective captions that are essential for good coherent output.</p><p></p><p>On a final note, I've had multiple requests to \"turbo-ize\" this model. I have no plans to mix turbo into NightVision, as the licensing on NightVision is nice and open right now with the SDXL licensing, and I'd like to keep it that way. NightVision isn't fast, but I promise you the longer gen times are worth the wait!</p><hr /><p></p><p></p><p>This is<strong> NightVision XL</strong>, a lightly trained base SDXL model that is then further refined with community LORAs to get it to where it is now. <strong>NightVision XL </strong>has been refined and biased to produce touched-up photorealistic portrait output that is ready-stylized for Social media posting! <strong>NightVision XL </strong>has nice coherency and is avoiding some of the weird body issues and biases that are starting to plague some of the other photorealistic models. Further, <strong>NightVision XL </strong>produces rich deep blacks and great evening/night time scenes. It can also produce ridiculously bright output as well!</p><p></p><p><strong>NightVision XL</strong> is capable of both SFW and NSFW output. As with all of my other models, tools and embeddings, <strong>NightVision XL</strong> is easy to use, preferring simple prompts and letting the model do the heavy lifting for scene building.</p><p></p><p><strong>NOTE - This version includes a baked VAE, no need to download or use the \"suggested\" external VAE.</strong></p><p></p><p><strong><u>WARNING - DO NOT USE SDXL REFINER WITH NIGHTVISION XL</u></strong></p><p>The SDXL refiner is incompatible and you will have reduced quality output if you try to use the base model refiner with <strong>NightVision XL</strong>.</p><p></p><p>Follow me here by clicking the heart ‚ù§Ô∏è and liking the model üëç, and you will be notified of any future versions I release. I also need your help with feedback, please please please post your images and your honest feedback below, I will use your feedback and your output to help guide future revisions!</p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.instagram.com/socalguitarist_/\">Follow me on IG!</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.threads.net/@socalguitarist_\">Follow me on Threads!</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/SKrfwWNa9u\">Chat with me on Discord</a></p><p></p><p>Patreon coming soon!</p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898674+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "144249",
    "prompt": "AniMerge\n<h2 id=\"!!!-uploadingsharing-my-models-outside-civitai-is-stricly-prohibited*-!!!-92pzxw6lw\"><strong><span style=\"color:rgb(250, 82, 82)\">!!! UPLOADING/SHARING MY MODELS OUTSIDE CIVITAI IS STRICLY PROHIBITED*</span></strong> <strong><span style=\"color:rgb(250, 82, 82)\">!!!</span></strong></h2><hr /><p>Check my <strong><u><span style=\"color:rgb(250, 82, 82)\">EXCLUSIVE</span></u></strong> models on <a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/u/aOLZe8jJNONrQadNcgm354ugzPD3\">Mage.Space</a>: <a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/05d04289a2142f35a9cd6d486a9c50d7\"><strong>AniMage PXL</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/8c08b7556d0342d397b60d10d8dc446e\"><strong>AniReal PXL</strong></a><strong><span style=\"color:rgb(34, 139, 230)\"> </span><span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span><span style=\"color:rgb(34, 139, 230)\"> </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/319e16adef75450cbadc4105c5c0babf\"><strong><span style=\"color:rgb(34, 139, 230)\">Lucid Dream</span></strong></a><strong><span style=\"color:rgb(34, 139, 230)\"> </span><span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span><span style=\"color:rgb(34, 139, 230)\"> </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/04f8ba407b28bcd490642337c78c085a\"><strong>AniMage<span style=\"color:rgb(34, 139, 230)\"> </span>SD1.5 </strong></a><strong><span style=\"color:rgb(250, 82, 82)\">‚Ä¢ </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/2f1eb43493644bdcbba5d837f2e7d83b\"><strong>Realistic Portrait</strong></a><br /><strong>SDXL - Pony</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/7f1e1dc38ca541a190665638f5eac0a5\"><strong>AniVerse PXL</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/c52ad2e5dc64445989432a3babda7455\"><strong>AniMerge PXL</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/5f0620e7941346e5ba609b1d6818b905\"><strong>AniToon PXL</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢ </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/ffa9c347274e487a82c39940e4e4c1ce\"><strong>AniMics PXL</strong></a><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/7084c020ad695014147d24cbc1d0b0ce\"><strong> </strong></a><strong><span style=\"color:rgb(250, 82, 82)\">‚Ä¢ </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/a3cb9984f6a63fa3d9579508e8045527\"><strong>AniVerse XL</strong></a><br /><strong>SD1.5</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/20a658c9b57e5916dc352793ccaa50db\"><strong>AniVerse</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/c2b74fd272d4b8ff87a3af9344424409\"><strong>AniThing</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/8d75a4725b8b45e5bc9c42a3dd6b0041\"><strong>AniMerge</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/2e7ecf8dc586a31d04411007af7c910c\"><strong>AniMesh</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/704df2ffe3ec24b1ff581d5048d562c9\"><strong>AniToon</strong></a><strong> <span style=\"color:rgb(250, 82, 82)\">‚Ä¢</span> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/play/1400dae0ecf2a5e3fcbec059de4a8e1f\"><strong>AniMics</strong></a></p><hr /><p>Also in Collaboration with <a target=\"_blank\" rel=\"ugc\" href=\"https://www.shakker.ai/userpage/751b8d22818d4996992184cb0dc11d32\"><strong>Shakker.ai</strong></a></p><hr /><p>This model is <u><span style=\"color:rgb(250, 82, 82)\">free for </span></u><strong><u><span style=\"color:rgb(250, 82, 82)\">personal</span> <span style=\"color:rgb(250, 82, 82)\">use</span></u><em><span style=\"color:rgb(250, 82, 82)\"> </span></em></strong>and free for <strong><span style=\"color:rgb(250, 82, 82)\">personal</span></strong><span style=\"color:rgb(250, 82, 82)\"> merging(</span>*<span style=\"color:rgb(250, 82, 82)\">)</span>.<br />For <strong><u><span style=\"color:rgb(250, 82, 82)\">commercial use</span></u></strong>, please be sure to <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/samael1976\"><strong>contact me </strong></a>(Ko-fi) or by email: <strong>samuele[dot]bonzio[at]gmail[dot]com</strong></p><hr /><h3 id=\"read-the-info-below-to-get-the-high-quality-images-(click-on-show-more)-2axevmqhj\">‚¨áRead the <span style=\"color:rgb(250, 82, 82)\">info below</span> to get the <span style=\"color:rgb(250, 82, 82)\">high quality images </span>(<em>click on show more</em>)‚¨á</h3><hr /><h2 id=\"animerge-is-experimenting-ska3e2ler\"><strong><span style=\"color:rgb(253, 126, 20)\">Animerge - is experimenting</span></strong></h2><p>This is a experimental project, while I'm training the new Aniverse model<br />So while I'm waiting, I like to experiment with some merges of Aniverse or Animesh with other models.</p><hr /><p>-&gt; If you are satisfied using my model, press on ‚ù§Ô∏è to follow the progress and consider leaving me ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê on model review, it's really important to me!</p><p>Thank you in advance üôá</p><p>And remember to publish your creations using this model! I‚Äôd really love to see what your imagination can do!</p><hr /><h2 id=\"recommended-settings:-mn0h1w418\"><strong><u><span style=\"color:rgb(250, 82, 82)\">Recommended Settings:</span></u></strong></h2><ul><li><p><strong>Excessive negative prompt can makes your creations worse, so follow my suggestions below!</strong></p></li><li><p><strong>Before applying a LoRA to produce your favorite character, try it without first. You might be surprised what this model can do!</strong></p></li></ul><hr /><h2 id=\"a1111-my-settings:-cz3wmni2c\"><strong><u><span style=\"color:rgb(250, 82, 82)\">A1111 my settings:</span></u></strong></h2><p></p><p><strong>I run <u><span style=\"color:rgb(250, 82, 82)\">my Home PC</span></u> A1111 with this setting:</strong></p><ul><li><p>set COMMANDLINE_ARGS= --xformers</p></li></ul><p></p><p><strong>if you can't install xFormers (read below) use my <u><span style=\"color:rgb(250, 82, 82)\">Google Colab Setting</span></u>:</strong></p><p></p><ul><li><p>set COMMANDLINE_ARGS= --disable-model-loading-ram-optimization --opt-sdp-no-mem-attention</p></li></ul><p></p><p><strong>My A1111 Version:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/a0af2852b67859b427b662789d0b42f592e78dec\"><strong>v1.6.0-RC-28-ga0af2852</strong></a> ‚ÄÄ‚Ä¢‚ÄÄ python: 3.10.6 ‚ÄÄ‚Ä¢‚ÄÄ torch: 2.0.1+cu118 ‚ÄÄ‚Ä¢‚ÄÄ xformers: 0.0.20 ‚ÄÄ‚Ä¢‚ÄÄ gradio: 3.41.2</p><p></p><p><strong><span style=\"color:rgb(250, 82, 82)\">If you want activate xformers optimization like </span><u><span style=\"color:rgb(250, 82, 82)\">my Home PC</span></u><span style=\"color:rgb(250, 82, 82)\"> </span>(</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://aipromptshome.com/fix-no-module-xformers-stable-diffusion-automatic-1111/\"><strong>How to install xFormers</strong></a><strong>)<span style=\"color:rgb(250, 82, 82)\">:</span></strong></p><ul><li><p>In A1111 click in \"<strong><em>Setting Tab</em></strong>\"</p></li><li><p>In the left coloumn, click in \"<strong><em>Optimization</em></strong>\"</p></li><li><p>in: \"<strong><em>Cross attention optimization</em></strong>\" select: \"<strong><em>xformers</em></strong>\"</p></li><li><p>Press in \"<strong><em>Apply Settings</em></strong>\"</p></li><li><p>Reboot your Stable Diffusion</p></li></ul><p></p><p><strong><span style=\"color:rgb(250, 82, 82)\">If you can't install xFormers use SDP-ATTENTION, like </span><u><span style=\"color:rgb(250, 82, 82)\">my Google Colab</span></u><span style=\"color:rgb(250, 82, 82)\">:</span></strong></p><ul><li><p>In A1111 click in \"<strong><em>Setting Tab</em></strong>\"</p></li><li><p>In the left coloumn, click in \"<strong><em>Optimization</em></strong>\"</p></li><li><p>in: \"<strong><em>Cross attention optimization</em></strong>\" select: \"<strong>sdp-no-mem - scaled dot product without memory efficient attention</strong>\"</p></li><li><p>Press in \"<strong><em>Apply Settings</em></strong>\"</p></li><li><p>Reboot your Stable Diffusion</p></li></ul><p></p><p><strong><span style=\"color:rgb(250, 82, 82)\">How to emulate the nvidia GPU follow this steps</span></strong>:</p><ul><li><p>In A1111 click in \"<strong><em>Setting Tab</em></strong>\"</p></li><li><p>In the left coloumn, click in \"<strong><em>Show all pages</em></strong>\"</p></li><li><p>Search \"<strong><em>Random number generator source</em></strong>\"</p></li><li><p>Select the voice: \"<strong><em>NV</em></strong>\"</p></li><li><p>Press in \"<strong><em>Apply Settings</em></strong>\"</p></li><li><p>Reboot your Stable Diffusion</p></li></ul><p></p><p><strong><span style=\"color:rgb(250, 82, 82)\">If you use my models, install the </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\"><strong><span style=\"color:rgb(34, 139, 230)\">ADetailer</span></strong></a><strong><span style=\"color:rgb(250, 82, 82)\"> extension for your A1111.</span></strong></p><p>Navigate to the \"<strong>Extensions</strong>\" tab within Stable Diffusion.</p><ul><li><p>Go to the \"<strong>Install from URL</strong>\" subsection.</p></li><li><p>Paste the following URL: <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\">https://github.com/Bing-su/adetailer</a></p></li><li><p>Click on the \"<strong>Install</strong>\" button to install the extension</p></li><li><p>Reboot your Stable Diffusion</p></li></ul><p></p><p><strong><span style=\"color:rgb(250, 82, 82)\">How to install Euler Smea Dyn and Euler Max Sampler:</span></strong></p><ul><li><p>In A1111 click in \"<strong><em>Extensions Tab</em></strong>\"</p></li><li><p>click in \"<strong><em>Install from URL</em></strong>\"</p></li><li><p>Under \"<span style=\"color:rgb(229, 231, 235)\">URL for extension's git repository</span>\" put this link: <strong>https://github.com/licyk/advanced_euler_sampler_extension</strong></p></li><li><p>Once installed click in: \"<strong><em>Installed\" </em></strong>Tab</p></li><li><p>Click in \"<strong><em>Apply and quit</em></strong>\"</p></li><li><p>Reboot your Stable Diffusion</p></li><li><p>Now at the end of the list of the sampler, you have the new sampler.</p></li></ul><p></p><p><strong><span style=\"color:rgb(250, 82, 82)\">How to use ADetailer with Euler Smea Dyn and Euler Max Sampler:</span></strong></p><ul><li><p>In A1111 click in \"<strong><em>txt2img</em></strong>\" tab</p></li><li><p>Expand and click in \"<strong>enable ADetailer</strong>\"</p></li><li><p>Scroll down and expand \"<strong>inpaint</strong>\" section</p></li><li><p>Click and turn on \"<strong>Use separate Sampler</strong>\"</p></li><li><p>Now select: \"DPM++ 2M Karras\" (or your favourite sampler)</p></li></ul><p></p><hr /><ul><li><p><strong>VAE:</strong>¬†VAE is included (but usually I still use the<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors\">¬†<strong>840000 ema pruned</strong></a>)</p></li><li><p><strong>Clip skip:</strong>¬†2</p></li><li><p><strong>Upscaler:</strong>¬†<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/116225?modelVersionId=125843\"><strong>4x-Ultrasharp</strong></a> or <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/141491?modelVersionId=156841\"><strong>4X NMKD Superscale</strong></a></p></li></ul><hr /><ul><li><p><strong>Sampling method: </strong>DPM++ 2M SDE Karras</p></li><li><p><strong>Sampling steps:</strong> 50+ (<u>minimum, it is very important not to go below this value)</u></p></li><li><p><strong>Width: </strong>576 (o 768)</p></li><li><p><strong>Height: </strong>1024</p></li><li><p><strong>CFG Scale:</strong> 6~7</p></li></ul><hr /><p><strong>MY FAVORITE PROMPT:</strong></p><ul><li><p>(masterpiece, best quality, highres:1.2), (photorealistic:1.2), (intricate and beautiful:1.2), (detailed light:1.2), (soft lighting, side lighting, reflected light), (colorful, dynamic angle), upper body shot, fashion photography, <strong><em>YOUR PROMPT</em></strong>, dynamic pose, light passing through hair, (abstract background:1.3), (official art), (perfect skin), (sharp)</p><hr /><p><strong>NEGATIVE PROMPT:</strong></p></li><li><p>(worst quality:1.8, low quality:1.8), moles, mole, tears, piercing, freckles, skindentation, cutoffs, shiny skin, lucid skin, pendant, scars on face, interlocked fingers,</p></li></ul><hr /><p><strong>YOU CAN ALSO USE THESE NEGATIVE EMBEDDINGS:</strong></p><ul><li><p><strong>1)</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808?modelVersionId=9536\"><strong>Easy Negative</strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/56519/negativehand-negative-embedding\"><strong>negative_hand-neg</strong></a>, EasyNegative, negative_hand-neg, moles, mole, piercing, tears, face skin imperfection, freckles, skindentation, cutoffs, shiny skin, scars on face, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/116230/bad-hands-5\"><strong>bad-hands-5</strong></a></p></li><li><p><strong>2)</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Xynon/models/blob/main/experimentals/TI/bad-image-v2-39000.pt\"><strong>Bad-Images-39000</strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/56519/negativehand-negative-embedding\"><strong>negative_hand-neg</strong></a>, moles, mole, piercing, tears, face skin imperfection, freckles, skindentation, cutoffs, shiny skin, scars on face, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/116230/bad-hands-5\"><strong>bad-hands-5</strong></a></p></li><li><p><strong>3)</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4629/deep-negative-v1x\"><strong>ng_deepnegative_v1_75t</strong></a>, (worst quality:1.4), (low quality:1.4), (normal quality:1.4), lowres, bad anatomy, bad hands, normal quality, ((monochrome)), ((grayscale)), ((watermark)), <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/56519/negativehand-negative-embedding\"><strong>negative_hand-neg</strong></a>, moles, mole, piercing, tears, face skin imperfection, freckles, skindentation, cutoffs, shiny skin, scars on face,<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/116230/bad-hands-5\"><strong>bad-hands-5</strong></a></p></li><li><p><strong>4)</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/71961?modelVersionId=94057\"><strong>FastNegativeV2</strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/56519/negativehand-negative-embedding\"><strong>negative_hand-neg</strong></a>, moles, mole, piercing, tears, face skin imperfection, freckles, skindentation, cutoffs, shiny skin, scars on face <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/116230/bad-hands-5\"><strong>bad-hands-5</strong></a></p></li><li><p><strong>5)</strong> For <strong>MEN images</strong>: girl, woman, female, tits, <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Xynon/models/blob/main/experimentals/TI/bad-image-v2-39000.pt\"><strong>BadImage_v2-39000</strong></a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/56519/negativehand-negative-embedding\"><strong>negative_hand-neg</strong></a>, moles, mole, piercing, tears, face skin imperfection, freckles, skindentation, cutoffs, shiny skin, bad-hands-5, scars on face, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/116230/bad-hands-5\"><strong>bad-hands 5</strong></a></p></li></ul><hr /><h3 id=\"hires.fix-setting:-pcwdv97ik\"><u><span style=\"color:rgb(250, 82, 82)\">HiRes.Fix Setting:</span></u></h3><p>I don't use Hi.Res fix because:</p><p>1) in my computer don't work</p><p>2) my models don't need it. Use txt2image, aderailer and the suggested upscaler in the resources tab.</p><p>If you still want use it, this is the setting sent me by¬†<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/MarkWar\"><strong>MarkWar</strong></a>¬†(follow him to see his creations ‚ù§Ô∏è).</p><p><strong>Hires upscale:</strong> 1.5</p><p><strong>Hires steps:</strong> 20~30</p><p><strong>Hires upscaler:</strong> R-ESRGAN 4x + Anime6B,</p><p><strong>Denoising strength:</strong> 0.4</p><p><strong>Adetailer:</strong>¬†<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Bingsu/adetailer/blob/main/face_yolov8n.pt\">face_yolov8n</a></p><p><strong>How to install and use adetailer:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Bing-su/adetailer\">Click Here</a></p><hr /><h3 id=\"inpainting-setting:-80k0r52b0\"><u><span style=\"color:rgb(250, 82, 82)\">Inpainting Setting:</span></u></h3><p>When you see that I used Inpainting on my images, I only modify the face (Hires Fix on my old PC doesn't work and got stuck). This is my setting:</p><ul><li><p>Click in the tab¬†img2img,¬†than click on¬†inpaint -&gt;</p></li><li><p>Paint the face¬†(only the face, neck, ears...) and after that set:</p></li><li><p>Inpaint masked</p></li><li><p>Only masked</p></li><li><p>Only masked padding, pixels:¬†12</p></li><li><p>Sampling steps:¬†50</p></li><li><p>Set:¬†Only masked</p></li><li><p>Batch Size:¬†8<br />in the Positive Prompt write:¬†(ultra realistic, best quality, masterpiece, perfect face)</p></li><li><p>Than click on¬†<em>GENERATE</em></p></li></ul><hr /><h3 id=\"controlnet-and-prompt-guide-video-tutorial:-ku3zoe1uu\"><u><span style=\"color:rgb(250, 82, 82)\">ControlNet &amp; Prompt guide video tutorial:</span></u></h3><p>Thanx to: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/tejasbale01\"><strong>tejasbale01</strong></a><strong> - </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/@spidey-ai\"><strong>Spidey Ai Art Tutorial</strong></a><span style=\"color:rgb(241, 241, 241)\"> (follow him in youtube)</span></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/watch?v=X95IVzPa_bU\"><strong>Animesh Full V1.5 + Controlnet | Prompt Guide |</strong></a></p><hr /><p>Do you like my work?</p><p>If you want you can help me to buy a new PC for Stable Diffusion!<br />‚ù§Ô∏è <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/samael1976\">You can buy me a <strong>(Espresso... I'm italian)</strong> coffee or a beer </a>‚ù§Ô∏è</p><p>This is the list of hardware if you are courius:¬†<a target=\"_blank\" rel=\"ugc\" href=\"https://www.amazon.it/hz/wishlist/ls/2FYKOW9MQY6A?ref_=list_d_wl_lfu_nav_10\">Amazon Wishlist</a></p><hr /><p>I must¬†thank you¬†<a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/@OlivioSarikas\"><strong>Olivio Sarikas</strong>¬†</a>and¬†<a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/@SECourses\"><strong>SECourses</strong></a>¬†for their video tutorials! (I'd really love to see a your video using my model¬†‚ù§Ô∏è¬†)</p><hr /><h3 id=\"you-are-solely-responsible-for-any-legal-liability-resulting-from-unethical-use-of-this-model-6ghsce1o6\"><strong>You are solely responsible for any legal liability resulting from unethical use of this model</strong></h3><p></p><ul><li><p><em>(*) </em><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/MarkWar\"><strong>MarkWar</strong></a>¬†<em>is authorized by me to do anything with my models.</em></p><p></p></li><li><p><em>(**) Why did I set such stringent rules? Because I'm tired of seeing sites like Pixai (and many others) that get rich on the backs of the model creators without giving anything in return.</em></p><p></p></li><li><p><em>(***) Low Rank Adaptation models (LoRAs) and Checkpoints created by me.</em></p><p><em>As per Creative ML OpenRAIL-M license section III, derivative content(i.e. LoRA, Checkpoints, mixes and other derivative content) is free to modify license for further distribution. In that case such is provided by licensing on each single model on </em><a target=\"_blank\" rel=\"ugc\" href=\"http://Civitai.com\"><em>Civitai.com</em></a><em>. All models produced by me are prohibiting hosting, reposting, reuploading or otherwise utilisation of my models on other sites that provide generation service without a my explicit authorization.</em></p><p></p></li><li><p><em>(****)According to Italian law (I'm Italian):</em></p><p><em>The law on copyright (</em><a target=\"_blank\" rel=\"ugc\" href=\"http://www.normattiva.it/uri-res/N2Ls?urn:nir:stato:legge:1941-04-22;633!vig=\"><em>law 22 April 1941, n. 633</em></a><em>, and subsequent amendments, most recently that provided for by the legislative decree of </em><a target=\"_blank\" rel=\"ugc\" href=\"http://www.normattiva.it/uri-res/N2Ls?urn:nir:stato:decreto.legge:2017-10-16;148!vig=\"><em>16 October 2017 n.148</em></a><em>) provides for the protection of \"intellectual works of a creative nature\", which belong to literature, music, figurative arts, architecture, theater and cinema, whatever their mode or form of expression.</em></p><p><em>Subsequent changes, linked to the evolution of new information technologies, have extended the scope of protection to photographic works, computer programs, databases and industrial design creations.</em></p><p><em>Copyright is acquired automatically when a work is defined as an intellectual creation.</em></p><p><em>Also valid for the US: </em><a target=\"_blank\" rel=\"ugc\" href=\"https://ufficiobrevetti.it/copyright/copyright-usa/\"><em>https:// ufficiobrevetti.it/copyright/copyright-usa/</em></a></p><p></p><p><em>All my Stable Diffusion models in Civitai (as per my approval) are covered by copyright.</em></p></li></ul>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898715+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "12542",
    "prompt": "Takeda Hiromitsu style (illustrious/Pony/1.5) | Goofy Ai\n<p>If you like my work, drop a 5 review and hit the heart icon. it's free and keeps me motivated</p><h2 id=\"all-my-models-are-officially-hosted-and-maintained-by-me-on-tensor.art-.-use-my-exclusive-and-public-model-for-free-on-tensor.art-79age6nn8\"><span style=\"color:rgb(250, 176, 5)\">All my models are officially hosted and maintained by me on</span> <a target=\"_blank\" rel=\"ugc\" href=\"http://Tensor.art\">Tensor.art</a> . use my <span style=\"color:rgb(250, 82, 82)\">Exclusive</span> and <span style=\"color:rgb(64, 192, 87)\">public</span> model for free on <a target=\"_blank\" rel=\"ugc\" href=\"http://tensor.art\">tensor.art</a></h2><p></p><h3 id=\"get-early-access-to-my-upcoming-nsfw-lora-in-my-patreon-.-05zgwrpei\"><span style=\"color:rgb(64, 192, 87)\">Get early access to my upcoming </span><span style=\"color:rgb(253, 126, 20)\">NSFW </span><span style=\"color:rgb(64, 192, 87)\">Lora in my </span><a target=\"_blank\" rel=\"ugc\" href=\"https://patreon.com/hinokiart\"><span style=\"color:rgb(250, 82, 82)\">Patreon </span></a><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/GoofyAi\"><span style=\"color:rgb(146, 147, 149)\">.</span></a></h3><p><span style=\"color:rgb(253, 126, 20)\">Support my work by joining any one of them and get early access to all my upcoming loras and other perks such as fan requests and Discord role.</span></p><h2 id=\"join-my-discord-server-anklrug8t\">Join my <strong><u>Discord Server</u></strong></h2><ul><li><p>check the images for prompts</p></li><li><p>use lora at 0.7-1</p></li><li><p>Adetailer for faces</p></li><li><p>Img2img upscale</p></li><li><p>4x-ultra sharp</p></li><li><p>comment you idea or request</p></li></ul>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898721+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "54073",
    "prompt": "Arthemy Comics\n<h1 id=\"heading-255\">Generate pictures with <span style=\"color:rgb(18, 184, 134)\">Arthemy</span></h1><h3 id=\"heading-256\">Searching for an <strong>AI characters generator</strong>?</h3><p>Arthemy, my AI image generator now has all of my models loaded and ready to be tried on your browser - no GPU required<br />----&gt; <a target=\"_blank\" rel=\"ugc\" href=\"https://arthemy.ai\">https://arthemy.ai</a></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/308e39cf-3608-4834-9b3e-8d9b7754c16d/width=525/308e39cf-3608-4834-9b3e-8d9b7754c16d.jpeg\" /></p><p></p><h2 id=\"heading-70\">‚ú¶ Comics Arthemy - Quick Start ‚ú¶</h2><p><strong>1</strong>_____ I highly suggest to use this <strong>embeddings</strong>:</p><ul><li><p>verybadimagenegative_v1.3 <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/11772/verybadimagenegative\">https://civitai.com/models/11772/verybadimagenegativehttps://civitai.com/models/11772/verybadimagenegative</a></p></li></ul><p><strong>2</strong>_____<strong>Size</strong>: Around 640 x 768</p><p><strong>3</strong>_____<strong>Prompt</strong>: Start from the prompt present here and tune the results based on your needs:</p><ul><li><p>Quick Prompt:</p><pre><code>[How],[what/who],[where],[other]\n\nexaple:\n(ultradetailed fantasy illustration:1.3), elf witch woman with a large hat and purple dress, on a snow-covered mountain with blowing wind, complex lighting and strong sense of movement</code></pre></li><li><p>Quick Negative Prompt:</p><pre><code>verybadimagenegative_v1.3, (worst quality:1.4),(low quality:1.4),(normal quality:1.3),lowres,watermark, title, (jpeg-artifacts:1.3)</code></pre></li></ul><p><strong>4</strong>_____<strong><em>Upscale: </em></strong><em>to get crisp results like the one shown in the pictures use HiResFix and Lanczos. I suggest to use this step only on the preferred pictures, since it's quite heavy on the performance side.</em></p><p></p><p>I hope you like my merge and I can't wait to see what you all are going to create with it!</p><p>For future update, about the AI Editor I'm building with an italian team and my models you can check:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.instagram.com/arthemy_vision/\">https://www.instagram.com/arthemy_ai/</a></p><p><br /><em>____________________________________</em></p><p></p><p>Merged / subtracted / inspired by Models:</p><p>DarkArtsStyle - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/109?modelVersionId=124\">https://civitai.com/models/109?modelVersionId=124</a></p><p>DiffusionBrushEverything - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/46294?modelVersionId=50908\">https://civitai.com/models/46294?modelVersionId=50908</a></p><p>ForgottenMixtheNovelist - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/81644?modelVersionId=86640\">https://civitai.com/models/81644?modelVersionId=86640</a></p><p>Icantbelieveits - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/81644?modelVersionId=86640\">https://civitai.com/models/81644?modelVersionId=86640</a></p><p>icomix - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16164/icomix\">https://civitai.com/models/16164/icomix</a></p><p>mcbsMachinecodesComics - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/71404?modelVersionId=76148\">https://civitai.com/models/71404?modelVersionId=76148</a></p><p>OccidentalMix V2.0 - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/63920?modelVersionId=68515\">https://civitai.com/models/63920?modelVersionId=68515</a></p><p>vividwatercolors - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4998/vivid-watercolors\">https://civitai.com/models/4998/vivid-watercolors</a></p><p>westerncartoontypeA - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/62060?modelVersionId=66582\">https://civitai.com/models/62060?modelVersionId=66582</a></p><p>Babes - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2220/babes\">https://civitai.com/models/2220/babes</a></p><p>Diffusion Brush Everything - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/46294/diffusion-brush-everything-sfw-nsfw-all-purpose-checkpoint-nuclear-diffusion-anime-hybrid\">https://civitai.com/models/46294/diffusion-brush-everything-sfw-nsfw-all-purpose-checkpoint-nuclear-diffusion-anime-hybrid</a></p><p>Cute Cartoon - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/85547/cute-cartoon-illustration\">https://civitai.com/models/85547/cute-cartoon-illustration</a></p><p>Western animation diffusion - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/86546?modelVersionId=92044\">https://civitai.com/models/86546?modelVersionId=92044</a></p><p>IdentityCrisis - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/89075?modelVersionId=94798\">https://civitai.com/models/89075?modelVersionId=94798</a></p><p>Vivid Watercolors - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4998/vivid-watercolors\">https://civitai.com/models/4998/vivid-watercolors</a></p><p>Exquisite detailsÊûÅËá¥ÂçéÂΩ© - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/118495/exquisite-details\">https://civitai.com/models/118495/exquisite-details</a></p><p>SXZ Luma - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/25831/sxz-luma\">https://civitai.com/models/25831/sxz-luma</a><br />+ some of my old mix</p><p>Some of these models have been used for subtraction, but they all have been useful in order to create this model.</p><p><em><br />If you like Comics Vision, remember to check these other models and consider to </em><strong><em>support their creators</em></strong><em>!</em></p><p></p><p></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898730+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "1295569",
    "prompt": "ON-THE-FLY ÂÆûÊó∂ÁîüÊàêÔºÅWan-AI ‰∏áÁõ∏/ Wan2.1 Video Model (multi-specs) - CausVid&Comfy&Kijai - workflow included\n<h1 id=\"all-in-one-wan-for-all-zd1mdfajf\">All in<strong><span style=\"color:rgb(250, 82, 82)\"> One</span></strong>, <strong><span style=\"color:rgb(250, 82, 82)\">Wan</span></strong><span style=\"color:rgb(250, 82, 82)\"> for All</span></h1><p>We are excited to introduce our<strong> latest model</strong> to our talented community creators:</p><p><span style=\"color:rgb(34, 139, 230)\">Wan2.1-</span><strong><span style=\"color:rgb(34, 139, 230)\">VACE</span></strong><span style=\"color:rgb(34, 139, 230)\">, All-in-One Video</span><strong><span style=\"color:rgb(34, 139, 230)\"> Creation</span></strong><span style=\"color:rgb(34, 139, 230)\"> and</span><strong><span style=\"color:rgb(34, 139, 230)\"> Editing model</span></strong><span style=\"color:rgb(34, 139, 230)\">.</span></p><p><span style=\"color:rgb(34, 139, 230)\">Model size:</span> <strong>1.3B</strong>, <strong>14B<span style=\"color:rgb(34, 139, 230)\"> </span></strong><span style=\"color:rgb(34, 139, 230)\">License:</span> <strong>Apache</strong>-2.0</p><p></p><p><span style=\"color:rgb(34, 139, 230)\">If we are in </span><strong><span style=\"color:rgb(34, 139, 230)\">Wan Day</span></strong><span style=\"color:rgb(34, 139, 230)\">, what will it </span><strong><span style=\"color:rgb(34, 139, 230)\">be like</span></strong><span style=\"color:rgb(34, 139, 230)\">?</span> Â¶ÇÊûúÊàë‰ª¨Âú®<strong>‰∏áÁõ∏‰∏ñÁïå</strong>Ôºå‰ºöÊòØ‰ªÄ‰πàÊ†∑Â≠êÔºü</p><div data-youtube-video><iframe width=\"640\" height=\"480\" allowfullscreen=\"true\" autoplay=\"false\" disablekbcontrols=\"false\" enableiframeapi=\"false\" endtime=\"0\" ivloadpolicy=\"0\" loop=\"false\" modestbranding=\"false\" origin playlist src=\"https://www.youtube.com/embed/na89nyG2kvg\" start=\"0\"></iframe></div><p></p><p>Ê®°ÂûãÊîØÊåÅ‰∏§ÁßçÊñáÊú¨Âà∞ËßÜÈ¢ëÊ®°ÂûãÔºà1.3B Âíå 14BÔºâÂíå‰∏§ÁßçÂàÜËæ®ÁéáÔºà480P Âíå 720PÔºâ„ÄÇ</p><p></p><p><strong><span style=\"color:rgb(193, 194, 197)\">WAN-VACE</span></strong><span style=\"color:rgb(193, 194, 197)\"> is not a</span><strong> T2V model</strong><span style=\"color:rgb(193, 194, 197)\"> per se, but rather R(</span><strong><span style=\"color:rgb(193, 194, 197)\">reference</span></strong><span style=\"color:rgb(193, 194, 197)\">)2V, Can be understood as</span><strong> Video ControlNet</strong><span style=\"color:rgb(193, 194, 197)\"> for </span><strong><span style=\"color:rgb(193, 194, 197)\">WAN</span></strong><span style=\"color:rgb(193, 194, 197)\"> , so there is no way to provide a</span><strong> T2V workflow</strong><span style=\"color:rgb(193, 194, 197)\">. The </span><strong>CausVid accelerator</strong><span style=\"color:rgb(193, 194, 197)\"> is a distillation </span><strong><span style=\"color:rgb(193, 194, 197)\">accelerator </span></strong><span style=\"color:rgb(193, 194, 197)\">technology that can be used on</span><strong> WAN-VACE</strong><span style=\"color:rgb(193, 194, 197)\"> to provide</span><strong> 4-8 steps</strong><span style=\"color:rgb(193, 194, 197)\"> of accelerated generation.</span></p><p></p><p><strong><span style=\"color:rgb(193, 194, 197)\">WAN-VACE</span></strong><span style=\"color:rgb(193, 194, 197)\">Êú¨Ë∫´‰∏çÊòØ</span><strong><span style=\"color:rgb(193, 194, 197)\">T2V</span></strong><span style=\"color:rgb(193, 194, 197)\">Ê®°ÂûãÔºåËÄåÊòØRÔºàÂèÇËÄÉÔºâ2VÔºåÂèØ‰ª•ÁêÜËß£‰∏∫WANÁöÑËßÜÈ¢ëCNÔºåÂõ†Ê≠§Êó†Ê≥ïÊèê‰æõT2VÂ∑•‰ΩúÊµÅÁ®ã„ÄÇCausVidÂä†ÈÄüÂô®ÊòØ‰∏ÄÁßçËí∏È¶èÂä†ÈÄüÊäÄÊúØÔºåÂèØÁî®‰∫éWAN-VACEÔºåÊèê‰æõ4-8Ê≠•Âä†ÈÄüÁîüÊàê„ÄÇ</span></p><p></p><h2 id=\"introduction-xlaw9e9qi\"><strong>Introduction</strong></h2><p><strong>VACE</strong> is an all-in-one model designed for video creation and editing. It encompasses various tasks, including reference-to-video generation (<strong>R2V</strong>), video-to-video editing (<strong>V2V</strong>), and masked video-to-video editing (<strong>MV2V</strong>), allowing users to compose these tasks freely. This functionality enables users to explore diverse possibilities and streamlines their workflows effectively, offering a range of capabilities, such as Move-Anything, Swap-Anything, Reference-Anything, Expand-Anything, Animate-Anything, and more.</p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/ali-vilab/VACE/blob/main/assets/materials/teaser.jpg\"><u><img src=\"https://github.com/ali-vilab/VACE/raw/main/assets/materials/teaser.jpg\" /></u></a></p><p><strong>VACE</strong>ÊòØ‰∏ÄÊ¨æ‰∏ì‰∏∫ËßÜÈ¢ëÂàõÂª∫ÂíåÁºñËæëËÄåËÆæËÆ°ÁöÑ‰∏Ä‰ΩìÂåñÊ®°Âûã„ÄÇÂÆÉÂåÖÊã¨ÂêÑÁßç‰ªªÂä°ÔºåÂåÖÊã¨ËßÜÈ¢ëÁîüÊàêÔºàR2VÔºâ„ÄÅËßÜÈ¢ëÂà∞ËßÜÈ¢ëÁºñËæëÔºàV2VÔºâÂíåÂ±èËîΩËßÜÈ¢ëÂà∞ËßÜÈ¢ëÂâ™ËæëÔºàMV2VÔºâÔºåÂÖÅËÆ∏Áî®Êà∑Ëá™Áî±ÁªÑÂêàËøô‰∫õ‰ªªÂä°„ÄÇÊ≠§ÂäüËÉΩ‰ΩøÁî®Êà∑ËÉΩÂ§üÊé¢Á¥¢ÂêÑÁßçÂèØËÉΩÊÄßÔºåÂπ∂ÊúâÊïàÂú∞ÁÆÄÂåñ‰ªñ‰ª¨ÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºåÊèê‰æõ‰∏ÄÁ≥ªÂàóÂäüËÉΩÔºåÂ¶ÇÁßªÂä®‰ªª‰ΩïÂÜÖÂÆπ„ÄÅ‰∫§Êç¢‰ªª‰ΩïÂÜÖÂÆπ„ÄÅÂºïÁî®‰ªª‰ΩïÂÜÖÂÆπ„ÄÅÊâ©Â±ï‰ªª‰ΩïÂÜÖÂÆπ„ÄÅ‰∏∫‰ªª‰ΩïÂÜÖÂÆπËÆæÁΩÆÂä®ÁîªÁ≠â„ÄÇ</p><hr /><p></p><h2 id=\"about-causvid-wan2-1:-5uvxb0q5e\">About CausVid<strong>-Wan2-1</strong>:</h2><p>5-16 The <strong>PERFECT</strong> solution to <strong>CausVid</strong> from<strong> Kijai </strong>ÔºàBest practicesÔºâ</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/blob/main/Wan21_CausVid_14B_T2V_lora_rank32.safetensors\">Wan21_CausVid_14B_T2V_lora_rank32.safetensors ¬∑ Kijai/WanVideo_comfy</a></p><p></p><p>Through <strong>weight extraction </strong>and <strong>block </strong>separation,</p><p><strong>KJ </strong>give us a universal <strong>CausVid LoRA</strong> in <span style=\"color:oklch(0.872 0.01 258.338)\">rank32 for Any 14B WAN model,</span></p><p><strong><span style=\"color:oklch(0.872 0.01 258.338)\">EVEN </span></strong><span style=\"color:oklch(0.872 0.01 258.338)\">including FT models and I2V modelÔºÅ</span></p><p></p><p>Although this <strong>may not h</strong>ave been <strong>CausVid</strong>'s initial intention, by flexibly adjusting the LoRA parameters (<strong>0.3~0.5</strong>), we have achieved <strong>unprecedented availability </strong>on home grade graphics cardsÔºÅ</p><p></p><p>KJ-<strong>Godlike </strong>also provides a <strong>1.3B bidirectional </strong>inference version of <strong>LoRA export</strong> file</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/blob/main/Wan21_CausVid_bidirect2_T2V_1_3B_lora_rank32.safetensors\">Wan21_CausVid_bidirect2_T2V_1_3B_lora_rank32.safetensors</a></p><p></p><p><strong>same time</strong>, we also noticed that <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/xunhuang1995\">xunhuang1995</a> uploaded the <strong>Warp-4Step_cfg2</strong> autoregressive version <strong>1.3B CausVid </strong>model from: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/tianweiy/CausVid/tree/main/autoregressive_checkpoint_warp_4step_cfg2\">tianweiy/CausVid</a></p><p></p><h1 id=\"-ew9tf66t0\"><strong><span style=\"color:rgb(250, 82, 82)\">Áõ∏</span></strong><span style=\"color:rgb(250, 82, 82)\">‰∏é‰∏∫Â£πÔºåÂÖ®ÈÉ®Âú®</span><strong><span style=\"color:rgb(250, 82, 82)\">‰∏á</span></strong></h1><p></p><h2 id=\"best-adaptation-for-wan-vace-full-models-2a4ib2r2e\"><strong><span style=\"color:rgb(34, 139, 230)\">Best</span></strong><span style=\"color:rgb(34, 139, 230)\"> Adaptation for </span><strong><span style=\"color:rgb(34, 139, 230)\">WAN-VACE</span></strong><span style=\"color:rgb(34, 139, 230)\"> full Models</span></h2><p>5/15 <strong>RED</strong>CausVid<strong>-Wan2-1</strong>-14B-<strong>DMD2-FP8 </strong>Uploaded<strong> 8-15</strong> steps <strong>CFG 1</strong></p><p><span style=\"color:rgb(250, 82, 82)\">Êú¨È°µÈù¢Âè≥‰æß‰∏ãËΩΩÂàóË°®Ôºå</span><strong><span style=\"color:rgb(250, 82, 82)\">Safetensors </span></strong><span style=\"color:rgb(250, 82, 82)\">Ê†ºÂºèÔºåworkflow Âú® Trainning data ÂéãÁº©ÂåÖÂÜÖ</span></p><p>The download list <strong>on the right side</strong> of<strong> this page </strong>is in Safetensors format, and the <strong>workflow is included</strong> in the<strong> Training data</strong> compressed file. The<strong> example images</strong> and <strong>videos</strong> also include workflows (<strong>yes, </strong>you can <strong>directly throw</strong> the original <strong>video files </strong>into <strong>ComfyUI</strong> and try to <strong>capture the workflow</strong>)</p><p><span style=\"color:rgb(193, 194, 197)\">5/15 </span><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Aiwood/models\"><strong>Aiwood</strong></a><strong> WAN-ACE </strong><span style=\"color:rgb(193, 194, 197)\">Fully functional workflow</span><strong> </strong><span style=\"color:rgb(193, 194, 197)\">Uploaded</span></p><p>5/15<strong> ComfyUI </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/kijai/ComfyUI-WanVideoWrapper\">KJ-WanVideoWrapper</a> have been updated</p><p>5/14 <strong>autoregressive_</strong><a target=\"_blank\" rel=\"ugc\" href=\"http://checkpoint.pt\"><strong>checkpoint.pt</strong></a> 1.3b Uploaded , <strong>PT </strong>UNET Loader</p><p>5/14 <strong>bidirectional_</strong><a target=\"_blank\" rel=\"ugc\" href=\"http://checkpoint2.pt\"><strong>checkpoint2.pt</strong></a> 1.3b Uploaded , <strong>PT </strong>UNET Loader</p><p><strong>NEW </strong>Sampler<strong> Flowmatch_causvid</strong> in<strong> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/kijai/ComfyUI-WanVideoWrapper\"><strong>KJ-Wan</strong>VideoWrapper</a></p><p></p><p>Releases fromÔºö</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/kijai/ComfyUI-WanVideoWrapper\">kijai/ComfyUI-WanVideoWrapper</a></p><p>‚≠ê leave a star‚≠ê</p><p></p><p>[ The adaptability test results of <strong>WAN1.2 LoRAs</strong> for<strong> VACE </strong>show that <strong>about 75% </strong>of<strong> I2V</strong>/<strong>T2V</strong> LoRA weights can take effect, but the <strong>sensitivity is reduced</strong> ( try to increase the LoRA weight ,more than <strong>100%</strong> Sometimes it can be helpful ) ]</p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7c930fcb-7b87-43b4-bcfb-7402523b6616/width=525/7c930fcb-7b87-43b4-bcfb-7402523b6616.jpeg\" /></p><p>Fullview of<strong> Aiwood WAN-ACE </strong>Fully functional workflowÔºö</p><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/52c375e5-bf93-4001-a9a3-29175a347a6d/width=525/52c375e5-bf93-4001-a9a3-29175a347a6d.jpeg\" /></p><p>source: <a target=\"_blank\" rel=\"ugc\" href=\"https://www.bilibili.com/video/BV1FGE6zGEDK\">https://www.bilibili.com/video/BV1FGE6zGEDK</a> ‚≠ê leave a star‚≠ê</p><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ced96cb1-a24b-4c73-9acb-0f931219029f/width=525/ced96cb1-a24b-4c73-9acb-0f931219029f.jpeg\" /><strong>CausVid</strong> Âä†ÈÄüÂô®<span style=\"color:rgb(193, 194, 197)\">È°πÁõÆÈ°µ </span><a target=\"_blank\" rel=\"ugc\" href=\"https://causvid.github.io/\">https://causvid.github.io/</a></p><hr /><p><strong>WAN-VACE </strong>Ê®°ÂûãÁöÑÂèÇÊï∞ÂíåÈÖçÁΩÆÂ¶Ç‰∏ãÔºö</p><p></p><p><strong><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ab33441f-aed6-4d87-973f-a047be58d132/width=525/ab33441f-aed6-4d87-973f-a047be58d132.jpeg\" /></strong></p><h2 id=\"-nmo009u55\"></h2><div data-youtube-video><iframe width=\"640\" height=\"480\" allowfullscreen=\"true\" autoplay=\"false\" disablekbcontrols=\"false\" enableiframeapi=\"false\" endtime=\"0\" ivloadpolicy=\"0\" loop=\"false\" modestbranding=\"false\" origin playlist src=\"https://www.youtube.com/embed/HZxhPlSQ2Uk\" start=\"0\"></iframe></div><p></p><p></p><p>üìå Wan2.1-VACE provides solutions for various tasks, including reference-to-video generation (R2V), video-to-video editing (V2V), and masked video-to-video editing (MV2V), allowing creators to freely combine these capabilities to achieve complex tasks.</p><p>üëâ Multimodal inputs enhancing the controllability of video generation.</p><p>üëâ Unified single model for consistent solutions across tasks.</p><p>üëâ Free combination of capabilities unlocking deeper creative</p><p></p><p>üìå Wan2.1-VACE‰∏∫ÂêÑÁßç‰ªªÂä°Êèê‰æõËß£ÂÜ≥ÊñπÊ°àÔºåÂåÖÊã¨ÂèÇËÄÉËßÜÈ¢ëÁîüÊàêÔºàR2VÔºâ„ÄÅËßÜÈ¢ëÂà∞ËßÜÈ¢ëÁºñËæëÔºàV2VÔºâÂíåÂ±èËîΩËßÜÈ¢ëÂà∞ËßÜÈ¢ëÂâ™ËæëÔºàMV2VÔºâÔºåÂÖÅËÆ∏Âàõ‰ΩúËÄÖËá™Áî±ÁªÑÂêàËøô‰∫õÂäüËÉΩÊù•ÂÆûÁé∞Â§çÊùÇÁöÑ‰ªªÂä°„ÄÇ</p><p>üëâ Â§öÊ®°ÊÄÅËæìÂÖ•Â¢ûÂº∫‰∫ÜËßÜÈ¢ëÁîüÊàêÁöÑÂèØÊéßÊÄß„ÄÇ</p><p>üëâ Áªü‰∏ÄÁöÑÂçï‰∏ÄÊ®°ÂûãÔºåÂÆûÁé∞Ë∑®‰ªªÂä°ÁöÑ‰∏ÄËá¥Ëß£ÂÜ≥ÊñπÊ°à„ÄÇ</p><p>üëâ Ëá™Áî±ÁªÑÂêàÂäüËÉΩÔºåÈáäÊîæÊõ¥Ê∑±Â±ÇÊ¨°ÁöÑÂàõÈÄ†Âäõ</p><p></p><hr /><p></p><h1 id=\"wanhybrid-ai-model-crafts-smooth-high-quality-videos-in-seconds-cknj16apy\"><span style=\"color:rgb(250, 82, 82)\">WAN</span><strong><span style=\"color:rgb(250, 82, 82)\">ÂÆûÊó∂ÁîüÊàê</span></strong><span style=\"color:rgb(250, 82, 82)\">Êù•‰∫Ü</span><strong><span style=\"color:rgb(250, 82, 82)\">ÔºÅ</span>Hybrid</strong> AI model <strong>crafts smooth, high-quality </strong>videos in <strong><span style=\"color:rgb(250, 82, 82)\">seconds</span></strong></h1><p>The CausVid generative AI tool uses a diffusion model to teach an autoregressive (frame-by-frame) system to rapidly produce stable, high-resolution videos.</p><p></p><p><strong>Wan</strong>2.1based Ê∑∑ÂêàAIÊ®°ÂûãÂú®Âá†ÁßíÈíüÂÜÖÔºà<strong>9Â∏ß/Áßí</strong>ÔºâÂà∂‰ΩúÂá∫ÊµÅÁïÖ„ÄÅÈ´òË¥®ÈáèÁöÑËßÜÈ¢ë</p><p>CausVidÁîüÊàêAIÂ∑•ÂÖ∑‰ΩøÁî®Êâ©Êï£Ê®°ÂûãÊù•ÊåáÂØºËá™ÂõûÂΩíÔºàÈÄêÂ∏ßÔºâÁ≥ªÁªüÂø´ÈÄüÁîüÊàêÁ®≥ÂÆöÁöÑÈ´òÂàÜËæ®ÁéáËßÜÈ¢ë„ÄÇ</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://news.mit.edu/2025/causevid-hybrid-ai-model-crafts-smooth-high-quality-videos-in-seconds-0506\">Hybrid AI model crafts smooth, high-quality videos in seconds | MIT News | Massachusetts Institute of Technology</a></p><p></p><h1 id=\"from-slow-bidirectional-tofast-autoregressive-video-diffusion-models-mhv3hjkcp\">From<strong> <span style=\"color:rgb(121, 80, 242)\">Slow Bidirectional</span></strong><span style=\"color:rgb(121, 80, 242)\"> </span>to<strong><br /></strong>Fast <strong><span style=\"color:rgb(190, 75, 219)\">Autoregressive Video</span></strong><span style=\"color:rgb(190, 75, 219)\"> </span>Diffusion Models</h1><p>CausVid <a target=\"_blank\" rel=\"ugc\" href=\"https://causvid.github.io/\">https://causvid.github.io/</a></p><p>tianweiy (<a target=\"_blank\" rel=\"ugc\" href=\"https://tianweiy.github.io/\">Tianwei Yin</a>)</p><p><span style=\"color:rgb(250, 82, 82)\">RedCaus</span>/<strong>RED</strong><span style=\"color:rgb(193, 194, 197)\">CausVid</span><strong>-Wan2-1</strong><span style=\"color:rgb(193, 194, 197)\">-14B-</span><strong>DMD2-FP8 </strong><span style=\"color:rgb(193, 194, 197)\">Uploaded / WAN-</span><strong><span style=\"color:rgb(193, 194, 197)\">VACE</span></strong><span style=\"color:rgb(193, 194, 197)\">14B</span><strong><span style=\"color:rgb(193, 194, 197)\"> </span></strong><span style=\"color:rgb(193, 194, 197)\">ÊúÄ‰Ω≥ÈÄÇÈÖç</span></p><p>CausVid<strong>/<span style=\"color:oklch(0.872 0.01 258.338)\">autoregressive_checkpoint</span></strong><span style=\"color:oklch(0.872 0.01 258.338)\"> uploaded / Ëá™ÂõûÂΩíÊ®°ÂûãÂü∫‰∫é WAN1.3B Â∑≤Êî∂ÂΩï</span></p><p>CausVid<strong>/bidirectional_checkpoint2 </strong><span style=\"color:oklch(0.872 0.01 258.338)\">uploaded / ÂèåÂêëÊé®ÂØºÊ®°ÂûãÂü∫‰∫é WAN1.3B Â∑≤Êî∂ÂΩï</span></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/kijai/ComfyUI-WanVideoWrapper\"><span style=\"color:rgb(34, 139, 230)\">Kijai</span></a><span style=\"color:oklch(0.872 0.01 258.338)\">/</span><strong><span style=\"color:oklch(0.872 0.01 258.338)\">Wan2_1-T2V-14B_CausVid</span></strong><span style=\"color:oklch(0.872 0.01 258.338)\">_fp8_e4m3fn.safetensors / HF‰ªìÂ∫ì </span><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main\">WanVideo_comfy</a></p><p>‚≠ê leave a star‚≠ê</p><p><img src=\"https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/202504/CausVid.gif?itok=mJfuvEFw\" alt=\"Brief computer-generated animation of a character in an old deep-sea diving suit walking on a leaf\" /></p><p><span style=\"color:oklch(0.707 0.022 261.325)\">licensed by </span><span style=\"color:oklch(0.928 0.006 264.531)\">Creative Commons Attribution Non Commercial 4.0</span></p><p></p><p><span style=\"color:rgb(134, 142, 150)\">Thank you for this friend's additional comment. I was too excited last night and didn't sleep, so I stopped updating before finishingÔºö</span></p><p></p><p>We‚Äôll need to use the official Python-based inference codes</p><p></p><p>1) Clone <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/tianweiy/CausVid\">https://github.com/tianweiy/CausVid</a> and follow instructions to install requirements</p><p>2) Clone <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B\">https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B</a> into wan_models/Wan2.1-T2V-1.3B</p><p>3) Put the pt file inside checkpoint_folder/<a target=\"_blank\" rel=\"ugc\" href=\"http://model.pt\">model.pt</a></p><p>4) Run inference code, python minimal_inference/autoregressive_<a target=\"_blank\" rel=\"ugc\" href=\"http://inference.py\">inference.py</a> --config_path configs/wan_causal_dmd.yaml --checkpoint_folder XXX --output_folder XXX --prompt_file_path XXX</p><p></p><p>Reddit posts about CausVid: <a target=\"_blank\" rel=\"ugc\" href=\"https://www.reddit.com/r/StableDiffusion/comments/1khjy4o/causvid_generate_videos_in_seconds_not_minutes/\">https://www.reddit.com/r/StableDiffusion/comments/1khjy4o/causvid_generate_videos_in_seconds_not_minutes/</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.reddit.com/r/StableDiffusion/comments/1k0gxer/causvid_from_slow_bidirectional_to_fast/\">https://www.reddit.com/r/StableDiffusion/comments/1k0gxer/causvid_from_slow_bidirectional_to_fast/</a></p><p></p><p>We have tested the<strong> CausVid</strong> based on Wan1.3b version, which has<strong> incredible speed</strong>, and are currently testing the<strong> 14B version</strong> produced by<strong> lightx2v</strong>.</p><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8dbb7d7f-65a4-49fd-ac56-8ff5454ef737/width=525/8dbb7d7f-65a4-49fd-ac56-8ff5454ef737.jpeg\" /><strong>LightX2V: Light Video Generation Inference Framework</strong></p><p></p><h2 id=\"supported-model-list-9liu5vqo3\"><strong>Supported Model List</strong></h2><p>‚úÖ <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/tencent/HunyuanVideo\"><u>HunyuanVideo-T2V</u></a></p><p>‚úÖ <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/tencent/HunyuanVideo-I2V\"><u>HunyuanVideo-I2V</u></a></p><p>‚úÖ <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B\"><u>Wan2.1-T2V</u></a></p><p>‚úÖ <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P\"><u>Wan2.1-I2V</u></a></p><p>‚úÖ <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/lightx2v/Wan2.1-T2V-14B-CausVid\"><u>Wan2.1-T2V-CausVid</u></a></p><p>‚úÖ <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Skywork/SkyReels-V2-DF-14B-540P\"><u>SkyReels-V2-DF</u></a></p><h2 id=\"how-to-run-yucqyjxdt\"><strong>How to Run</strong></h2><p>Please refer to the <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/ModelTC/lightx2v/tree/main/docs\"><u>documentation</u></a> in lightx2v.</p><p>‚≠ê leave a star‚≠ê</p><hr /><p></p><h1 id=\"wan-2.1-model-zoo-xdscrek5c\"><strong>ÈÄö‰πâ</strong>ÂÆûÈ™åÂÆ§ <strong>WAN</strong> 2.1 <strong>Model Zoo</strong></h1><p><span style=\"color:rgb(130, 132, 164)\">Institute for Intelligent Computing‰∏ìÊ≥®‰∫éÂêÑÈ¢ÜÂüüÂ§ßÊ®°ÂûãÊäÄÊúØÁ†îÂèë‰∏éÂàõÊñ∞Â∫îÁî®„ÄÇÂÆûÈ™åÂÆ§Á†îÁ©∂ÊñπÂêëÊ∂µÁõñËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ„ÄÅÂ§öÊ®°ÊÄÅ„ÄÅËßÜËßâAIGC„ÄÅËØ≠Èü≥Á≠âÂ§ö‰∏™È¢ÜÂüü„ÄÇÊàë‰ª¨Âπ∂ÁßØÊûÅÊé®ËøõÁ†îÁ©∂ÊàêÊûúÁöÑ‰∫ß‰∏öÂåñËêΩÂú∞„ÄÇÂÆûÈ™åÂÆ§ÂêåÊó∂ÁßØÊûÅÂèÇ‰∏éÂºÄÊ∫êÁ§æÂå∫Âª∫ËÆæÔºåÂÖ®Êñπ‰ΩçÊã•Êä±ÂºÄÊ∫êÁ§æÂå∫ÔºåÂÖ±ÂêåÊé¢Á¥¢AIÊ®°ÂûãÁöÑÂºÄÊ∫êÂºÄÊîæ„ÄÇ</span></p><p></p><p><strong><span style=\"color:rgb(121, 80, 242)\">Developer / </span></strong><span style=\"color:rgb(121, 80, 242)\">Models </span><strong><span style=\"color:rgb(121, 80, 242)\">Name / Kijai</span></strong><span style=\"color:rgb(121, 80, 242)\">`s </span><strong><span style=\"color:rgb(121, 80, 242)\">ComfyUI</span></strong><span style=\"color:rgb(121, 80, 242)\"> Model</span></p><hr /><p><span style=\"color:rgb(250, 82, 82)\">RedCaus</span>/<strong>RED</strong><span style=\"color:rgb(193, 194, 197)\">CausVid</span><strong>-Wan2-1</strong><span style=\"color:rgb(193, 194, 197)\">-14B-</span><strong>DMD2-FP8 </strong><span style=\"color:rgb(193, 194, 197)\">Uploaded / </span><span style=\"color:rgb(34, 139, 230)\">WAN-</span><strong><span style=\"color:rgb(34, 139, 230)\">VACE</span></strong><span style=\"color:rgb(34, 139, 230)\">14B</span><strong><span style=\"color:rgb(34, 139, 230)\"> </span></strong><span style=\"color:rgb(34, 139, 230)\">ÊúÄ‰Ω≥ÈÄÇÈÖç</span></p><p>CausVid<strong>/<span style=\"color:oklch(0.872 0.01 258.338)\">autoregressive_checkpoint</span></strong><span style=\"color:oklch(0.872 0.01 258.338)\"> included / Ëá™ÂõûÂΩíÊ®°ÂûãÂü∫‰∫é WAN1.3B Â∑≤Êî∂ÂΩï</span></p><p>CausVid<strong>/bidirectional_checkpoint2 </strong><span style=\"color:oklch(0.872 0.01 258.338)\">included / ÂèåÂêëÊé®ÂØºÊ®°ÂûãÂü∫‰∫é WAN1.3B Â∑≤Êî∂ÂΩï</span></p><p><span style=\"color:rgb(134, 142, 150)\">CausVid</span><strong><span style=\"color:rgb(134, 142, 150)\">/wan_causal_ode_checkpoint_model </span></strong><span style=\"color:rgb(134, 142, 150)\">testing / Ëá™ÂõûÂΩíÂõ†ÊûúÊé®ÂØº ÊµãËØï‰∏≠</span></p><p><span style=\"color:rgb(134, 142, 150)\">CausVid</span><strong><span style=\"color:rgb(134, 142, 150)\">/wan_i2v_causal_ode_checkpoint_model </span></strong><span style=\"color:rgb(134, 142, 150)\">testing / ÊñáÁîüÂõæÊ®°Âûã ÊµãËØï‰∏≠</span></p><p><span style=\"color:rgb(77, 77, 77)\">lightx2v</span><strong><span style=\"color:rgb(77, 77, 77)\">/Wan2.1-T2V-14B-CausVid </span></strong><span style=\"color:rgb(77, 77, 77)\">unqualify / Ëá™ÂõûÂΩíÊ®°Âûã14B AiWoodÂÆûÊµã‰∏çËææÊ†á</span></p><p><span style=\"color:rgb(77, 77, 77)\">lightx2v</span><strong><span style=\"color:rgb(77, 77, 77)\">/Wan2.1-T2V-14B-CausVid quant </span></strong><span style=\"color:rgb(77, 77, 77)\">unqualify / Ëá™ÂõûÂΩíÊ®°Âûã14BÈáèÂåñÁâà ÂÆûÊµã‰∏çËææÊ†á</span></p><hr /><p>Wan Team<strong>/1.3B text-to-video</strong> included / <strong>ÊñáÁîüËßÜÈ¢ë1.3B</strong> Â∑≤Êî∂ÂΩï</p><p>Wan Team<strong>/14B text-to-video </strong>included / <strong>ÊñáÁîüËßÜÈ¢ë14B</strong> Â∑≤Êî∂ÂΩï</p><p>Wan Team<strong>/14B image-to-video 480P </strong>included / <strong>ÂõæÁîüËßÜÈ¢ë14B</strong> Â∑≤Êî∂ÂΩï</p><p>Wan Team<strong>/14B image-to-video 720P </strong>included / <strong>ÂõæÁîüËßÜÈ¢ë14B</strong> Â∑≤Êî∂ÂΩï</p><p>Wan Team<strong>/14B first-last-frame-to-video 720P </strong>included / <strong>ËßÜÈ¢ëÈ¶ñÂ∞æÂ∏ß</strong> Â∑≤Êî∂ÂΩï</p><p>Wan Team<strong>/Wan2_1_VAE </strong>included / KiJai‚Äòs WAN<strong>ËßÜÈ¢ëVAE</strong> Â∑≤Êî∂ÂΩï</p><p>ComfyORG<strong>/Wan2.1_VAE </strong>included / Comfy‚Äòs WAN<strong>ËßÜÈ¢ëVAE</strong> Â∑≤Êî∂ÂΩï</p><p>google/umt5-xxl umt5-xxl-enc<strong> safetensors </strong>included / <strong>TEÁºñÁ†ÅÂô®</strong> Â∑≤Êî∂ÂΩï</p><p><span style=\"color:rgb(193, 194, 197)\">mlf/open-clip-xlm-roberta-large-vit-huge-14 </span><strong><span style=\"color:rgb(193, 194, 197)\">safetensors</span></strong> included / <strong>CLIPÁºñÁ†ÅÂô® </strong>Â∑≤Êî∂ÂΩï</p><hr /><p>DiffSynth-Studio Team/1.3B <strong>aesthetics </strong>LoRA <a target=\"_blank\" rel=\"ugc\" href=\"https://modelscope.cn/models/DiffSynth-Studio/Wan2.1-1.3b-lora-aesthetics-v1\">ÁæéÂ≠¶Ëí∏È¶è-ÈÄö‰πâ‰∏áÁõ∏2.1-1.3B-LoRA-v1</a></p><p>DiffSynth-Studio Team/1.3B<strong> Highres-fix</strong> LoRA <a target=\"_blank\" rel=\"ugc\" href=\"https://modelscope.cn/models/DiffSynth-Studio/Wan2.1-1.3b-lora-highresfix-v1\">È´òÂàÜËæ®Áéá‰øÆÂ§ç-ÈÄö‰πâ‰∏áÁõ∏2.1-1.3B-LoRA-v1</a></p><p>DiffSynth-Studio Team/1.3B<strong> ExVideo </strong>LoRA <a target=\"_blank\" rel=\"ugc\" href=\"https://modelscope.cn/models/DiffSynth-Studio/Wan2.1-1.3b-lora-exvideo-v1\">ÈïøÂ∫¶Êâ©Â±ï-ÈÄö‰πâ‰∏áÁõ∏2.1-1.3B-LoRA-v1</a></p><p>DiffSynth-Studio Team/1.3B<strong> Speed Control</strong> adapter <a target=\"_blank\" rel=\"ugc\" href=\"https://modelscope.cn/models/DiffSynth-Studio/Wan2.1-1.3b-speedcontrol-v1\">ÈÄüÂ∫¶ÊéßÂà∂-ÈÄö‰πâ‰∏áÁõ∏2.1-1.3B-ÈÄÇÈÖçÂô®-v1</a></p><hr /><p>PAI Team/<a target=\"_blank\" rel=\"ugc\" href=\"https://modelscope.cn/models/PAI/Wan2.1-Fun-1.3B-InP\"> WAN2.1 Fun 1.3B InP ÊîØÊåÅÈ¶ñÂ∞æÂ∏ß</a> / <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main\">Kijai/WanVideo_comfy</a></p><p>PAI Team/<a target=\"_blank\" rel=\"ugc\" href=\"https://modelscope.cn/models/PAI/Wan2.1-Fun-14B-InP\"> WAN2.1 Fun 14B InP ÊîØÊåÅÈ¶ñÂ∞æÂ∏ß</a> / <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main\">Kijai/WanVideo_comfy</a></p><p>PAI Team/<a target=\"_blank\" rel=\"ugc\" href=\"https://modelscope.cn/models/PAI/Wan2.1-Fun-1.3B-Control\"> WAN2.1 Fun 1.3B Control ÊéßÂà∂Âô®</a> / <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main\">Kijai/WanVideo_comfy</a></p><p>PAI Team/<a target=\"_blank\" rel=\"ugc\" href=\"https://modelscope.cn/models/PAI/Wan2.1-Fun-14B-Control\"> WAN2.1 Fun 14B Control ÊéßÂà∂Âô®</a> / <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main\">Kijai/WanVideo_comfy</a></p><p>PAI Team/<a target=\"_blank\" rel=\"ugc\" href=\"https://modelscope.cn/models/PAI/Wan2.1-Fun-14B-Control\"> WAN2.1 Fun 14B Control ÊéßÂà∂Âô®</a> / <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main\">Kijai/WanVideo_comfy</a></p><p>PAI Team/<a target=\"_blank\" rel=\"ugc\" href=\"https://modelscope.cn/models/PAI/Wan2.1-Fun-14B-Control\"> WAN2.1-Fun-V1_1-14B-Control-Camera</a> / <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main\">Kijai/WanVideo_comfy</a></p><p>IIC Team/ <a target=\"_blank\" rel=\"ugc\" href=\"https://modelscope.cn/models/iic/VACE-Wan2.1-1.3B-Preview\">VACE-ÈÄö‰πâ‰∏áÁõ∏2.1-1.3B-Preview </a>/ <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main\">Kijai/WanVideo_comfy</a></p><hr /><p>IC (<strong> In-Context </strong>) Controler Â§öÊ®°ÊÄÅÊéßÂà∂Âô® :</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/ali-vilab\">ali-vilab</a>/ <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/ali-vilab/VACE\">VACE: All-in-One Video Creation and Editing </a>/ <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main\">Kijai/WanVideo_comfy</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Phantom-video\">Phantom-video</a>/<a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Phantom-video/Phantom\"><strong>Phantom </strong></a><strong>Subject-Consistent via Cross-Modal Alignment</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/KwaiVGI\">KwaiVGI</a>/ <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/KwaiVGI/ReCamMaster\"><strong>ReCamMaster </strong></a><strong>Camera-Controlled ÈïúÂ§¥Â§öËßíÂ∫¶</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://modelscope.cn/models/iic/VACE-Wan2.1-1.3B-Preview\"> </a>/ <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main\">Kijai/WanVideo_comfy</a></p><hr /><p>Digital <strong>Character </strong>Êï∞Â≠ó‰∫∫ via Wan2.1 :</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/ali-vilab\">ali-vilab</a>/ <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/ali-vilab/UniAnimate-DiT\"><strong>UniAnimate-DiT ÈïøÂ∫èÂàóÈ™®È™ºËßíËâ≤ËßÜÈ¢ë</strong></a><a target=\"_blank\" rel=\"ugc\" href=\"https://modelscope.cn/models/iic/VACE-Wan2.1-1.3B-Preview\"> </a>/ <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main\">Kijai/WanVideo_comfy</a></p><p>Fantasy-AMAP/ Èü≥È¢ëÈ©±Âä®<strong>Êï∞Â≠ó‰∫∫</strong> Fantasy<strong>Talking</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://modelscope.cn/models/iic/VACE-Wan2.1-1.3B-Preview\"> </a>/ <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main\">Kijai/WanVideo_comfy</a></p><p>Fantasy-AMAP/ ËßíËâ≤‰∏ÄËá¥ÊÄßË∫´‰ªΩ‰øùÁïô Fantasy<strong>ID</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://modelscope.cn/models/iic/VACE-Wan2.1-1.3B-Preview\"> </a>/ <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Fantasy-AMAP/fantasy-id\">Fantasy-AMAP/fantasy-id</a></p><hr /><p>Uncensored<strong> NSFW </strong>Ëß£ÈîÅÁâàÊú¨Ôºö</p><p><strong><span style=\"color:rgb(250, 82, 82)\">RED</span></strong><span style=\"color:rgb(250, 82, 82)\">Craft</span> AIGC / WAN2.1 720P<strong> NSFW </strong>Unlocked /<strong><span style=\"color:rgb(250, 82, 82)\"> </span></strong><span style=\"color:rgb(250, 82, 82)\">for</span><strong><span style=\"color:rgb(250, 82, 82)\">Private use„Äê</span></strong><span style=\"color:rgb(250, 82, 82)\">ÈùûÂÖ¨ÂºÄ„Äë</span></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/CubeyAI\"><strong>CubeyAI</strong></a> / <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1307155/wan-general-nsfw-model-fixed\">WAN General NSFW model (FIXED) </a>/<strong><span style=\"color:rgb(250, 82, 82)\"> </span></strong><span style=\"color:rgb(250, 82, 82)\">The </span><strong><span style=\"color:rgb(250, 82, 82)\">Best Universal</span></strong><span style=\"color:rgb(250, 82, 82)\"> LoRA</span></p><hr /><p>ÊòÜ‰ªë‰∏áÁª¥ÂèëÂ∏É <em>SkyReels based on</em><strong><em> Wan2.1</em></strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Skywork\"><strong>Skywork</strong></a><strong> </strong>/ SkyReels-V2-I2V-14B-720P /<strong> Image-to-Video</strong> / <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main/Skyreels\">Kijai/WanVideo_comfy</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Skywork\"><strong>Skywork</strong></a><strong> </strong>/ SkyReels-V2-I2V-14B-540P / <strong>Image-to-Video</strong> / <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main/Skyreels\">Kijai/WanVideo_comfy</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Skywork\"><strong>Skywork</strong></a><strong> </strong>/ SkyReels-V2-T2V-14B-540P /<strong> Text-to-Video</strong> / <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main/Skyreels\">Kijai/WanVideo_comfy</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Skywork\"><strong>Skywork</strong></a><strong> </strong>/ SkyReels-V2-T2V-14B-720P /<strong>Text-to-Video</strong> / <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main/Skyreels\">Kijai/WanVideo_comfy</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Skywork\"><strong>Skywork</strong></a><strong> </strong>/ SkyReels-V2-I2V-1.3B-540P /<strong> Image-to-Video</strong> / <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main/Skyreels\">Kijai/WanVideo_comfy</a></p><hr /><p><strong>Auto</strong>Regressive<strong> Diffusion</strong>-Forcing<strong> Êó†ÈôêÈïøÂ∫¶ÁîüÊàê</strong>Êû∂ÊûÑ</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Skywork\"><strong>Skywork</strong></a><strong> </strong>/ SkyReels-V2-DF-14B-720P / <strong>Text-to-Video</strong> / <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main/Skyreels\">Kijai/WanVideo_comfy</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Skywork\"><strong>Skywork</strong></a><strong> </strong>/ SkyReels-V2-DF-14B-540P /<strong> Text-to-Video</strong> / <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main/Skyreels\">Kijai/WanVideo_comfy</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Skywork\"><strong>Skywork</strong></a><strong> </strong>/ SkyReels-V2-DF-1.3B-540P /<strong> Text-to-Video</strong> / <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main/Skyreels\">Kijai/WanVideo_comfy</a></p><hr /><p>ÊòÜ‰ªë‰∏áÁª¥ÂèëÂ∏É <em>SkyReels ËßÜÈ¢ëÊ†áÊ≥®Ê®°ÂûãÔºö</em></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Skywork\"><strong>Skywork</strong></a><strong> </strong>/ SkyCaptioner-V1 <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Skywork\">Skywork (Skywork)</a> / <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Skywork/SkyCaptioner-V1\">Skywork/SkyCaptioner-V1</a></p><hr /><p>Tiny<strong> AutoEncoder</strong> / taew2_1 <strong>safetensors </strong>/ <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main/Skyreels\">Kijai/WanVideo_comfy</a></p><p>A tiny distilled VAE model for encoding images into latents and decoding latent representations into images</p><hr /><p></p><h1 id=\"wan-comfy-orgwan_2.1_comfyui_repackaged-fdujo3vl7\"><strong>WAN</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Comfy-Org\"> Comfy-Org</a>/<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged\"><strong>Wan_2.1_ComfyUI_repackaged</strong></a></h1><p></p><h2 id=\"nodeswebp-4trnxg56x\"><span style=\"color:rgb(34, 139, 230)\">„Äê‰æãÂõæÈ°µÈù¢ËìùËâ≤NodesÊàñ‰∏ãËΩΩwebpÊñá‰ª∂-ÂèØÂ§çÁé∞ËßÜÈ¢ëÂ∑•‰ΩúÊµÅ„Äë</span></h2><p><strong>Gallery </strong>sample images/videos (<strong>WEBP</strong> format) including the<strong> ComfyUI native </strong>workflow</p><p></p><p>This is a concise and clear<strong> GGUF model</strong> loading and <strong>tiled sampling </strong>workflowÔºö</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1309674?modelVersionId=1480645\">Wan 2.1 Low vram Comfy UI Workflow (GGUF) 4gb Vram - v1.1 | Wan Video Workflows | Civitai</a></p><p></p><p>ËäÇÁÇπÔºöÔºàÊàñ‰ΩøÁî® comfyui manager ÂÆâË£ÖËá™ÂÆö‰πâËäÇÁÇπÔºâ</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/city96/ComfyUI-GGUF\">https://github.com/city96/ComfyUI-GGUF</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/kijai/ComfyUI-WanVideoWrapper\">https://github.com/kijai/ComfyUI-WanVideoWrapper</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/BlenderNeko/ComfyUI_TiledKSampler\">https://github.com/BlenderNeko/ComfyUI_TiledKSampler</a></p><p></p><p>* Ê≥®ÊÑèÈúÄË¶ÅÊõ¥Êñ∞Âà∞ÊúÄÊñ∞ÁâàÊú¨ÁöÑ comfyui-<strong>KJNodes</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/kijai/ComfyUI-KJNodes\">GitHub - kijai/ComfyUI-KJNodes: Various custom nodes for ComfyUI </a><strong>update </strong>to the <strong>latest version</strong> of Comfyui <strong>KJNodes</strong></p><hr /><p></p><p></p><h1 id=\"kijai-comfyui-wrapper-nodes-for-wanvideo-z8p71be7e\"><strong>Kijai </strong>ComfyUI wrapper nodes for<strong> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Wan-Video/Wan2.1\"><strong>Wan</strong>Video</a></h1><h1 id=\"work-in-progress-orjxw3i1g\">WORK IN PROGRESS</h1><p><span data-type=\"mention\" class=\"mantine-1yiar0p\" data-id=\"mention:3318239\" data-label=\"kijaidesign\">@kijaidesign</span> 's works</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Kijai/WanVideo_comfy/tree/main\">Huggingface - Kijai/WanVideo_comfy</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/kijai/ComfyUI-WanVideoWrapper/\">GitHub - kijai/ComfyUI-WanVideoWrapper</a></p><p></p><p>‰∏ªÂõæËßÜÈ¢ëÊù•Ëá™<a target=\"_blank\" rel=\"ugc\" href=\"https://www.bilibili.com/video/BV1TKP3eVEue\"><strong> AiWood</strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.bilibili.com/video/BV1TKP3eVEue\">https://www.bilibili.com/video/BV1TKP3eVEue</a></p><p></p><p>Text encoders to <code>ComfyUI/models/text_encoders</code></p><p>Transformer to <code>ComfyUI/models/diffusion_models</code></p><p>Vae to <code>ComfyUI/models/vae</code></p><p>Right now I have only ran the I2V model succesfully.</p><p>Can't get frame counts under 81 to work, this was 512x512x81</p><p>~16GB used with 20/40 blocks offloaded</p><p></p><hr /><h1 id=\"-d69pgz314\"></h1><h1 id=\"diffsynth-studio-inference-gui-r14ja4s6i\"><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/modelscope/DiffSynth-Studio/tree/main/examples/wanvideo\">DiffSynth-Studio </a>Inference <strong>GUI</strong></h1><h1 id=\"wan-video-lora-and-finetune-training.-cdrnjo3ia\">Wan-Video <strong>LoRA</strong> &amp; Finetune <strong>training</strong>.</h1><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/modelscope/DiffSynth-Studio/tree/main/examples/wanvideo\">DiffSynth-Studio/examples/wanvideo at main ¬∑ modelscope/DiffSynth-Studio ¬∑ GitHub</a></p><p></p><p></p><hr /><p></p><p><img src=\"https://huggingface.co/Wan-AI/Wan2.1-T2V-14B/resolve/main/assets/logo.png\" /></p><p></p><p>üíú <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Wan-AI/Wan2.1-T2V-14B\"><strong><u>Wan</u></strong></a> ¬†¬† ÔΩú ¬†¬† üñ•Ô∏è <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/Wan-Video/Wan2.1\"><strong><u>GitHub</u></strong></a> ¬†¬† | ¬†¬†ü§ó <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Wan-AI/\"><strong><u>Hugging Face</u></strong></a>¬†¬† | ¬†¬†ü§ñ <a target=\"_blank\" rel=\"ugc\" href=\"https://modelscope.cn/organization/Wan-AI\"><strong><u>ModelScope</u></strong></a>¬†¬† | ¬†¬† üìë <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Wan-AI/Wan2.1-T2V-14B\"><strong><u>Paper (Coming soon)</u></strong></a> ¬†¬† | ¬†¬† üìë <a target=\"_blank\" rel=\"ugc\" href=\"https://wanxai.com/\"><strong><u>Blog</u></strong></a> ¬†¬† | ¬†¬†üí¨ <a target=\"_blank\" rel=\"ugc\" href=\"https://gw.alicdn.com/imgextra/i2/O1CN01tqjWFi1ByuyehkTSB_!!6000000000015-0-tps-611-1279.jpg\"><strong><u>WeChat Group</u></strong></a>¬†¬† | ¬†¬† üìñ <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/p5XbdQV7\"><strong><u>Discord</u></strong></a>¬†¬†</p><hr /><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Wan-AI/Wan2.1-T2V-14B/blob/main/%22%22\"><strong><u>Wan: Open and Advanced Large-Scale Video Generative Models</u></strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://modelscope.cn/learn/992?pid=991\">ÈÄö‰πâ‰∏áÁõ∏Wan2.1ËßÜÈ¢ëÊ®°ÂûãÂºÄÊ∫êÔºÅËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÊñ∞Ê†áÊùÜÔºåÊîØÊåÅ‰∏≠ÊñáÂ≠óÊïà+È´òË¥®ÈáèËßÜÈ¢ëÁîüÊàê</a></p><p>In this repository, we present <strong>Wan2.1</strong>, a comprehensive and open suite of video foundation models that pushes the boundaries of video generation. <strong>Wan2.1</strong> offers these key features:</p><ul><li><p>üëç <strong>SOTA Performance</strong>: <strong>Wan2.1</strong> consistently outperforms existing open-source models and state-of-the-art commercial solutions across multiple benchmarks.</p></li><li><p>üëç <strong>Supports Consumer-grade GPUs</strong>: The T2V-1.3B model requires only 8.19 GB VRAM, making it compatible with almost all consumer-grade GPUs. It can generate a 5-second 480P video on an RTX 4090 in about 4 minutes (without optimization techniques like quantization). Its performance is even comparable to some closed-source models.</p></li><li><p>üëç <strong>Multiple Tasks</strong>: <strong>Wan2.1</strong> excels in Text-to-Video, Image-to-Video, Video Editing, Text-to-Image, and Video-to-Audio, advancing the field of video generation.</p></li><li><p>üëç <strong>Visual Text Generation</strong>: <strong>Wan2.1</strong> is the first video model capable of generating both Chinese and English text, featuring robust text generation that enhances its practical applications.</p></li><li><p>üëç <strong>Powerful Video VAE</strong>: <strong>Wan-VAE</strong> delivers exceptional efficiency and performance, encoding and decoding 1080P videos of any length while preserving temporal information, making it an ideal foundation for video and image generation.</p></li></ul><p>This repository features our T2V-14B model, which establishes a new SOTA performance benchmark among both open-source and closed-source models. It demonstrates exceptional capabilities in generating high-quality visuals with significant motion dynamics. It is also the only video model capable of producing both Chinese and English text and supports video generation at both 480P and 720P resolutions.</p><p></p><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/33945c82-3897-41e6-b181-ccc16c32f168/width=525/33945c82-3897-41e6-b181-ccc16c32f168.jpeg\" /></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898789+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "58431",
    "prompt": "DarkSun\n<p>My models are just a mix of everything that you yourself can find on this wonderful site.<span style=\"color:rgb(60, 64, 67)\"> </span>I'm not chasing fame, I don't need your money, I just sometimes spend a few hours of my free time experimenting with my favorite models.<span style=\"color:rgb(60, 64, 67)\"> </span>The page with this model exists on this site only because once my friends asked me to share their mix.<span style=\"color:rgb(60, 64, 67)\"> </span>And because it's just damn convenient.<span style=\"color:rgb(60, 64, 67)\"> </span>Please don't accuse me of stealing someone's property.<span style=\"color:rgb(60, 64, 67)\"> </span>Considering what we're all doing here, that's a little ironic.<span style=\"color:rgb(60, 64, 67)\"> </span>In my mixes, I use such checkpoints as Luma, RevAnim, DDosmix, Perfect World, GalenaRedux, DarkSushi, CosmicBabes and so on.<span style=\"color:rgb(60, 64, 67)\"> </span>I don't even remember all the model names.<span style=\"color:rgb(60, 64, 67)\"> </span>I don't do anything that you can't do yourself.</p><p><span style=\"color:rgb(250, 176, 5)\">Try, experiment, enjoy!</span></p><p></p><p>Here is the workflow for my pictures:</p><ol><li><p>Sampler: DPM++ 2M Karras (because it runs faster on my weaker hardware, while giving a good result)</p></li><li><p>Base image size: 512x768 (because I don't have enough VRAM for more).</p></li><li><p>CFG Scale - 7. Steps - 30.</p></li><li><p>Default negative line: EasyNegative, drawn by bad-artist, sketch by bad-artist-anime, (bad_prompt:0.8), (artist name, signature, watermark:1.4), (ugly:1.2), (worst quality, poor details:1.4), bad-hands-5, badhandv4, blurry, child, loli, kids</p></li></ol><p>Then I generate 5 pictures to identify any obvious problems, after that I make another 10-20 pictures, choose the best one from them and proceed to the upscaling stage.</p><ol><li><p>I turn on the option Hires.fix</p></li><li><p>Upscale by - 2 (because I don't have enough VRAM for more)</p></li><li><p>Upscaler - 4xUltraSharp</p></li><li><p>Haires steps - 15 (half of the steps from the first stage)</p></li><li><p>Denoising strength - from 0.3 to 0.6 (the larger this value, the more detailed the picture will be, but the greater the risk of getting artifacts and distortions in those places that the neural network considers doubtful or incomprehensible)</p></li><li><p>Turn on ADetailer.<span style=\"color:rgb(60, 64, 67)\"> </span>The 1st is - face_yolov8.pt, the 2nd is the mediapipe_face_mesh_eyes_only.<span style=\"color:rgb(60, 64, 67)\"> </span>If necessary, I fill in its positive and negative lines, but more often this is simply not necessary.</p></li><li><p>PROFIT!</p></li></ol>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898799+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "251417",
    "prompt": "Midjourney mimic\n<p><span style=\"color:rgb(193, 194, 197)\">MJ52_v2.0 is a continuation of main model 1.2, they complement each other, using two versions at the same time you will get stunning results. Use v1.2 with 0.1 - 0.8 of weight and add v2.0 to additional micro details with 0.3 - 1 of weight.</span><br />best with DPM++ 2M SDE, DPM++ 3M SDE<br />LoRa mimicking midjourney slyle v5.2 <span style=\"color:rgb(189, 193, 198)\">This LoRA works as:</span><br />v.1.2 - <span style=\"color:rgb(189, 193, 198)\">Color enhancer (adds contrast and colors)</span><br />v.1.2 - <span style=\"color:rgb(189, 193, 198)\">BG depth improver (adds depth on the background)</span><br /><span style=\"color:rgb(189, 193, 198)\">v.1.2 - Composition improver (change composition)</span><br />v.2.0 - <span style=\"color:rgb(189, 193, 198)\">Detail tweaker (make little changes and supplements the picture with MICRO details) </span><br /></p><p><span style=\"color:rgb(189, 193, 198)\">CFG Scale 4 - 6. </span><br /><span style=\"color:rgb(193, 194, 197)\">Use v1.2 with 0.1 - 0.8 of weight and add v2.0 to add micro details with 0.3 - 1 of weight.</span></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898802+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  },
  {
    "id": "207101",
    "prompt": "üü°STOIQO Afrodite | FLUX, XL\n<p><span style=\"color:rgb(255, 226, 36)\">üü°:</span><strong><span style=\"color:rgb(255, 226, 36)\">Flux </span></strong><span style=\"color:rgb(255, 226, 36)\">Models </span><span style=\"color:rgb(76, 110, 245)\">üîµ:</span><strong><span style=\"color:rgb(76, 110, 245)\">SD XL</span></strong><span style=\"color:rgb(76, 110, 245)\"> Models </span><span style=\"color:rgb(250, 82, 82)\">üî¥:</span><strong><span style=\"color:rgb(250, 82, 82)\">Expired </span></strong><span style=\"color:rgb(250, 82, 82)\">Models</span></p><p><span style=\"color:rgb(255, 246, 69)\"><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/81a7a8c4-e59f-4fd3-adc9-8411ff8209a1/width=525/81a7a8c4-e59f-4fd3-adc9-8411ff8209a1.jpeg\" /></span>üü° <strong>STOIQO Afrodite</strong> is a specialized model designed to generate high-quality adult photography content. It allows users to create realistic and explicit images with a strong emphasis on fine details and authentic textures. Perfect for those seeking precision in the adult photography space, it provides creators with the ultimate tool to produce high-end explicit visual content.</p><h1 id=\"versions-and-recommended-settings:-li1oolja6\"><strong><span style=\"color:rgb(255, 246, 69)\">Versions and Recommended Settings:</span></strong></h1><p><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/466d3ebe-9150-4ac4-bab8-89353e0b6c62/width=525/466d3ebe-9150-4ac4-bab8-89353e0b6c62.jpeg\" /></p><ul><li><p><strong>MAIN <span style=\"color:rgb(76, 110, 245)\">SAMPLER:</span><span style=\"color:rgb(130, 201, 30)\"> Euler</span>+ <span style=\"color:rgb(130, 201, 30)\">Beta</span></strong></p></li><li><p><strong><span style=\"color:rgb(130, 201, 30)\">GUIDANCE </span></strong>(In Forge:'<span style=\"color:rgb(130, 201, 30)\">Distilled CFG Scale</span>')<strong>:<span style=\"color:rgb(250, 176, 5)\"> </span><span style=\"color:rgb(130, 201, 30)\">2</span>+ | <span style=\"color:rgb(250, 176, 5)\">STEPS</span>:<span style=\"color:rgb(250, 176, 5)\"> 15</span>+</strong></p></li><li><p><strong>(<span style=\"color:rgb(250, 82, 82)\">Recommended</span>)<span style=\"color:rgb(76, 110, 245)\">: </span><span style=\"color:rgb(130, 201, 30)\">GUIDANCE</span>: <span style=\"color:rgb(130, 201, 30)\">3.5</span> | <span style=\"color:rgb(250, 176, 5)\">STEPS</span>: <span style=\"color:rgb(250, 176, 5)\">25</span></strong></p></li></ul><p>We finally got to the release of the flux.1 Dev version of <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/207101\"><strong>Afrodite</strong></a>. As for <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/161068\"><strong>NewReality</strong> </a>we are still in an experimental Alpha version, which still has many problems, but which I will be able to intervene thanks to your feedback.</p><p>The <strong>Main Download (Full 11GB)</strong> is the version containing only the Unet, so you can use it accompanied by the clips of your choice, depending on whether you prefer the fp8, the fp16 or want to experiment with new clip_l or t5.</p><p>In the file section of the sidebar you can instead find the <strong>Secondary Download (Pruned 20GB)</strong> of the AIO version with t5xxl_fp16, clip_l and VAE already included.</p><p>The <strong>Full/Pruned nomenclature</strong> is just to be able to keep the Unet as the main download. All the others change with the AIO as the main. The two models are composed as mentioned above.</p><p><strong><img src=\"https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/882afcd7-a2e5-4526-b5dc-75c77e5340db/width=525/882afcd7-a2e5-4526-b5dc-75c77e5340db.jpeg\" /><span style=\"color:rgb(253, 126, 20)\">Refiner </span>is <span style=\"color:rgb(253, 126, 20)\">unnecessary</span> and <span style=\"color:rgb(250, 176, 5)\">Clip </span>and <span style=\"color:rgb(250, 82, 82)\">VAE </span>are <span style=\"color:rgb(250, 82, 82)\">included</span></strong></p><ul><li><p><strong>MAIN <span style=\"color:rgb(76, 110, 245)\">SAMPLER:</span><span style=\"color:rgb(130, 201, 30)\"> dpmpp_3m_sde </span>+ <span style=\"color:rgb(130, 201, 30)\">exponential</span></strong></p></li><li><p><strong><span style=\"color:rgb(130, 201, 30)\">CFG</span>: <span style=\"color:rgb(130, 201, 30)\">2</span>+ | <span style=\"color:rgb(250, 176, 5)\">STEPS</span>: <span style=\"color:rgb(250, 176, 5)\">16</span>+</strong></p></li><li><p><strong>(<span style=\"color:rgb(250, 82, 82)\">Recommended</span>)<span style=\"color:rgb(76, 110, 245)\">: </span><span style=\"color:rgb(130, 201, 30)\">CFG</span>: <span style=\"color:rgb(130, 201, 30)\">4</span> | <span style=\"color:rgb(250, 176, 5)\">STEPS</span>: <span style=\"color:rgb(250, 176, 5)\">25</span></strong></p></li></ul><h1 id=\"credits:-xnudnotm4\"><strong><span style=\"color:rgb(255, 219, 77)\">Credits:</span></strong></h1><p><strong>Afrodite </strong>is the result of countless hours of work, involving several hundred iterations through training, merging of models and LoRAs, fine-tuning specific blocks or captions, as well as performing additive and subtractive merges. Due to the complexity of this process, it is difficult to provide a precise, step-by-step account of every decision and experiment. However, each phase has played a significant role in shaping the final product, whether by direct influence or through valuable lessons learned along the way.</p><p>Given the intricacies and challenges involved, I want to extend my heartfelt gratitude to the creators of the models that have contributed to this journey, either directly or indirectly. Regardless of whether they were incorporated into the final iteration, their work provided inspiration, insight, and progress throughout the project.</p><p>To all the creators whose models supported this endeavor, I extend my deepest thanks. I encourage everyone to explore and support their work, as it deserves recognition for the incredible value it brings to the community.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/EauDeNoire\"><strong><u><span style=\"color:rgb(250, 176, 5)\">EauDeNoire</span></u></strong></a><strong><span style=\"color:rgb(250, 176, 5)\"> </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/humblemikey\"><strong><u><span style=\"color:rgb(76, 110, 245)\">humblemikey</span></u></strong></a><strong><span style=\"color:rgb(76, 110, 245)\"> </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/socalguitarist\"><strong><u><span style=\"color:rgb(130, 201, 30)\">socalguitarist</span></u></strong></a><strong><span style=\"color:rgb(130, 201, 30)\"> </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/ZyloO\"><strong><u><span style=\"color:rgb(250, 176, 5)\">ZyloO</span></u></strong></a><strong><span style=\"color:rgb(250, 176, 5)\"> </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/xlabs_ai\"><strong><u><span style=\"color:rgb(250, 82, 82)\">xlabs_ai</span></u></strong></a><strong><span style=\"color:rgb(250, 82, 82)\"> </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/aramintastudio\"><strong><u><span style=\"color:rgb(190, 75, 219)\">aramintastudio</span></u></strong></a><strong><span style=\"color:rgb(190, 75, 219)\"> </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Seeker70\"><strong><u><span style=\"color:rgb(76, 110, 245)\">Seeker70</span></u></strong></a><strong><span style=\"color:rgb(76, 110, 245)\"> </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Ai_Art_Vision\"><strong><u><span style=\"color:rgb(250, 176, 5)\">Ai_Art_Vision</span></u></strong></a><strong><span style=\"color:rgb(250, 176, 5)\"> </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/PromptoAI\"><strong><u><span style=\"color:rgb(190, 75, 219)\">PromptoAI</span></u></strong></a><strong><span style=\"color:rgb(190, 75, 219)\"> </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/alvdansen\"><strong><u><span style=\"color:rgb(250, 82, 82)\">alvdansen</span></u></strong></a><strong><span style=\"color:rgb(250, 82, 82)\"> </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/aip0pp\"><strong><u><span style=\"color:rgb(76, 110, 245)\">aip0pp</span></u></strong></a><strong><span style=\"color:rgb(76, 110, 245)\"> </span></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/SG_161222\"><strong><u><span style=\"color:rgb(250, 176, 5)\">SG_161222</span></u></strong></a></p><p><strong>WORK IN PROGRESS...</strong></p>",
    "meta": {
      "source": "civitai",
      "collected_at": "2025-09-14T16:35:14.898810+00:00",
      "schema_version": "raw.v1"
    },
    "extra": {}
  }
]